/opt/anaconda3/envs/py3_8/bin/python3.8 /Users/jas0n/PycharmProjects/scipy_sparse/main.py
in the movie-100k datasets, there are 943 users and 1682 items !
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.0450000000000017
  (0, 1680)	3.0450000000000017
  (0, 1679)	3.0446951345999964
  (0, 1678)	3.0450000000000017
  (0, 1677)	3.0443902692000018
  (0, 1676)	3.0450000000000017
  (0, 1675)	3.0450000000000017
  (0, 1674)	3.0450000000000017
  (0, 1673)	3.0450000000000017
  (0, 1672)	3.0450000000000017
  (0, 1671)	3.0443909391000004
  (0, 1670)	3.0450000000000017
  (0, 1669)	3.0450000000000017
  (0, 1668)	3.04469680935
  (0, 1667)	3.0450000000000017
  (0, 1666)	3.0450000000000017
  (0, 1665)	3.04469680935
  (0, 1664)	3.0450000000000017
  (0, 1663)	3.044697235649996
  (0, 1662)	3.04469680935
  (0, 1661)	3.0446939470500016
  (0, 1660)	3.0443867370000026
  (0, 1659)	3.0446889228000025
  (0, 1658)	3.0450000000000017
  (0, 1657)	3.0450032581500013
  :	:
  (942, 24)	3.0438989919090003
  (942, 23)	3.0294615343499993
  (942, 22)	3.058799217615003
  (942, 21)	3.093740213498998
  (942, 20)	3.0030011009820003
  (942, 19)	3.0178990400760037
  (942, 18)	3.0229618698270015
  (942, 17)	3.008149046856001
  (942, 16)	3.0105450852750013
  (942, 15)	3.0114868083749986
  (942, 14)	3.064209070824002
  (942, 13)	3.052458412452003
  (942, 12)	3.026071632060005
  (942, 11)	3.0998071367009956
  (942, 10)	3.059837489897999
  (942, 9)	3.0251655018810037
  (942, 8)	3.067617476618996
  (942, 7)	3.067736831747998
  (942, 6)	3.0855211972740033
  (942, 5)	3.013295127335998
  (942, 4)	3.0145093483950007
  (942, 3)	3.036462779250004
  (942, 2)	3.0085171913879996
  (942, 1)	3.014007557409
  (942, 0)	3.1025200514040048
this is the 0 epoch
rmse loss on training set is 1.2063915161997822
rmse loss on test set is 1.2010729537827483
for this epoch using 74.23811507225037 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.085304364218083
  (0, 1680)	3.0853090223132598
  (0, 1679)	3.0846891100754674
  (0, 1678)	3.08530716991735
  (0, 1677)	3.0840710502335886
  (0, 1676)	3.085305022279306
  (0, 1675)	3.0853082832237377
  (0, 1674)	3.0853082832237377
  (0, 1673)	3.0853082832237377
  (0, 1672)	3.085301524683742
  (0, 1671)	3.0840742753749146
  (0, 1670)	3.0853082832237377
  (0, 1669)	3.0853082832237377
  (0, 1668)	3.0846992018433546
  (0, 1667)	3.0853082832237377
  (0, 1666)	3.0853082832237377
  (0, 1665)	3.0846992018433546
  (0, 1664)	3.0853082832237377
  (0, 1663)	3.0846903950840114
  (0, 1662)	3.0846992018433546
  (0, 1661)	3.0846903181330547
  (0, 1660)	3.0840551524922533
  (0, 1659)	3.0846510141562695
  (0, 1658)	3.0853082832237377
  (0, 1657)	3.085315706790292
  :	:
  (942, 24)	3.083728577281564
  (942, 23)	3.0570291791872037
  (942, 22)	3.114484884336654
  (942, 21)	3.1801402046299843
  (942, 20)	3.0052605116775086
  (942, 19)	3.035042110665163
  (942, 18)	3.0452123119786525
  (942, 17)	3.015915281381232
  (942, 16)	3.0202297786246173
  (942, 15)	3.0224668926194016
  (942, 14)	3.1231491734446046
  (942, 13)	3.102179152585281
  (942, 12)	3.050160637309658
  (942, 11)	3.192566451626287
  (942, 10)	3.115540770661858
  (942, 9)	3.049332310688223
  (942, 8)	3.1303998580506347
  (942, 7)	3.1310818060625034
  (942, 6)	3.1622639196882063
  (942, 5)	3.0262099155769824
  (942, 4)	3.0281149129897766
  (942, 3)	3.0700518115886126
  (942, 2)	3.0162401857569914
  (942, 1)	3.026884042569661
  (942, 0)	3.1935386807844854
this is the 1 epoch
rmse loss on training set is 1.172321100186055
rmse loss on test set is 1.1719889481515184
for this epoch using 74.32602906227112 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.121202576951276
  (0, 1680)	3.1212167134733124
  (0, 1679)	3.120272648932376
  (0, 1678)	3.1212108994527625
  (0, 1677)	3.1193343984119934
  (0, 1676)	3.1212046884674884
  (0, 1675)	3.121214220852429
  (0, 1674)	3.121214220852429
  (0, 1673)	3.121214220852429
  (0, 1672)	3.1211938637271124
  (0, 1671)	3.1193424949687705
  (0, 1670)	3.121214220852429
  (0, 1669)	3.121214220852429
  (0, 1668)	3.1202978650860578
  (0, 1667)	3.121214220852429
  (0, 1666)	3.121214220852429
  (0, 1665)	3.1202978650860578
  (0, 1664)	3.121214220852429
  (0, 1663)	3.120270372268623
  (0, 1662)	3.1202978650860578
  (0, 1661)	3.1202798295068153
  (0, 1660)	3.119297670125309
  (0, 1659)	3.120177459303537
  (0, 1658)	3.121214220852429
  (0, 1657)	3.1212268732336166
  :	:
  (942, 24)	3.1197662845159995
  (942, 23)	3.082786917241021
  (942, 22)	3.1671357727606377
  (942, 21)	3.259560176264164
  (942, 20)	3.0068334474609757
  (942, 19)	3.051446503971511
  (942, 18)	3.06675901311426
  (942, 17)	3.0233012260537713
  (942, 16)	3.029114862265153
  (942, 15)	3.032952523655659
  (942, 14)	3.177136375418671
  (942, 13)	3.1492342271321143
  (942, 12)	3.0723750472115463
  (942, 11)	3.2785555951054817
  (942, 10)	3.16727420553647
  (942, 9)	3.0725228656486285
  (942, 8)	3.188568569005556
  (942, 7)	3.1901804288560593
  (942, 6)	3.230922145986213
  (942, 5)	3.038744599629888
  (942, 4)	3.0408627220281264
  (942, 3)	3.1009150048431526
  (942, 2)	3.0232185315418545
  (942, 1)	3.038694583917086
  (942, 0)	3.2740670401064227
this is the 2 epoch
rmse loss on training set is 1.143398442443687
rmse loss on test set is 1.1470484011341036
for this epoch using 75.47107982635498 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.153004742274572
  (0, 1680)	3.1530332794945863
  (0, 1679)	3.1517569437631736
  (0, 1678)	3.1530211705673943
  (0, 1677)	3.150492716958953
  (0, 1676)	3.1530092304958126
  (0, 1675)	3.1530277669990667
  (0, 1674)	3.1530277669990667
  (0, 1673)	3.1530277669990667
  (0, 1672)	3.1529869580436842
  (0, 1671)	3.150508392264012
  (0, 1670)	3.1530277669990667
  (0, 1669)	3.1530277669990667
  (0, 1668)	3.1518038982620395
  (0, 1667)	3.1530277669990667
  (0, 1666)	3.1530277669990667
  (0, 1665)	3.1518038982620395
  (0, 1664)	3.1530277669990667
  (0, 1663)	3.151748562461543
  (0, 1662)	3.1518038982620395
  (0, 1661)	3.1517736365936893
  (0, 1660)	3.150427143554284
  (0, 1659)	3.1515802548467478
  (0, 1658)	3.1530277669990667
  (0, 1657)	3.1530468590169596
  :	:
  (942, 24)	3.1522989209007144
  (942, 23)	3.106829896467291
  (942, 22)	3.216854852485795
  (942, 21)	3.332396251118468
  (942, 20)	3.007779097064815
  (942, 19)	3.0671375850728
  (942, 18)	3.087617492463907
  (942, 17)	3.030315844439292
  (942, 16)	3.0372631394034677
  (942, 15)	3.042961861525861
  (942, 14)	3.2264987433802506
  (942, 13)	3.1937141180546242
  (942, 12)	3.092832971777715
  (942, 11)	3.358095891396351
  (942, 10)	3.2152296323971488
  (942, 9)	3.0947699854909176
  (942, 8)	3.2423669013704917
  (942, 7)	3.2452098028092835
  (942, 6)	3.2921862566276983
  (942, 5)	3.050905881570067
  (942, 4)	3.0528061459339746
  (942, 3)	3.1292186459716858
  (942, 2)	3.029507418372808
  (942, 1)	3.0495140343639826
  (942, 0)	3.345093084527419
this is the 3 epoch
rmse loss on training set is 1.1188866445994714
rmse loss on test set is 1.125676027746476
for this epoch using 75.0919599533081 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.181030693529492
  (0, 1680)	3.1810786008014738
  (0, 1679)	3.1794627691849704
  (0, 1678)	3.1810576748802393
  (0, 1677)	3.177867863489701
  (0, 1676)	3.181038597877378
  (0, 1675)	3.1810685784096275
  (0, 1674)	3.1810685784096275
  (0, 1673)	3.1810685784096275
  (0, 1672)	3.1810005077692325
  (0, 1671)	3.177894170853629
  (0, 1670)	3.1810685784096275
  (0, 1669)	3.1810685784096275
  (0, 1668)	3.1795379348902086
  (0, 1667)	3.1810685784096275
  (0, 1666)	3.1810685784096275
  (0, 1665)	3.1795379348902086
  (0, 1664)	3.1810685784096275
  (0, 1663)	3.1794459624088893
  (0, 1662)	3.1795379348902086
  (0, 1661)	3.179492451463805
  (0, 1660)	3.1777659372226386
  (0, 1659)	3.179181247411961
  (0, 1658)	3.1810685784096275
  (0, 1657)	3.181095456353411
  :	:
  (942, 24)	3.1816145270505487
  (942, 23)	3.12925983581523
  (942, 22)	3.263762289827454
  (942, 21)	3.399066078341108
  (942, 20)	3.0081579590816196
  (942, 19)	3.082146314831214
  (942, 18)	3.1078089064076275
  (942, 17)	3.036972650711833
  (942, 16)	3.0447373694057824
  (942, 15)	3.052517026692382
  (942, 14)	3.2715678576313425
  (942, 13)	3.235722678173492
  (942, 12)	3.1116576495565433
  (942, 11)	3.4315382157203307
  (942, 10)	3.259616866599479
  (942, 9)	3.116113518492719
  (942, 8)	3.2920516209397785
  (942, 7)	3.2963691269186257
  (942, 6)	3.346729857174628
  (942, 5)	3.062705120724633
  (942, 4)	3.0640022247794056
  (942, 3)	3.155139263132201
  (942, 2)	3.035164645823118
  (942, 1)	3.0594219818322235
  (942, 0)	3.4075659986392264
this is the 4 epoch
rmse loss on training set is 1.098122191109791
rmse loss on test set is 1.1073551337633012
for this epoch using 75.59468913078308 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2056010537874937
  (0, 1680)	3.2056732989819796
  (0, 1679)	3.2037115491905226
  (0, 1678)	3.205640881025507
  (0, 1677)	3.2017822173555266
  (0, 1676)	3.2056135167352795
  (0, 1675)	3.2056570838493212
  (0, 1674)	3.2056570838493212
  (0, 1673)	3.2056570838493212
  (0, 1672)	3.205555030555279
  (0, 1671)	3.2018225082219907
  (0, 1670)	3.2056570838493212
  (0, 1669)	3.2056570838493212
  (0, 1668)	3.203821220395582
  (0, 1667)	3.2056570838493212
  (0, 1666)	3.2056570838493212
  (0, 1665)	3.203821220395582
  (0, 1664)	3.2056570838493212
  (0, 1663)	3.203684227847336
  (0, 1662)	3.203821220395582
  (0, 1661)	3.2037576154538994
  (0, 1660)	3.2016369713919146
  (0, 1659)	3.2033031319374117
  (0, 1658)	3.2056570838493212
  (0, 1657)	3.205693215468018
  :	:
  (942, 24)	3.207995939267876
  (942, 23)	3.150181310459899
  (942, 22)	3.3079895735101887
  (942, 21)	3.45999660629399
  (942, 20)	3.008029842824578
  (942, 19)	3.096507215869602
  (942, 18)	3.1273582344591784
  (942, 17)	3.0432881836685928
  (942, 16)	3.0515987091218837
  (942, 15)	3.061642557057764
  (942, 14)	3.3126718661109056
  (942, 13)	3.2753727172268707
  (942, 12)	3.1289734898163553
  (942, 11)	3.499250773467317
  (942, 10)	3.30065575956151
  (942, 9)	3.136597631474396
  (942, 8)	3.3378857903696453
  (942, 7)	3.343871574404191
  (942, 6)	3.3951995090359293
  (942, 5)	3.074156860980028
  (942, 4)	3.074508974618666
  (942, 3)	3.1788571406248707
  (942, 2)	3.0402483117920154
  (942, 1)	3.0684990625139035
  (942, 0)	3.4623845073865906
this is the 5 epoch
rmse loss on training set is 1.0805186677036815
rmse loss on test set is 1.0916292271866614
for this epoch using 75.02155113220215 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2270301841777815
  (0, 1680)	3.2271316917820423
  (0, 1679)	3.224818315397781
  (0, 1678)	3.227084988777035
  (0, 1677)	3.2225516420185243
  (0, 1676)	3.227048437381434
  (0, 1675)	3.22710743995785
  (0, 1674)	3.22710743995785
  (0, 1673)	3.22710743995785
  (0, 1672)	3.226964807319786
  (0, 1671)	3.2226095177723844
  (0, 1670)	3.22710743995785
  (0, 1669)	3.22710743995785
  (0, 1668)	3.2249685796575718
  (0, 1667)	3.22710743995785
  (0, 1666)	3.22710743995785
  (0, 1665)	3.2249685796575718
  (0, 1664)	3.22710743995785
  (0, 1663)	3.2247786238194296
  (0, 1662)	3.2249685796575718
  (0, 1661)	3.2248840622348434
  (0, 1660)	3.2223566658616827
  (0, 1659)	3.2242623475708565
  (0, 1658)	3.22710743995785
  (0, 1657)	3.227154399407012
  :	:
  (942, 24)	3.2317158730219635
  (942, 23)	3.1696988458918236
  (942, 22)	3.349674697400174
  (942, 21)	3.5156140709591557
  (942, 20)	3.0074524307140247
  (942, 19)	3.1102567432998716
  (942, 18)	3.1462928143150606
  (942, 17)	3.0492808014689348
  (942, 16)	3.0579055941870448
  (942, 15)	3.0703642030310827
  (942, 14)	3.3501300373870397
  (942, 13)	3.312782292346284
  (942, 12)	3.1449030205630124
  (942, 11)	3.5616088824400145
  (942, 10)	3.33856974850746
  (942, 9)	3.1562686743675514
  (942, 8)	3.3801328475426398
  (942, 7)	3.387937538220531
  (942, 6)	3.4382072261188052
  (942, 5)	3.085277656623171
  (942, 4)	3.0843834674501456
  (942, 3)	3.200551308504897
  (942, 2)	3.0448151168210815
  (942, 1)	3.0768243217587754
  (942, 0)	3.510388827043969
this is the 6 epoch
rmse loss on training set is 1.065566251354296
rmse loss on test set is 1.0781006961573587
for this epoch using 75.08987307548523 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.245620863714516
  (0, 1680)	3.245756479599902
  (0, 1679)	3.243086398641555
  (0, 1678)	3.2456926135845103
  (0, 1677)	3.240480183698608
  (0, 1676)	3.245646213970588
  (0, 1675)	3.245722217219443
  (0, 1674)	3.245722217219443
  (0, 1673)	3.245722217219443
  (0, 1672)	3.245532559303556
  (0, 1671)	3.24055944890697
  (0, 1670)	3.245722217219443
  (0, 1669)	3.245722217219443
  (0, 1668)	3.2432831167982394
  (0, 1667)	3.245722217219443
  (0, 1666)	3.245722217219443
  (0, 1665)	3.2432831167982394
  (0, 1664)	3.245722217219443
  (0, 1663)	3.243032710135617
  (0, 1662)	3.2432831167982394
  (0, 1661)	3.243175013671602
  (0, 1660)	3.2402296235874384
  (0, 1659)	3.242363715004925
  (0, 1658)	3.245722217219443
  (0, 1657)	3.2457816697607877
  :	:
  (942, 24)	3.253033373733165
  (942, 23)	3.1879147266308845
  (942, 22)	3.3889583038715805
  (942, 21)	3.5663361033307015
  (942, 20)	3.0064803012630867
  (942, 19)	3.1234320135349987
  (942, 18)	3.1646411865879243
  (942, 17)	3.0549697516860483
  (942, 16)	3.063712989048811
  (942, 15)	3.078708011256655
  (942, 14)	3.384248692109653
  (942, 13)	3.348071675466447
  (942, 12)	3.1595646314575387
  (942, 11)	3.618986712344935
  (942, 10)	3.373580776116531
  (942, 9)	3.1751735462681574
  (942, 8)	3.4190518935216225
  (942, 7)	3.42878916895859
  (942, 6)	3.4763254518169147
  (942, 5)	3.096085156178698
  (942, 4)	3.0936805156188085
  (942, 3)	3.2203958099602237
  (942, 2)	3.0489191795799075
  (942, 1)	3.084473404104611
  (942, 0)	3.552355829555747
this is the 7 epoch
rmse loss on training set is 1.0528279199736352
rmse loss on test set is 1.0664273399307156
for this epoch using 75.3877899646759 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.261660490337343
  (0, 1680)	3.2618349529161934
  (0, 1679)	3.2588036426631053
  (0, 1678)	3.2617509913084333
  (0, 1677)	3.2558562940177675
  (0, 1676)	3.261694305825436
  (0, 1675)	3.2617886058518515
  (0, 1674)	3.2617886058518515
  (0, 1673)	3.2617886058518515
  (0, 1672)	3.261545646312382
  (0, 1671)	3.255960912383211
  (0, 1670)	3.2617886058518515
  (0, 1669)	3.2617886058518515
  (0, 1668)	3.2590524358973854
  (0, 1667)	3.2617886058518515
  (0, 1666)	3.2617886058518515
  (0, 1665)	3.2590524358973854
  (0, 1664)	3.2617886058518515
  (0, 1663)	3.258734550547488
  (0, 1662)	3.2590524358973854
  (0, 1661)	3.2589181971896646
  (0, 1660)	3.2555448416744963
  (0, 1659)	3.2578966045225197
  (0, 1658)	3.2617886058518515
  (0, 1657)	3.2618622929076597
  :	:
  (942, 24)	3.2721914455831285
  (942, 23)	3.204927414975443
  (942, 22)	3.4259806752543702
  (942, 21)	3.6125657649550953
  (942, 20)	3.005164319078217
  (942, 19)	3.136069841075789
  (942, 18)	3.1824322068547253
  (942, 17)	3.0603744723048347
  (942, 16)	3.0690719356845686
  (942, 15)	3.086699648973042
  (942, 14)	3.415318346083202
  (942, 13)	3.3813609427436213
  (942, 12)	3.173070990729678
  (942, 11)	3.6717508375998906
  (942, 10)	3.405905424582611
  (942, 9)	3.193358485744675
  (942, 8)	3.454894088522686
  (942, 7)	3.4666460871819464
  (942, 6)	3.5100841552694932
  (942, 5)	3.106597404287736
  (942, 4)	3.1024518216187906
  (942, 3)	3.2385570455545802
  (942, 2)	3.0526112643366408
  (942, 1)	3.0915173875974036
  (942, 0)	3.5889969046623444
this is the 8 epoch
rmse loss on training set is 1.04193346143568
rmse loss on test set is 1.056317537074317
for this epoch using 75.19831800460815 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.275418570151285
  (0, 1680)	3.2756364874564636
  (0, 1679)	3.2722399061518193
  (0, 1678)	3.2755294702497544
  (0, 1677)	3.2689503420538832
  (0, 1676)	3.2754622673042406
  (0, 1675)	3.275575908737836
  (0, 1674)	3.275575908737836
  (0, 1673)	3.275575908737836
  (0, 1672)	3.2752735532520765
  (0, 1671)	3.2690843959216336
  (0, 1670)	3.275575908737836
  (0, 1669)	3.275575908737836
  (0, 1668)	3.2725461489019843
  (0, 1667)	3.275575908737836
  (0, 1666)	3.275575908737836
  (0, 1665)	3.2725461489019843
  (0, 1664)	3.275575908737836
  (0, 1663)	3.272154211655408
  (0, 1662)	3.2725461489019843
  (0, 1661)	3.2723833509037386
  (0, 1660)	3.2685732147879225
  (0, 1659)	3.2711324008798166
  (0, 1658)	3.275575908737836
  (0, 1657)	3.2756656337259047
  :	:
  (942, 24)	3.289415657905303
  (942, 23)	3.2208304747818777
  (942, 22)	3.46087945478361
  (942, 21)	3.6546872693390173
  (942, 20)	3.0035513088968084
  (942, 19)	3.148206033525924
  (942, 18)	3.199694382836315
  (942, 17)	3.0655140823006297
  (942, 16)	3.074029336360556
  (942, 15)	3.0943639244771286
  (942, 14)	3.443611878402473
  (942, 13)	3.4127681154712803
  (942, 12)	3.185528016052854
  (942, 11)	3.720255402182237
  (942, 10)	3.435752093393968
  (942, 9)	3.210868210612827
  (942, 8)	3.487900023003393
  (942, 7)	3.501722128630981
  (942, 6)	3.5399696620846903
  (942, 5)	3.1168323240637297
  (942, 4)	3.1107454799942302
  (942, 3)	3.255192001212735
  (942, 2)	3.0559383310389636
  (942, 1)	3.0980221085077293
  (942, 0)	3.6209579842127817
this is the 9 epoch
rmse loss on training set is 1.032572274402057
rmse loss on test set is 1.0475247242791557
for this epoch using 74.76842308044434 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.287145261787107
  (0, 1680)	3.2874110938923433
  (0, 1679)	3.2836456195315815
  (0, 1678)	3.2872780575223124
  (0, 1677)	3.2800131815408475
  (0, 1676)	3.2872002930287376
  (0, 1675)	3.2873340884796316
  (0, 1674)	3.2873340884796316
  (0, 1673)	3.2873340884796316
  (0, 1672)	3.286966431959309
  (0, 1671)	3.2801808354390856
  (0, 1670)	3.2873340884796316
  (0, 1669)	3.2873340884796316
  (0, 1668)	3.2840144371914914
  (0, 1667)	3.2873340884796316
  (0, 1666)	3.2873340884796316
  (0, 1665)	3.2840144371914914
  (0, 1664)	3.2873340884796316
  (0, 1663)	3.283542317701798
  (0, 1662)	3.2840144371914914
  (0, 1661)	3.2838207829325388
  (0, 1660)	3.2795660962841926
  (0, 1659)	3.282323030857561
  (0, 1658)	3.2873340884796316
  (0, 1657)	3.287441703705629
  :	:
  (942, 24)	3.304913534615733
  (942, 23)	3.235711901571598
  (942, 22)	3.493787980383822
  (942, 21)	3.6930631280515342
  (942, 20)	3.001683942754529
  (942, 19)	3.1598748980942855
  (942, 18)	3.216455396946988
  (942, 17)	3.070407024656856
  (942, 16)	3.0786279135226695
  (942, 15)	3.1017244639676815
  (942, 14)	3.4693835374771447
  (942, 13)	3.4424077756137157
  (942, 12)	3.1970342874513573
  (942, 11)	3.764838669577913
  (942, 10)	3.463319049503211
  (942, 9)	3.2277453384772876
  (942, 8)	3.5182979184070766
  (942, 7)	3.5342229723688283
  (942, 6)	3.5664248466512998
  (942, 5)	3.1268073459182792
  (942, 4)	3.1186057400927556
  (942, 3)	3.2704471827488466
  (942, 2)	3.058943330609905
  (942, 1)	3.1040478505985454
  (942, 0)	3.64882121935513
this is the 10 epoch
rmse loss on training set is 1.0244857570427506
rmse loss on test set is 1.0398417038451973
for this epoch using 74.88343596458435 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2970707576914937
  (0, 1680)	3.2973888038361485
  (0, 1679)	3.2932511779442137
  (0, 1678)	3.297226801707703
  (0, 1677)	3.289275554180728
  (0, 1676)	3.29713860019316
  (0, 1675)	3.297293150549735
  (0, 1674)	3.297293150549735
  (0, 1673)	3.297293150549735
  (0, 1672)	3.296854480187099
  (0, 1671)	3.2894810225883035
  (0, 1670)	3.297293150549735
  (0, 1669)	3.297293150549735
  (0, 1668)	3.2936874483544747
  (0, 1667)	3.297293150549735
  (0, 1666)	3.297293150549735
  (0, 1665)	3.2936874483544747
  (0, 1664)	3.297293150549735
  (0, 1663)	3.293129442472464
  (0, 1662)	3.2936874483544747
  (0, 1661)	3.2934607664019397
  (0, 1660)	3.2887546975894892
  (0, 1659)	3.2917003341116353
  (0, 1658)	3.297293150549735
  (0, 1657)	3.297420545313729
  :	:
  (942, 24)	3.318874548811806
  (942, 23)	3.2496537705417823
  (942, 22)	3.524834122085751
  (942, 21)	3.728032464340254
  (942, 20)	2.9996007815782137
  (942, 19)	3.1711089174599802
  (942, 18)	3.232741778256182
  (942, 17)	3.0750708294959868
  (942, 16)	3.0829062986142017
  (942, 15)	3.1088035104239022
  (942, 14)	3.4928686096425516
  (942, 13)	3.470390079331082
  (942, 12)	3.207680802611808
  (942, 11)	3.805820728023351
  (942, 10)	3.4887931879859995
  (942, 9)	3.244030027443684
  (942, 8)	3.5463025128860552
  (942, 7)	3.5643445046917024
  (942, 6)	3.5898503470968453
  (942, 5)	3.1365391530122184
  (942, 4)	3.1260729571980246
  (942, 3)	3.284458100386817
  (942, 2)	3.0616651806384896
  (942, 1)	3.1096492979293457
  (942, 0)	3.6731078551342438
this is the 11 epoch
rmse loss on training set is 1.017459854148366
rmse loss on test set is 1.0330951404510385
for this epoch using 74.77206087112427 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.305405307693815
  (0, 1680)	3.305779697465995
  (0, 1679)	3.3012669755585415
  (0, 1678)	3.3055858172627888
  (0, 1677)	3.2969481338542894
  (0, 1676)	3.3054874532288268
  (0, 1675)	3.305663168040746
  (0, 1674)	3.305663168040746
  (0, 1673)	3.305663168040746
  (0, 1672)	3.305147963115829
  (0, 1671)	3.2971956531759714
  (0, 1670)	3.305663168040746
  (0, 1669)	3.305663168040746
  (0, 1668)	3.3017753334246676
  (0, 1667)	3.305663168040746
  (0, 1666)	3.305663168040746
  (0, 1665)	3.3017753334246676
  (0, 1664)	3.305663168040746
  (0, 1663)	3.3011261432261243
  (0, 1662)	3.3017753334246676
  (0, 1661)	3.3015135753241487
  (0, 1660)	3.296350130192249
  (0, 1659)	3.2994760815042263
  (0, 1658)	3.305663168040746
  (0, 1657)	3.3058122580222675
  :	:
  (942, 24)	3.3314705670734575
  (942, 23)	3.2627321261896385
  (942, 22)	3.554139524714677
  (942, 21)	3.7599102557074775
  (942, 20)	2.997336423957274
  (942, 19)	3.1819385582753106
  (942, 18)	3.2485786923986684
  (942, 17)	3.0795219699247793
  (942, 16)	3.0868992103121053
  (942, 15)	3.115621815608782
  (942, 14)	3.514283594087791
  (942, 13)	3.4968200964735243
  (942, 12)	3.21755098913083
  (942, 11)	3.843502133431458
  (942, 10)	3.5123493568652613
  (942, 9)	3.2597597852761733
  (942, 8)	3.572114496754358
  (942, 7)	3.5922717817125025
  (942, 6)	3.6106065092669906
  (942, 5)	3.1460435178176263
  (942, 4)	3.133183675345712
  (942, 3)	3.29734916928886
  (942, 2)	3.0641388687419506
  (942, 1)	3.1148756716255668
  (942, 0)	3.694281914100217
this is the 12 epoch
rmse loss on training set is 1.0113181262015039
rmse loss on test set is 1.0271404713790275
for this epoch using 76.95098757743835 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3123397176342277
  (0, 1680)	3.312774405588053
  (0, 1679)	3.307883913877368
  (0, 1678)	3.312545783576048
  (0, 1677)	3.303222044178683
  (0, 1676)	3.312437663552757
  (0, 1675)	3.312634780940414
  (0, 1674)	3.312634780940414
  (0, 1673)	3.312634780940414
  (0, 1672)	3.312037710180051
  (0, 1671)	3.3035158487572156
  (0, 1670)	3.312634780940414
  (0, 1669)	3.312634780940414
  (0, 1668)	3.3084687573733835
  (0, 1667)	3.312634780940414
  (0, 1666)	3.312634780940414
  (0, 1665)	3.3084687573733835
  (0, 1664)	3.312634780940414
  (0, 1663)	3.307723469145235
  (0, 1662)	3.3084687573733835
  (0, 1661)	3.3081699940879004
  (0, 1660)	3.3025439223217883
  (0, 1659)	3.3058424726150886
  (0, 1658)	3.312634780940414
  (0, 1657)	3.3128074988582497
  :	:
  (942, 24)	3.342856612475569
  (942, 23)	3.275017049743244
  (942, 22)	3.5818191699540756
  (942, 21)	3.7889872936591957
  (942, 20)	2.9949217250536893
  (942, 19)	3.1923921811593816
  (942, 18)	3.2639898226425097
  (942, 17)	3.0837757878990684
  (942, 16)	3.090637690750604
  (942, 15)	3.1221986014212217
  (942, 14)	3.533826750060626
  (942, 13)	3.5217974111589605
  (942, 12)	3.226720902606515
  (942, 11)	3.878163293465936
  (942, 10)	3.534150118411367
  (942, 9)	3.2749694040506077
  (942, 8)	3.5959203767731656
  (942, 7)	3.618178467849685
  (942, 6)	3.62901581517847
  (942, 5)	3.155335208465032
  (942, 4)	3.1399707981895935
  (942, 3)	3.3092339145424914
  (942, 2)	3.0663956418441813
  (942, 1)	3.119770989124054
  (942, 0)	3.7127543707768997
this is the 13 epoch
rmse loss on training set is 1.0059155375780169
rmse loss on test set is 1.0218573479010167
for this epoch using 75.79167604446411 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3180461838672337
  (0, 1680)	3.318544946993331
  (0, 1679)	3.3132742448231296
  (0, 1678)	3.3182787795841118
  (0, 1677)	3.308269710062151
  (0, 1676)	3.3181614251724283
  (0, 1675)	3.318380030869335
  (0, 1674)	3.318380030869335
  (0, 1673)	3.318380030869335
  (0, 1672)	3.31769594801774
  (0, 1671)	3.3086140119565064
  (0, 1670)	3.318380030869335
  (0, 1669)	3.318380030869335
  (0, 1668)	3.313939743759037
  (0, 1667)	3.318380030869335
  (0, 1666)	3.318380030869335
  (0, 1665)	3.313939743759037
  (0, 1664)	3.318380030869335
  (0, 1663)	3.313093804938844
  (0, 1662)	3.313939743759037
  (0, 1661)	3.3136021614014406
  (0, 1660)	3.3075088706356
  (0, 1659)	3.3109729722793197
  (0, 1658)	3.318380030869335
  (0, 1657)	3.3185783183650672
  :	:
  (942, 24)	3.3531718393836822
  (942, 23)	3.286572852448553
  (942, 22)	3.607981184681018
  (942, 21)	3.8155306789887207
  (942, 20)	2.9923840573480525
  (942, 19)	3.202496026382053
  (942, 18)	3.278997319827087
  (942, 17)	3.0878464716924294
  (942, 16)	3.0941493754269582
  (942, 15)	3.1285515714467516
  (942, 14)	3.5516789049943047
  (942, 13)	3.5454159268583747
  (942, 12)	3.235259553019704
  (942, 11)	3.9100644215532374
  (942, 10)	3.5543458386635414
  (942, 9)	3.289690985489051
  (942, 8)	3.617892664903755
  (942, 7)	3.642226643658964
  (942, 6)	3.645365599212274
  (942, 5)	3.164427947403341
  (942, 4)	3.1464638149263093
  (942, 3)	3.320215390005804
  (942, 2)	3.0684632491327313
  (942, 1)	3.124374399316567
  (942, 0)	3.7288875657917058
this is the 14 epoch
rmse loss on training set is 1.0011330398638445
rmse loss on test set is 1.0171456492478128
for this epoch using 74.82494401931763 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3226793509657297
  (0, 1680)	3.3232457884889866
  (0, 1679)	3.317592635947891
  (0, 1678)	3.322939341354792
  (0, 1677)	3.3122459305409957
  (0, 1676)	3.322813373442068
  (0, 1675)	3.3230534187103693
  (0, 1674)	3.3230534187103693
  (0, 1673)	3.3230534187103693
  (0, 1672)	3.3222773568509316
  (0, 1671)	3.3126449027416847
  (0, 1670)	3.3230534187103693
  (0, 1669)	3.3230534187103693
  (0, 1668)	3.318342740991343
  (0, 1667)	3.3230534187103693
  (0, 1666)	3.3230534187103693
  (0, 1665)	3.318342740991343
  (0, 1664)	3.3230534187103693
  (0, 1663)	3.317391936822273
  (0, 1662)	3.318342740991343
  (0, 1661)	3.317964636090937
  (0, 1660)	3.311400113926249
  (0, 1659)	3.3150233726437275
  (0, 1658)	3.3230534187103693
  (0, 1657)	3.32327921937397
  :	:
  (942, 24)	3.362540635253652
  (942, 23)	3.297458353435802
  (942, 22)	3.6327268347190924
  (942, 21)	3.83978470124655
  (942, 20)	2.9897475921613514
  (942, 19)	3.212274254312181
  (942, 18)	3.2936218030067033
  (942, 17)	3.09174707030367
  (942, 16)	3.0974587785305148
  (942, 15)	3.134696957577894
  (942, 14)	3.568004433618222
  (942, 13)	3.5677638279491664
  (942, 12)	3.2432293139614323
  (942, 11)	3.939445915978522
  (942, 10)	3.573075015649913
  (942, 9)	3.303954029367179
  (942, 8)	3.638190303983985
  (942, 7)	3.664566892876659
  (942, 6)	3.6599108988929205
  (942, 5)	3.173334408312844
  (942, 4)	3.1526890568186454
  (942, 3)	3.330386739109037
  (942, 2)	3.070366214436458
  (942, 1)	3.1287205590591265
  (942, 0)	3.7429996684467763
this is the 15 epoch
rmse loss on training set is 0.9968729456810295
rmse loss on test set is 1.0129220602814315
for this epoch using 76.06552982330322 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3263775037521985
  (0, 1680)	3.327015038791286
  (0, 1679)	3.3209773689514717
  (0, 1678)	3.326665653830265
  (0, 1677)	3.3152890840726745
  (0, 1676)	3.3265317780775363
  (0, 1675)	3.3267930963420973
  (0, 1674)	3.3267930963420973
  (0, 1673)	3.3267930963420973
  (0, 1672)	3.3259202614034806
  (0, 1671)	3.315746846797511
  (0, 1670)	3.3267930963420973
  (0, 1669)	3.3267930963420973
  (0, 1668)	3.321815821493373
  (0, 1667)	3.3267930963420973
  (0, 1666)	3.3267930963420973
  (0, 1665)	3.321815821493373
  (0, 1664)	3.3267930963420973
  (0, 1663)	3.320756251962265
  (0, 1662)	3.321815821493373
  (0, 1661)	3.3213955959896526
  (0, 1660)	3.3143563397976483
  (0, 1659)	3.3181329911720567
  (0, 1658)	3.3267930963420973
  (0, 1657)	3.3270483497802985
  :	:
  (942, 24)	3.3710737841069767
  (942, 23)	3.3077272101227413
  (942, 22)	3.6561506543359767
  (942, 21)	3.8619719794513956
  (942, 20)	2.9870335867330384
  (942, 19)	3.2217490239834
  (942, 18)	3.307882396269728
  (942, 17)	3.0954895333326444
  (942, 16)	3.1005875804052336
  (942, 15)	3.1406495899725977
  (942, 14)	3.5829523372988334
  (942, 13)	3.588923657850391
  (942, 12)	3.250686379688622
  (942, 11)	3.966529044522239
  (942, 10)	3.5904647739086024
  (942, 9)	3.317785563549708
  (942, 8)	3.6569592587016255
  (942, 7)	3.6853385941276016
  (942, 6)	3.672877324969409
  (942, 5)	3.182066240147476
  (942, 4)	3.1586699665888656
  (942, 3)	3.3398318418247155
  (942, 2)	3.0721261202664145
  (942, 1)	3.1328400260614178
  (942, 0)	3.7553690478468402
this is the 16 epoch
rmse loss on training set is 0.9930550400595817
rmse loss on test set is 1.009117173930616
for this epoch using 75.73856806755066 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3292638253435385
  (0, 1680)	3.3299757080286634
  (0, 1679)	3.3235516032732684
  (0, 1678)	3.3295808084707277
  (0, 1677)	3.317522398075812
  (0, 1676)	3.3294398021051457
  (0, 1675)	3.329722124232215
  (0, 1674)	3.329722124232215
  (0, 1673)	3.329722124232215
  (0, 1672)	3.328747888019341
  (0, 1671)	3.3180430077845977
  (0, 1670)	3.329722124232215
  (0, 1669)	3.329722124232215
  (0, 1668)	3.324481945613632
  (0, 1667)	3.329722124232215
  (0, 1666)	3.329722124232215
  (0, 1665)	3.324481945613632
  (0, 1664)	3.329722124232215
  (0, 1663)	3.3233100030801714
  (0, 1662)	3.324481945613632
  (0, 1661)	3.324018101727961
  (0, 1660)	3.316501055922893
  (0, 1659)	3.3204259357193515
  (0, 1658)	3.329722124232215
  (0, 1657)	3.330008761072196
  :	:
  (942, 24)	3.378869642830646
  (942, 23)	3.3174282768580428
  (942, 22)	3.678340671663238
  (942, 21)	3.8822947665019023
  (942, 20)	2.9842606662351674
  (942, 19)	3.230940596780019
  (942, 18)	3.3217967903148145
  (942, 17)	3.099084767508968
  (942, 16)	3.1035549078300546
  (942, 15)	3.146422981421988
  (942, 14)	3.596657369388788
  (942, 13)	3.6089724812718313
  (942, 12)	3.2576812436953886
  (942, 11)	3.9915168381499098
  (942, 10)	3.6066314679738594
  (942, 9)	3.331210299336962
  (942, 8)	3.674333214577752
  (942, 7)	3.704670356868013
  (942, 6)	3.6844638672274264
  (942, 5)	3.190634109647299
  (942, 4)	3.1644273681822046
  (942, 3)	3.348626005518351
  (942, 2)	3.0737618909292492
  (942, 1)	3.1367596506008457
  (942, 0)	3.7662384550566377
this is the 17 epoch
rmse loss on training set is 0.9896133514760465
rmse loss on test set is 1.0056730640123657
for this epoch using 75.75906920433044 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.331447670122654
  (0, 1680)	3.332236981826718
  (0, 1679)	3.3254246537606447
  (0, 1678)	3.3317940757533626
  (0, 1677)	3.3190552317679267
  (0, 1676)	3.3316467756519264
  (0, 1675)	3.3319497438578374
  (0, 1674)	3.3319497438578374
  (0, 1673)	3.3319497438578374
  (0, 1672)	3.330869636870675
  (0, 1671)	3.3196426725455646
  (0, 1670)	3.3319497438578374
  (0, 1669)	3.3319497438578374
  (0, 1668)	3.3264502393648416
  (0, 1667)	3.3319497438578374
  (0, 1666)	3.3319497438578374
  (0, 1665)	3.3264502393648416
  (0, 1664)	3.3319497438578374
  (0, 1663)	3.3251625871618913
  (0, 1662)	3.3264502393648416
  (0, 1661)	3.3259413744656854
  (0, 1660)	3.3179438747955885
  (0, 1659)	3.3220123851385237
  (0, 1658)	3.3319497438578374
  (0, 1657)	3.332269681578048
  :	:
  (942, 24)	3.3860152950019775
  (942, 23)	3.326605973840559
  (942, 22)	3.6993786986570023
  (942, 21)	3.900936341680828
  (942, 20)	2.9814450936434658
  (942, 19)	3.2398674552839073
  (942, 18)	3.335381319966885
  (942, 17)	3.1025427032215687
  (942, 16)	3.1063776009024653
  (942, 15)	3.1520294194659955
  (942, 14)	3.6092411661791997
  (942, 13)	3.6279821046227796
  (942, 12)	3.264259179574152
  (942, 11)	4.014595117487047
  (942, 10)	3.6216813503473513
  (942, 9)	3.3442507999739752
  (942, 8)	3.690434340135601
  (942, 7)	3.7226805534931136
  (942, 6)	3.6948455782113094
  (942, 5)	3.199047755691176
  (942, 4)	3.1699797283978532
  (942, 3)	3.3568366684316744
  (942, 2)	3.075290066136389
  (942, 1)	3.140502954187079
  (942, 0)	3.775818952627258
this is the 18 epoch
rmse loss on training set is 0.9864934955654286
rmse loss on test set is 1.002541268488734
for this epoch using 78.88118696212769 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.333025814618364
  (0, 1680)	3.333895473012089
  (0, 1679)	3.326693245489169
  (0, 1678)	3.333402155540654
  (0, 1677)	3.319984335437676
  (0, 1676)	3.333249447558418
  (0, 1675)	3.333572627976712
  (0, 1674)	3.333572627976712
  (0, 1673)	3.333572627976712
  (0, 1672)	3.332382332214662
  (0, 1671)	3.3206425124161996
  (0, 1670)	3.333572627976712
  (0, 1669)	3.333572627976712
  (0, 1668)	3.3278172491262064
  (0, 1667)	3.333572627976712
  (0, 1666)	3.333572627976712
  (0, 1665)	3.3278172491262064
  (0, 1664)	3.333572627976712
  (0, 1663)	3.326410801310992
  (0, 1662)	3.3278172491262064
  (0, 1661)	3.327262050674242
  (0, 1660)	3.3187817750063315
  (0, 1659)	3.322989848053254
  (0, 1658)	3.333572627976712
  (0, 1657)	3.333927767459916
  :	:
  (942, 24)	3.3925876578021947
  (942, 23)	3.3353006534135403
  (942, 22)	3.7193406612894884
  (942, 21)	3.9180624340556585
  (942, 20)	2.978601023054422
  (942, 19)	3.248546429803057
  (942, 18)	3.348651050946217
  (942, 17)	3.1058723661279988
  (942, 16)	3.1090704626741625
  (942, 15)	3.1574800613957326
  (942, 14)	3.6208133543055294
  (942, 13)	3.6460193341921907
  (942, 12)	3.270460710582862
  (942, 11)	4.035933593030222
  (942, 10)	3.635711270181829
  (942, 9)	3.3569276534941177
  (942, 8)	3.7053740779578113
  (942, 7)	3.739477910074335
  (942, 6)	3.704176097377478
  (942, 5)	3.207316050500671
  (942, 4)	3.175343404891413
  (942, 3)	3.3645240933912066
  (942, 2)	3.076725059585406
  (942, 1)	3.144090487571471
  (942, 0)	3.784293554132394
this is the 19 epoch
rmse loss on training set is 0.9836505052535278
rmse loss on test set is 0.9996811238266282
for this epoch using 76.67249703407288 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.334083660511384
  (0, 1680)	3.3350364252022096
  (0, 1679)	3.3274427200444325
  (0, 1678)	3.3344903795596794
  (0, 1677)	3.3203950605291896
  (0, 1676)	3.334333189033867
  (0, 1675)	3.3346760829983273
  (0, 1674)	3.3346760829983273
  (0, 1673)	3.3346760829983273
  (0, 1672)	3.3333714248954434
  (0, 1671)	3.3211277950463844
  (0, 1670)	3.3346760829983273
  (0, 1669)	3.3346760829983273
  (0, 1668)	3.328668147669317
  (0, 1667)	3.3346760829983273
  (0, 1666)	3.3346760829983273
  (0, 1665)	3.328668147669317
  (0, 1664)	3.3346760829983273
  (0, 1663)	3.32714005002747
  (0, 1662)	3.328668147669317
  (0, 1661)	3.328065388304841
  (0, 1660)	3.319100313343905
  (0, 1659)	3.3234443737529835
  (0, 1658)	3.3346760829983273
  (0, 1657)	3.335068305708956
  :	:
  (942, 24)	3.3986545260884076
  (942, 23)	3.3435489548016233
  (942, 22)	3.738296951473809
  (942, 21)	3.9338226346770093
  (942, 20)	2.9757407340031516
  (942, 19)	3.2569928270902277
  (942, 18)	3.361619870920583
  (942, 17)	3.109081950285326
  (942, 16)	3.1116464894464113
  (942, 15)	3.1627850286895036
  (942, 14)	3.6314726144235148
  (942, 13)	3.663146256364348
  (942, 12)	3.2763220587358712
  (942, 11)	4.0556869943644696
  (942, 10)	3.6488093776383015
  (942, 9)	3.369259643667146
  (942, 8)	3.7192539390238823
  (942, 7)	3.75516212697637
  (942, 6)	3.712589993859195
  (942, 5)	3.215447064012687
  (942, 4)	3.180532877274554
  (942, 3)	3.3717420362774537
  (942, 2)	3.0780793992617834
  (942, 1)	3.147540163641673
  (942, 0)	3.7918205561995095
this is the 20 epoch
rmse loss on training set is 0.9810470673678008
rmse loss on test set is 0.997058395289807
for this epoch using 76.08353686332703 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.334696372771662
  (0, 1680)	3.3357348513302303
  (0, 1679)	3.3277481763582295
  (0, 1678)	3.3351338490153815
  (0, 1677)	3.320362503701069
  (0, 1676)	3.334973132363885
  (0, 1675)	3.335335186483634
  (0, 1674)	3.335335186483634
  (0, 1673)	3.335335186483634
  (0, 1672)	3.3339121300773447
  (0, 1671)	3.3211735299233607
  (0, 1670)	3.335335186483634
  (0, 1669)	3.335335186483634
  (0, 1668)	3.329077874641267
  (0, 1667)	3.335335186483634
  (0, 1666)	3.335335186483634
  (0, 1665)	3.329077874641267
  (0, 1664)	3.335335186483634
  (0, 1663)	3.327425486987434
  (0, 1662)	3.329077874641267
  (0, 1661)	3.328426407457032
  (0, 1660)	3.318974770828296
  (0, 1659)	3.32345169802508
  (0, 1658)	3.335335186483634
  (0, 1657)	3.3357663521798093
  :	:
  (942, 24)	3.4042755442042845
  (942, 23)	3.3513841414105867
  (942, 22)	3.7563127869247475
  (942, 21)	3.948351767606018
  (942, 20)	2.9728748457495127
  (942, 19)	3.265220557328246
  (942, 18)	3.37430058123
  (942, 17)	3.1121788903019922
  (942, 16)	3.114117080907512
  (942, 15)	3.1679534985122046
  (942, 14)	3.641307687965695
  (942, 13)	3.6794205279508323
  (942, 12)	3.2818755676017113
  (942, 11)	4.07399619532855
  (942, 10)	3.6610558158721003
  (942, 9)	3.3812639148189607
  (942, 8)	3.732166281748722
  (942, 7)	3.7698245077938854
  (942, 6)	3.7202049177615257
  (942, 5)	3.2234481287647543
  (942, 4)	3.1855609596472374
  (942, 3)	3.3785383791419044
  (942, 2)	3.0793639478612422
  (942, 1)	3.150867563013217
  (942, 0)	3.7985365600348318
this is the 21 epoch
rmse loss on training set is 0.978652094771224
rmse loss on test set is 0.9946441538957115
for this epoch using 76.08628511428833 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.334929942667908
  (0, 1680)	3.3360565968838025
  (0, 1679)	3.3276755359201546
  (0, 1678)	3.3353984970909085
  (0, 1677)	3.319952574749398
  (0, 1676)	3.3352352344169427
  (0, 1675)	3.335615849530787
  (0, 1674)	3.335615849530787
  (0, 1673)	3.335615849530787
  (0, 1672)	3.334070489933059
  (0, 1671)	3.32084553751746
  (0, 1670)	3.335615849530787
  (0, 1669)	3.335615849530787
  (0, 1668)	3.3291122013585412
  (0, 1667)	3.335615849530787
  (0, 1666)	3.335615849530787
  (0, 1665)	3.3291122013585412
  (0, 1664)	3.335615849530787
  (0, 1663)	3.3273330811341486
  (0, 1662)	3.3291122013585412
  (0, 1661)	3.328410955386141
  (0, 1660)	3.318471222526664
  (0, 1659)	3.323078313531445
  (0, 1658)	3.335615849530787
  (0, 1657)	3.3360877944305596
  :	:
  (942, 24)	3.4095031009753245
  (942, 23)	3.3588364171122116
  (942, 22)	3.7734485689004056
  (942, 21)	3.961771199363738
  (942, 20)	2.970012511485896
  (942, 19)	3.2732422566767045
  (942, 18)	3.3867049867366155
  (942, 17)	3.1151699308173515
  (942, 16)	3.1164922301914313
  (942, 15)	3.172993790728553
  (942, 14)	3.650398319134475
  (942, 13)	3.694895667800925
  (942, 12)	3.287150095513835
  (942, 11)	4.090989311412946
  (942, 10)	3.6725233881089276
  (942, 9)	3.392956127800801
  (942, 8)	3.7441950627264746
  (942, 7)	3.7835485808360545
  (942, 6)	3.7271235584547022
  (942, 5)	3.2313259034313795
  (942, 4)	3.1904389940370215
  (942, 3)	3.384955721906624
  (942, 2)	3.080588102902099
  (942, 1)	3.154086211728792
  (942, 0)	3.8045591896761217
this is the 22 epoch
rmse loss on training set is 0.9764395728891185
rmse loss on test set is 0.9924138572562751
for this epoch using 75.46487808227539 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3348421704430193
  (0, 1680)	3.336059322683888
  (0, 1679)	3.3272825272315183
  (0, 1678)	3.3353420711370756
  (0, 1677)	3.3192229833259663
  (0, 1676)	3.335177259749939
  (0, 1675)	3.3355757988518246
  (0, 1674)	3.3355757988518246
  (0, 1673)	3.3355757988518246
  (0, 1672)	3.3339043560656916
  (0, 1671)	3.320201437011467
  (0, 1670)	3.3355757988518246
  (0, 1669)	3.3355757988518246
  (0, 1668)	3.328828714803816
  (0, 1667)	3.3355757988518246
  (0, 1666)	3.3355757988518246
  (0, 1665)	3.328828714803816
  (0, 1664)	3.3355757988518246
  (0, 1663)	3.3269206019417505
  (0, 1662)	3.328828714803816
  (0, 1661)	3.3280766907298305
  (0, 1660)	3.317647526058966
  (0, 1659)	3.3223824594360356
  (0, 1658)	3.3355757988518246
  (0, 1657)	3.3360903341826305
  :	:
  (942, 24)	3.4143831468772805
  (942, 23)	3.3659332196395777
  (942, 22)	3.7897602307105154
  (942, 21)	3.974190073797
  (942, 20)	2.9671615930826953
  (942, 19)	3.2810694036068897
  (942, 18)	3.398843982070045
  (942, 17)	3.11806119222424
  (942, 16)	3.1187806945425463
  (942, 15)	3.177913449492808
  (942, 14)	3.658816128286196
  (942, 13)	3.709621343304103
  (942, 12)	3.292171377749444
  (942, 11)	4.106782753033339
  (942, 10)	3.683278191535931
  (942, 9)	3.404350605507123
  (942, 8)	3.755416550544216
  (942, 7)	3.7964107019760056
  (942, 6)	3.7334354143483166
  (942, 5)	3.2390864337568788
  (942, 4)	3.1951770250019997
  (942, 3)	3.391031929581329
  (942, 2)	3.0817599768976747
  (942, 1)	3.1572078315669163
  (942, 0)	3.809989521088331
this is the 23 epoch
rmse loss on training set is 0.9743876290802963
rmse loss on test set is 0.9903465978972907
for this epoch using 74.9247989654541 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3344835661517975
  (0, 1680)	3.33579340572734
  (0, 1679)	3.3266195880625955
  (0, 1678)	3.335015033052508
  (0, 1677)	3.318224143072684
  (0, 1676)	3.3348496818159417
  (0, 1675)	3.335265477044191
  (0, 1674)	3.335265477044191
  (0, 1673)	3.335265477044191
  (0, 1672)	3.333464290148424
  (0, 1671)	3.3192915512628023
  (0, 1670)	3.335265477044191
  (0, 1669)	3.335265477044191
  (0, 1668)	3.328277719406338
  (0, 1667)	3.335265477044191
  (0, 1666)	3.335265477044191
  (0, 1665)	3.328277719406338
  (0, 1664)	3.335265477044191
  (0, 1663)	3.3262385224113395
  (0, 1662)	3.328277719406338
  (0, 1661)	3.3274739855255757
  (0, 1660)	3.3165542273996875
  (0, 1659)	3.321415028726982
  (0, 1658)	3.335265477044191
  (0, 1657)	3.3358243879134504
  :	:
  (942, 24)	3.4189559348646252
  (942, 23)	3.372699490448226
  (942, 22)	3.8052995721543876
  (942, 21)	3.985706464978695
  (942, 20)	2.9643288174094446
  (942, 19)	3.2887124279533664
  (942, 18)	3.4107276331593934
  (942, 17)	3.1208582319997453
  (942, 16)	3.1209901476589583
  (942, 15)	3.182719318925244
  (942, 14)	3.6666254157807994
  (942, 13)	3.723643647321229
  (942, 12)	3.296962357552746
  (942, 11)	4.121482224023071
  (942, 10)	3.693380212978831
  (942, 9)	3.4154604671579274
  (942, 8)	3.7658999973761547
  (942, 7)	3.8084806312672814
  (942, 6)	3.7392183826719037
  (942, 5)	3.246735210087687
  (942, 4)	3.1997839561694645
  (942, 3)	3.3968006341054515
  (942, 2)	3.082886558482961
  (942, 1)	3.160242564173534
  (942, 0)	3.814914240532486
this is the 24 epoch
rmse loss on training set is 0.9724777820646081
rmse loss on test set is 0.988424488533388
for this epoch using 75.13818788528442 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.333898169794947
  (0, 1680)	3.3353027592499536
  (0, 1679)	3.325730686704415
  (0, 1678)	3.3344613789914694
  (0, 1677)	3.3169999944173694
  (0, 1676)	3.3342965034145027
  (0, 1675)	3.334728862195175
  (0, 1674)	3.334728862195175
  (0, 1673)	3.334728862195175
  (0, 1672)	3.3327943839047753
  (0, 1671)	3.318159730269704
  (0, 1670)	3.334728862195175
  (0, 1669)	3.334728862195175
  (0, 1668)	3.327503057811844
  (0, 1667)	3.334728862195175
  (0, 1666)	3.334728862195175
  (0, 1665)	3.327503057811844
  (0, 1664)	3.334728862195175
  (0, 1663)	3.3253308409914855
  (0, 1662)	3.327503057811844
  (0, 1661)	3.3266467462181644
  (0, 1660)	3.315235385214209
  (0, 1659)	3.320220394341877
  (0, 1658)	3.334728862195175
  (0, 1657)	3.3353339067285788
  :	:
  (942, 24)	3.423256688036201
  (942, 23)	3.379157921263289
  (942, 22)	3.820114576791849
  (942, 21)	3.9964084449463586
  (942, 20)	2.961519915515608
  (942, 19)	3.296180812129745
  (942, 18)	3.4223652534068676
  (942, 17)	3.1235661013370555
  (942, 16)	3.123127315013054
  (942, 15)	3.187417612707376
  (942, 14)	3.673883897443481
  (942, 13)	3.7370053625694064
  (942, 12)	3.3015434867922524
  (942, 11)	4.135183659033498
  (942, 10)	3.7028838837640907
  (942, 9)	3.426297751142688
  (942, 8)	3.7757082655917724
  (942, 7)	3.819822078489166
  (942, 6)	3.744540180328255
  (942, 5)	3.2542772210460926
  (942, 4)	3.20426768980193
  (942, 3)	3.4022916914517474
  (942, 2)	3.083973855709376
  (942, 1)	3.1631991706650524
  (942, 0)	3.8194075530322777
this is the 25 epoch
rmse loss on training set is 0.9706943363081181
rmse loss on test set is 0.9866321589908521
for this epoch using 76.25190711021423 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.333124293693658
  (0, 1680)	3.3346255749731264
  (0, 1679)	3.324654065209039
  (0, 1678)	3.333719381344659
  (0, 1677)	3.3155887490734277
  (0, 1676)	3.333555999335274
  (0, 1675)	3.334004209765817
  (0, 1674)	3.334004209765817
  (0, 1673)	3.334004209765817
  (0, 1672)	3.331933001364955
  (0, 1671)	3.316844096207344
  (0, 1670)	3.334004209765817
  (0, 1669)	3.334004209765817
  (0, 1668)	3.3265428536466874
  (0, 1667)	3.334004209765817
  (0, 1666)	3.334004209765817
  (0, 1665)	3.3265428536466874
  (0, 1664)	3.334004209765817
  (0, 1663)	3.324235825419963
  (0, 1662)	3.3265428536466874
  (0, 1661)	3.325633156657126
  (0, 1660)	3.3137293167710746
  (0, 1659)	3.318837157034744
  (0, 1658)	3.334004209765817
  (0, 1657)	3.334657118467389
  :	:
  (942, 24)	3.4273161983909666
  (942, 23)	3.3853291781182233
  (942, 22)	3.8342497102599853
  (942, 21)	4.006375066126244
  (942, 20)	2.958739746075817
  (942, 19)	3.303483184332536
  (942, 18)	3.433765474198158
  (942, 17)	3.126189397003627
  (942, 16)	3.1251980935579957
  (942, 15)	3.1920139776517846
  (942, 14)	3.680643374200127
  (942, 13)	3.7497462116210083
  (942, 12)	3.3059329976461065
  (942, 11)	4.147974096783131
  (942, 10)	3.7118385929424176
  (942, 9)	3.436873526623902
  (942, 8)	3.784898408473935
  (942, 7)	3.830493214874098
  (942, 6)	3.7494596083065654
  (942, 5)	3.261717003134807
  (942, 4)	3.2086352506591735
  (942, 3)	3.4075315956648495
  (942, 2)	3.0850270228942227
  (942, 1)	3.1660852085856344
  (942, 0)	3.823532862756568
this is the 26 epoch
rmse loss on training set is 0.9690238928288533
rmse loss on test set is 0.9849563439673135
for this epoch using 76.86448979377747 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.332195191229248
  (0, 1680)	3.333794991673857
  (0, 1679)	3.3234229087856004
  (0, 1678)	3.332822257117601
  (0, 1677)	3.3140235604536032
  (0, 1676)	3.332661385325071
  (0, 1675)	3.333124720878884
  (0, 1674)	3.333124720878884
  (0, 1673)	3.333124720878884
  (0, 1672)	3.330913447515033
  (0, 1671)	3.3153777142647765
  (0, 1670)	3.333124720878884
  (0, 1669)	3.333124720878884
  (0, 1668)	3.3254301804514843
  (0, 1667)	3.333124720878884
  (0, 1666)	3.333124720878884
  (0, 1665)	3.3254301804514843
  (0, 1664)	3.333124720878884
  (0, 1663)	3.322986682658025
  (0, 1662)	3.3254301804514843
  (0, 1661)	3.3244663472558784
  (0, 1660)	3.3120692696430027
  (0, 1659)	3.3172988191179154
  (0, 1658)	3.333124720878884
  (0, 1657)	3.333827196174127
  :	:
  (942, 24)	3.4311613615445533
  (942, 23)	3.391232104067226
  (942, 22)	3.8477461988176915
  (942, 21)	4.015677260439414
  (942, 20)	2.955992404537255
  (942, 19)	3.3106274038226124
  (942, 18)	3.444936309688852
  (942, 17)	3.128732308512011
  (942, 16)	3.1272076572564482
  (942, 15)	3.196513551454205
  (942, 14)	3.6869503393637912
  (942, 13)	3.7619030915301988
  (942, 12)	3.3101471470819095
  (942, 11)	4.159932488481722
  (942, 10)	3.7202891593207608
  (942, 9)	3.4471979943649256
  (942, 8)	3.793522205485655
  (942, 7)	3.840547149827307
  (942, 6)	3.7540276727458584
  (942, 5)	3.2690586862376154
  (942, 4)	3.2128928955020157
  (942, 3)	3.4125438521729383
  (942, 2)	3.0860504724798714
  (942, 1)	3.168907188196284
  (942, 0)	3.827344247136338
this is the 27 epoch
rmse loss on training set is 0.967454953374029
rmse loss on test set is 0.9833855446206673
for this epoch using 77.59217023849487 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3311396567778058
  (0, 1680)	3.3328396949203514
  (0, 1679)	3.3220659462188458
  (0, 1678)	3.3317987675355045
  (0, 1677)	3.3123331249022
  (0, 1676)	3.3316414182138026
  (0, 1675)	3.3321191418404106
  (0, 1674)	3.3321191418404106
  (0, 1673)	3.3321191418404106
  (0, 1672)	3.3297645681629624
  (0, 1671)	3.313789194205424
  (0, 1670)	3.3321191418404106
  (0, 1669)	3.3321191418404106
  (0, 1668)	3.3241936616561936
  (0, 1667)	3.3321191418404106
  (0, 1666)	3.3321191418404106
  (0, 1665)	3.3241936616561936
  (0, 1664)	3.3321191418404106
  (0, 1663)	3.321612159788458
  (0, 1662)	3.3241936616561936
  (0, 1661)	3.3231749951821925
  (0, 1660)	3.3102840241062044
  (0, 1659)	3.3156343889271915
  (0, 1658)	3.3321191418404106
  (0, 1657)	3.332872857769659
  :	:
  (942, 24)	3.4348156525600153
  (942, 23)	3.3968839019751678
  (942, 22)	3.860642288001875
  (942, 21)	4.024378658544042
  (942, 20)	2.953281319380857
  (942, 19)	3.317620638555069
  (942, 18)	3.455885215977195
  (942, 17)	3.131198660796082
  (942, 16)	3.129160549840611
  (942, 15)	3.2009210149318945
  (942, 14)	3.692846527591366
  (942, 13)	3.7735102927297413
  (942, 12)	3.3142004361008444
  (942, 11)	4.17113044245983
  (942, 10)	3.7282762636265896
  (942, 9)	3.4572805774124578
  (942, 8)	3.8016266534617262
  (942, 7)	3.850032372584343
  (942, 6)	3.758288575763619
  (942, 5)	3.276306035103673
  (942, 4)	3.217046209590817
  (942, 3)	3.417349313100942
  (942, 2)	3.0870479733545677
  (942, 1)	3.171670710070118
  (942, 0)	3.8308877458569865
this is the 28 epoch
rmse loss on training set is 0.9659775994430614
rmse loss on test set is 0.9819097501490838
for this epoch using 76.82274913787842 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3299825620266343
  (0, 1680)	3.3317844531697665
  (0, 1679)	3.320607986528203
  (0, 1678)	3.330673754059976
  (0, 1677)	3.310542218996443
  (0, 1676)	3.3305209323907174
  (0, 1675)	3.3310123000796406
  (0, 1674)	3.3310123000796406
  (0, 1673)	3.3310123000796406
  (0, 1672)	3.3285112862029513
  (0, 1671)	3.312103227917601
  (0, 1670)	3.3310123000796406
  (0, 1669)	3.3310123000796406
  (0, 1668)	3.322858006818146
  (0, 1667)	3.3310123000796406
  (0, 1666)	3.3310123000796406
  (0, 1665)	3.322858006818146
  (0, 1664)	3.3310123000796406
  (0, 1663)	3.320137081100299
  (0, 1662)	3.322858006818146
  (0, 1661)	3.3217838608000583
  (0, 1660)	3.3083984314957307
  (0, 1659)	3.3138689212223467
  (0, 1658)	3.3310123000796406
  (0, 1657)	3.331818902114427
  :	:
  (942, 24)	3.438299548091385
  (942, 23)	3.4023002988980817
  (942, 22)	3.8729734817759365
  (942, 21)	4.032536333601413
  (942, 20)	2.9506093368439696
  (942, 19)	3.3244694355465896
  (942, 18)	3.4666191448880563
  (942, 17)	3.1335919526525484
  (942, 16)	3.1310607661479533
  (942, 15)	3.2052406391093853
  (942, 14)	3.6983694097959092
  (942, 13)	3.7845997022949236
  (942, 12)	3.318105805797227
  (942, 11)	4.181632907212856
  (942, 10)	3.735836842708035
  (942, 9)	3.4671300023576928
  (942, 8)	3.809254415728391
  (942, 7)	3.858993159558421
  (942, 6)	3.7622805887908273
  (942, 5)	3.2834624869843516
  (942, 4)	3.2211001914925164
  (942, 3)	3.421966477502419
  (942, 2)	3.0880227370368556
  (942, 1)	3.1743805859027208
  (942, 0)	3.8342024847494827
this is the 29 epoch
rmse loss on training set is 0.9645832313177022
rmse loss on test set is 0.9805202081384112
for this epoch using 75.49647808074951 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3287453339637834
  (0, 1680)	3.3306505955274113
  (0, 1679)	3.3190703971851248
  (0, 1678)	3.329468616107139
  (0, 1677)	3.3086721782631114
  (0, 1676)	3.329321317926783
  (0, 1675)	3.329825581797108
  (0, 1674)	3.329825581797108
  (0, 1673)	3.329825581797108
  (0, 1672)	3.3271750795657034
  (0, 1671)	3.3103410683147656
  (0, 1670)	3.329825581797108
  (0, 1669)	3.329825581797108
  (0, 1668)	3.321444489442891
  (0, 1667)	3.329825581797108
  (0, 1666)	3.329825581797108
  (0, 1665)	3.321444489442891
  (0, 1664)	3.329825581797108
  (0, 1663)	3.3185828266829804
  (0, 1662)	3.321444489442891
  (0, 1661)	3.320314265682069
  (0, 1660)	3.306433893870731
  (0, 1659)	3.3120239988434936
  (0, 1658)	3.329825581797108
  (0, 1657)	3.3306866867566676
  :	:
  (942, 24)	3.4416308999176746
  (942, 23)	3.4074956935976
  (942, 22)	3.8847727628889897
  (942, 21)	4.04020147449269
  (942, 20)	2.947978795364986
  (942, 19)	3.3311797844395308
  (942, 18)	3.4771445926662374
  (942, 17)	3.135915391244898
  (942, 16)	3.13291182329128
  (942, 15)	3.2094763275408513
  (942, 14)	3.7035526383692168
  (942, 13)	3.795200991990639
  (942, 12)	3.321874812280036
  (942, 11)	4.191498795844593
  (942, 10)	3.743004448027532
  (942, 9)	3.4767543719407707
  (942, 8)	3.81644423154523
  (942, 7)	3.867469948681972
  (942, 6)	3.766036820522017
  (942, 5)	3.2905311856424593
  (942, 4)	3.225059327441617
  (942, 3)	3.426411759473715
  (942, 2)	3.088977493045442
  (942, 1)	3.177040944339622
  (942, 0)	3.8373216532234564
this is the 30 epoch
rmse loss on training set is 0.9632643552416593
rmse loss on test set is 0.9792092345917907
for this epoch using 75.40360498428345 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.327446379759658
  (0, 1680)	3.329456436392081
  (0, 1679)	3.3174715291299286
  (0, 1678)	3.328201735683955
  (0, 1677)	3.306741322575897
  (0, 1676)	3.3280609455657264
  (0, 1675)	3.3285773565369787
  (0, 1674)	3.3285773565369787
  (0, 1673)	3.3285773565369787
  (0, 1672)	3.3257744060700687
  (0, 1671)	3.308520954862672
  (0, 1670)	3.3285773565369787
  (0, 1669)	3.3285773565369787
  (0, 1668)	3.319971371629871
  (0, 1667)	3.3285773565369787
  (0, 1666)	3.3285773565369787
  (0, 1665)	3.319971371629871
  (0, 1664)	3.3285773565369787
  (0, 1663)	3.316967757775917
  (0, 1662)	3.319971371629871
  (0, 1661)	3.3187845174340436
  (0, 1660)	3.3044087902634733
  (0, 1659)	3.310118160873277
  (0, 1658)	3.3285773565369787
  (0, 1657)	3.329494552586199
  :	:
  (942, 24)	3.444825264716698
  (942, 23)	3.41248328870794
  (942, 22)	3.896070795383606
  (942, 21)	4.047419993663953
  (942, 20)	2.945391590911361
  (942, 19)	3.337757174758433
  (942, 18)	3.487467643919317
  (942, 17)	3.1381719229838474
  (942, 16)	3.134716822823609
  (942, 15)	3.2136316542658747
  (942, 14)	3.7084264470003525
  (942, 13)	3.8053417917320878
  (942, 12)	3.3255177824410582
  (942, 11)	4.200781555368251
  (942, 10)	3.749809570895385
  (942, 9)	3.4861612297680207
  (942, 8)	3.823231288479523
  (942, 7)	3.8754996824062817
  (942, 6)	3.769585890798727
  (942, 5)	3.297515011982499
  (942, 4)	3.2289276564145837
  (942, 3)	3.430699727061426
  (942, 2)	3.0899145546802393
  (942, 1)	3.1796553234944462
  (942, 0)	3.8402733523712094
this is the 31 epoch
rmse loss on training set is 0.9620144092872035
rmse loss on test set is 0.9779700562958266
for this epoch using 75.70843696594238 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3261014635671553
  (0, 1680)	3.328217652018867
  (0, 1679)	3.3158270936333323
  (0, 1678)	3.326888853967234
  (0, 1677)	3.304765333299425
  (0, 1676)	3.326755543613652
  (0, 1675)	3.327283353708064
  (0, 1674)	3.327283353708064
  (0, 1673)	3.327283353708064
  (0, 1672)	3.3243250802001527
  (0, 1671)	3.306658490809155
  (0, 1670)	3.327283353708064
  (0, 1669)	3.327283353708064
  (0, 1668)	3.318454280588236
  (0, 1667)	3.327283353708064
  (0, 1666)	3.327283353708064
  (0, 1665)	3.318454280588236
  (0, 1664)	3.327283353708064
  (0, 1663)	3.3153075939231407
  (0, 1662)	3.318454280588236
  (0, 1661)	3.31721028637722
  (0, 1660)	3.302338854586329
  (0, 1659)	3.3081672823633834
  (0, 1658)	3.327283353708064
  (0, 1657)	3.328258200421354
  :	:
  (942, 24)	3.4478961946311055
  (942, 23)	3.417275209013069
  (942, 22)	3.9068961103195745
  (942, 21)	4.054233074819086
  (942, 20)	2.942849234249006
  (942, 19)	3.3442066473659375
  (942, 18)	3.497594011169935
  (942, 17)	3.140364261100315
  (942, 16)	3.1364785049557513
  (942, 15)	3.2177098977892515
  (942, 14)	3.7130180092128855
  (942, 13)	3.8150478492269215
  (942, 12)	3.3290439524544593
  (942, 11)	4.209529684571488
  (942, 10)	3.7562799369581787
  (942, 9)	3.4953576178912167
  (942, 8)	3.829647560410593
  (942, 7)	3.8831161212370136
  (942, 6)	3.7729525208718213
  (942, 5)	3.3044166115635525
  (942, 4)	3.2327088269830044
  (942, 3)	3.4348433147557205
  (942, 2)	3.0908358763358885
  (942, 1)	3.1822267516913363
  (942, 0)	3.8430813293153014
this is the 32 epoch
rmse loss on training set is 0.9608276203623572
rmse loss on test set is 0.9767966795863621
for this epoch using 75.40586376190186 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.324724039997312
  (0, 1680)	3.326947613759779
  (0, 1679)	3.314150495775125
  (0, 1678)	3.3255434045801984
  (0, 1677)	3.3027575869700523
  (0, 1676)	3.325418531487134
  (0, 1675)	3.325956995807666
  (0, 1674)	3.325956995807666
  (0, 1673)	3.325956995807666
  (0, 1672)	3.322840606562865
  (0, 1671)	3.3047669769150416
  (0, 1670)	3.325956995807666
  (0, 1669)	3.325956995807666
  (0, 1668)	3.316906541794818
  (0, 1667)	3.325956995807666
  (0, 1666)	3.325956995807666
  (0, 1665)	3.316906541794818
  (0, 1664)	3.325956995807666
  (0, 1663)	3.313615746709984
  (0, 1662)	3.316906541794818
  (0, 1661)	3.3156049388605107
  (0, 1660)	3.300237509995152
  (0, 1659)	3.306184910413588
  (0, 1658)	3.325956995807666
  (0, 1657)	3.3269910242862184
  :	:
  (942, 24)	3.4508554928457884
  (942, 23)	3.4218826072077952
  (942, 22)	3.9172752758458165
  (942, 21)	4.060677665576317
  (942, 20)	2.940352901107703
  (942, 19)	3.350532840619014
  (942, 18)	3.5075290703812607
  (942, 17)	3.1424949102191184
  (942, 16)	3.138199295782279
  (942, 15)	3.221714071460013
  (942, 14)	3.7173517595222374
  (942, 13)	3.8243431766436644
  (942, 12)	3.3324615907708095
  (942, 11)	4.217787204235358
  (942, 10)	3.76244077244019
  (942, 9)	3.5043501279621365
  (942, 8)	3.835722113856426
  (942, 7)	3.8903501297895726
  (942, 6)	3.7761580495855966
  (942, 5)	3.311238419257512
  (942, 4)	3.23640614691374
  (942, 3)	3.438854012202304
  (942, 2)	3.091743103363444
  (942, 1)	3.184757817823185
  (942, 0)	3.8457656118365584
this is the 33 epoch
rmse loss on training set is 0.9596988863397381
rmse loss on test set is 0.975683780714234
for this epoch using 74.74322199821472 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.323325548712426
  (0, 1680)	3.3256576824268063
  (0, 1679)	3.3124531289949286
  (0, 1678)	3.3241768080065235
  (0, 1677)	3.3007294499833257
  (0, 1676)	3.3240613143642306
  (0, 1675)	3.324609692788
  (0, 1674)	3.324609692788
  (0, 1673)	3.324609692788
  (0, 1672)	3.321332474466266
  (0, 1671)	3.302857706163032
  (0, 1670)	3.324609692788
  (0, 1669)	3.324609692788
  (0, 1668)	3.315339473248219
  (0, 1667)	3.324609692788
  (0, 1666)	3.324609692788
  (0, 1665)	3.315339473248219
  (0, 1664)	3.324609692788
  (0, 1663)	3.311903614540346
  (0, 1662)	3.315339473248219
  (0, 1661)	3.313979831657184
  (0, 1660)	3.298116164186509
  (0, 1659)	3.3041825610756916
  (0, 1658)	3.324609692788
  (0, 1657)	3.325704405820031
  :	:
  (942, 24)	3.453713438046784
  (942, 23)	3.4263157584205235
  (942, 22)	3.9272330527694286
  (942, 21)	4.066786920001459
  (942, 20)	2.9379034760982283
  (942, 19)	3.356740031708917
  (942, 18)	3.5172778928120203
  (942, 17)	3.1445661882272042
  (942, 16)	3.1398813483729593
  (942, 15)	3.225646950603328
  (942, 14)	3.72144968085783
  (942, 13)	3.8332501851869663
  (942, 12)	3.3357781072349484
  (942, 11)	4.225594083465284
  (942, 10)	3.7683150445600386
  (942, 9)	3.513144946630059
  (942, 8)	3.841481385246198
  (942, 7)	3.8972299373765575
  (942, 6)	3.7792208841321604
  (942, 5)	3.3179826813094953
  (942, 4)	3.2400226263891554
  (942, 3)	3.4427420315828066
  (942, 2)	3.0926376153924973
  (942, 1)	3.187250732578145
  (942, 0)	3.848343055847049
this is the 34 epoch
rmse loss on training set is 0.9586236785035989
rmse loss on test set is 0.9746266139278863
for this epoch using 74.60600805282593 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3219156742410565
  (0, 1680)	3.324357467883525
  (0, 1679)	3.310744634830015
  (0, 1678)	3.322798731244363
  (0, 1677)	3.298690538415672
  (0, 1676)	3.322693543044976
  (0, 1675)	3.3232511016670236
  (0, 1674)	3.3232511016670236
  (0, 1673)	3.3232511016670236
  (0, 1672)	3.3198104177220915
  (0, 1671)	3.300940223577904
  (0, 1670)	3.3232511016670236
  (0, 1669)	3.3232511016670236
  (0, 1668)	3.31376264493292
  (0, 1667)	3.3232511016670236
  (0, 1666)	3.3232511016670236
  (0, 1665)	3.31376264493292
  (0, 1664)	3.3232511016670236
  (0, 1663)	3.310180842573523
  (0, 1662)	3.31376264493292
  (0, 1661)	3.312344571560601
  (0, 1660)	3.2959844697638903
  (0, 1659)	3.3021699812154433
  (0, 1658)	3.3232511016670236
  (0, 1657)	3.324407973922838
  :	:
  (942, 24)	3.4564789812831114
  (942, 23)	3.4305841446727676
  (942, 22)	3.9367925367549863
  (942, 21)	4.072590595665754
  (942, 20)	2.9355015911434132
  (942, 19)	3.362832173642947
  (942, 18)	3.5268452735427718
  (942, 17)	3.1465802457119785
  (942, 16)	3.1415265784935533
  (942, 15)	3.2295110967347562
  (942, 14)	3.725331561621386
  (942, 13)	3.8417898084632793
  (942, 12)	3.3390001498200768
  (942, 11)	4.232986625778289
  (942, 10)	3.773923678431657
  (942, 9)	3.521747895799104
  (942, 8)	3.8469494316498696
  (942, 7)	3.9037813751118686
  (942, 6)	3.7821568931615466
  (942, 5)	3.324651475045509
  (942, 4)	3.2435610156290533
  (942, 3)	3.4465164559193635
  (942, 2)	3.0935205639280494
  (942, 1)	3.189707381654745
  (942, 0)	3.8508278168885677
this is the 35 epoch
rmse loss on training set is 0.9575979604771365
rmse loss on test set is 0.9736209341274797
for this epoch using 74.83921980857849 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3205025747760093
  (0, 1680)	3.3230550576277977
  (0, 1679)	3.3090331316101955
  (0, 1678)	3.3214173164595646
  (0, 1677)	3.2966489467608278
  (0, 1676)	3.3213233427843267
  (0, 1675)	3.3218893551427433
  (0, 1674)	3.3218893551427433
  (0, 1673)	3.3218893551427433
  (0, 1672)	3.31828264343257
  (0, 1671)	3.299022554943447
  (0, 1670)	3.3218893551427433
  (0, 1669)	3.3218893551427433
  (0, 1668)	3.3121841072619067
  (0, 1667)	3.3218893551427433
  (0, 1666)	3.3218893551427433
  (0, 1665)	3.3121841072619067
  (0, 1664)	3.3218893551427433
  (0, 1663)	3.308455551593403
  (0, 1662)	3.3121841072619067
  (0, 1661)	3.310707243948092
  (0, 1660)	3.293850553460059
  (0, 1659)	3.3001553791204303
  (0, 1658)	3.3218893551427433
  (0, 1657)	3.3231098333977633
  :	:
  (942, 24)	3.45915991841424
  (942, 23)	3.4346965303480688
  (942, 22)	3.945975288248206
  (942, 21)	4.078115409573989
  (942, 20)	2.933147659099428
  (942, 19)	3.36881292829656
  (942, 18)	3.536235756995992
  (942, 17)	3.1485390832249727
  (942, 16)	3.143136695633821
  (942, 15)	3.2333088791599125
  (942, 14)	3.729015225476594
  (942, 13)	3.8499816155031565
  (942, 12)	3.3421336903347583
  (942, 11)	4.23999781842424
  (942, 10)	3.779285752620393
  (942, 9)	3.5301644683100104
  (942, 8)	3.8521481573370306
  (942, 7)	3.910028091450114
  (942, 6)	3.7849797492181247
  (942, 5)	3.331246726458165
  (942, 4)	3.2470238376106426
  (942, 3)	3.450185370364343
  (942, 2)	3.0943929049451295
  (942, 1)	3.192129371962155
  (942, 0)	3.853231755556635
this is the 36 epoch
rmse loss on training set is 0.9566181205590724
rmse loss on test set is 0.9726629315384708
for this epoch using 75.77626991271973 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3190930833782555
  (0, 1680)	3.321757217789158
  (0, 1679)	3.307325415539725
  (0, 1678)	3.320039382059579
  (0, 1677)	3.2946114490198743
  (0, 1676)	3.3199575145221645
  (0, 1675)	3.320531262631749
  (0, 1674)	3.320531262631749
  (0, 1673)	3.320531262631749
  (0, 1672)	3.316756033184021
  (0, 1671)	3.2971114078588877
  (0, 1670)	3.320531262631749
  (0, 1669)	3.320531262631749
  (0, 1668)	3.310610591926527
  (0, 1667)	3.320531262631749
  (0, 1666)	3.320531262631749
  (0, 1665)	3.310610591926527
  (0, 1664)	3.320531262631749
  (0, 1663)	3.306734539243311
  (0, 1662)	3.310610591926527
  (0, 1661)	3.309074613742526
  (0, 1660)	3.2917212176607102
  (0, 1659)	3.298145627301753
  (0, 1658)	3.320531262631749
  (0, 1657)	3.3218167660122484
  :	:
  (942, 24)	3.461763041004389
  (942, 23)	3.4386610296424154
  (942, 22)	3.9548014511643586
  (942, 21)	4.083385356989134
  (942, 20)	2.930841903164388
  (942, 19)	3.3746856959325555
  (942, 18)	3.5454536597502133
  (942, 17)	3.1504445666047545
  (942, 16)	3.1447132299416145
  (942, 15)	3.2370424942366807
  (942, 14)	3.7325167366925247
  (942, 13)	3.8578439142731025
  (942, 12)	3.345184100328596
  (942, 11)	4.246657648218926
  (942, 10)	3.7844186753756888
  (942, 9)	3.538399859558633
  (942, 8)	3.8570975183827185
  (942, 7)	3.9159917479894224
  (942, 6)	3.7877012267164796
  (942, 5)	3.3377702258847934
  (942, 4)	3.250413416503806
  (942, 3)	3.4537559783450473
  (942, 2)	3.095255427120038
  (942, 1)	3.19451807168855
  (942, 0)	3.8555647855802238
this is the 37 epoch
rmse loss on training set is 0.9556809150072078
rmse loss on test set is 0.9717491763302893
for this epoch using 74.69365406036377 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.317692884685047
  (0, 1680)	3.320469569639722
  (0, 1679)	3.3056271372704114
  (0, 1678)	3.3186705992844514
  (0, 1677)	3.292583675256378
  (0, 1676)	3.318601711609937
  (0, 1675)	3.319182486828452
  (0, 1674)	3.319182486828452
  (0, 1673)	3.319182486828452
  (0, 1672)	3.3152363197449293
  (0, 1671)	3.2952123482497377
  (0, 1670)	3.319182486828452
  (0, 1669)	3.319182486828452
  (0, 1668)	3.3090476882561073
  (0, 1667)	3.319182486828452
  (0, 1666)	3.319182486828452
  (0, 1665)	3.3090476882561073
  (0, 1664)	3.319182486828452
  (0, 1663)	3.305023456733018
  (0, 1662)	3.3090476882561073
  (0, 1661)	3.3074523018748305
  (0, 1660)	3.289602117346562
  (0, 1659)	3.296146440610627
  (0, 1658)	3.319182486828452
  (0, 1657)	3.320534407075604
  :	:
  (942, 24)	3.464294268223854
  (942, 23)	3.4424851668728014
  (942, 22)	3.9632898613195073
  (942, 21)	4.088421996856795
  (942, 20)	2.9285843826006777
  (942, 19)	3.3804536415514637
  (942, 18)	3.554503090925814
  (942, 17)	3.152298440572186
  (942, 16)	3.146257555590169
  (942, 15)	3.2407139825514286
  (942, 14)	3.7358505836033506
  (942, 13)	3.8653938464676516
  (942, 12)	3.34815621829958
  (942, 11)	4.2529933869489795
  (942, 10)	3.7893383434064005
  (942, 9)	3.5464589955133112
  (942, 8)	3.861815707376627
  (942, 7)	3.9216921972587357
  (942, 6)	3.7903314609727414
  (942, 5)	3.344223641975443
  (942, 4)	3.253731902366879
  (942, 3)	3.4572347042519875
  (942, 2)	3.0961087762611794
  (942, 1)	3.196874645017107
  (942, 0)	3.8578351722272366
this is the 38 epoch
rmse loss on training set is 0.9547834202905279
rmse loss on test set is 0.9708765714902585
for this epoch using 74.70785784721375 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3163066699133386
  (0, 1680)	3.319196744409786
  (0, 1679)	3.3039429567617127
  (0, 1678)	3.317315647104981
  (0, 1677)	3.290570266418451
  (0, 1676)	3.3172605948262452
  (0, 1675)	3.317847698574237
  (0, 1674)	3.317847698574237
  (0, 1673)	3.317847698574237
  (0, 1672)	3.3137282420594008
  (0, 1671)	3.293329955137343
  (0, 1670)	3.317847698574237
  (0, 1669)	3.317847698574237
  (0, 1668)	3.3074999978817408
  (0, 1667)	3.317847698574237
  (0, 1666)	3.317847698574237
  (0, 1665)	3.3074999978817408
  (0, 1664)	3.317847698574237
  (0, 1663)	3.303326963816061
  (0, 1662)	3.3074999978817408
  (0, 1661)	3.305844940042485
  (0, 1660)	3.287497915260867
  (0, 1659)	3.2941625324817525
  (0, 1658)	3.317847698574237
  (0, 1657)	3.3192674003230946
  :	:
  (942, 24)	3.4667587620402176
  (942, 23)	3.446175930430721
  (942, 22)	3.971458145515321
  (942, 21)	4.093244707215547
  (942, 20)	2.9263750152332073
  (942, 19)	3.3861197184054053
  (942, 18)	3.563387970396126
  (942, 17)	3.1541023407904785
  (942, 16)	3.1477709110417984
  (942, 15)	3.244325244236139
  (942, 14)	3.7390298424997197
  (942, 13)	3.872647474324342
  (942, 12)	3.3510544091906582
  (942, 11)	4.259029849183736
  (942, 10)	3.7940592849113717
  (942, 9)	3.5543465575460016
  (942, 8)	3.8663193201304784
  (942, 7)	3.927147644096868
  (942, 6)	3.7928791731734584
  (942, 5)	3.3506085341311405
  (942, 4)	3.2569812925831454
  (942, 3)	3.4606272841875403
  (942, 2)	3.096953476433439
  (942, 1)	3.1992000821756243
  (942, 0)	3.860049787754255
this is the 39 epoch
rmse loss on training set is 0.9539229927160165
rmse loss on test set is 0.9700423125725879
for this epoch using 74.57711720466614 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3149382726634253
  (0, 1680)	3.317942518913192
  (0, 1679)	3.302276678936427
  (0, 1678)	3.3159783479314098
  (0, 1677)	3.288575009941441
  (0, 1676)	3.315937968187233
  (0, 1675)	3.316530712540062
  (0, 1674)	3.316530712540062
  (0, 1673)	3.316530712540062
  (0, 1672)	3.3122356810407707
  (0, 1671)	3.291467956183297
  (0, 1670)	3.316530712540062
  (0, 1669)	3.316530712540062
  (0, 1668)	3.3059712702114883
  (0, 1667)	3.316530712540062
  (0, 1666)	3.316530712540062
  (0, 1665)	3.3059712702114883
  (0, 1664)	3.316530712540062
  (0, 1663)	3.301648864548218
  (0, 1662)	3.3059712702114883
  (0, 1661)	3.304256306272074
  (0, 1660)	3.285412417820767
  (0, 1659)	3.292197751827254
  (0, 1658)	3.316530712540062
  (0, 1657)	3.3180195336107214
  :	:
  (942, 24)	3.4691610277279863
  (942, 23)	3.4497398210849135
  (942, 22)	3.9793228121199675
  (942, 21)	4.097870913674667
  (942, 20)	2.9242135971291767
  (942, 19)	3.3916866889767587
  (942, 18)	3.572112045055366
  (942, 17)	3.155857804563383
  (942, 16)	3.149254416613539
  (942, 15)	3.247878052630665
  (942, 14)	3.7420663240382566
  (942, 13)	3.879619860153459
  (942, 12)	3.3538826170577067
  (942, 11)	4.264789625104993
  (942, 10)	3.7985947884280775
  (942, 9)	3.5620670044474774
  (942, 8)	3.870623506119837
  (942, 7)	3.9323747921124586
  (942, 6)	3.795351865590722
  (942, 5)	3.3569263635763127
  (942, 4)	3.2601634504598014
  (942, 3)	3.4639388461343175
  (942, 2)	3.0977899482092996
  (942, 1)	3.2014952254221023
  (942, 0)	3.862214329769249
this is the 40 epoch
rmse loss on training set is 0.9530972341429905
rmse loss on test set is 0.9692438531928086
for this epoch using 74.46838402748108 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3135907877636264
  (0, 1680)	3.3167099342229998
  (0, 1679)	3.3006313723758605
  (0, 1678)	3.3146617863724965
  (0, 1677)	3.286600958379226
  (0, 1676)	3.3146368977935423
  (0, 1675)	3.315234605961776
  (0, 1674)	3.315234605961776
  (0, 1673)	3.315234605961776
  (0, 1672)	3.31076177840599
  (0, 1671)	3.289629346258161
  (0, 1670)	3.315234605961776
  (0, 1669)	3.315234605961776
  (0, 1668)	3.3044645209594283
  (0, 1667)	3.315234605961776
  (0, 1666)	3.315234605961776
  (0, 1665)	3.3044645209594283
  (0, 1664)	3.315234605961776
  (0, 1663)	3.2999922260725327
  (0, 1662)	3.3044645209594283
  (0, 1661)	3.302689443528872
  (0, 1660)	3.283348694024395
  (0, 1659)	3.290255202839083
  (0, 1658)	3.315234605961776
  (0, 1657)	3.316793857660505
  :	:
  (942, 24)	3.4715050014946662
  (942, 23)	3.45318289526153
  (942, 22)	3.986899333919536
  (942, 21)	4.102316293752635
  (942, 20)	2.9220998198142394
  (942, 19)	3.3971571436940624
  (942, 18)	3.5806789033524318
  (942, 17)	3.157566280326657
  (942, 16)	3.150709089699168
  (942, 15)	3.251374066472934
  (942, 14)	3.744970704043409
  (942, 13)	3.886325139223006
  (942, 12)	3.356644411694543
  (942, 11)	4.270293290747372
  (942, 10)	3.8029570189201274
  (942, 9)	3.5696245919566865
  (942, 8)	3.8747421042455428
  (942, 7)	3.9373889765980943
  (942, 6)	3.7977559908372434
  (942, 5)	3.3631785032135983
  (942, 4)	3.2632801213587452
  (942, 3)	3.467173980756468
  (942, 2)	3.0986185244248343
  (942, 1)	3.2037607914943163
  (942, 0)	3.8643335076212537
this is the 41 epoch
rmse loss on training set is 0.9523039627417423
rmse loss on test set is 0.968478875339729
for this epoch using 74.64199590682983 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3122666751549117
  (0, 1680)	3.315501399396137
  (0, 1679)	3.299009473055658
  (0, 1678)	3.313368413042755
  (0, 1677)	3.284650533068561
  (0, 1676)	3.313359815713353
  (0, 1675)	3.313961822425753
  (0, 1674)	3.313961822425753
  (0, 1673)	3.313961822425753
  (0, 1672)	3.3093090405497962
  (0, 1671)	3.287816491040642
  (0, 1670)	3.313961822425753
  (0, 1669)	3.313961822425753
  (0, 1668)	3.302982135728511
  (0, 1667)	3.313961822425753
  (0, 1666)	3.313961822425753
  (0, 1665)	3.302982135728511
  (0, 1664)	3.313961822425753
  (0, 1663)	3.298359482433904
  (0, 1662)	3.302982135728511
  (0, 1661)	3.301146763374036
  (0, 1660)	3.28130917936207
  (0, 1659)	3.288337349713853
  (0, 1658)	3.313961822425753
  (0, 1657)	3.315592789854487
  :	:
  (942, 24)	3.4737941268133015
  (942, 23)	3.4565108038608687
  (942, 22)	3.994202223949155
  (942, 21)	4.106594959599906
  (942, 20)	2.920033285335675
  (942, 19)	3.402533517630023
  (942, 18)	3.589091988279591
  (942, 17)	3.159229136071511
  (942, 16)	3.152135857957305
  (942, 15)	3.254814840780523
  (942, 14)	3.7477526403820742
  (942, 13)	3.8927765865887265
  (942, 12)	3.359343029913236
  (942, 11)	4.2755595978331655
  (942, 10)	3.807157122390721
  (942, 9)	3.5770233900971733
  (942, 8)	3.87868776535592
  (942, 7)	3.9422042851579286
  (942, 6)	3.800097098495249
  (942, 5)	3.3693662463944403
  (942, 4)	3.2663329466827724
  (942, 3)	3.470336803914892
  (942, 2)	3.099439463770937
  (942, 1)	3.2059973909850177
  (942, 0)	3.8664112012648024
this is the 42 epoch
rmse loss on training set is 0.9515411879488905
rmse loss on test set is 0.9677452637412766
for this epoch using 75.21616721153259 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.310967850594533
  (0, 1680)	3.31431878202577
  (0, 1679)	3.2974128749031713
  (0, 1678)	3.3121001351961548
  (0, 1677)	3.2827256146101886
  (0, 1676)	3.3121086106813253
  (0, 1675)	3.3127142624828725
  (0, 1674)	3.3127142624828725
  (0, 1673)	3.3127142624828725
  (0, 1672)	3.3078794292376976
  (0, 1671)	3.2860312174319226
  (0, 1670)	3.3127142624828725
  (0, 1669)	3.3127142624828725
  (0, 1668)	3.3015259604269214
  (0, 1667)	3.3127142624828725
  (0, 1666)	3.3127142624828725
  (0, 1665)	3.3015259604269214
  (0, 1664)	3.3127142624828725
  (0, 1663)	3.296752525205426
  (0, 1662)	3.3015259604269214
  (0, 1661)	3.2996301364498204
  (0, 1660)	3.2792957665185534
  (0, 1659)	3.286446108093004
  (0, 1658)	3.3127142624828725
  (0, 1657)	3.314418204855563
  :	:
  (942, 24)	3.4760314208651173
  (942, 23)	3.4597288271077278
  (942, 22)	4.001245104950433
  (942, 21)	4.110719621380809
  (942, 20)	2.918013519443652
  (942, 19)	3.4078181054018324
  (942, 18)	3.5973546089855195
  (942, 17)	3.1608476668234364
  (942, 16)	3.153535570735039
  (942, 15)	3.2582018365693353
  (942, 14)	3.7504208774144234
  (942, 13)	3.8989866784098925
  (942, 12)	3.3619814120989573
  (942, 11)	4.280605645189123
  (942, 10)	3.8112053201847353
  (942, 9)	3.58426729858008
  (942, 8)	3.8824720628372282
  (942, 7)	3.9468336672006954
  (942, 6)	3.802379962043223
  (942, 5)	3.37549081472514
  (942, 4)	3.2693234759992365
  (942, 3)	3.4734310118572647
  (942, 2)	3.1002529625074287
  (942, 1)	3.2082055450461273
  (942, 0)	3.868450596458794
this is the 43 epoch
rmse loss on training set is 0.9508070889282859
rmse loss on test set is 0.9670410836533037
for this epoch using 76.10336995124817 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3096957647586374
  (0, 1680)	3.313163487200959
  (0, 1679)	3.2958430087576702
  (0, 1678)	3.3108583957652082
  (0, 1677)	3.280827621750128
  (0, 1676)	3.310884707193712
  (0, 1675)	3.3114933626697085
  (0, 1674)	3.3114933626697085
  (0, 1673)	3.3114933626697085
  (0, 1672)	3.306474440697743
  (0, 1671)	3.2842748923694263
  (0, 1670)	3.3114933626697085
  (0, 1669)	3.3114933626697085
  (0, 1668)	3.3000973800981157
  (0, 1667)	3.3114933626697085
  (0, 1666)	3.3114933626697085
  (0, 1665)	3.3000973800981157
  (0, 1664)	3.3114933626697085
  (0, 1663)	3.295172782508991
  (0, 1662)	3.3000973800981157
  (0, 1661)	3.298140971373263
  (0, 1660)	3.277309884452546
  (0, 1659)	3.2845829248103904
  (0, 1658)	3.3114933626697085
  (0, 1657)	3.3132715136345188
  :	:
  (942, 24)	3.4782195323284353
  (942, 23)	3.4628419058762687
  (942, 22)	4.008040773043303
  (942, 21)	4.114701733359592
  (942, 20)	2.9160399831275297
  (942, 19)	3.413013074470645
  (942, 18)	3.6054699511649315
  (942, 17)	3.1624231012860498
  (942, 16)	3.1549090089620697
  (942, 15)	3.2615364295390297
  (942, 14)	3.7529833393647625
  (942, 13)	3.9049671482455253
  (942, 12)	3.364562234588231
  (942, 11)	4.285447033548422
  (942, 10)	3.8151109940276275
  (942, 9)	3.5913600605030687
  (942, 8)	3.886105592455409
  (942, 7)	3.951289033347359
  (942, 6)	3.804608688641803
  (942, 5)	3.3815533650155767
  (942, 4)	3.27225317754749
  (942, 3)	3.4764599299357695
  (942, 2)	3.10105916455044
  (942, 1)	3.2103856997738784
  (942, 0)	3.870454299645048
this is the 44 epoch
rmse loss on training set is 0.9500999959718108
rmse loss on test set is 0.9663645615487381
for this epoch using 75.50591611862183 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3084514721448928
  (0, 1680)	3.31203652627432
  (0, 1679)	3.294300911135534
  (0, 1678)	3.309644242206076
  (0, 1677)	3.2789575800649953
  (0, 1676)	3.3096891344013963
  (0, 1675)	3.3103001643371153
  (0, 1674)	3.3103001643371153
  (0, 1673)	3.3103001643371153
  (0, 1672)	3.3050951745123336
  (0, 1671)	3.282548491444757
  (0, 1670)	3.3103001643371153
  (0, 1669)	3.3103001643371153
  (0, 1668)	3.298697387565719
  (0, 1667)	3.3103001643371153
  (0, 1666)	3.3103001643371153
  (0, 1665)	3.298697387565719
  (0, 1664)	3.3103001643371153
  (0, 1663)	3.293621287833399
  (0, 1662)	3.298697387565719
  (0, 1661)	3.2966802834402347
  (0, 1660)	3.275352567260124
  (0, 1659)	3.2827488473591346
  (0, 1658)	3.3103001643371153
  (0, 1657)	3.31215373230352
  :	:
  (942, 24)	3.480360791602342
  (942, 23)	3.4658546698802324
  (942, 22)	4.014601256145983
  (942, 21)	4.1185516245263
  (942, 20)	2.9141120827136984
  (942, 19)	3.4181204770161893
  (942, 18)	3.6134410863604756
  (942, 17)	3.163956607747132
  (942, 16)	3.1562568937191737
  (942, 15)	3.264819917840395
  (942, 14)	3.755447213811519
  (942, 13)	3.91072903878147
  (942, 12)	3.367087938356072
  (942, 11)	4.290098005370925
  (942, 10)	3.818882762744115
  (942, 9)	3.5983052745476245
  (942, 8)	3.8895980625177247
  (942, 7)	3.955581345708015
  (942, 6)	3.8067868140188303
  (942, 5)	3.3875549954663637
  (942, 4)	3.275123447344685
  (942, 3)	3.479426555608262
  (942, 2)	3.1018581701507824
  (942, 1)	3.2125382385816543
  (942, 0)	3.872424435400013
this is the 45 epoch
rmse loss on training set is 0.9494183743758708
rmse loss on test set is 0.9657140682728241
for this epoch using 75.263986825943 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3072356910153204
  (0, 1680)	3.310938576677331
  (0, 1679)	3.2927872840412302
  (0, 1678)	3.308458386388941
  (0, 1677)	3.277116181693512
  (0, 1676)	3.3085225860412457
  (0, 1675)	3.309135373525546
  (0, 1674)	3.309135373525546
  (0, 1673)	3.309135373525546
  (0, 1672)	3.303742393550151
  (0, 1671)	3.2808526585683455
  (0, 1670)	3.309135373525546
  (0, 1669)	3.309135373525546
  (0, 1668)	3.2973266431330543
  (0, 1667)	3.309135373525546
  (0, 1666)	3.309135373525546
  (0, 1665)	3.2973266431330543
  (0, 1664)	3.309135373525546
  (0, 1663)	3.292098739891741
  (0, 1662)	3.2973266431330543
  (0, 1661)	3.2952487543799585
  (0, 1660)	3.273424514066309
  (0, 1659)	3.280944584327615
  (0, 1658)	3.309135373525546
  (0, 1657)	3.3110655419956436
  :	:
  (942, 24)	3.482457254420896
  (942, 23)	3.4687714630747384
  (942, 22)	4.020937867626234
  (942, 21)	4.122278615408254
  (942, 20)	2.9122291787052608
  (942, 19)	3.423142260543632
  (942, 18)	3.621270980298313
  (942, 17)	3.1654492993330687
  (942, 16)	3.157579893658679
  (942, 15)	3.2680535290270822
  (942, 14)	3.7578190263660267
  (942, 13)	3.916282749398663
  (942, 12)	3.369560754441194
  (942, 11)	4.294571571158177
  (942, 10)	3.822528551504384
  (942, 9)	3.6051064058532813
  (942, 8)	3.892958375318183
  (942, 7)	3.959720699893943
  (942, 6)	3.8089173844107607
  (942, 5)	3.3934967511795637
  (942, 4)	3.2779356170765723
  (942, 3)	3.482333596392212
  (942, 2)	3.1026500433523734
  (942, 1)	3.2146634928275537
  (942, 0)	3.874362728959917
this is the 46 epoch
rmse loss on training set is 0.9487608104107
rmse loss on test set is 0.9650881043022534
for this epoch using 75.91828203201294 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.306048855475851
  (0, 1680)	3.309870033879474
  (0, 1679)	3.29130254692111
  (0, 1678)	3.307301256629815
  (0, 1677)	3.275303837212401
  (0, 1676)	3.3073854725026166
  (0, 1675)	3.3079994129828827
  (0, 1674)	3.3079994129828827
  (0, 1673)	3.3079994129828827
  (0, 1672)	3.3024165760350117
  (0, 1671)	3.279187757779513
  (0, 1670)	3.3079994129828827
  (0, 1669)	3.3079994129828827
  (0, 1668)	3.2959855264336664
  (0, 1667)	3.3079994129828827
  (0, 1666)	3.3079994129828827
  (0, 1665)	3.2959855264336664
  (0, 1664)	3.3079994129828827
  (0, 1663)	3.2906055546158237
  (0, 1662)	3.2959855264336664
  (0, 1661)	3.2938467842566586
  (0, 1660)	3.2715261410451544
  (0, 1659)	3.2791705579095147
  (0, 1658)	3.3079994129828827
  (0, 1657)	3.3100073408862913
  :	:
  (942, 24)	3.4845107396975123
  (942, 23)	3.4715963665759464
  (942, 22)	4.027061255621202
  (942, 21)	4.125891122539936
  (942, 20)	2.9103905935208285
  (942, 19)	3.428080277362565
  (942, 18)	3.628962500365279
  (942, 17)	3.1669022386876233
  (942, 16)	3.1588786314304897
  (942, 15)	3.2712384262823195
  (942, 14)	3.760104707493146
  (942, 13)	3.9216380799547603
  (942, 12)	3.3719827264885986
  (942, 11)	4.298879623595875
  (942, 10)	3.826055654358163
  (942, 9)	3.611766795725902
  (942, 8)	3.8961947007348328
  (942, 7)	3.9637163995495284
  (942, 6)	3.8110030272682445
  (942, 5)	3.399379629069071
  (942, 4)	3.2806909609355674
  (942, 3)	3.4851835033630816
  (942, 2)	3.1034348183949523
  (942, 1)	3.2167617509292135
  (942, 0)	3.8762705759759934
this is the 47 epoch
rmse loss on training set is 0.9481259990661192
rmse loss on test set is 0.9644852868053746
for this epoch using 76.46937298774719 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3048911606607296
  (0, 1680)	3.3088310564588927
  (0, 1679)	3.2898468817285256
  (0, 1678)	3.306173042831297
  (0, 1677)	3.2735207206257457
  (0, 1676)	3.3062779659975234
  (0, 1675)	3.3068924672924394
  (0, 1674)	3.3068924672924394
  (0, 1673)	3.3068924672924394
  (0, 1672)	3.3011179607197456
  (0, 1671)	3.277553918171334
  (0, 1670)	3.3068924672924394
  (0, 1669)	3.3068924672924394
  (0, 1668)	3.294674181400353
  (0, 1667)	3.3068924672924394
  (0, 1666)	3.3068924672924394
  (0, 1665)	3.294674181400353
  (0, 1664)	3.3068924672924394
  (0, 1663)	3.289141910256948
  (0, 1662)	3.294674181400353
  (0, 1661)	3.2924745364864605
  (0, 1660)	3.269657626539147
  (0, 1659)	3.2774269494638086
  (0, 1658)	3.3068924672924394
  (0, 1657)	3.3089792893243
  :	:
  (942, 24)	3.486522862335328
  (942, 23)	3.474333219369917
  (942, 22)	4.032981448420612
  (942, 21)	4.129396751908867
  (942, 20)	2.9085956182694233
  (942, 19)	3.4329362930626033
  (942, 18)	3.636518422323715
  (942, 17)	3.1683164421423546
  (942, 16)	3.1601536892475512
  (942, 15)	3.274375714001067
  (942, 14)	3.762309652322736
  (942, 13)	3.926804271117174
  (942, 12)	3.374355730744228
  (942, 11)	4.303033040725855
  (942, 10)	3.829470790738988
  (942, 9)	3.618289670318118
  (942, 8)	3.899314542760625
  (942, 7)	3.967577024114188
  (942, 6)	3.8130460122151546
  (942, 5)	3.4052045822380803
  (942, 4)	3.283390701547238
  (942, 3)	3.4879785007202897
  (942, 2)	3.104212505203348
  (942, 1)	3.2188332661680104
  (942, 0)	3.8781491013589022
this is the 48 epoch
rmse loss on training set is 0.9475127333110228
rmse loss on test set is 0.9639043382493164
for this epoch using 76.1094799041748 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3037626018761928
  (0, 1680)	3.307821605138626
  (0, 1679)	3.2884202719546463
  (0, 1678)	3.30507373558629
  (0, 1677)	3.271766808323011
  (0, 1676)	3.3052000396890384
  (0, 1675)	3.3058145219647073
  (0, 1674)	3.3058145219647073
  (0, 1673)	3.3058145219647073
  (0, 1672)	3.2998465860195374
  (0, 1671)	3.275951072785734
  (0, 1670)	3.3058145219647073
  (0, 1669)	3.3058145219647073
  (0, 1668)	3.2933925552066428
  (0, 1667)	3.3058145219647073
  (0, 1666)	3.3058145219647073
  (0, 1665)	3.2933925552066428
  (0, 1664)	3.3058145219647073
  (0, 1663)	3.287707786447985
  (0, 1662)	3.2933925552066428
  (0, 1661)	3.29113197682352
  (0, 1660)	3.267818950134684
  (0, 1659)	3.27571373898558
  (0, 1658)	3.3058145219647073
  (0, 1657)	3.307981348926313
  :	:
  (942, 24)	3.488495061648743
  (942, 23)	3.4769856370503445
  (942, 22)	4.038707896270209
  (942, 21)	4.132802382555029
  (942, 20)	2.906843518681181
  (942, 19)	3.43771199409635
  (942, 18)	3.6439414363493188
  (942, 17)	3.16969288343803
  (942, 16)	3.1614056137062874
  (942, 15)	3.277466442798988
  (942, 14)	3.7644387742079126
  (942, 13)	3.9317900415535303
  (942, 12)	3.3766814937973084
  (942, 11)	4.307041779230585
  (942, 10)	3.8327801565500192
  (942, 9)	3.62467814840375
  (942, 8)	3.9023247996706965
  (942, 7)	3.9713104904564926
  (942, 6)	3.815048303558499
  (942, 5)	3.410972523883537
  (942, 4)	3.286036015107701
  (942, 3)	3.4907206118829297
  (942, 2)	3.1049830940869607
  (942, 1)	3.220878263358484
  (942, 0)	3.879999208811856
this is the 49 epoch
rmse loss on training set is 0.9469198946473985
rmse loss on test set is 0.9633440763399925
for this epoch using 75.61155366897583 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.302663008455836
  (0, 1680)	3.3068414765404115
  (0, 1679)	3.287022536377699
  (0, 1678)	3.3040031599967556
  (0, 1677)	3.270041912758643
  (0, 1676)	3.304151501530578
  (0, 1675)	3.3047653972451125
  (0, 1674)	3.3047653972451125
  (0, 1673)	3.3047653972451125
  (0, 1672)	3.298602323857473
  (0, 1671)	3.2743789922319526
  (0, 1670)	3.3047653972451125
  (0, 1669)	3.3047653972451125
  (0, 1668)	3.2921404319326
  (0, 1667)	3.3047653972451125
  (0, 1666)	3.3047653972451125
  (0, 1665)	3.2921404319326
  (0, 1664)	3.3047653972451125
  (0, 1663)	3.286302997980057
  (0, 1662)	3.2921404319326
  (0, 1661)	3.289818907067765
  (0, 1660)	3.266009926447982
  (0, 1659)	3.2740307392460304
  (0, 1658)	3.3047653972451125
  (0, 1657)	3.30701331638678
  :	:
  (942, 24)	3.4904286259608672
  (942, 23)	3.479557028797548
  (942, 22)	4.044249509917241
  (942, 21)	4.136114241375279
  (942, 20)	2.9051335402981753
  (942, 19)	3.442408994568204
  (942, 18)	3.651234152467619
  (942, 17)	3.171032497049197
  (942, 16)	3.1626349199625134
  (942, 15)	3.280511614011217
  (942, 14)	3.7664965527031753
  (942, 13)	3.9366036222570293
  (942, 12)	3.37896160833109
  (942, 11)	4.310914958805295
  (942, 10)	3.8359894703791295
  (942, 9)	3.630935248352919
  (942, 8)	3.905231818457855
  (942, 7)	3.9749241089603866
  (942, 6)	3.817011605478365
  (942, 5)	3.4166843307808454
  (942, 4)	3.2886280358381588
  (942, 3)	3.493411682523013
  (942, 2)	3.105746559756374
  (942, 1)	3.2228969445354587
  (942, 0)	3.8818216224281845
this is the 50 epoch
rmse loss on training set is 0.9463464447760971
rmse loss on test set is 0.9628034051144296
for this epoch using 75.29569911956787 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.3015920729908164
  (0, 1680)	3.3058903323188567
  (0, 1679)	3.2856533581933984
  (0, 1678)	3.3029610048702405
  (0, 1677)	3.2683457115165684
  (0, 1676)	3.3031320234793586
  (0, 1675)	3.303744777300199
  (0, 1674)	3.303744777300199
  (0, 1673)	3.303744777300199
  (0, 1672)	3.297384908885242
  (0, 1671)	3.272837313691657
  (0, 1670)	3.303744777300199
  (0, 1669)	3.303744777300199
  (0, 1668)	3.290917461617343
  (0, 1667)	3.303744777300199
  (0, 1666)	3.303744777300199
  (0, 1665)	3.290917461617343
  (0, 1664)	3.303744777300199
  (0, 1663)	3.2849272239570353
  (0, 1662)	3.290917461617343
  (0, 1661)	3.2885349941567177
  (0, 1660)	3.2642302342857916
  (0, 1659)	3.2723776252701047
  (0, 1658)	3.303744777300199
  (0, 1657)	3.3060748526660526
  :	:
  (942, 24)	3.4923247138709597
  (942, 23)	3.4820506127865007
  (942, 22)	4.049614696188432
  (942, 21)	4.139337970071981
  (942, 20)	2.9034649130164065
  (942, 19)	3.4470288423163558
  (942, 18)	3.658399105456462
  (942, 17)	3.1723361811581956
  (942, 16)	3.163842095349613
  (942, 15)	3.283512183737016
  (942, 14)	3.768487076561389
  (942, 13)	3.9412527882575668
  (942, 12)	3.3811975471120306
  (942, 11)	4.314660938495657
  (942, 10)	3.839104015333955
  (942, 9)	3.6370638944016096
  (942, 8)	3.9080414441043
  (942, 7)	3.9784246345875074
  (942, 6)	3.8189374008806607
  (942, 5)	3.4223408463960387
  (942, 4)	3.291167859848843
  (942, 3)	3.4960534008963355
  (942, 2)	3.10650286474994
  (942, 1)	3.224889493791812
  (942, 0)	3.883616921534454
this is the 51 epoch
rmse loss on training set is 0.9457914182202688
rmse loss on test set is 0.9622813070320025
for this epoch using 75.16416192054749 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.300549376517892
  (0, 1680)	3.3049677242586544
  (0, 1679)	3.2843123101096996
  (0, 1678)	3.3019468478768643
  (0, 1677)	3.2666777723425295
  (0, 1676)	3.302141166667234
  (0, 1675)	3.302752235365068
  (0, 1674)	3.302752235365068
  (0, 1673)	3.302752235365068
  (0, 1672)	3.2961939636622253
  (0, 1671)	3.2713255658939957
  (0, 1670)	3.302752235365068
  (0, 1669)	3.302752235365068
  (0, 1668)	3.289723185280764
  (0, 1667)	3.302752235365068
  (0, 1666)	3.302752235365068
  (0, 1665)	3.289723185280764
  (0, 1664)	3.302752235365068
  (0, 1663)	3.2835800329113836
  (0, 1662)	3.289723185280764
  (0, 1661)	3.2872797952243022
  (0, 1660)	3.2624794417652687
  (0, 1659)	3.270753959739146
  (0, 1658)	3.302752235365068
  (0, 1657)	3.3051655081393743
  :	:
  (942, 24)	3.4941843726241157
  (942, 23)	3.4844694301900354
  (942, 22)	4.054811390862654
  (942, 21)	4.142478685083557
  (942, 20)	2.9018368550585367
  (942, 19)	3.451573024365612
  (942, 18)	3.665438759273876
  (942, 17)	3.173604800319139
  (942, 16)	3.165027602514448
  (942, 15)	3.286469066479742
  (942, 14)	3.7704140822830694
  (942, 13)	3.9457448879460735
  (942, 12)	3.383390675420455
  (942, 11)	4.318287385790603
  (942, 10)	3.8421286769361234
  (942, 9)	3.6430669222983263
  (942, 8)	3.9107590641996217
  (942, 7)	3.981818313388481
  (942, 6)	3.820826984766425
  (942, 5)	3.4279428836670505
  (942, 4)	3.2936565484922946
  (942, 3)	3.4986473157887112
  (942, 2)	3.107251962350645
  (942, 1)	3.226856081381773
  (942, 0)	3.8853855697926587
this is the 52 epoch
rmse loss on training set is 0.9452539157771369
rmse loss on test set is 0.9617768359347791
for this epoch using 77.17104887962341 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2995344101782664
  (0, 1680)	3.3040731158474164
  (0, 1679)	3.2829988759184587
  (0, 1678)	3.300960177179608
  (0, 1677)	3.2650375746573186
  (0, 1676)	3.301178403041966
  (0, 1675)	3.3017872553645478
  (0, 1674)	3.3017872553645478
  (0, 1673)	3.3017872553645478
  (0, 1672)	3.2950290203059236
  (0, 1671)	3.2698431905733463
  (0, 1670)	3.3017872553645478
  (0, 1669)	3.3017872553645478
  (0, 1668)	3.288557056426743
  (0, 1667)	3.3017872553645478
  (0, 1666)	3.3017872553645478
  (0, 1665)	3.288557056426743
  (0, 1664)	3.3017872553645478
  (0, 1663)	3.282260904394407
  (0, 1662)	3.288557056426743
  (0, 1661)	3.2860527791389305
  (0, 1660)	3.2607570279065516
  (0, 1659)	3.2691592148356974
  (0, 1658)	3.3017872553645478
  (0, 1657)	3.3042847442192884
  :	:
  (942, 24)	3.496008553960667
  (942, 23)	3.486816357924671
  (942, 22)	4.059847089074813
  (942, 21)	4.145541031244828
  (942, 20)	2.900248576446692
  (942, 19)	3.4560429718200996
  (942, 18)	3.672355511064129
  (942, 17)	3.1748391878477125
  (942, 16)	3.1661918821359434
  (942, 15)	3.2893831384260896
  (942, 14)	3.7722809886925766
  (942, 13)	3.950086870217624
  (942, 12)	3.38554226210168
  (942, 11)	4.321801339180852
  (942, 10)	3.845067977468335
  (942, 9)	3.648947084400194
  (942, 8)	3.9133896493636255
  (942, 7)	3.9851109248900274
  (942, 6)	3.822681492860115
  (942, 5)	3.4334912274913494
  (942, 4)	3.296095131275274
  (942, 3)	3.5011948523577603
  (942, 2)	3.1079937990628634
  (942, 1)	3.2287968671898866
  (942, 0)	3.8871279394301395
this is the 53 epoch
rmse loss on training set is 0.944733098688511
rmse loss on test set is 0.9612891107657321
for this epoch using 75.21693682670593 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2985465937975804
  (0, 1680)	3.3032059007743584
  (0, 1679)	3.2817124689943187
  (0, 1678)	3.300000409987808
  (0, 1677)	3.2634245280008356
  (0, 1676)	3.300243133929358
  (0, 1675)	3.300849250458327
  (0, 1674)	3.300849250458327
  (0, 1673)	3.300849250458327
  (0, 1672)	3.293889539064177
  (0, 1671)	3.2683895608600406
  (0, 1670)	3.300849250458327
  (0, 1669)	3.300849250458327
  (0, 1668)	3.2874184594775318
  (0, 1667)	3.300849250458327
  (0, 1666)	3.300849250458327
  (0, 1665)	3.2874184594775318
  (0, 1664)	3.300849250458327
  (0, 1663)	3.280969247491304
  (0, 1662)	3.2874184594775318
  (0, 1661)	3.284853344970908
  (0, 1660)	3.2590624011492437
  (0, 1659)	3.2675927909842817
  (0, 1658)	3.300849250458327
  (0, 1657)	3.3034319519016804
  :	:
  (942, 24)	3.4977981277755372
  (942, 23)	3.4890941202691432
  (942, 22)	4.064728873464668
  (942, 21)	4.148529229844172
  (942, 20)	2.8986992820361435
  (942, 19)	3.460440064256804
  (942, 18)	3.679151694788651
  (942, 17)	3.1760401479683082
  (942, 16)	3.1673353552829684
  (942, 15)	3.292255240403506
  (942, 14)	3.7740909279640813
  (942, 13)	3.9542853096196757
  (942, 12)	3.3876534893956918
  (942, 11)	4.325209264822159
  (942, 10)	3.847926107126548
  (942, 9)	3.6547070542819475
  (942, 8)	3.9159377898855663
  (942, 7)	3.9883078207431266
  (942, 6)	3.8245019261408983
  (942, 5)	3.4389866369527007
  (942, 4)	3.2984846083893755
  (942, 3)	3.503697326117467
  (942, 2)	3.108728316709282
  (942, 1)	3.2307120036524086
  (942, 0)	3.888844331340752
this is the 54 epoch
rmse loss on training set is 0.9442281834368743
rmse loss on test set is 0.9608173099498485
for this epoch using 75.49213004112244 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2975852917829283
  (0, 1680)	3.3023654187501137
  (0, 1679)	3.280452448116123
  (0, 1678)	3.299066908429621
  (0, 1677)	3.261837987802635
  (0, 1676)	3.299334705912221
  (0, 1675)	3.2999375789053587
  (0, 1674)	3.2999375789053587
  (0, 1673)	3.2999375789053587
  (0, 1672)	3.2927749242049424
  (0, 1671)	3.2669639969994337
  (0, 1670)	3.2999375789053587
  (0, 1669)	3.2999375789053587
  (0, 1668)	3.286306725534632
  (0, 1667)	3.2999375789053587
  (0, 1666)	3.2999375789053587
  (0, 1665)	3.286306725534632
  (0, 1664)	3.2999375789053587
  (0, 1663)	3.279704416656926
  (0, 1662)	3.286306725534632
  (0, 1661)	3.2836808377845212
  (0, 1660)	3.2573949151888666
  (0, 1659)	3.266054032887111
  (0, 1658)	3.2999375789053587
  (0, 1657)	3.302606467630875
  :	:
  (942, 24)	3.4995538938752015
  (942, 23)	3.4913052994716383
  (942, 22)	4.069463440263381
  (942, 21)	4.151447121672703
  (942, 20)	2.8971881741628476
  (942, 19)	3.4647656336744617
  (942, 18)	3.685829584523265
  (942, 17)	3.1772084577462496
  (942, 16)	3.168458425460165
  (942, 15)	3.2950861805502045
  (942, 14)	3.7758467734737104
  (942, 13)	3.958346429673947
  (942, 12)	3.389725461684783
  (942, 11)	4.3285171078782065
  (942, 10)	3.850706952293215
  (942, 9)	3.66034943091398
  (942, 8)	3.9184077289500228
  (942, 7)	3.991413959979911
  (942, 6)	3.8262891718364336
  (942, 5)	3.44442984731605
  (942, 4)	3.3008259529122137
  (942, 3)	3.506155955283646
  (942, 2)	3.1094554542001833
  (942, 1)	3.232601638206339
  (942, 0)	3.890534991693252
this is the 55 epoch
rmse loss on training set is 0.9437384370880724
rmse loss on test set is 0.9603606663570298
for this epoch using 77.07803392410278 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.296649826683702
  (0, 1680)	3.30155096899456
  (0, 1679)	3.279218130957811
  (0, 1678)	3.298158993090205
  (0, 1677)	3.260277268825413
  (0, 1676)	3.298452424373226
  (0, 1675)	3.2990515575944968
  (0, 1674)	3.2990515575944968
  (0, 1673)	3.2990515575944968
  (0, 1672)	3.2916845375706956
  (0, 1671)	3.265565779745973
  (0, 1670)	3.2990515575944968
  (0, 1669)	3.2990515575944968
  (0, 1668)	3.2852211458123626
  (0, 1667)	3.2990515575944968
  (0, 1666)	3.2990515575944968
  (0, 1665)	3.2852211458123626
  (0, 1664)	3.2990515575944968
  (0, 1663)	3.278465725219133
  (0, 1662)	3.2852211458123626
  (0, 1661)	3.282534562101186
  (0, 1660)	3.255753882480599
  (0, 1659)	3.2645422432043376
  (0, 1658)	3.2990515575944968
  (0, 1657)	3.3018075868306074
  :	:
  (942, 24)	3.5012765920838733
  (942, 23)	3.493452345448061
  (942, 22)	4.0740571234924525
  (942, 21)	4.154298205596302
  (942, 20)	2.8957144549513965
  (942, 19)	3.469020968046
  (942, 18)	3.6923913974582945
  (942, 17)	3.1783448688296354
  (942, 16)	3.1695614803841132
  (942, 15)	3.2978767367285275
  (942, 14)	3.7775511648132256
  (942, 13)	3.9622761245248714
  (942, 12)	3.3917592132822514
  (942, 11)	4.331730339060249
  (942, 10)	3.8534141212144766
  (942, 9)	3.66587674245829
  (942, 8)	3.920803392781712
  (942, 7)	3.9944339411933663
  (942, 6)	3.8280440213641618
  (942, 5)	3.4498215718164746
  (942, 4)	3.3031201127243577
  (942, 3)	3.5085718716725074
  (942, 2)	3.110175149020254
  (942, 1)	3.2344659153314916
  (942, 0)	3.892200125590328
this is the 56 epoch
rmse loss on training set is 0.9432631731127553
rmse loss on test set is 0.9599184627762818
for this epoch using 76.2860279083252 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.295739490721001
  (0, 1680)	3.300761821696912
  (0, 1679)	3.2780088055528394
  (0, 1678)	3.297275954519934
  (0, 1677)	3.258741656585749
  (0, 1676)	3.2975955650061057
  (0, 1675)	3.298190473545626
  (0, 1674)	3.298190473545626
  (0, 1673)	3.298190473545626
  (0, 1672)	3.2906177101020244
  (0, 1671)	3.2641941617363797
  (0, 1670)	3.298190473545626
  (0, 1669)	3.298190473545626
  (0, 1668)	3.2841609830482517
  (0, 1667)	3.298190473545626
  (0, 1666)	3.298190473545626
  (0, 1665)	3.2841609830482517
  (0, 1664)	3.298190473545626
  (0, 1663)	3.277252456854198
  (0, 1662)	3.2841609830482517
  (0, 1661)	3.2814137933379266
  (0, 1660)	3.254138585715032
  (0, 1659)	3.2630566941859462
  (0, 1658)	3.298190473545626
  (0, 1657)	3.301034575405182
  :	:
  (942, 24)	3.5029669109179977
  (942, 23)	3.495537584662506
  (942, 22)	4.078515917432469
  (942, 21)	4.157085673124379
  (942, 20)	2.894277328323864
  (942, 19)	3.47320731451717
  (942, 18)	3.6988392966338988
  (942, 17)	3.179450109022319
  (942, 16)	3.170644893526144
  (942, 15)	3.3006276587085974
  (942, 14)	3.7792065302641955
  (942, 13)	3.9660799790529597
  (942, 12)	3.393755715370907
  (942, 11)	4.3348539968288256
  (942, 10)	3.856050967334906
  (942, 9)	3.671291449725556
  (942, 8)	3.9231284180082606
  (942, 7)	3.99737203192298
  (942, 6)	3.8297671856404762
  (942, 5)	3.455162503264852
  (942, 4)	3.305368012180822
  (942, 3)	3.510946130322256
  (942, 2)	3.110887338472002
  (942, 1)	3.2363049782421425
  (942, 0)	3.893839908241663
this is the 57 epoch
rmse loss on training set is 0.9428017476283631
rmse loss on test set is 0.9594900278410006
for this epoch using 76.19562721252441 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.294853555552229
  (0, 1680)	3.2999972277145844
  (0, 1679)	3.2768237399987745
  (0, 1678)	3.296417062979323
  (0, 1677)	3.2572304170182216
  (0, 1676)	3.2967633835622827
  (0, 1675)	3.297353593647739
  (0, 1674)	3.297353593647739
  (0, 1673)	3.297353593647739
  (0, 1672)	3.289573751597091
  (0, 1671)	3.2628483771081678
  (0, 1670)	3.297353593647739
  (0, 1669)	3.297353593647739
  (0, 1668)	3.2831254811563686
  (0, 1667)	3.297353593647739
  (0, 1666)	3.297353593647739
  (0, 1665)	3.2831254811563686
  (0, 1664)	3.297353593647739
  (0, 1663)	3.27606387530095
  (0, 1662)	3.2831254811563686
  (0, 1661)	3.280317787487446
  (0, 1660)	3.2525482875327656
  (0, 1659)	3.261596637524028
  (0, 1658)	3.297353593647739
  (0, 1657)	3.30028667947741
  :	:
  (942, 24)	3.504625495020264
  (942, 23)	3.497563228270974
  (942, 22)	4.082845497504749
  (942, 21)	4.159812439397847
  (942, 20)	2.892876001745413
  (942, 19)	3.477325882289661
  (942, 18)	3.705175393439507
  (942, 17)	3.1805248837070432
  (942, 16)	3.171709025453712
  (942, 15)	3.303339670146449
  (942, 14)	3.7808151069988587
  (942, 13)	3.969763287578804
  (942, 12)	3.3957158821873668
  (942, 11)	4.337892725676379
  (942, 10)	3.8586206105175376
  (942, 9)	3.6765959493313622
  (942, 8)	3.925386176509588
  (942, 7)	4.000232195502634
  (942, 6)	3.8314593081224553
  (942, 5)	3.460453315490614
  (942, 4)	3.307570553570914
  (942, 3)	3.513279717986955
  (942, 2)	3.111591960709759
  (942, 1)	3.2381189702775197
  (942, 0)	3.8954544940466698
this is the 58 epoch
rmse loss on training set is 0.9423535560121187
rmse loss on test set is 0.9590747323529464
for this epoch using 76.44274926185608 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2939912805046108
  (0, 1680)	3.2992564267443574
  (0, 1679)	3.2756621906353156
  (0, 1678)	3.295581576654238
  (0, 1677)	3.255742804616402
  (0, 1676)	3.2959551240663805
  (0, 1675)	3.296540172867734
  (0, 1674)	3.296540172867734
  (0, 1673)	3.296540172867734
  (0, 1672)	3.288551958940772
  (0, 1671)	3.2615276495967502
  (0, 1670)	3.296540172867734
  (0, 1669)	3.296540172867734
  (0, 1668)	3.2821138733568347
  (0, 1667)	3.296540172867734
  (0, 1666)	3.296540172867734
  (0, 1665)	3.2821138733568347
  (0, 1664)	3.296540172867734
  (0, 1663)	3.2748992325472233
  (0, 1662)	3.2821138733568347
  (0, 1661)	3.2792457892730384
  (0, 1660)	3.25098223871154
  (0, 1659)	3.2601613126609803
  (0, 1658)	3.296540172867734
  (0, 1657)	3.2995631335968345
  :	:
  (942, 24)	3.506252951519651
  (942, 23)	3.499531379600152
  (942, 22)	4.087051239695111
  (942, 21)	4.1624811709737735
  (942, 20)	2.891509687737644
  (942, 19)	3.4813778452222226
  (942, 18)	3.7114017499025698
  (942, 17)	3.181569877135443
  (942, 16)	3.172754224997271
  (942, 15)	3.3060134703781707
  (942, 14)	3.782378959245518
  (942, 13)	3.9733310712716894
  (942, 12)	3.3976405765369293
  (942, 11)	4.3408508108675665
  (942, 10)	3.8611259563530798
  (942, 9)	3.6817925765847916
  (942, 8)	3.92757979799549
  (942, 7)	4.003018115601907
  (942, 6)	3.8331209758975398
  (942, 5)	3.465694664639398
  (942, 4)	3.3097286183954977
  (942, 3)	3.5155735606351715
  (942, 2)	3.112288955593351
  (942, 1)	3.239908036033551
  (942, 0)	3.8970440239229953
this is the 59 epoch
rmse loss on training set is 0.9419180298412939
rmse loss on test set is 0.9586719859593948
for this epoch using 77.61320233345032 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2931519194822663
  (0, 1680)	3.298538654170163
  (0, 1679)	3.274523408900138
  (0, 1678)	3.294768748545745
  (0, 1677)	3.2542780692545366
  (0, 1676)	3.2951700257054957
  (0, 1675)	3.2957494611341134
  (0, 1674)	3.2957494611341134
  (0, 1673)	3.2957494611341134
  (0, 1672)	3.2875516230079835
  (0, 1671)	3.2602311993151996
  (0, 1670)	3.2957494611341134
  (0, 1669)	3.2957494611341134
  (0, 1668)	3.2811253889855503
  (0, 1667)	3.2957494611341134
  (0, 1666)	3.2957494611341134
  (0, 1665)	3.2811253889855503
  (0, 1664)	3.2957494611341134
  (0, 1663)	3.2737577756929936
  (0, 1662)	3.2811253889855503
  (0, 1661)	3.278197038982576
  (0, 1660)	3.2494396850303033
  (0, 1659)	3.2587499537599647
  (0, 1658)	3.2957494611341134
  (0, 1657)	3.2988631676227618
  :	:
  (942, 24)	3.5078498554625255
  (942, 23)	3.501444041025546
  (942, 22)	4.091138238637121
  (942, 21)	4.165094310743233
  (942, 20)	2.890177605187372
  (942, 19)	3.4853643441800295
  (942, 18)	3.7175203807892756
  (942, 17)	3.1825857535997093
  (942, 16)	3.1737808302666415
  (942, 15)	3.3086497360488143
  (942, 14)	3.783899994630131
  (942, 13)	3.9767880943663454
  (942, 12)	3.3995306147141875
  (942, 11)	4.343732209976875
  (942, 10)	3.8635697137419105
  (942, 9)	3.686883608138912
  (942, 8)	3.929712190529151
  (942, 7)	4.005733218669815
  (942, 6)	3.8347527290944132
  (942, 5)	3.4708871903415632
  (942, 4)	3.3118430684870255
  (942, 3)	3.5178285300696115
  (942, 2)	3.112978265387029
  (942, 1)	3.2416723222729056
  (942, 0)	3.8986086311671326
this is the 60 epoch
rmse loss on training set is 0.9414946341238906
rmse loss on test set is 0.9582812341440894
for this epoch using 81.24843382835388 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2923347267255667
  (0, 1680)	3.297843146766287
  (0, 1679)	3.2734066470411234
  (0, 1678)	3.2939778322135687
  (0, 1677)	3.2528354618686817
  (0, 1676)	3.2944073285709417
  (0, 1675)	3.294980709074606
  (0, 1674)	3.294980709074606
  (0, 1673)	3.294980709074606
  (0, 1672)	3.286572034420154
  (0, 1671)	3.258958248395016
  (0, 1670)	3.294980709074606
  (0, 1669)	3.294980709074606
  (0, 1668)	3.2801592591626463
  (0, 1667)	3.294980709074606
  (0, 1666)	3.294980709074606
  (0, 1665)	3.2801592591626463
  (0, 1664)	3.294980709074606
  (0, 1663)	3.2726387526690552
  (0, 1662)	3.2801592591626463
  (0, 1661)	3.277170778160039
  (0, 1660)	3.2479198729892977
  (0, 1659)	3.2573617955177827
  (0, 1658)	3.294980709074606
  (0, 1657)	3.2981860124607483
  :	:
  (942, 24)	3.5094167544411143
  (942, 23)	3.503303120306061
  (942, 22)	4.095111324461303
  (942, 21)	4.167654100283197
  (942, 20)	2.888878980474696
  (942, 19)	3.4892864891587885
  (942, 18)	3.7235332555370495
  (942, 17)	3.1835731584989744
  (942, 16)	3.1747891695370405
  (942, 15)	3.31124912259333
  (942, 14)	3.7853799788833697
  (942, 13)	3.980138879282019
  (942, 12)	3.4013867708955874
  (942, 11)	4.34654058152924
  (942, 10)	3.8659544109133135
  (942, 9)	3.691871264428831
  (942, 8)	3.9317860591920444
  (942, 7)	4.00838069447027
  (942, 6)	3.8363550688515433
  (942, 5)	3.4760315167655813
  (942, 4)	3.313914746993868
  (942, 3)	3.520045449770564
  (942, 2)	3.1136598353254037
  (942, 1)	3.243411978645259
  (942, 0)	3.900148446090125
this is the 61 epoch
rmse loss on training set is 0.9410828647869882
rmse loss on test set is 0.9579019554973692
for this epoch using 81.37375211715698 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.291538961579499
  (0, 1680)	3.297169147412182
  (0, 1679)	3.272311162841213
  (0, 1678)	3.293208086529382
  (0, 1677)	3.2514142391530494
  (0, 1676)	3.2936662784091753
  (0, 1675)	3.2942331727637826
  (0, 1674)	3.2942331727637826
  (0, 1673)	3.2942331727637826
  (0, 1672)	3.2856124883111644
  (0, 1671)	3.2577080256438924
  (0, 1670)	3.2942331727637826
  (0, 1669)	3.2942331727637826
  (0, 1668)	3.279214721475609
  (0, 1667)	3.2942331727637826
  (0, 1666)	3.2942331727637826
  (0, 1665)	3.279214721475609
  (0, 1664)	3.2942331727637826
  (0, 1663)	3.2715414169673647
  (0, 1662)	3.279214721475609
  (0, 1661)	3.276166254310797
  (0, 1660)	3.246422054542197
  (0, 1659)	3.2559960779779957
  (0, 1658)	3.2942331727637826
  (0, 1657)	3.297530904809048
  :	:
  (942, 24)	3.5109541725293143
  (942, 23)	3.5051104364260293
  (942, 22)	4.0989750785072
  (942, 21)	4.170162599910767
  (942, 20)	2.8876130484416724
  (942, 19)	3.493145361207484
  (942, 18)	3.7294423000365575
  (942, 17)	3.1845327193118123
  (942, 16)	3.175779562022574
  (942, 15)	3.313812265584294
  (942, 14)	3.7868205490821025
  (942, 13)	3.9833877207295045
  (942, 12)	3.40320978106259
  (942, 11)	4.349279311019066
  (942, 10)	3.868282410029965
  (942, 9)	3.6967577119203674
  (942, 8)	3.9338039230666535
  (942, 7)	4.010963514880167
  (942, 6)	3.837928464047553
  (942, 5)	3.481128253568904
  (942, 4)	3.3159444792480346
  (942, 3)	3.52222510005411
  (942, 2)	3.1143336140655173
  (942, 1)	3.245127158245407
  (942, 0)	3.9016635996344142
this is the 62 epoch
rmse loss on training set is 0.9406822463946315
rmse loss on test set is 0.9575336592354373
for this epoch using 82.0443229675293 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2907638924073006
  (0, 1680)	3.2965159089554277
  (0, 1679)	3.271236223492148
  (0, 1678)	3.292458779576463
  (0, 1677)	3.250013667407842
  (0, 1676)	3.292946130518293
  (0, 1675)	3.2935061176174267
  (0, 1674)	3.2935061176174267
  (0, 1673)	3.2935061176174267
  (0, 1672)	3.2846722882394825
  (0, 1671)	3.256479770356545
  (0, 1670)	3.2935061176174267
  (0, 1669)	3.2935061176174267
  (0, 1668)	3.278291023813301
  (0, 1667)	3.2935061176174267
  (0, 1666)	3.2935061176174267
  (0, 1665)	3.278291023813301
  (0, 1664)	3.2935061176174267
  (0, 1663)	3.2704650315196204
  (0, 1662)	3.278291023813301
  (0, 1661)	3.2751827247566814
  (0, 1660)	3.2449454909768094
  (0, 1659)	3.2546520504819054
  (0, 1658)	3.2935061176174267
  (0, 1657)	3.2968970910513415
  :	:
  (942, 24)	3.5124626136211705
  (942, 23)	3.5068677249902644
  (942, 22)	4.102733847986118
  (942, 21)	4.172621706679708
  (942, 20)	2.8863790532201636
  (942, 19)	3.4969420141707013
  (942, 18)	3.73524939827885
  (942, 17)	3.1854650464851306
  (942, 16)	3.1767523185523676
  (942, 15)	3.3163397819600937
  (942, 14)	3.7882232255759694
  (942, 13)	3.986538698884169
  (942, 12)	3.405000346507569
  (942, 11)	4.351951534556101
  (942, 10)	3.870555920510864
  (942, 9)	3.7015450651890762
  (942, 8)	3.9357681306957386
  (942, 7)	4.013484451105055
  (942, 6)	3.8394733569702137
  (942, 5)	3.48617799675728
  (942, 4)	3.3179330735323487
  (942, 3)	3.5243682226248976
  (942, 2)	3.114999554041369
  (942, 1)	3.246818018033376
  (942, 0)	3.903154226146194
this is the 63 epoch
rmse loss on training set is 0.9402923300704839
rmse loss on test set is 0.9571758829421991
for this epoch using 81.5919120311737 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2900087997689678
  (0, 1680)	3.2958826973419173
  (0, 1679)	3.270181108736246
  (0, 1678)	3.2917291918150013
  (0, 1677)	3.2486330256574787
  (0, 1676)	3.2922461529096236
  (0, 1675)	3.2927988215526667
  (0, 1674)	3.2927988215526667
  (0, 1673)	3.2927988215526667
  (0, 1672)	3.2837507493656655
  (0, 1671)	3.255272735397435
  (0, 1670)	3.2927988215526667
  (0, 1669)	3.2927988215526667
  (0, 1668)	3.2773874274698573
  (0, 1667)	3.2927988215526667
  (0, 1666)	3.2927988215526667
  (0, 1665)	3.2773874274698573
  (0, 1664)	3.2927988215526667
  (0, 1663)	3.2694088718432384
  (0, 1662)	3.2773874274698573
  (0, 1661)	3.274219459760104
  (0, 1660)	3.243489456063677
  (0, 1659)	3.2533289748777614
  (0, 1658)	3.2927988215526667
  (0, 1657)	3.296283830415137
  :	:
  (942, 24)	3.5139425642552284
  (942, 23)	3.508576643212891
  (942, 22)	4.106391759675092
  (942, 21)	4.175033170533535
  (942, 20)	2.8851762489353154
  (942, 19)	3.5006774762695185
  (942, 18)	3.740956393881499
  (942, 17)	3.1863707342482717
  (942, 16)	3.177707742162601
  (942, 15)	3.3188322711454443
  (942, 14)	3.7895894227340454
  (942, 13)	3.989595691696052
  (942, 12)	3.4067591369682244
  (942, 11)	4.35456016036213
  (942, 10)	3.87277701119259
  (942, 9)	3.7062353888477353
  (942, 8)	3.937680874161403
  (942, 7)	4.015946089452659
  (942, 6)	3.840990168076569
  (942, 5)	3.4911813294623735
  (942, 4)	3.319881321761175
  (942, 3)	3.5264755245945065
  (942, 2)	3.115657611735136
  (942, 1)	3.2484847191371458
  (942, 0)	3.9046204654509906
this is the 64 epoch
rmse loss on training set is 0.9399126916036347
rmse loss on test set is 0.9568281905105558
for this epoch using 83.60242199897766 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.289272978968455
  (0, 1680)	3.295268794117191
  (0, 1679)	3.2691451133798726
  (0, 1678)	3.2910186186169863
  (0, 1677)	3.247271608142755
  (0, 1676)	3.2915656288383377
  (0, 1675)	3.2921105775179207
  (0, 1674)	3.2921105775179207
  (0, 1673)	3.2921105775179207
  (0, 1672)	3.2828472009992566
  (0, 1671)	3.254086189659027
  (0, 1670)	3.2921105775179207
  (0, 1669)	3.2921105775179207
  (0, 1668)	3.2765032096219775
  (0, 1667)	3.2921105775179207
  (0, 1666)	3.2921105775179207
  (0, 1665)	3.2765032096219775
  (0, 1664)	3.2921105775179207
  (0, 1663)	3.268372228558401
  (0, 1662)	3.2765032096219775
  (0, 1661)	3.2732757450207424
  (0, 1660)	3.2420532385760708
  (0, 1659)	3.252026128092898
  (0, 1658)	3.2921105775179207
  (0, 1657)	3.2956903974997003
  :	:
  (942, 24)	3.515394495996798
  (942, 23)	3.510238774536506
  (942, 22)	4.109952732714793
  (942, 21)	4.177398608806701
  (942, 20)	2.884003900299
  (942, 19)	3.5043527515375033
  (942, 18)	3.7465650915060364
  (942, 17)	3.1872503613604
  (942, 16)	3.1786461286158025
  (942, 15)	3.321290316074888
  (942, 14)	3.790920458632092
  (942, 13)	3.9925623864019975
  (942, 12)	3.4084867934315324
  (942, 11)	4.357107888320443
  (942, 10)	3.8749476214365375
  (942, 9)	3.7108306993376354
  (942, 8)	3.9395442019128715
  (942, 7)	4.018350845791339
  (942, 6)	3.8424792999757424
  (942, 5)	3.496138822646455
  (942, 4)	3.3217900000867493
  (942, 3)	3.5285476820275923
  (942, 2)	3.1163077478773964
  (942, 1)	3.250127427055954
  (942, 0)	3.906062464356669
this is the 65 epoch
rmse loss on training set is 0.9395429297185753
rmse loss on test set is 0.9564901702625705
for this epoch using 83.47040891647339 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.288555742060268
  (0, 1680)	3.294673498389372
  (0, 1679)	3.268127549269156
  (0, 1678)	3.2903263722611586
  (0, 1677)	3.2459287262771603
  (0, 1676)	3.2909038587936976
  (0, 1675)	3.2914406954831437
  (0, 1674)	3.2914406954831437
  (0, 1673)	3.2914406954831437
  (0, 1672)	3.281960988605735
  (0, 1671)	3.2529194199855493
  (0, 1670)	3.2914406954831437
  (0, 1669)	3.2914406954831437
  (0, 1668)	3.2756376652700867
  (0, 1667)	3.2914406954831437
  (0, 1666)	3.2914406954831437
  (0, 1665)	3.2756376652700867
  (0, 1664)	3.2914406954831437
  (0, 1663)	3.267354409366801
  (0, 1662)	3.2756376652700867
  (0, 1661)	3.272350883635134
  (0, 1660)	3.2406361442721017
  (0, 1659)	3.2507428041603132
  (0, 1658)	3.2914406954831437
  (0, 1657)	3.2951160842640053
  :	:
  (942, 24)	3.5168188674408203
  (942, 23)	3.511855632914384
  (942, 22)	4.113420490578429
  (942, 21)	4.17971951924512
  (942, 20)	2.882861283106197
  (942, 19)	3.507968821126917
  (942, 18)	3.7520772581776605
  (942, 17)	3.1881044917980734
  (942, 16)	3.179567766857259
  (942, 15)	3.3237144841289363
  (942, 14)	3.7922175637881534
  (942, 13)	3.995442290299116
  (942, 12)	3.4101839306431465
  (942, 11)	4.359597227760576
  (942, 10)	3.8770695712796295
  (942, 9)	3.7153329665976713
  (942, 8)	3.941360030459617
  (942, 7)	4.020700978808845
  (942, 6)	3.8439411407481985
  (942, 5)	3.5010510357419804
  (942, 4)	3.3236598694416912
  (942, 3)	3.530585343071156
  (942, 2)	3.1169499275869077
  (942, 1)	3.2517463117798178
  (942, 0)	3.9074803776889557
this is the 66 epoch
rmse loss on training set is 0.9391826644926329
rmse loss on test set is 0.9561614332304593
for this epoch using 80.5457808971405 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2878564193943975
  (0, 1680)	3.294096128332596
  (0, 1679)	3.2671277468065583
  (0, 1678)	3.289651783467045
  (0, 1677)	3.2446037101460767
  (0, 1676)	3.2902601620280687
  (0, 1675)	3.2907885039693054
  (0, 1674)	3.2907885039693054
  (0, 1673)	3.2907885039693054
  (0, 1672)	3.2810914753522935
  (0, 1671)	3.251771732641062
  (0, 1670)	3.2907885039693054
  (0, 1669)	3.2907885039693054
  (0, 1668)	3.274790108721894
  (0, 1667)	3.2907885039693054
  (0, 1666)	3.2907885039693054
  (0, 1665)	3.274790108721894
  (0, 1664)	3.2907885039693054
  (0, 1663)	3.2663547405708866
  (0, 1662)	3.274790108721894
  (0, 1661)	3.2714441975980617
  (0, 1660)	3.2392374974175624
  (0, 1659)	3.2494783157792915
  (0, 1658)	3.2907885039693054
  (0, 1657)	3.2945602015538022
  :	:
  (942, 24)	3.5182161258894777
  (942, 23)	3.5134286667851407
  (942, 22)	4.116798572272535
  (942, 21)	4.181997291699263
  (942, 20)	2.881747684645301
  (942, 19)	3.511526644498299
  (942, 18)	3.7574946245168213
  (942, 17)	3.188933675389245
  (942, 16)	3.180472939417078
  (942, 15)	3.326105327991253
  (942, 14)	3.793481889043184
  (942, 13)	3.9982387408337425
  (942, 12)	3.4118511393545363
  (942, 11)	4.362030513642765
  (942, 10)	3.8791445707160546
  (942, 9)	3.7197441156234845
  (942, 8)	3.9431301550348623
  (942, 7)	4.022998602175893
  (942, 6)	3.845376066699146
  (942, 5)	3.505918517232741
  (942, 4)	3.325491676026448
  (942, 3)	3.5325891307155484
  (942, 2)	3.1175841204591563
  (942, 1)	3.2533415478385344
  (942, 0)	3.908874368947489
this is the 67 epoch
rmse loss on training set is 0.9388315359059349
rmse loss on test set is 0.955841611582487
for this epoch using 75.55062699317932 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.287174360768173
  (0, 1680)	3.2935360222994032
  (0, 1679)	3.2661450560767795
  (0, 1678)	3.288994202536595
  (0, 1677)	3.2432959096169593
  (0, 1676)	3.289633877693083
  (0, 1675)	3.2901533511856336
  (0, 1674)	3.2901533511856336
  (0, 1673)	3.2901533511856336
  (0, 1672)	3.280238043261269
  (0, 1671)	3.250642454389846
  (0, 1670)	3.2901533511856336
  (0, 1669)	3.2901533511856336
  (0, 1668)	3.2739598746866987
  (0, 1667)	3.2901533511856336
  (0, 1666)	3.2901533511856336
  (0, 1665)	3.2739598746866987
  (0, 1664)	3.2901533511856336
  (0, 1663)	3.265372568201979
  (0, 1662)	3.2739598746866987
  (0, 1661)	3.270555028913868
  (0, 1660)	3.237856641918025
  (0, 1659)	3.2482319954790952
  (0, 1658)	3.2901533511856336
  (0, 1657)	3.294022080236141
  :	:
  (942, 24)	3.519586708751648
  (942, 23)	3.514959262766277
  (942, 22)	4.120090342825504
  (942, 21)	4.184233218626703
  (942, 20)	2.880662404032575
  (942, 19)	3.5150271605053116
  (942, 18)	3.7628188858913445
  (942, 17)	3.18973844839916
  (942, 16)	3.181361922765229
  (942, 15)	3.328463386434666
  (942, 14)	3.7947145126729307
  (942, 13)	4.000954915055498
  (942, 12)	3.413488988336094
  (942, 11)	4.3644099212911875
  (942, 10)	3.8811742281891926
  (942, 9)	3.724066027927385
  (942, 8)	3.944856259324453
  (942, 7)	4.0252456957095175
  (942, 6)	3.846784444630452
  (942, 5)	3.510741805182987
  (942, 4)	3.327286151749692
  (942, 3)	3.5345596452303445
  (942, 2)	3.118210300611664
  (942, 1)	3.2549133142918913
  (942, 0)	3.910244610656128
this is the 68 epoch
rmse loss on training set is 0.9384892025111612
rmse loss on test set is 0.9555303571794665
for this epoch using 76.34417796134949 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2865089362447075
  (0, 1680)	3.2929925396016464
  (0, 1679)	3.265178847641457
  (0, 1678)	3.288353000162985
  (0, 1677)	3.242004695119926
  (0, 1676)	3.2890243656428235
  (0, 1675)	3.2895346058342323
  (0, 1674)	3.2895346058342323
  (0, 1673)	3.2895346058342323
  (0, 1672)	3.2794000940305597
  (0, 1671)	3.249530933248445
  (0, 1670)	3.2895346058342323
  (0, 1669)	3.2895346058342323
  (0, 1668)	3.2731463190398307
  (0, 1667)	3.2895346058342323
  (0, 1666)	3.2895346058342323
  (0, 1665)	3.2731463190398307
  (0, 1664)	3.2895346058342323
  (0, 1663)	3.2644072588167985
  (0, 1662)	3.2731463190398307
  (0, 1661)	3.269682740377229
  (0, 1660)	3.236492942119564
  (0, 1659)	3.2470031964460686
  (0, 1658)	3.2895346058342323
  (0, 1657)	3.2935010720011255
  :	:
  (942, 24)	3.5209310447049873
  (942, 23)	3.5164487490904555
  (942, 22)	4.1232990031149654
  (942, 21)	4.186428504526834
  (942, 20)	2.8796047524793624
  (942, 19)	3.5184712883854545
  (942, 18)	3.7680517034968104
  (942, 17)	3.190519334073054
  (942, 16)	3.182234987625911
  (942, 15)	3.330789185042637
  (942, 14)	3.795916446808567
  (942, 13)	4.003593838482077
  (942, 12)	3.4150980261817603
  (942, 11)	4.366737479810005
  (942, 10)	3.8831600583652413
  (942, 9)	3.72830054290869
  (942, 8)	3.946539924346903
  (942, 7)	4.027444115622498
  (942, 6)	3.8481666337037588
  (942, 5)	3.5155214277197415
  (942, 4)	3.3290440146281037
  (942, 3)	3.5364974663129267
  (942, 2)	3.1188284466927105
  (942, 1)	3.2564617946709613
  (942, 0)	3.9115912844696776
this is the 69 epoch
rmse loss on training set is 0.9381553402110592
rmse loss on test set is 0.9552273402493173
for this epoch using 76.47216033935547 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.285859536689746
  (0, 1680)	3.2924650610115735
  (0, 1679)	3.2642285130542796
  (0, 1678)	3.2877275679583273
  (0, 1677)	3.2407294581502364
  (0, 1676)	3.288431006955678
  (0, 1675)	3.288931657633747
  (0, 1674)	3.288931657633747
  (0, 1673)	3.288931657633747
  (0, 1672)	3.278577049573041
  (0, 1671)	3.2484365389607914
  (0, 1670)	3.288931657633747
  (0, 1669)	3.288931657633747
  (0, 1668)	3.272348819308839
  (0, 1667)	3.288931657633747
  (0, 1666)	3.288931657633747
  (0, 1665)	3.272348819308839
  (0, 1664)	3.288931657633747
  (0, 1663)	3.263458200014131
  (0, 1662)	3.272348819308839
  (0, 1661)	3.2688267160750235
  (0, 1660)	3.2351457833298127
  (0, 1659)	3.2457912930663024
  (0, 1658)	3.288931657633747
  (0, 1657)	3.2929965498825546
  :	:
  (942, 24)	3.522249554655859
  (942, 23)	3.517898398805919
  (942, 22)	4.12642759908093
  (942, 21)	4.188584274417508
  (942, 20)	2.878574053499892
  (942, 19)	3.521859928666176
  (942, 18)	3.773194705371868
  (942, 17)	3.191276843139936
  (942, 16)	3.1830923992567812
  (942, 15)	3.333083236872543
  (942, 14)	3.7970886432354853
  (942, 13)	4.006158393416377
  (942, 12)	3.416678782927323
  (942, 11)	4.369015084304138
  (942, 10)	3.885103489253132
  (942, 9)	3.7324494591430892
  (942, 8)	3.948182636562163
  (942, 7)	4.029595603937231
  (942, 6)	3.849522986956994
  (942, 5)	3.520257903473299
  (942, 4)	3.3307659691514573
  (942, 3)	3.538403154983733
  (942, 2)	3.119438541859563
  (942, 1)	3.2579871768791224
  (942, 0)	3.912914581088135
this is the 70 epoch
rmse loss on training set is 0.9378296411339118
rmse loss on test set is 0.9549322481685141
for this epoch using 77.70663118362427 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.285225574071654
  (0, 1680)	3.291952989027831
  (0, 1679)	3.2632934651411145
  (0, 1678)	3.287117318745179
  (0, 1677)	3.239469611537051
  (0, 1676)	3.2878532042197306
  (0, 1675)	3.288343917606923
  (0, 1674)	3.288343917606923
  (0, 1673)	3.288343917606923
  (0, 1672)	3.2777683523195873
  (0, 1671)	3.2473586632409073
  (0, 1670)	3.288343917606923
  (0, 1669)	3.288343917606923
  (0, 1668)	3.271566774925838
  (0, 1667)	3.288343917606923
  (0, 1666)	3.288343917606923
  (0, 1665)	3.271566774925838
  (0, 1664)	3.288343917606923
  (0, 1663)	3.2625248007162027
  (0, 1662)	3.271566774925838
  (0, 1661)	3.2679863616537013
  (0, 1660)	3.233814572103861
  (0, 1659)	3.2445956812289474
  (0, 1658)	3.288343917606923
  (0, 1657)	3.29250790854223
  :	:
  (942, 24)	3.5235426525275164
  (942, 23)	3.5193094327604806
  (942, 22)	4.129479030367916
  (942, 21)	4.1907015814519415
  (942, 20)	2.877569643066689
  (942, 19)	3.52519396399462
  (942, 18)	3.7782494873546795
  (942, 17)	3.1920114742813417
  (942, 16)	3.183934417697685
  (942, 15)	3.3353460430661337
  (942, 14)	3.798231998632384
  (942, 13)	4.008651326754322
  (942, 12)	3.4182317715026382
  (942, 11)	4.371244507014409
  (942, 10)	3.887005868729127
  (942, 9)	3.736514535598513
  (942, 8)	3.9497857952793374
  (942, 7)	4.0317017971353435
  (942, 6)	3.8508538525279037
  (942, 5)	3.524951741980153
  (942, 4)	3.332452706617801
  (942, 3)	3.540277255257545
  (942, 2)	3.1200405737312518
  (942, 1)	3.2594896530602897
  (942, 0)	3.91421470002165
this is the 71 epoch
rmse loss on training set is 0.9375118125973099
rmse loss on test set is 0.9546447843403215
for this epoch using 76.01511073112488 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.284606481563383
  (0, 1680)	3.2914557479451383
  (0, 1679)	3.2623731380838423
  (0, 1678)	3.286521686650425
  (0, 1677)	3.2382245895172597
  (0, 1676)	3.287290381620538
  (0, 1675)	3.2877708181708214
  (0, 1674)	3.2877708181708214
  (0, 1673)	3.2877708181708214
  (0, 1672)	3.276973465324524
  (0, 1671)	3.24629671982164
  (0, 1670)	3.2877708181708214
  (0, 1669)	3.2877708181708214
  (0, 1668)	3.270799607284825
  (0, 1667)	3.2877708181708214
  (0, 1666)	3.2877708181708214
  (0, 1665)	3.270799607284825
  (0, 1664)	3.2877708181708214
  (0, 1663)	3.2616064912534934
  (0, 1662)	3.270799607284825
  (0, 1661)	3.2671611043910476
  (0, 1660)	3.2324987363339037
  (0, 1659)	3.243415778429569
  (0, 1658)	3.2877708181708214
  (0, 1657)	3.292034564356754
  :	:
  (942, 24)	3.5248107459027627
  (942, 23)	3.520683022386571
  (942, 22)	4.1324560584354355
  (942, 21)	4.192781413763756
  (942, 20)	2.8765908697195437
  (942, 19)	3.5284742598988346
  (942, 18)	3.783217613985851
  (942, 17)	3.192723714568334
  (942, 16)	3.184761297993084
  (942, 15)	3.3375780934120365
  (942, 14)	3.7993473593064984
  (942, 13)	4.011075257318651
  (942, 12)	3.4197574890353195
  (942, 11)	4.373427407466775
  (942, 10)	3.8888684705189647
  (942, 9)	3.740497492784178
  (942, 8)	3.951350719426761
  (942, 7)	4.033764234107946
  (942, 6)	3.8521595746307913
  (942, 5)	3.5296034440522868
  (942, 4)	3.33410490544306
  (942, 3)	3.542120295617159
  (942, 2)	3.1206345343202155
  (942, 1)	3.260969419440646
  (942, 0)	3.915491849241516
this is the 72 epoch
rmse loss on training set is 0.9372015761524857
rmse loss on test set is 0.9543646671609757
for this epoch using 75.44693613052368 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2840017134800386
  (0, 1680)	3.2909727837610467
  (0, 1679)	3.261466987341394
  (0, 1678)	3.2859401270353343
  (0, 1677)	3.236993847647457
  (0, 1676)	3.28674198486479
  (0, 1675)	3.2872118130631667
  (0, 1674)	3.2872118130631667
  (0, 1673)	3.2872118130631667
  (0, 1672)	3.2761918722071854
  (0, 1671)	3.2452501443427426
  (0, 1670)	3.2872118130631667
  (0, 1669)	3.2872118130631667
  (0, 1668)	3.270046759637159
  (0, 1667)	3.2872118130631667
  (0, 1666)	3.2872118130631667
  (0, 1665)	3.270046759637159
  (0, 1664)	3.2872118130631667
  (0, 1663)	3.260702723286574
  (0, 1662)	3.270046759637159
  (0, 1661)	3.2663503931055597
  (0, 1660)	3.231197725175722
  (0, 1659)	3.242251023707143
  (0, 1658)	3.2872118130631667
  (0, 1657)	3.291575955340352
  :	:
  (942, 24)	3.5260542365439913
  (942, 23)	3.5220202923033024
  (942, 22)	4.135361314173464
  (942, 21)	4.1948247006192645
  (942, 20)	2.8756370946336167
  (942, 19)	3.5317016654869975
  (942, 18)	3.788100619362568
  (942, 17)	3.193414039869968
  (942, 16)	3.185573290391684
  (942, 15)	3.3397798668649608
  (942, 14)	3.8004355254750166
  (942, 13)	4.013432682751011
  (942, 12)	3.4212564180218292
  (942, 11)	4.37556534172543
  (942, 10)	3.8906924996854317
  (942, 9)	3.7444000138389617
  (942, 8)	3.952878653742053
  (942, 7)	4.0357843634656545
  (942, 6)	3.8534404943255205
  (942, 5)	3.534213502116133
  (942, 4)	3.3357232314486622
  (942, 3)	3.543932790312842
  (942, 2)	3.121220419946669
  (942, 1)	3.262426676149311
  (942, 0)	3.916746244746455
this is the 73 epoch
rmse loss on training set is 0.9368986667015639
rmse loss on test set is 0.9540916290657429
for this epoch using 75.60945701599121 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.283410745080956
  (0, 1680)	3.290503563948734
  (0, 1679)	3.2605744894366575
  (0, 1678)	3.2853721162903877
  (0, 1677)	3.2357768625829193
  (0, 1676)	3.286207480968904
  (0, 1675)	3.2866663771337494
  (0, 1674)	3.2866663771337494
  (0, 1673)	3.2866663771337494
  (0, 1672)	3.2754230769582344
  (0, 1671)	3.2442183941069587
  (0, 1670)	3.2866663771337494
  (0, 1669)	3.2866663771337494
  (0, 1668)	3.2693076968541175
  (0, 1667)	3.2866663771337494
  (0, 1666)	3.2866663771337494
  (0, 1665)	3.2693076968541175
  (0, 1664)	3.2866663771337494
  (0, 1663)	3.259812969593561
  (0, 1662)	3.2693076968541175
  (0, 1661)	3.2655536979322495
  (0, 1660)	3.229911008841136
  (0, 1659)	3.241100877444136
  (0, 1658)	3.2866663771337494
  (0, 1657)	3.2911315409326343
  :	:
  (942, 24)	3.5272735208097763
  (942, 23)	3.5233223227497508
  (942, 22)	4.138197305056495
  (942, 21)	4.196832317947607
  (942, 20)	2.87470769165139
  (942, 19)	3.534877014090815
  (942, 18)	3.792900007948491
  (942, 17)	3.194082915235752
  (942, 16)	3.18637064052618
  (942, 15)	3.3419518320253756
  (942, 14)	3.801497255137631
  (942, 13)	4.015725985992426
  (942, 12)	3.422729027379983
  (942, 11)	4.377659770831689
  (942, 10)	3.8924790976648636
  (942, 9)	3.748223745564311
  (942, 8)	3.954370774434189
  (942, 7)	4.037763550262135
  (942, 6)	3.854696950112889
  (942, 5)	3.5387824005243633
  (942, 4)	3.337308338130269
  (942, 3)	3.5457152405078243
  (942, 2)	3.1217982311388943
  (942, 1)	3.263861627022797
  (942, 0)	3.917978110068266
this is the 74 epoch
rmse loss on training set is 0.9366028316813289
rmse loss on test set is 0.9538254156477489
for this epoch using 76.41697573661804 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2828330722610986
  (0, 1680)	3.2900475771206135
  (0, 1679)	3.259695141634161
  (0, 1678)	3.284817151520075
  (0, 1677)	3.234573131748247
  (0, 1676)	3.285686357937217
  (0, 1675)	3.286134006025814
  (0, 1674)	3.286134006025814
  (0, 1673)	3.286134006025814
  (0, 1672)	3.274666603635829
  (0, 1671)	3.24320094772872
  (0, 1670)	3.286134006025814
  (0, 1669)	3.286134006025814
  (0, 1668)	3.268581905081075
  (0, 1667)	3.286134006025814
  (0, 1666)	3.286134006025814
  (0, 1665)	3.268581905081075
  (0, 1664)	3.286134006025814
  (0, 1663)	3.2589367237481954
  (0, 1662)	3.268581905081075
  (0, 1661)	3.2647705099896993
  (0, 1660)	3.22863807828091
  (0, 1659)	3.2399648210545746
  (0, 1658)	3.286134006025814
  (0, 1657)	3.290700801676107
  :	:
  (942, 24)	3.52846898998511
  (942, 23)	3.5245901518627716
  (942, 22)	4.1409664218671
  (942, 21)	4.198805093312135
  (942, 20)	2.873802047282847
  (942, 19)	3.53800112385847
  (942, 18)	3.7976172553429337
  (942, 17)	3.1947307952545922
  (942, 16)	3.1871535895759986
  (942, 15)	3.344094447583352
  (942, 14)	3.8025332675807277
  (942, 13)	4.0179574413794725
  (942, 12)	3.4241757733954152
  (942, 11)	4.37971206850225
  (942, 10)	3.8942293468917697
  (942, 9)	3.7519702994064157
  (942, 8)	3.955828194364802
  (942, 7)	4.039703082180264
  (942, 6)	3.855929278384944
  (942, 5)	3.5433106158432097
  (942, 4)	3.3388608669103483
  (942, 3)	3.547468135288228
  (942, 2)	3.1223679725223015
  (942, 1)	3.2652744793970783
  (942, 0)	3.9191876757364463
this is the 75 epoch
rmse loss on training set is 0.9363138303076783
rmse loss on test set is 0.9535657848430775
for this epoch using 76.05175495147705 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2822682111533004
  (0, 1680)	3.2896043326040125
  (0, 1679)	3.2588284615297596
  (0, 1678)	3.2842747501387217
  (0, 1677)	3.2333821729207943
  (0, 1676)	3.2851781243515195
  (0, 1675)	3.285614215768694
  (0, 1674)	3.285614215768694
  (0, 1673)	3.285614215768694
  (0, 1672)	3.273921995972911
  (0, 1671)	3.2421973046966373
  (0, 1670)	3.285614215768694
  (0, 1669)	3.285614215768694
  (0, 1668)	3.2678688913047638
  (0, 1667)	3.285614215768694
  (0, 1666)	3.285614215768694
  (0, 1665)	3.2678688913047638
  (0, 1664)	3.285614215768694
  (0, 1663)	3.258073499709762
  (0, 1662)	3.2678688913047638
  (0, 1661)	3.2640003409595
  (0, 1660)	3.2273784447795624
  (0, 1659)	3.238842356581872
  (0, 1658)	3.285614215768694
  (0, 1657)	3.290283238804937
  :	:
  (942, 24)	3.5296410305393815
  (942, 23)	3.52582477781096
  (942, 22)	4.143670945017576
  (942, 21)	4.200743810379868
  (942, 20)	2.8729195606776554
  (942, 19)	3.5410747983020068
  (942, 18)	3.8022538090130458
  (942, 17)	3.195358124392318
  (942, 16)	3.1879223744150758
  (942, 15)	3.3462081627297673
  (942, 14)	3.803544246549256
  (942, 13)	4.020129220381757
  (942, 12)	3.4255971005732406
  (942, 11)	4.381723528153975
  (942, 10)	3.8959442750473356
  (942, 9)	3.755641252392078
  (942, 8)	3.957251967791531
  (942, 7)	4.041604175225699
  (942, 6)	3.857137813755075
  (942, 5)	3.547798617117754
  (942, 4)	3.340381447376733
  (942, 3)	3.5491919525531643
  (942, 2)	3.1229296526995802
  (942, 1)	3.266665443890721
  (942, 0)	3.920375178717678
this is the 76 epoch
rmse loss on training set is 0.9360314328753324
rmse loss on test set is 0.9533125061763628
for this epoch using 75.18017601966858 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.281715697659606
  (0, 1680)	3.2891733599473785
  (0, 1679)	3.2579739865705113
  (0, 1678)	3.2837444493958965
  (0, 1677)	3.232203523745136
  (0, 1676)	3.284682308889963
  (0, 1675)	3.2851065423000754
  (0, 1674)	3.2851065423000754
  (0, 1673)	3.2851065423000754
  (0, 1672)	3.273188816913897
  (0, 1671)	3.2412069848679166
  (0, 1670)	3.2851065423000754
  (0, 1669)	3.2851065423000754
  (0, 1668)	3.2671681828515933
  (0, 1667)	3.2851065423000754
  (0, 1666)	3.2851065423000754
  (0, 1665)	3.2671681828515933
  (0, 1664)	3.2851065423000754
  (0, 1663)	3.257222831343067
  (0, 1662)	3.2671681828515933
  (0, 1661)	3.2632427225964395
  (0, 1660)	3.2261316394802737
  (0, 1659)	3.2377330062248064
  (0, 1658)	3.2851065423000754
  (0, 1657)	3.2898783737631394
  :	:
  (942, 24)	3.5307900243247086
  (942, 23)	3.527027160795826
  (942, 22)	4.146313050496307
  (942, 21)	4.202649212940201
  (942, 20)	2.8720596435727184
  (942, 19)	3.5440988268034936
  (942, 18)	3.806811088991851
  (942, 17)	3.1959653373097416
  (942, 16)	3.1886772277467013
  (942, 15)	3.348293417537823
  (942, 14)	3.804530843119197
  (942, 13)	4.022243397004238
  (942, 12)	3.426993442404819
  (942, 11)	4.383695369315907
  (942, 10)	3.897624858964317
  (942, 9)	3.75923814802186
  (942, 8)	3.958643094712283
  (942, 7)	4.04346797896869
  (942, 6)	3.8583228892886443
  (942, 5)	3.552246866117304
  (942, 4)	3.3418706975093064
  (942, 3)	3.5508871597995935
  (942, 2)	3.123483284124047
  (942, 1)	3.268034734182163
  (942, 0)	3.9215408618429097
this is the 77 epoch
rmse loss on training set is 0.935755420108176
rmse loss on test set is 0.9530653600617415
for this epoch using 76.13683676719666 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.281175086927452
  (0, 1680)	3.288754208372447
  (0, 1679)	3.2571312735205256
  (0, 1678)	3.2832258058469748
  (0, 1677)	3.2310367411940764
  (0, 1676)	3.2841984597911376
  (0, 1675)	3.2846105409335573
  (0, 1674)	3.2846105409335573
  (0, 1673)	3.2846105409335573
  (0, 1672)	3.272466648096588
  (0, 1671)	3.240229527910171
  (0, 1670)	3.2846105409335573
  (0, 1669)	3.2846105409335573
  (0, 1668)	3.266479326832788
  (0, 1667)	3.2846105409335573
  (0, 1666)	3.2846105409335573
  (0, 1665)	3.266479326832788
  (0, 1664)	3.2846105409335573
  (0, 1663)	3.256384271884239
  (0, 1662)	3.266479326832788
  (0, 1661)	3.2624972061849373
  (0, 1660)	3.224897212855422
  (0, 1659)	3.2366363118076
  (0, 1658)	3.2846105409335573
  (0, 1657)	3.2894857476680546
  :	:
  (942, 24)	3.531916348724979
  (942, 23)	3.528198224929819
  (942, 22)	4.148894815463149
  (942, 21)	4.204522008518335
  (942, 20)	2.8712217202182013
  (942, 19)	3.547073985083988
  (942, 18)	3.811290488545072
  (942, 17)	3.196552859162916
  (942, 16)	3.1894183782272
  (942, 15)	3.350350643317525
  (942, 14)	3.805493678299698
  (942, 13)	4.02430195287604
  (942, 12)	3.428365222058533
  (942, 11)	4.385628743483718
  (942, 10)	3.899272028217759
  (942, 9)	3.762762497124057
  (942, 8)	3.960002524845675
  (942, 7)	4.045295581371457
  (942, 6)	3.85948483665226
  (942, 5)	3.5566558175629486
  (942, 4)	3.3433292238962693
  (942, 3)	3.552554214814086
  (942, 2)	3.124028882967959
  (942, 1)	3.269382566783335
  (942, 0)	3.922684973232422
this is the 78 epoch
rmse loss on training set is 0.9354855825558873
rmse loss on test set is 0.9528241371543145
for this epoch using 76.00458192825317 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2806459527840555
  (0, 1680)	3.2883464461858694
  (0, 1679)	3.256299897885835
  (0, 1678)	3.2827183947822673
  (0, 1677)	3.229881400989415
  (0, 1676)	3.283726144276816
  (0, 1675)	3.2841257857848376
  (0, 1674)	3.2841257857848376
  (0, 1673)	3.2841257857848376
  (0, 1672)	3.2717550892924327
  (0, 1671)	3.2392644927038585
  (0, 1670)	3.2841257857848376
  (0, 1669)	3.2841257857848376
  (0, 1668)	3.2658018895494423
  (0, 1667)	3.2841257857848376
  (0, 1666)	3.2841257857848376
  (0, 1665)	3.2658018895494423
  (0, 1664)	3.2841257857848376
  (0, 1663)	3.255557393365471
  (0, 1662)	3.2658018895494423
  (0, 1661)	3.2617633619549458
  (0, 1660)	3.223674734136141
  (0, 1659)	3.2355518342075635
  (0, 1658)	3.2841257857848376
  (0, 1657)	3.289104920732327
  :	:
  (942, 24)	3.5330203767645725
  (942, 23)	3.52933886000037
  (942, 22)	4.151418223516695
  (942, 21)	4.206362871624834
  (942, 20)	2.8704052272846043
  (942, 19)	3.550001035638562
  (942, 18)	3.8156933748091153
  (942, 17)	3.197121105887184
  (942, 16)	3.190146050579774
  (942, 15)	3.352380262945382
  (942, 14)	3.806433345391502
  (942, 13)	4.026306782045961
  (942, 12)	3.4297128530025307
  (942, 11)	4.3875247394663495
  (942, 10)	3.9008866684283157
  (942, 9)	3.766215778672515
  (942, 8)	3.9613311612796407
  (942, 7)	4.047088013235058
  (942, 6)	3.8606239861966474
  (942, 5)	3.56102591933885
  (942, 4)	3.3447576219415516
  (942, 3)	3.55419356628281
  (942, 2)	3.124566468987156
  (942, 1)	3.2707091608118892
  (942, 0)	3.9238077657266266
this is the 79 epoch
rmse loss on training set is 0.9352217200330268
rmse loss on test set is 0.9525886377479971
for this epoch using 76.01492285728455 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.280127887140229
  (0, 1680)	3.2879496601613334
  (0, 1679)	3.2554794533096776
  (0, 1678)	3.2822218096258005
  (0, 1677)	3.2287370969935547
  (0, 1676)	3.283264947944397
  (0, 1675)	3.2836518691678145
  (0, 1674)	3.2836518691678145
  (0, 1673)	3.2836518691678145
  (0, 1672)	3.2710537578166217
  (0, 1671)	3.2383114567163194
  (0, 1670)	3.2836518691678145
  (0, 1669)	3.2836518691678145
  (0, 1668)	3.2651354558687675
  (0, 1667)	3.2836518691678145
  (0, 1666)	3.2836518691678145
  (0, 1665)	3.2651354558687675
  (0, 1664)	3.2836518691678145
  (0, 1663)	3.2547417860100403
  (0, 1662)	3.2651354558687675
  (0, 1661)	3.261040778468694
  (0, 1660)	3.2224637907119766
  (0, 1659)	3.2344791527516565
  (0, 1658)	3.2836518691678145
  (0, 1657)	3.2887354716556665
  :	:
  (942, 24)	3.534102477184626
  (942, 23)	3.530449923128115
  (942, 22)	4.153885169654225
  (942, 21)	4.208172446677876
  (942, 20)	2.869609613753436
  (942, 19)	3.5528807281408397
  (942, 18)	3.820021089402425
  (942, 17)	3.197670484466266
  (942, 16)	3.19086046569983
  (942, 15)	3.3543826911716383
  (942, 14)	3.807350412125208
  (942, 13)	4.028259695503445
  (942, 12)	3.431036739566573
  (942, 11)	4.389384388270519
  (942, 10)	3.9024696243025128
  (942, 9)	3.7695994405710476
  (942, 8)	3.9626298638173516
  (942, 7)	4.048846252297173
  (942, 6)	3.8617406669861034
  (942, 5)	3.5653576126889965
  (942, 4)	3.346156476064422
  (942, 3)	3.555805654329531
  (942, 2)	3.1250960653835533
  (942, 1)	3.2720147377637128
  (942, 0)	3.9249094963291093
this is the 80 epoch
rmse loss on training set is 0.9349636410969842
rmse loss on test set is 0.9523586712158353
for this epoch using 76.39122009277344 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.279620499373431
  (0, 1680)	3.2875634549020045
  (0, 1679)	3.2546695509476433
  (0, 1678)	3.281735661313711
  (0, 1677)	3.2276034405815786
  (0, 1676)	3.282814474138916
  (0, 1675)	3.2831884009701513
  (0, 1674)	3.2831884009701513
  (0, 1673)	3.2831884009701513
  (0, 1672)	3.270362287917439
  (0, 1671)	3.237370015357117
  (0, 1670)	3.2831884009701513
  (0, 1669)	3.2831884009701513
  (0, 1668)	3.2644796285809625
  (0, 1667)	3.2831884009701513
  (0, 1666)	3.2831884009701513
  (0, 1665)	3.2644796285809625
  (0, 1664)	3.2831884009701513
  (0, 1663)	3.253937057607193
  (0, 1662)	3.2644796285809625
  (0, 1661)	3.2603290619875662
  (0, 1660)	3.2212639875102806
  (0, 1659)	3.233417864591799
  (0, 1658)	3.2831884009701513
  (0, 1657)	3.2883769969961634
  :	:
  (942, 24)	3.535163014493126
  (942, 23)	3.5315322403267833
  (942, 22)	4.156297464944126
  (942, 21)	4.2099513506316
  (942, 20)	2.868834340793502
  (942, 19)	3.5557137998197437
  (942, 18)	3.824274949012269
  (942, 17)	3.1982013931878117
  (942, 16)	3.191561840752881
  (942, 15)	3.3563583349068677
  (942, 14)	3.80824542260088
  (942, 13)	4.030162425442235
  (942, 12)	3.432337277449233
  (942, 11)	4.391208667564149
  (942, 10)	3.9040217024322463
  (942, 9)	3.7729149004068363
  (942, 8)	3.9638994520468054
  (942, 7)	4.050571227009008
  (942, 6)	3.862835206785252
  (942, 5)	3.569651332400698
  (942, 4)	3.347526359892507
  (942, 3)	3.5573909109901884
  (942, 2)	3.125617698666254
  (942, 1)	3.273299521287271
  (942, 0)	3.9259904256664586
this is the 81 epoch
rmse loss on training set is 0.9347111625617855
rmse loss on test set is 0.952134055489354
for this epoch using 75.90325403213501 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2791234156979376
  (0, 1680)	3.2871874521910986
  (0, 1679)	3.25386981883089
  (0, 1678)	3.2812595776600286
  (0, 1677)	3.2264800600017525
  (0, 1676)	3.282374343312601
  (0, 1675)	3.2827350080165525
  (0, 1674)	3.2827350080165525
  (0, 1673)	3.2827350080165525
  (0, 1672)	3.2696803301531556
  (0, 1671)	3.2364397813224195
  (0, 1670)	3.2827350080165525
  (0, 1669)	3.2827350080165525
  (0, 1668)	3.2638340277448843
  (0, 1667)	3.2827350080165525
  (0, 1666)	3.2827350080165525
  (0, 1665)	3.2638340277448843
  (0, 1664)	3.2827350080165525
  (0, 1663)	3.2531428328748624
  (0, 1662)	3.2638340277448843
  (0, 1661)	3.2596278358273816
  (0, 1660)	3.2200749463634053
  (0, 1659)	3.232367584067137
  (0, 1658)	3.2827350080165525
  (0, 1657)	3.288029110529123
  :	:
  (942, 24)	3.5362023489943946
  (942, 23)	3.5325866079717754
  (942, 22)	4.158656840928716
  (942, 21)	4.211700175340091
  (942, 20)	2.8680788816247933
  (942, 19)	3.5585009758110293
  (942, 18)	3.828456245958756
  (942, 17)	3.198714221886274
  (942, 16)	3.19225038926591
  (942, 15)	3.3583075934897417
  (942, 14)	3.809118899048287
  (942, 13)	4.032016629282807
  (942, 12)	3.4336148541762572
  (942, 11)	4.392998505756257
  (942, 10)	3.9055436738737446
  (942, 9)	3.776163546175204
  (942, 8)	3.9651407081582337
  (942, 7)	4.0522638200176155
  (942, 6)	3.863907932012324
  (942, 5)	3.5739075069761044
  (942, 4)	3.348867836448855
  (942, 3)	3.558949760631826
  (942, 2)	3.1261313985124706
  (942, 1)	3.2745637369608174
  (942, 0)	3.92705081746858
this is the 82 epoch
rmse loss on training set is 0.9344641090446717
rmse loss on test set is 0.9519146165737359
for this epoch using 75.95641326904297 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2786362785290475
  (0, 1680)	3.2868212903374823
  (0, 1679)	3.2530799012238316
  (0, 1678)	3.2807932027167035
  (0, 1677)	3.2253665997309606
  (0, 1676)	3.281944192378765
  (0, 1675)	3.2822913334262775
  (0, 1674)	3.2822913334262775
  (0, 1673)	3.2822913334262775
  (0, 1672)	3.2690075507629572
  (0, 1671)	3.235520383935114
  (0, 1670)	3.2822913334262775
  (0, 1669)	3.2822913334262775
  (0, 1668)	3.263198290028974
  (0, 1667)	3.2822913334262775
  (0, 1666)	3.2822913334262775
  (0, 1665)	3.263198290028974
  (0, 1664)	3.2822913334262775
  (0, 1663)	3.2523587528169817
  (0, 1662)	3.263198290028974
  (0, 1661)	3.2589367397085773
  (0, 1660)	3.2188963053702735
  (0, 1659)	3.2313279420599414
  (0, 1658)	3.2822913334262775
  (0, 1657)	3.287691442600125
  :	:
  (942, 24)	3.5372208368026348
  (942, 23)	3.5336137941836374
  (942, 22)	4.160964953774421
  (942, 21)	4.213419489683772
  (942, 20)	2.867342721371679
  (942, 19)	3.56124296948584
  (942, 18)	3.832566248737607
  (942, 17)	3.1992093521743192
  (942, 16)	3.1929263212130428
  (942, 15)	3.3602308589375345
  (942, 14)	3.809971343424956
  (942, 13)	4.03382389346863
  (942, 12)	3.434869849514926
  (942, 11)	4.394754785727301
  (942, 10)	3.907036276524294
  (942, 9)	3.7793467369775526
  (942, 8)	3.9663543795311185
  (942, 7)	4.053924871377233
  (942, 6)	3.864959167666698
  (942, 5)	3.578126558792947
  (942, 4)	3.3501814583339176
  (942, 3)	3.5604826203224897
  (942, 2)	3.1266371976288228
  (942, 1)	3.2758076120736885
  (942, 0)	3.9280909380718096
this is the 83 epoch
rmse loss on training set is 0.9342223125430525
rmse loss on test set is 0.9517001880960111
for this epoch using 75.13329410552979 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.278158745846895
  (0, 1680)	3.2864646235217396
  (0, 1679)	3.2522994579821547
  (0, 1678)	3.280336196133532
  (0, 1677)	3.224262719830777
  (0, 1676)	3.281523674065541
  (0, 1675)	3.281857035970621
  (0, 1674)	3.281857035970621
  (0, 1673)	3.281857035970621
  (0, 1672)	3.268343631037734
  (0, 1671)	3.2346114684862326
  (0, 1670)	3.281857035970621
  (0, 1669)	3.281857035970621
  (0, 1668)	3.262572068053094
  (0, 1667)	3.281857035970621
  (0, 1666)	3.281857035970621
  (0, 1665)	3.262572068053094
  (0, 1664)	3.281857035970621
  (0, 1663)	3.2515844740809214
  (0, 1662)	3.262572068053094
  (0, 1661)	3.258255429106936
  (0, 1660)	3.217727718257983
  (0, 1659)	3.230298585351001
  (0, 1658)	3.281857035970621
  (0, 1657)	3.2873636394780648
  :	:
  (942, 24)	3.5382188298433532
  (942, 23)	3.5346145401323508
  (942, 22)	4.163223388184934
  (942, 21)	4.215109841482326
  (942, 20)	2.866625356906843
  (942, 19)	3.5639404827586034
  (942, 18)	3.8366062025432686
  (942, 17)	3.1996871576635018
  (942, 16)	3.193589843096188
  (942, 15)	3.362128516180867
  (942, 14)	3.810803238867912
  (942, 13)	4.035585737050168
  (942, 12)	3.4361026358492968
  (942, 11)	4.396478348240837
  (942, 10)	3.908500217313683
  (942, 9)	3.7824658036945
  (942, 8)	3.9675411811107124
  (942, 7)	4.055555181511772
  (942, 6)	3.8659892372369318
  (942, 5)	3.5823089042553256
  (942, 4)	3.351467767903012
  (942, 3)	3.5619899001582183
  (942, 2)	3.127135131613795
  (942, 1)	3.2770313754123483
  (942, 0)	3.9291110559467115
this is the 84 epoch
rmse loss on training set is 0.9339856120393254
rmse loss on test set is 0.9514906108836004
for this epoch using 75.28008389472961 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2776904905645017
  (0, 1680)	3.2861171211474587
  (0, 1679)	3.2515281639156073
  (0, 1678)	3.279888232522545
  (0, 1677)	3.22316809530867
  (0, 1676)	3.2811124562743808
  (0, 1675)	3.2814317894350573
  (0, 1674)	3.2814317894350573
  (0, 1673)	3.2814317894350573
  (0, 1672)	3.2676882666952327
  (0, 1671)	3.2337126955820636
  (0, 1670)	3.2814317894350573
  (0, 1669)	3.2814317894350573
  (0, 1668)	3.2619550297358684
  (0, 1667)	3.2814317894350573
  (0, 1666)	3.2814317894350573
  (0, 1665)	3.2619550297358684
  (0, 1664)	3.2814317894350573
  (0, 1663)	3.250819668319732
  (0, 1662)	3.2619550297358684
  (0, 1661)	3.2575835746094284
  (0, 1660)	3.2165688537479906
  (0, 1659)	3.2292791759791704
  (0, 1658)	3.2814317894350573
  (0, 1657)	3.287045362712781
  :	:
  (942, 24)	3.5391966758459845
  (942, 23)	3.5355895612677597
  (942, 22)	4.165433661092117
  (942, 21)	4.216771759215529
  (942, 20)	2.8659262966875234
  (942, 19)	3.5665942063757563
  (942, 18)	3.8405773297735815
  (942, 17)	3.2001480041751695
  (942, 16)	3.1942411580212116
  (942, 15)	3.3640009432839073
  (942, 14)	3.811615051012996
  (942, 13)	4.037303615069442
  (942, 12)	3.4373135785200466
  (942, 11)	4.3981699950649
  (942, 10)	3.90993617422562
  (942, 9)	3.785522049635627
  (942, 8)	3.9687017975922765
  (942, 7)	4.057155513948257
  (942, 6)	3.866998462594813
  (942, 5)	3.58645495393568
  (942, 4)	3.352727297439812
  (942, 3)	3.56347200355241
  (942, 2)	3.1276252388217523
  (942, 1)	3.2782352570518807
  (942, 0)	3.9301114412514115
this is the 85 epoch
rmse loss on training set is 0.9337538531314202
rmse loss on test set is 0.9512857325708638
for this epoch using 75.4413640499115 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.27723119990398
  (0, 1680)	3.285778467201395
  (0, 1679)	3.2507657081594363
  (0, 1678)	3.2794490008307715
  (0, 1677)	3.222082415488108
  (0, 1676)	3.280710221446797
  (0, 1675)	3.2810152819896983
  (0, 1674)	3.2810152819896983
  (0, 1673)	3.2810152819896983
  (0, 1672)	3.2670411672634554
  (0, 1671)	3.232823740500825
  (0, 1670)	3.2810152819896983
  (0, 1669)	3.2810152819896983
  (0, 1668)	3.261346857651248
  (0, 1667)	3.2810152819896983
  (0, 1666)	3.2810152819896983
  (0, 1665)	3.261346857651248
  (0, 1664)	3.2810152819896983
  (0, 1663)	3.2500640215629426
  (0, 1662)	3.261346857651248
  (0, 1661)	3.256920861278962
  (0, 1660)	3.215419394930802
  (0, 1659)	3.228269390608918
  (0, 1658)	3.2810152819896983
  (0, 1657)	3.2867362885009803
  :	:
  (942, 24)	3.540154718330314
  (942, 23)	3.5365395484810263
  (942, 22)	4.167597225137993
  (942, 21)	4.218405753571569
  (942, 20)	2.865245060585037
  (942, 19)	3.569204820187433
  (942, 18)	3.844480830517311
  (942, 17)	3.200592249942107
  (942, 16)	3.1948804657702943
  (942, 15)	3.3658485116513797
  (942, 14)	3.8124072291945574
  (942, 13)	4.038978921757418
  (942, 12)	3.4385030361328277
  (942, 11)	4.399830491828326
  (942, 10)	3.911344798163201
  (942, 9)	3.7885167511675544
  (942, 8)	3.96983688542944
  (942, 7)	4.058726597839656
  (942, 6)	3.8679871638798597
  (942, 5)	3.590565112708544
  (942, 4)	3.3539605693261594
  (942, 3)	3.564929327492023
  (942, 2)	3.128107560229119
  (942, 1)	3.279419488153468
  (942, 0)	3.9310923654110916
this is the 86 epoch
rmse loss on training set is 0.9335268876871038
rmse loss on test set is 0.9510854072315229
for this epoch using 75.6341860294342 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2767805747838668
  (0, 1680)	3.2854483596256587
  (0, 1679)	3.2500117935574
  (0, 1678)	3.279018203724337
  (0, 1677)	3.2210053833904735
  (0, 1676)	3.2803166659427268
  (0, 1675)	3.2806072155712855
  (0, 1674)	3.2806072155712855
  (0, 1673)	3.2806072155712855
  (0, 1672)	3.2664020554753206
  (0, 1671)	3.2319442925617894
  (0, 1670)	3.2806072155712855
  (0, 1669)	3.2806072155712855
  (0, 1668)	3.2607472483973106
  (0, 1667)	3.2806072155712855
  (0, 1666)	3.2806072155712855
  (0, 1665)	3.2607472483973106
  (0, 1664)	3.2806072155712855
  (0, 1663)	3.249317233598938
  (0, 1662)	3.2607472483973106
  (0, 1661)	3.256266988031033
  (0, 1660)	3.2142790386519904
  (0, 1659)	3.227268919909077
  (0, 1658)	3.2806072155712855
  (0, 1657)	3.2864361070637376
  :	:
  (942, 24)	3.541093296589066
  (942, 23)	3.537465169201724
  (942, 22)	4.1697154719607905
  (942, 21)	4.220012318840199
  (942, 20)	2.864581179708832
  (942, 19)	3.5717729934032056
  (942, 18)	3.848317883025533
  (942, 17)	3.201020245801783
  (942, 16)	3.1955079628706913
  (942, 15)	3.3676715862232185
  (942, 14)	3.8131802075370254
  (942, 13)	4.04061299355536
  (942, 12)	3.4396713608381386
  (942, 11)	4.4014605706356
  (942, 10)	3.9127267146711335
  (942, 9)	3.791451158321425
  (942, 8)	3.970947074681751
  (942, 7)	4.06026913029389
  (942, 6)	3.868955659377776
  (942, 5)	3.5946397798769496
  (942, 4)	3.3551680962087653
  (942, 3)	3.5663622627650042
  (942, 2)	3.1285821393028717
  (942, 1)	3.2805843007682727
  (942, 0)	3.932054100723637
this is the 87 epoch
rmse loss on training set is 0.9333045735203652
rmse loss on test set is 0.950889495034902
for this epoch using 75.59487223625183 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2763383292201347
  (0, 1680)	3.285126509704278
  (0, 1679)	3.249266136058898
  (0, 1678)	3.278595556986425
  (0, 1677)	3.2199367151313716
  (0, 1676)	3.2799314994327773
  (0, 1675)	3.2802073052790925
  (0, 1674)	3.2802073052790925
  (0, 1673)	3.2802073052790925
  (0, 1672)	3.2657706666770867
  (0, 1671)	3.2310740545092353
  (0, 1670)	3.2802073052790925
  (0, 1669)	3.2802073052790925
  (0, 1668)	3.2601559119797225
  (0, 1667)	3.2802073052790925
  (0, 1666)	3.2802073052790925
  (0, 1665)	3.2601559119797225
  (0, 1664)	3.2802073052790925
  (0, 1663)	3.2485790173714095
  (0, 1662)	3.2601559119797225
  (0, 1661)	3.2556216670246947
  (0, 1660)	3.213147494912107
  (0, 1659)	3.226277467945215
  (0, 1658)	3.2802073052790925
  (0, 1657)	3.2861445220377994
  :	:
  (942, 24)	3.542012745668279
  (942, 23)	3.5383670684347783
  (942, 22)	4.17178973529677
  (942, 21)	4.221591934166463
  (942, 20)	2.863934196226031
  (942, 19)	3.5742993848336075
  (942, 18)	3.852089644167944
  (942, 17)	3.2014323353817318
  (942, 16)	3.1961238426605085
  (942, 15)	3.3694705256581674
  (942, 14)	3.8139344059486397
  (942, 13)	4.042207111970718
  (942, 12)	3.4408188985859183
  (942, 11)	4.403060932461317
  (942, 10)	3.9140825255265193
  (942, 9)	3.794326495381339
  (942, 8)	3.9720329707151323
  (942, 7)	4.061783778524532
  (942, 6)	3.869904265396108
  (942, 5)	3.5986793492920506
  (942, 4)	3.3563503811628643
  (942, 3)	3.5677711941623156
  (942, 2)	3.1290490218718974
  (942, 1)	3.2817299276479197
  (942, 0)	3.9329969199912704
this is the 88 epoch
rmse loss on training set is 0.9330867740879853
rmse loss on test set is 0.9506978619242864
for this epoch using 75.66514205932617 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2759041897427736
  (0, 1680)	3.2848126414660967
  (0, 1679)	3.24852846413204
  (0, 1678)	3.2781807889310715
  (0, 1677)	3.21887613933302
  (0, 1676)	3.279554444306403
  (0, 1675)	3.279815278786668
  (0, 1674)	3.279815278786668
  (0, 1673)	3.279815278786668
  (0, 1672)	3.2651467482524064
  (0, 1671)	3.2302127419131312
  (0, 1670)	3.279815278786668
  (0, 1669)	3.279815278786668
  (0, 1668)	3.2595725712117
  (0, 1667)	3.279815278786668
  (0, 1666)	3.279815278786668
  (0, 1665)	3.2595725712117
  (0, 1664)	3.279815278786668
  (0, 1663)	3.24784909839168
  (0, 1662)	3.2595725712117
  (0, 1661)	3.254984623069773
  (0, 1660)	3.212024486282416
  (0, 1659)	3.225294751587639
  (0, 1658)	3.279815278786668
  (0, 1657)	3.2858612498828768
  :	:
  (942, 24)	3.542913396347186
  (942, 23)	3.5392458697410527
  (942, 22)	4.173821293908858
  (942, 21)	4.223145064678933
  (942, 20)	2.863303663177249
  (942, 19)	3.576784643118526
  (942, 18)	3.8557972498748803
  (942, 17)	3.2018288552775056
  (942, 16)	3.196728295351648
  (942, 15)	3.371245682506929
  (942, 14)	3.8146702310267293
  (942, 13)	4.0437625062773135
  (942, 12)	3.4419459893572553
  (942, 11)	4.404632249343463
  (942, 10)	3.9154128102087955
  (942, 9)	3.7971439614545233
  (942, 8)	3.9730951557677416
  (942, 7)	4.06327118183729
  (942, 6)	3.8708332961392187
  (942, 5)	3.6026842094666605
  (942, 4)	3.357507917853298
  (942, 3)	3.569156500658027
  (942, 2)	3.1295082560011633
  (942, 1)	3.2828566020619783
  (942, 0)	3.933921096177345
this is the 89 epoch
rmse loss on training set is 0.9328733582050437
rmse loss on test set is 0.9505103793156431
for this epoch using 75.96319580078125 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2754778948294687
  (0, 1680)	3.284506491105432
  (0, 1679)	3.2477985181941653
  (0, 1678)	3.27777363983408
  (0, 1677)	3.2178233965542518
  (0, 1676)	3.279185235097354
  (0, 1675)	3.2794308757709234
  (0, 1674)	3.2794308757709234
  (0, 1673)	3.2794308757709234
  (0, 1672)	3.2645300590635102
  (0, 1671)	3.229360082587918
  (0, 1670)	3.2794308757709234
  (0, 1669)	3.2794308757709234
  (0, 1668)	3.2589969611319676
  (0, 1667)	3.2794308757709234
  (0, 1666)	3.2794308757709234
  (0, 1665)	3.2589969611319676
  (0, 1664)	3.2794308757709234
  (0, 1663)	3.247127214168526
  (0, 1662)	3.2589969611319676
  (0, 1661)	3.254355593051737
  (0, 1660)	3.210909747337774
  (0, 1659)	3.2243204999366113
  (0, 1658)	3.2794308757709234
  (0, 1657)	3.2855860193061135
  :	:
  (942, 24)	3.5437955751185926
  (942, 23)	3.540102176165227
  (942, 22)	4.175811374352544
  (942, 21)	4.224672162505454
  (942, 20)	2.8626891442895706
  (942, 19)	3.5792294069435084
  (942, 18)	3.859441815566006
  (942, 17)	3.202210135223831
  (942, 16)	3.197321508090283
  (942, 15)	3.372997403375873
  (942, 14)	3.8153880768828627
  (942, 13)	4.04528035606902
  (942, 12)	3.443052967375681
  (942, 11)	4.406175166393295
  (942, 10)	3.9167181272586724
  (942, 9)	3.7999047310245166
  (942, 8)	3.9741341903926477
  (942, 7)	4.064731953465199
  (942, 6)	3.871743063584819
  (942, 5)	3.606654743683112
  (942, 4)	3.358641190693022
  (942, 3)	3.5705185555699996
  (942, 2)	3.12995989186917
  (942, 1)	3.283964557622393
  (942, 0)	3.9348269020880675
this is the 90 epoch
rmse loss on training set is 0.9326641997778545
rmse loss on test set is 0.9503269238153229
for this epoch using 76.10952401161194 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.275059194357393
  (0, 1680)	3.2842078064215348
  (0, 1679)	3.247076050060798
  (0, 1678)	3.277373861382425
  (0, 1677)	3.2167782387391664
  (0, 1676)	3.278823617927706
  (0, 1675)	3.279053847359627
  (0, 1674)	3.279053847359627
  (0, 1673)	3.279053847359627
  (0, 1672)	3.26392036891064
  (0, 1671)	3.2285158160303693
  (0, 1670)	3.279053847359627
  (0, 1669)	3.279053847359627
  (0, 1668)	3.258428828441694
  (0, 1667)	3.279053847359627
  (0, 1666)	3.279053847359627
  (0, 1665)	3.258428828441694
  (0, 1664)	3.279053847359627
  (0, 1663)	3.2464131136563656
  (0, 1662)	3.258428828441694
  (0, 1661)	3.2537343253752637
  (0, 1660)	3.209803024107873
  (0, 1659)	3.223354453765714
  (0, 1658)	3.279053847359627
  (0, 1657)	3.285318570705132
  :	:
  (942, 24)	3.5446596041707874
  (942, 23)	3.540936571114323
  (942, 22)	4.177761153588656
  (942, 21)	4.226173667687469
  (942, 20)	2.8620902137872735
  (942, 19)	3.581634305245235
  (942, 18)	3.8630244365663198
  (942, 17)	3.202576498259331
  (942, 16)	3.19790366501509
  (942, 15)	3.374726029081992
  (942, 14)	3.8160883258956337
  (942, 13)	4.046761793675619
  (942, 12)	3.4441401613000795
  (942, 11)	4.407690303637575
  (942, 10)	3.9179990155350466
  (942, 9)	3.8026099544881355
  (942, 8)	3.975150614787543
  (942, 7)	4.066166682264721
  (942, 6)	3.8726338773635236
  (942, 5)	3.610591330095964
  (942, 4)	3.3597506749992903
  (942, 3)	3.571857726703881
  (942, 2)	3.1304039816485214
  (942, 1)	3.285054028115103
  (942, 0)	3.935714610077806
this is the 91 epoch
rmse loss on training set is 0.932459177553123
rmse loss on test set is 0.9501473769551962
for this epoch using 75.18437194824219 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.274647849074003
  (0, 1680)	3.2839163462776506
  (0, 1679)	3.246360822413889
  (0, 1678)	3.2769812161426213
  (0, 1677)	3.2157404286851525
  (0, 1676)	3.2784693499709956
  (0, 1675)	3.278683955598043
  (0, 1674)	3.278683955598043
  (0, 1673)	3.278683955598043
  (0, 1672)	3.2633174580104045
  (0, 1671)	3.227679692877323
  (0, 1670)	3.278683955598043
  (0, 1669)	3.278683955598043
  (0, 1668)	3.2578679309611243
  (0, 1667)	3.278683955598043
  (0, 1666)	3.278683955598043
  (0, 1665)	3.2578679309611243
  (0, 1664)	3.278683955598043
  (0, 1663)	3.2457065567227437
  (0, 1662)	3.2578679309611243
  (0, 1661)	3.253120579427333
  (0, 1660)	3.2087040735475187
  (0, 1659)	3.2223963649843967
  (0, 1658)	3.278683955598043
  (0, 1657)	3.2850586556301407
  :	:
  (942, 24)	3.545505801371724
  (942, 23)	3.5417496191898494
  (942, 22)	4.179671761451996
  (942, 21)	4.227650009003363
  (942, 20)	2.86150645620103
  (942, 19)	3.5839999574068755
  (942, 18)	3.8665461885101937
  (942, 17)	3.2029282608852836
  (942, 16)	3.1984749473134952
  (942, 15)	3.3764318947996803
  (942, 14)	3.816771349397879
  (942, 13)	4.0482079064485745
  (942, 12)	3.4452078944011926
  (942, 11)	4.409178257707962
  (942, 10)	3.9192559953779456
  (942, 9)	3.805260758677159
  (942, 8)	3.976144950021365
  (942, 7)	4.067575934283413
  (942, 6)	3.873506044642567
  (942, 5)	3.6144943418300826
  (942, 4)	3.3608368371476742
  (942, 3)	3.5731743764825192
  (942, 2)	3.130840579390022
  (942, 1)	3.286125247338734
  (942, 0)	3.9365844917772232
this is the 92 epoch
rmse loss on training set is 0.9322581748820998
rmse loss on test set is 0.9499716249441664
for this epoch using 74.8704080581665 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.274243630087216
  (0, 1680)	3.283631880080096
  (0, 1679)	3.2456526082897046
  (0, 1678)	3.2765954770487733
  (0, 1677)	3.214709739530626
  (0, 1676)	3.2781221989350855
  (0, 1675)	3.278320972935218
  (0, 1674)	3.278320972935218
  (0, 1673)	3.278320972935218
  (0, 1672)	3.2627211164935925
  (0, 1671)	3.2268514743836567
  (0, 1670)	3.278320972935218
  (0, 1669)	3.278320972935218
  (0, 1668)	3.257314037106475
  (0, 1667)	3.278320972935218
  (0, 1666)	3.278320972935218
  (0, 1665)	3.257314037106475
  (0, 1664)	3.278320972935218
  (0, 1663)	3.245007313635439
  (0, 1662)	3.257314037106475
  (0, 1661)	3.2525141250601126
  (0, 1660)	3.2076126630263584
  (0, 1659)	3.221445996119993
  (0, 1658)	3.278320972935218
  (0, 1657)	3.2848060362657967
  :	:
  (942, 24)	3.5463344802559433
  (942, 23)	3.5425418669766002
  (942, 22)	4.18154428298443
  (942, 21)	4.229101604710104
  (942, 20)	2.860937466176037
  (942, 19)	3.586326973444232
  (942, 18)	3.8700081277340597
  (942, 17)	3.2032657332186285
  (942, 16)	3.199035533275969
  (942, 15)	3.3781153302002216
  (942, 14)	3.817437508304477
  (942, 13)	4.049619738924661
  (942, 12)	3.446256484723364
  (942, 11)	4.410639603390681
  (942, 10)	3.9204895696852256
  (942, 9)	3.8078582473654685
  (942, 8)	3.977117699166023
  (942, 7)	4.068960254209425
  (942, 6)	3.8743598700146498
  (942, 5)	3.618364147074306
  (942, 4)	3.3619001347239736
  (942, 3)	3.5744688620626293
  (942, 2)	3.131269740910116
  (942, 1)	3.287178448950507
  (942, 0)	3.937436817843172
this is the 93 epoch
rmse loss on training set is 0.9320610794987632
rmse loss on test set is 0.9497995584346799
for this epoch using 75.50891327857971 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2738463183753232
  (0, 1680)	3.2833541872775855
  (0, 1679)	3.2449511905866912
  (0, 1678)	3.276216426910406
  (0, 1677)	3.2136859542629685
  (0, 1676)	3.2777819425650496
  (0, 1675)	3.2779646817302717
  (0, 1674)	3.2779646817302717
  (0, 1673)	3.2779646817302717
  (0, 1672)	3.262131143922737
  (0, 1671)	3.226030931920702
  (0, 1670)	3.2779646817302717
  (0, 1669)	3.2779646817302717
  (0, 1668)	3.2567669253871205
  (0, 1667)	3.2779646817302717
  (0, 1666)	3.2779646817302717
  (0, 1665)	3.2567669253871205
  (0, 1664)	3.2779646817302717
  (0, 1663)	3.2443151645695316
  (0, 1662)	3.2567669253871205
  (0, 1661)	3.2519147420940904
  (0, 1660)	3.2065285698384582
  (0, 1659)	3.2205031198196457
  (0, 1658)	3.2779646817302717
  (0, 1657)	3.284560484932959
  :	:
  (942, 24)	3.547145950014747
  (942, 23)	3.543313843790539
  (942, 22)	4.183379760640336
  (942, 21)	4.230528863211242
  (942, 20)	2.860382848279615
  (942, 19)	3.5886159541834997
  (942, 18)	3.8734112916583285
  (942, 17)	3.2035892191398125
  (942, 16)	3.1995855983487402
  (942, 15)	3.3797766595842202
  (942, 14)	3.8180871536864776
  (942, 13)	4.050998294874049
  (942, 12)	3.4472862452329895
  (942, 11)	4.412074895048691
  (942, 10)	3.9217002249098285
  (942, 9)	3.810403501762344
  (942, 8)	3.9780693483415455
  (942, 7)	4.070320166712178
  (942, 6)	3.875195655392672
  (942, 5)	3.6222011091711965
  (942, 4)	3.3629410166740943
  (942, 3)	3.5757415354405846
  (942, 2)	3.131691523681839
  (942, 1)	3.288213866319145
  (942, 0)	3.9382718577293034
this is the 94 epoch
rmse loss on training set is 0.9318677833109563
rmse loss on test set is 0.94963107230333
for this epoch using 75.58305788040161 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.273455704316606
  (0, 1680)	3.28308305688087
  (0, 1679)	3.2442563615932736
  (0, 1678)	3.2758438579402025
  (0, 1677)	3.212668865246353
  (0, 1676)	3.277448368165949
  (0, 1675)	3.2776148737784667
  (0, 1674)	3.2776148737784667
  (0, 1673)	3.2776148737784667
  (0, 1672)	3.261547348829403
  (0, 1671)	3.2252178464951653
  (0, 1670)	3.2776148737784667
  (0, 1669)	3.2776148737784667
  (0, 1668)	3.2562263839232446
  (0, 1667)	3.2776148737784667
  (0, 1666)	3.2776148737784667
  (0, 1665)	3.2562263839232446
  (0, 1664)	3.2776148737784667
  (0, 1663)	3.2436298991344428
  (0, 1662)	3.2562263839232446
  (0, 1661)	3.2513222198413407
  (0, 1660)	3.2054515807316717
  (0, 1659)	3.219567518372113
  (0, 1658)	3.2776148737784667
  (0, 1657)	3.284321783610472
  :	:
  (942, 24)	3.5479405154897834
  (942, 23)	3.54406606238844
  (942, 22)	4.185179196371734
  (942, 21)	4.231932183659065
  (942, 20)	2.8598422168087647
  (942, 19)	3.590867491431206
  (942, 18)	3.876756699159079
  (942, 17)	3.2038990164355576
  (942, 16)	3.2001253151848386
  (942, 15)	3.3814162020077583
  (942, 14)	3.8187206272964676
  (942, 13)	4.052344539239771
  (942, 12)	3.44829748395521
  (942, 11)	4.4134846679273085
  (942, 10)	3.9228884319837616
  (942, 9)	3.8128975809926624
  (942, 8)	3.9790003676815333
  (942, 7)	4.071656177682391
  (942, 6)	3.8760136999107977
  (942, 5)	3.6260055867031125
  (942, 4)	3.363959923452014
  (942, 3)	3.576992743548652
  (942, 2)	3.1321059867292766
  (942, 1)	3.2892317323848177
  (942, 0)	3.939089879476171
this is the 95 epoch
rmse loss on training set is 0.9316781822037472
rmse loss on test set is 0.9494660654444916
for this epoch using 74.8069109916687 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2730715872387512
  (0, 1680)	3.2828182870026374
  (0, 1679)	3.2435679225356466
  (0, 1678)	3.275477571301627
  (0, 1677)	3.211658273769678
  (0, 1676)	3.277121272145706
  (0, 1675)	3.2772713498573642
  (0, 1674)	3.2772713498573642
  (0, 1673)	3.2772713498573642
  (0, 1672)	3.260969548271155
  (0, 1671)	3.2244120082884087
  (0, 1670)	3.2772713498573642
  (0, 1669)	3.2772713498573642
  (0, 1668)	3.2556922099838896
  (0, 1667)	3.2772713498573642
  (0, 1666)	3.2772713498573642
  (0, 1665)	3.2556922099838896
  (0, 1664)	3.2772713498573642
  (0, 1663)	3.24295131592091
  (0, 1662)	3.2556922099838896
  (0, 1661)	3.2507363566489205
  (0, 1660)	3.2043814914567137
  (0, 1659)	3.2186389832494933
  (0, 1658)	3.2772713498573642
  (0, 1657)	3.2840897234768445
  :	:
  (942, 24)	3.548718477170392
  (942, 23)	3.544799019641493
  (942, 22)	4.1869435536002335
  (942, 21)	4.233311956497389
  (942, 20)	2.8593151955979144
  (942, 19)	3.593082168137047
  (942, 18)	3.8800453509299833
  (942, 17)	3.2041954169369298
  (942, 16)	3.2006548536938277
  (942, 15)	3.383034271402607
  (942, 14)	3.8193382620499152
  (942, 13)	4.0536593999746175
  (942, 12)	3.4492905040998614
  (942, 11)	4.414869439353458
  (942, 10)	3.924054647174863
  (942, 9)	3.8153415225644682
  (942, 8)	3.9799112122258937
  (942, 7)	4.072968775379771
  (942, 6)	3.876814299832198
  (942, 5)	3.629777933574968
  (942, 4)	3.364957287165799
  (942, 3)	3.578222828343019
  (942, 2)	3.1325131905255374
  (942, 1)	3.2902322795259673
  (942, 0)	3.9398911495196867
this is the 96 epoch
rmse loss on training set is 0.9314921758538918
rmse loss on test set is 0.9493044405760823
for this epoch using 75.03970694541931 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2726937749875837
  (0, 1680)	3.2825596844172638
  (0, 1679)	3.242885683145042
  (0, 1678)	3.275117376676
  (0, 1677)	3.2106539896140927
  (0, 1676)	3.2768004595775064
  (0, 1675)	3.2769339192924467
  (0, 1674)	3.2769339192924467
  (0, 1673)	3.2769339192924467
  (0, 1672)	3.260397567407962
  (0, 1671)	3.2236132162157154
  (0, 1670)	3.2769339192924467
  (0, 1669)	3.2769339192924467
  (0, 1668)	3.255164209544858
  (0, 1667)	3.2769339192924467
  (0, 1666)	3.2769339192924467
  (0, 1665)	3.255164209544858
  (0, 1664)	3.2769339192924467
  (0, 1663)	3.2422792220674723
  (0, 1662)	3.255164209544858
  (0, 1661)	3.250156959461996
  (0, 1660)	3.203318106335695
  (0, 1659)	3.2177173146684823
  (0, 1658)	3.2769339192924467
  (0, 1657)	3.2838641044715673
  :	:
  (942, 24)	3.5494801311946027
  (942, 23)	3.545513197174977
  (942, 22)	4.188673759082226
  (942, 21)	4.2346685639511765
  (942, 20)	2.858801417827432
  (942, 19)	3.5952605585501494
  (942, 18)	3.8832782298349184
  (942, 17)	3.204478706653008
  (942, 16)	3.2011743810900457
  (942, 15)	3.384631176690989
  (942, 14)	3.819940382466513
  (942, 13)	4.054943769781305
  (942, 12)	3.450265604178006
  (942, 11)	4.416229709837597
  (942, 10)	3.9251993128814053
  (942, 9)	3.8177363428245905
  (942, 8)	3.9808023227464417
  (942, 7)	4.074258431495177
  (942, 6)	3.8775977484635638
  (942, 5)	3.6335184990938347
  (942, 4)	3.3659335317218924
  (942, 3)	3.5794321268848726
  (942, 2)	3.1329131968941932
  (942, 1)	3.291215739432873
  (942, 0)	3.9406759325171503
this is the 97 epoch
rmse loss on training set is 0.9313096675550225
rmse loss on test set is 0.9491461040566831
for this epoch using 75.83444905281067 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2723220835150886
  (0, 1680)	3.282307064140254
  (0, 1679)	3.2422094612444714
  (0, 1678)	3.274763091848953
  (0, 1677)	3.2096558306399903
  (0, 1676)	3.2764857437817225
  (0, 1675)	3.276602399542166
  (0, 1674)	3.276602399542166
  (0, 1673)	3.276602399542166
  (0, 1672)	3.2598312390977213
  (0, 1671)	3.2228212775053775
  (0, 1670)	3.276602399542166
  (0, 1669)	3.276602399542166
  (0, 1668)	3.2546421968665302
  (0, 1667)	3.276602399542166
  (0, 1666)	3.276602399542166
  (0, 1665)	3.2546421968665302
  (0, 1664)	3.276602399542166
  (0, 1663)	3.2416134328464192
  (0, 1662)	3.2546421968665302
  (0, 1661)	3.249583843406543
  (0, 1660)	3.202261237849917
  (0, 1659)	3.2168023211710746
  (0, 1658)	3.276602399542166
  (0, 1657)	3.283644734875901
  :	:
  (942, 24)	3.5502257693539545
  (942, 23)	3.5462090619760516
  (942, 22)	4.190370704673477
  (942, 21)	4.236002380468222
  (942, 20)	2.858300525832987
  (942, 19)	3.5974032283692985
  (942, 18)	3.8864563012516884
  (942, 17)	3.2047491659002554
  (942, 16)	3.201684061939745
  (942, 15)	3.386207221895265
  (942, 14)	3.820527305075337
  (942, 13)	4.056198507761355
  (942, 12)	3.4512230781097943
  (942, 11)	4.417565964086777
  (942, 10)	3.926322858369647
  (942, 9)	3.8200830374027825
  (942, 8)	3.9816741265112974
  (942, 7)	4.075525602134112
  (942, 6)	3.8783643360766504
  (942, 5)	3.6372276280457085
  (942, 4)	3.366889072967359
  (942, 3)	3.5806209714152657
  (942, 2)	3.13330606891416
  (942, 1)	3.29218234298781
  (942, 0)	3.941444491189318
this is the 98 epoch
rmse loss on training set is 0.9311305640524838
rmse loss on test set is 0.9489909657131473
for this epoch using 75.22890305519104 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2719563364860034
  (0, 1680)	3.2820602490267965
  (0, 1679)	3.241539082354212
  (0, 1678)	3.2744145423156508
  (0, 1677)	3.208663622392782
  (0, 1676)	3.2761769459266805
  (0, 1675)	3.2762766158018084
  (0, 1674)	3.2762766158018084
  (0, 1673)	3.2762766158018084
  (0, 1672)	3.259270403510499
  (0, 1671)	3.2220360072969583
  (0, 1670)	3.2762766158018084
  (0, 1669)	3.2762766158018084
  (0, 1668)	3.2541259940907614
  (0, 1667)	3.2762766158018084
  (0, 1666)	3.2762766158018084
  (0, 1665)	3.2541259940907614
  (0, 1664)	3.2762766158018084
  (0, 1663)	3.240953771268519
  (0, 1662)	3.2541259940907614
  (0, 1661)	3.2490168313910477
  (0, 1660)	3.201210706246276
  (0, 1659)	3.215893819224092
  (0, 1658)	3.2762766158018084
  (0, 1657)	3.283431430912454
  :	:
  (942, 24)	3.5509556791020254
  (942, 23)	3.5468870669715096
  (942, 22)	4.192035248998943
  (942, 21)	4.237313773118092
  (942, 20)	2.857812170916185
  (942, 19)	3.5995107348875552
  (942, 18)	3.8895805134072594
  (942, 17)	3.2050070694279844
  (942, 16)	3.202184058206885
  (942, 15)	3.387762706242879
  (942, 14)	3.821099338787164
  (942, 13)	4.057424440977807
  (942, 12)	3.4521632153247563
  (942, 11)	4.418878671936483
  (942, 10)	3.927425700458569
  (942, 9)	3.8223825816448236
  (942, 8)	3.9825270379929543
  (942, 7)	4.0767707287275865
  (942, 6)	3.8791143498367426
  (942, 5)	3.6409056607696164
  (942, 4)	3.3678243188305164
  (942, 3)	3.5817896894249466
  (942, 2)	3.133691870828016
  (942, 1)	3.2931323201516687
  (942, 0)	3.9421970861777793
this is the 99 epoch
rmse loss on training set is 0.9309547753874483
rmse loss on test set is 0.9488389386780911
for this epoch using 75.17122411727905 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2715963649028184
  (0, 1680)	3.281819069389068
  (0, 1679)	3.2408743793158106
  (0, 1678)	3.2740715609043947
  (0, 1677)	3.2076771977272305
  (0, 1676)	3.2758738946479795
  (0, 1675)	3.275956400625835
  (0, 1674)	3.275956400625835
  (0, 1673)	3.275956400625835
  (0, 1672)	3.2587149077609237
  (0, 1671)	3.221257228258352
  (0, 1670)	3.275956400625835
  (0, 1669)	3.275956400625835
  (0, 1668)	3.2536154308566494
  (0, 1667)	3.275956400625835
  (0, 1666)	3.275956400625835
  (0, 1665)	3.2536154308566494
  (0, 1664)	3.275956400625835
  (0, 1663)	3.2403000677061695
  (0, 1662)	3.2536154308566494
  (0, 1661)	3.248455753726771
  (0, 1660)	3.200166339162008
  (0, 1659)	3.2149916328371835
  (0, 1658)	3.275956400625835
  (0, 1657)	3.2832240163633553
  :	:
  (942, 24)	3.551670143566699
  (942, 23)	3.547547651577277
  (942, 22)	4.193668219033134
  (942, 21)	4.238603101952493
  (942, 20)	2.8573360131566288
  (942, 19)	3.6015836271317645
  (942, 18)	3.8926517977047883
  (942, 17)	3.205252686540001
  (942, 16)	3.2026745292979952
  (942, 15)	3.3892979242669825
  (942, 14)	3.821656785237065
  (942, 13)	4.058622365936598
  (942, 12)	3.453086300855241
  (942, 11)	4.420168289208199
  (942, 10)	3.9285082441561645
  (942, 9)	3.8246359310351026
  (942, 8)	3.983361459524471
  (942, 7)	4.077994238875986
  (942, 6)	3.8798480737379073
  (942, 5)	3.6445529332292232
  (942, 4)	3.3687396694597243
  (942, 3)	3.5829386037196715
  (942, 2)	3.134070667953659
  (942, 1)	3.2940658998568133
  (942, 0)	3.942933975916563
this is the 100 epoch
rmse loss on training set is 0.9307822147495115
rmse loss on test set is 0.9486899392365302
for this epoch using 75.69943714141846 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2712420067483814
  (0, 1680)	3.2815833626315576
  (0, 1679)	3.2402151919337805
  (0, 1678)	3.273733987417999
  (0, 1677)	3.2066963964495545
  (0, 1676)	3.275576425685656
  (0, 1675)	3.2756415935680345
  (0, 1674)	3.2756415935680345
  (0, 1673)	3.2756415935680345
  (0, 1672)	3.258164605558295
  (0, 1671)	3.2204847702209887
  (0, 1670)	3.2756415935680345
  (0, 1669)	3.2756415935680345
  (0, 1668)	3.2531103439344062
  (0, 1667)	3.2756415935680345
  (0, 1666)	3.2756415935680345
  (0, 1665)	3.2531103439344062
  (0, 1664)	3.2756415935680345
  (0, 1663)	3.2396521595343746
  (0, 1662)	3.2531103439344062
  (0, 1661)	3.247900447766022
  (0, 1660)	3.1991279712671123
  (0, 1659)	3.2140955931987247
  (0, 1658)	3.2756415935680345
  (0, 1657)	3.2830223222062083
  :	:
  (942, 24)	3.5523694415658285
  (942, 23)	3.548191242221122
  (942, 22)	4.195270411596147
  (942, 21)	4.239870720331121
  (942, 20)	2.8568717212257004
  (942, 19)	3.603622445997235
  (942, 18)	3.895671069042911
  (942, 17)	3.2054862812126506
  (942, 16)	3.203155632105869
  (942, 15)	3.390813165902957
  (942, 14)	3.8221999390999355
  (942, 13)	4.059793049991177
  (942, 12)	3.4539926154236733
  (942, 11)	4.421435258499092
  (942, 10)	3.929570883250837
  (942, 9)	3.8268440216090442
  (942, 8)	3.9841777819083655
  (942, 7)	4.079196547131116
  (942, 6)	3.880565788545009
  (942, 5)	3.6481697770822605
  (942, 4)	3.3696355173602974
  (942, 3)	3.5840680324817895
  (942, 2)	3.1344425265992664
  (942, 1)	3.294983309906098
  (942, 0)	3.9436554165169553
this is the 101 epoch
rmse loss on training set is 0.9306127983374458
rmse loss on test set is 0.9485438866811196
for this epoch using 75.79535102844238 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2708931066457017
  (0, 1680)	3.281352972904034
  (0, 1679)	3.2395613666347076
  (0, 1678)	3.2734016682925087
  (0, 1677)	3.205721064976913
  (0, 1676)	3.2752843815388135
  (0, 1675)	3.2753320408389834
  (0, 1674)	3.2753320408389834
  (0, 1673)	3.2753320408389834
  (0, 1672)	3.2576193568737697
  (0, 1671)	3.219718469832639
  (0, 1670)	3.2753320408389834
  (0, 1669)	3.2753320408389834
  (0, 1668)	3.252610576876874
  (0, 1667)	3.2753320408389834
  (0, 1666)	3.2753320408389834
  (0, 1665)	3.252610576876874
  (0, 1664)	3.2753320408389834
  (0, 1663)	3.239009890789089
  (0, 1662)	3.252610576876874
  (0, 1661)	3.2473507575578147
  (0, 1660)	3.198095443923909
  (0, 1659)	3.213205538329088
  (0, 1658)	3.2753320408389834
  (0, 1657)	3.282826186267534
  :	:
  (942, 24)	3.553053847626477
  (942, 23)	3.5488182528402796
  (942, 22)	4.196842594770154
  (942, 21)	4.241116975216521
  (942, 20)	2.856418972202162
  (942, 19)	3.6056277243780683
  (942, 18)	3.8986392261274263
  (942, 17)	3.2057081122094173
  (942, 16)	3.2036275210522716
  (942, 15)	3.3923087165811445
  (942, 14)	3.8227290883816543
  (942, 13)	4.060937232674449
  (942, 12)	3.454882435524314
  (942, 11)	4.4226800099094925
  (942, 10)	3.930614000861542
  (942, 9)	3.8290077703557746
  (942, 8)	3.98497638498176
  (942, 7)	4.080378055721194
  (942, 6)	3.881267771742291
  (942, 5)	3.6517565197476958
  (942, 4)	3.3705122475297493
  (942, 3)	3.5851782893286326
  (942, 2)	3.1348075139814764
  (942, 1)	3.295884776877671
  (942, 0)	3.9443616616646735
this is the 102 epoch
rmse loss on training set is 0.9304464452272388
rmse loss on test set is 0.9484007031753873
for this epoch using 75.50339794158936 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.270549515534344
  (0, 1680)	3.281127750771364
  (0, 1679)	3.238912756142964
  (0, 1678)	3.2730744562724516
  (0, 1677)	3.2047510560134773
  (0, 1676)	3.274997611136926
  (0, 1675)	3.275027594980246
  (0, 1674)	3.275027594980246
  (0, 1673)	3.275027594980246
  (0, 1672)	3.2570790276240875
  (0, 1671)	3.2189581702271766
  (0, 1670)	3.275027594980246
  (0, 1669)	3.275027594980246
  (0, 1668)	3.2521159796880577
  (0, 1667)	3.275027594980246
  (0, 1666)	3.275027594980246
  (0, 1665)	3.2521159796880577
  (0, 1664)	3.275027594980246
  (0, 1663)	3.2383731118420807
  (0, 1662)	3.2521159796880577
  (0, 1661)	3.2468065335203695
  (0, 1660)	3.197068604863189
  (0, 1659)	3.2123213127506216
  (0, 1658)	3.275027594980246
  (0, 1657)	3.282635452892853
  :	:
  (942, 24)	3.5537236320073045
  (942, 23)	3.549429085355295
  (942, 22)	4.198385509240834
  (942, 21)	4.242342207441243
  (942, 20)	2.855977451389789
  (942, 19)	3.6075999872933244
  (942, 18)	3.9015571517758247
  (942, 17)	3.2059184331923114
  (942, 16)	3.2040903481297556
  (942, 15)	3.393784857316035
  (942, 14)	3.8232445146879224
  (942, 13)	4.062055626962296
  (942, 12)	3.455756033500141
  (942, 11)	4.4239029617137335
  (942, 10)	3.931637969949753
  (942, 9)	3.831128075611369
  (942, 8)	3.9857576381414392
  (942, 7)	4.081539155223223
  (942, 6)	3.8819542974881673
  (942, 5)	3.655313484471051
  (942, 4)	3.3713702375912042
  (942, 3)	3.5862696833682355
  (942, 2)	3.13516569814678
  (942, 1)	3.29677052603558
  (942, 0)	3.9450529625284045
this is the 103 epoch
rmse loss on training set is 0.9302830772473819
rmse loss on test set is 0.9482603136245105
for this epoch using 75.50749087333679 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2702110903627175
  (0, 1680)	3.2809075528996856
  (0, 1679)	3.238269219172429
  (0, 1678)	3.2727522101022126
  (0, 1677)	3.203786228242645
  (0, 1676)	3.274715969527315
  (0, 1675)	3.274728114554604
  (0, 1674)	3.274728114554604
  (0, 1673)	3.274728114554604
  (0, 1672)	3.256543489371105
  (0, 1671)	3.2182037207106817
  (0, 1670)	3.274728114554604
  (0, 1669)	3.274728114554604
  (0, 1668)	3.2516264085079123
  (0, 1667)	3.274728114554604
  (0, 1666)	3.274728114554604
  (0, 1665)	3.2516264085079123
  (0, 1664)	3.274728114554604
  (0, 1663)	3.2377416790920304
  (0, 1662)	3.2516264085079123
  (0, 1661)	3.2462676321298134
  (0, 1660)	3.196047307876253
  (0, 1659)	3.211442767173844
  (0, 1658)	3.274728114554604
  (0, 1657)	3.282449972632989
  :	:
  (942, 24)	3.5543790607240284
  (942, 23)	3.5500241301214603
  (942, 22)	4.199899869567967
  (942, 21)	4.243546751950017
  (942, 20)	2.855546852137159
  (942, 19)	3.6095397520094603
  (942, 18)	3.9044257132148332
  (942, 17)	3.2061174928300695
  (942, 16)	3.2045442629424836
  (942, 15)	3.3952418647921916
  (942, 14)	3.823746493473013
  (942, 13)	4.063148920472217
  (942, 12)	3.456613677615312
  (942, 11)	4.42510452097891
  (942, 10)	3.932643153796312
  (942, 9)	3.833205817443081
  (942, 8)	3.986521900832128
  (942, 7)	4.0826802251867145
  (942, 6)	3.882625636576214
  (942, 5)	3.6588409903877346
  (942, 4)	3.3722098579250774
  (942, 3)	3.587342519252718
  (942, 2)	3.135517147895905
  (942, 1)	3.297640781245879
  (942, 0)	3.945729567679091
this is the 104 epoch
rmse loss on training set is 0.9301226188605806
rmse loss on test set is 0.9481226455530289
for this epoch using 75.04500079154968 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.26987769379566
  (0, 1680)	3.280692241758103
  (0, 1679)	3.237630620133631
  (0, 1678)	3.272434794232698
  (0, 1677)	3.2028264460345723
  (0, 1676)	3.274439317578109
  (0, 1675)	3.2744334638516848
  (0, 1674)	3.2744334638516848
  (0, 1673)	3.2744334638516848
  (0, 1672)	3.2560126190366305
  (0, 1671)	3.2174549764631073
  (0, 1670)	3.2744334638516848
  (0, 1669)	3.2744334638516848
  (0, 1668)	3.25114172531289
  (0, 1667)	3.2744334638516848
  (0, 1666)	3.2744334638516848
  (0, 1665)	3.25114172531289
  (0, 1664)	3.2744334638516848
  (0, 1663)	3.2371154546708176
  (0, 1662)	3.25114172531289
  (0, 1661)	3.245733915624305
  (0, 1660)	3.1950314125222268
  (0, 1659)	3.210569758198993
  (0, 1658)	3.2744334638516848
  (0, 1657)	3.282269601945746
  :	:
  (942, 24)	3.555020395577818
  (942, 23)	3.550603766359022
  (942, 22)	4.2013863653891175
  (942, 21)	4.244730938019689
  (942, 20)	2.855126875659766
  (942, 19)	3.6114475281591614
  (942, 18)	3.9072457623712644
  (942, 17)	3.206305534903466
  (942, 16)	3.2049894127462712
  (942, 15)	3.396680011447057
  (942, 14)	3.8242352942701787
  (942, 13)	4.064217776600774
  (942, 12)	3.4574556321236565
  (942, 11)	4.426285084136146
  (942, 10)	3.9336299064457068
  (942, 9)	3.835241858024746
  (942, 8)	3.9872695230008093
  (942, 7)	4.083801634712609
  (942, 6)	3.8832820564017885
  (942, 5)	3.6623393525847985
  (942, 4)	3.3730314717988987
  (942, 3)	3.5883970972299166
  (942, 2)	3.135861932711313
  (942, 1)	3.2984957648980293
  (942, 0)	3.946391723018934
this is the 105 epoch
rmse loss on training set is 0.9299649970517366
rmse loss on test set is 0.9479876289892373
for this epoch using 75.52175998687744 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2695491939368497
  (0, 1680)	3.2804816853355683
  (0, 1679)	3.236996828855726
  (0, 1678)	3.2721220785429064
  (0, 1677)	3.2018715791685426
  (0, 1676)	3.2741675216960915
  (0, 1675)	3.2741435126085228
  (0, 1674)	3.2741435126085228
  (0, 1673)	3.2741435126085228
  (0, 1672)	3.255486298631876
  (0, 1671)	3.2167117982551185
  (0, 1670)	3.2741435126085228
  (0, 1669)	3.2741435126085228
  (0, 1668)	3.2506617976315395
  (0, 1667)	3.2741435126085228
  (0, 1666)	3.2741435126085228
  (0, 1665)	3.2506617976315395
  (0, 1664)	3.2741435126085228
  (0, 1663)	3.2364943061647997
  (0, 1662)	3.2506617976315395
  (0, 1661)	3.2452052517231817
  (0, 1660)	3.194020783850139
  (0, 1659)	3.209702148032628
  (0, 1658)	3.2741435126085228
  (0, 1657)	3.282094202912566
  :	:
  (942, 24)	3.5556478941863205
  (942, 23)	3.5511683625634167
  (942, 22)	4.20284566256026
  (942, 21)	4.245895089459228
  (942, 20)	2.854717230864481
  (942, 19)	3.613323817856956
  (942, 18)	3.910018136156346
  (942, 17)	3.2064827984076967
  (942, 16)	3.205425942487665
  (942, 15)	3.3980995655508877
  (942, 14)	3.824711180905432
  (942, 13)	4.065262835603136
  (942, 12)	3.4582821573337026
  (942, 11)	4.427445037508402
  (942, 10)	3.9345985731204416
  (942, 9)	3.837237042003806
  (942, 8)	3.9880008455198945
  (942, 7)	4.084903742990751
  (942, 6)	3.8839238209344553
  (942, 5)	3.665808882160969
  (942, 4)	3.3738354354954776
  (942, 3)	3.58943371319334
  (942, 2)	3.1362001226875447
  (942, 1)	3.299335697831479
  (942, 0)	3.9470396717194762
this is the 106 epoch
rmse loss on training set is 0.9298101412216397
rmse loss on test set is 0.9478551963556442
for this epoch using 75.35568881034851 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2692254640651104
  (0, 1680)	3.280275756872004
  (0, 1679)	3.2363677203225034
  (0, 1678)	3.2718139380755025
  (0, 1677)	3.2009215025695053
  (0, 1676)	3.2739004535588183
  (0, 1675)	3.2738581357441467
  (0, 1674)	3.2738581357441467
  (0, 1673)	3.2738581357441467
  (0, 1672)	3.254964415000866
  (0, 1671)	3.215974052179194
  (0, 1670)	3.2738581357441467
  (0, 1669)	3.2738581357441467
  (0, 1668)	3.2501864982745037
  (0, 1667)	3.2738581357441467
  (0, 1666)	3.2738581357441467
  (0, 1665)	3.2501864982745037
  (0, 1664)	3.2738581357441467
  (0, 1663)	3.235878106350138
  (0, 1662)	3.2501864982745037
  (0, 1661)	3.244681513360309
  (0, 1660)	3.193015292134937
  (0, 1659)	3.208839804218398
  (0, 1658)	3.2738581357441467
  (0, 1657)	3.2819236429694145
  :	:
  (942, 24)	3.5562618100172414
  (942, 23)	3.5517182768965365
  (942, 22)	4.204278404236722
  (942, 21)	4.247039524791749
  (942, 20)	2.854317634176495
  (942, 19)	3.6151691158117
  (942, 18)	3.9127436567439005
  (942, 17)	3.206649517652062
  (942, 16)	3.205853994842321
  (942, 15)	3.3995007912840163
  (942, 14)	3.82517441169623
  (942, 13)	4.066284715617935
  (942, 12)	3.4590935096704807
  (942, 11)	4.428584757798346
  (942, 10)	3.935549490607632
  (942, 9)	3.8391921968601035
  (942, 8)	3.9887162005817043
  (942, 7)	4.0859868997990425
  (942, 6)	3.884551190695368
  (942, 5)	3.6692498862851437
  (942, 4)	3.3746220984391933
  (942, 3)	3.5904526587308356
  (942, 2)	3.1365317884644903
  (942, 1)	3.300160799267114
  (942, 0)	3.9476736541682325
this is the 107 epoch
rmse loss on training set is 0.929657983086215
rmse loss on test set is 0.9477252823652691
for this epoch using 75.92668509483337 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.268906382384279
  (0, 1680)	3.2800743346031767
  (0, 1679)	3.2357431744220104
  (0, 1678)	3.271510252785986
  (0, 1677)	3.1999760960580272
  (0, 1676)	3.273637989860288
  (0, 1675)	3.2735772131078815
  (0, 1674)	3.2735772131078815
  (0, 1673)	3.2735772131078815
  (0, 1672)	3.254446859577282
  (0, 1671)	3.2152416093944796
  (0, 1670)	3.2735772131078815
  (0, 1669)	3.2735772131078815
  (0, 1668)	3.2497157050782595
  (0, 1667)	3.2735772131078815
  (0, 1666)	3.2735772131078815
  (0, 1665)	3.2497157050782595
  (0, 1664)	3.2735772131078815
  (0, 1663)	3.2352667329416347
  (0, 1662)	3.2497157050782595
  (0, 1661)	3.244162578431069
  (0, 1660)	3.1920148126269883
  (0, 1659)	3.2079825993813986
  (0, 1658)	3.2735772131078815
  (0, 1657)	3.2817577946512024
  :	:
  (942, 24)	3.556862392424171
  (942, 23)	3.5522538575601508
  (942, 22)	4.205685211897923
  (942, 21)	4.248164557420657
  (942, 20)	2.853927809368854
  (942, 19)	3.6169839094362106
  (942, 18)	3.9154231318423935
  (942, 17)	3.2068059223570695
  (942, 16)	3.2062737102525443
  (942, 15)	3.4008839488115443
  (942, 14)	3.8256252396364814
  (942, 13)	4.067284013640205
  (942, 12)	3.459889941734589
  (942, 11)	4.42970461253997
  (942, 10)	3.936482987619999
  (942, 9)	3.8411081332567316
  (942, 8)	3.9894159120665575
  (942, 7)	4.0870514459674165
  (942, 6)	3.885164422739856
  (942, 5)	3.6726626682536065
  (942, 4)	3.3753918033205172
  (942, 3)	3.5914542211722575
  (942, 2)	3.1368570011633286
  (942, 1)	3.3009712867435153
  (942, 0)	3.948293907922906
this is the 108 epoch
rmse loss on training set is 0.9295084565807333
rmse loss on test set is 0.9475978239233488
for this epoch using 75.51412916183472 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.268591831785893
  (0, 1680)	3.2798773015186695
  (0, 1679)	3.2351230757089473
  (0, 1678)	3.2712109073047095
  (0, 1677)	3.1990352441132
  (0, 1676)	3.273380012069647
  (0, 1675)	3.2733006292404223
  (0, 1674)	3.2733006292404223
  (0, 1673)	3.2733006292404223
  (0, 1672)	3.2539335281539534
  (0, 1671)	3.214514345884727
  (0, 1670)	3.2733006292404223
  (0, 1669)	3.2733006292404223
  (0, 1668)	3.24924930066206
  (0, 1667)	3.2733006292404223
  (0, 1666)	3.2733006292404223
  (0, 1665)	3.24924930066206
  (0, 1664)	3.2733006292404223
  (0, 1663)	3.234660068354511
  (0, 1662)	3.24924930066206
  (0, 1661)	3.243648329552307
  (0, 1660)	3.191019225314402
  (0, 1659)	3.207130410985637
  (0, 1658)	3.2733006292404223
  (0, 1657)	3.281596535349272
  :	:
  (942, 24)	3.557449886684589
  (942, 23)	3.55277544315229
  (942, 22)	4.20706668631883
  (942, 21)	4.249270495781434
  (942, 20)	2.853547487394592
  (942, 19)	3.618768678954232
  (942, 18)	3.918057354961184
  (942, 17)	3.206952237748963
  (942, 16)	3.2066852269640633
  (942, 15)	3.4022492943556797
  (942, 14)	3.826063912568946
  (942, 13)	4.0682613064455735
  (942, 12)	3.460671702358725
  (942, 11)	4.43080496051664
  (942, 10)	3.93739938513331
  (942, 9)	3.8429856453832794
  (942, 8)	3.990100295886513
  (942, 7)	4.08809771380907
  (942, 6)	3.8857637706446018
  (942, 5)	3.6760475275456836
  (942, 4)	3.376144886218852
  (942, 3)	3.592438683636234
  (942, 2)	3.137175832325268
  (942, 1)	3.3017673760578017
  (942, 0)	3.9489006676728433
this is the 109 epoch
rmse loss on training set is 0.9293614977689875
rmse loss on test set is 0.9474727600341253
for this epoch using 75.71761274337769 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2682816996240542
  (0, 1680)	3.2796845451324104
  (0, 1679)	3.2345073131795137
  (0, 1678)	3.2709157907112147
  (0, 1677)	3.198098835647813
  (0, 1676)	3.273126406202282
  (0, 1675)	3.2730282731473475
  (0, 1674)	3.2730282731473475
  (0, 1673)	3.2730282731473475
  (0, 1672)	3.253424320664599
  (0, 1671)	3.213792142228782
  (0, 1670)	3.2730282731473475
  (0, 1669)	3.2730282731473475
  (0, 1668)	3.2487871721973374
  (0, 1667)	3.2730282731473475
  (0, 1666)	3.2730282731473475
  (0, 1665)	3.2487871721973374
  (0, 1664)	3.2730282731473475
  (0, 1663)	3.2340579994784524
  (0, 1662)	3.2487871721973374
  (0, 1661)	3.243138653834782
  (0, 1660)	3.1900284146975117
  (0, 1659)	3.2062831211038203
  (0, 1658)	3.2730282731473475
  (0, 1657)	3.281439747081239
  :	:
  (942, 24)	3.5580245340396996
  (942, 23)	3.5532833630076817
  (942, 22)	4.208423408491263
  (942, 21)	4.250357643480605
  (942, 20)	2.8531764062215563
  (942, 19)	3.620523897504896
  (942, 18)	3.920647105671104
  (942, 17)	3.2070886846519358
  (942, 16)	3.2070886810620913
  (942, 15)	3.4035970802658584
  (942, 14)	3.82649067334644
  (942, 13)	4.069217151467846
  (942, 12)	3.4614390366618895
  (942, 11)	4.431886152148714
  (942, 10)	3.9382989967017554
  (942, 9)	3.8448255112915724
  (942, 8)	3.9907696603067815
  (942, 7)	4.089126027521583
  (942, 6)	3.8863494844992363
  (942, 5)	3.6794047598783126
  (942, 4)	3.3768816767234537
  (942, 3)	3.5934063250762374
  (942, 2)	3.1374883538527976
  (942, 1)	3.302549281210721
  (942, 0)	3.9494941652070454
this is the 110 epoch
rmse loss on training set is 0.9292170447568523
rmse loss on test set is 0.9473500317124087
for this epoch using 75.76071190834045 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2679758775020327
  (0, 1680)	3.279495957264978
  (0, 1679)	3.23389578005777
  (0, 1678)	3.270624796320278
  (0, 1677)	3.1971667637952517
  (0, 1676)	3.272877062602725
  (0, 1675)	3.272760038084322
  (0, 1674)	3.272760038084322
  (0, 1673)	3.272760038084322
  (0, 1672)	3.252919140977049
  (0, 1671)	3.213074883382855
  (0, 1670)	3.272760038084322
  (0, 1669)	3.272760038084322
  (0, 1668)	3.248329211189077
  (0, 1667)	3.272760038084322
  (0, 1666)	3.272760038084322
  (0, 1665)	3.248329211189077
  (0, 1664)	3.272760038084322
  (0, 1663)	3.2334604174634354
  (0, 1662)	3.248329211189077
  (0, 1661)	3.242633442667271
  (0, 1660)	3.189042269575022
  (0, 1659)	3.205440616199012
  (0, 1658)	3.272760038084322
  (0, 1657)	3.2812873162726786
  :	:
  (942, 24)	3.558586571736049
  (942, 23)	3.5537779375229346
  (942, 22)	4.209755940497704
  (942, 21)	4.251426299423347
  (942, 20)	2.852814310669905
  (942, 19)	3.6222500312447727
  (942, 18)	3.923193149859544
  (942, 17)	3.207215479577895
  (942, 16)	3.2074842065066114
  (942, 15)	3.40492755508675
  (942, 14)	3.826905759982546
  (942, 13)	4.070152087633011
  (942, 12)	3.4621921861017073
  (942, 11)	4.432948529853113
  (942, 10)	3.9391821287533486
  (942, 9)	3.8466284932241686
  (942, 8)	3.9914243062464205
  (942, 7)	4.090136703560267
  (942, 6)	3.8869218109020833
  (942, 5)	3.682734657259324
  (942, 4)	3.377602498052658
  (942, 3)	3.5943574203261233
  (942, 2)	3.1377946379535175
  (942, 1)	3.303317214356107
  (942, 0)	3.9500746293882063
this is the 111 epoch
rmse loss on training set is 0.9290750376102216
rmse loss on test set is 0.9472295818996772
for this epoch using 75.8868579864502 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2676742610698923
  (0, 1680)	3.2793114338373677
  (0, 1679)	3.233288373593291
  (0, 1678)	3.2703378214791035
  (0, 1677)	3.1962389257074824
  (0, 1676)	3.2726318757387634
  (0, 1675)	3.2724958213535533
  (0, 1674)	3.2724958213535533
  (0, 1673)	3.2724958213535533
  (0, 1672)	3.252417896697562
  (0, 1671)	3.2123624584742205
  (0, 1670)	3.2724958213535533
  (0, 1669)	3.2724958213535533
  (0, 1668)	3.2478753132685623
  (0, 1667)	3.2724958213535533
  (0, 1666)	3.2724958213535533
  (0, 1665)	3.2478753132685623
  (0, 1664)	3.2724958213535533
  (0, 1663)	3.232867217516609
  (0, 1662)	3.2478753132685623
  (0, 1661)	3.2421325915120756
  (0, 1660)	3.1880606828412534
  (0, 1659)	3.2046027869175666
  (0, 1658)	3.2724958213535533
  (0, 1657)	3.281139133549993
  :	:
  (942, 24)	3.5591362330687812
  (942, 23)	3.554259478467365
  (942, 22)	4.2110648263402215
  (942, 21)	4.25247675793085
  (942, 20)	2.852460952252423
  (942, 19)	3.6239475394477645
  (942, 18)	3.9256962399802915
  (942, 17)	3.2073328348141366
  (942, 16)	3.207871935167067
  (942, 15)	3.406240963624279
  (942, 14)	3.827309405793061
  (942, 13)	4.07106663615149
  (942, 12)	3.4629313885248707
  (942, 11)	4.433992428377293
  (942, 10)	3.940049080866342
  (942, 9)	3.848395337935889
  (942, 8)	3.992064527560068
  (942, 7)	4.091130050985693
  (942, 6)	3.8874809929597895
  (942, 5)	3.6860375080396026
  (942, 4)	3.3783076671713546
  (942, 3)	3.595292240145209
  (942, 2)	3.1380947570863733
  (942, 1)	3.3040713857542165
  (942, 0)	3.9506422861323114
this is the 112 epoch
rmse loss on training set is 0.9289354182768522
rmse loss on test set is 0.9471113553843656
for this epoch using 75.34499311447144 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2673767498327
  (0, 1680)	3.2791308746753787
  (0, 1679)	3.2326849948693215
  (0, 1678)	3.2700547673750577
  (0, 1677)	3.1953152223635812
  (0, 1676)	3.272390744006286
  (0, 1675)	3.2722355241107275
  (0, 1674)	3.2722355241107275
  (0, 1673)	3.2722355241107275
  (0, 1672)	3.2519204989855037
  (0, 1671)	3.211654760605505
  (0, 1670)	3.2722355241107275
  (0, 1669)	3.2722355241107275
  (0, 1668)	3.2474253779968505
  (0, 1667)	3.2722355241107275
  (0, 1666)	3.2722355241107275
  (0, 1665)	3.2474253779968505
  (0, 1664)	3.2722355241107275
  (0, 1663)	3.2322782987098235
  (0, 1662)	3.2474253779968505
  (0, 1661)	3.241635999711035
  (0, 1660)	3.187083551293823
  (0, 1659)	3.2037695278926988
  (0, 1658)	3.2722355241107275
  (0, 1657)	3.280995093544031
  :	:
  (942, 24)	3.559673747426097
  (942, 23)	3.554728289280145
  (942, 22)	4.212350592727089
  (942, 21)	4.253509308848551
  (942, 20)	2.8521160890175405
  (942, 19)	3.6256168746028385
  (942, 18)	3.9281571152980583
  (942, 17)	3.207440958508784
  (942, 16)	3.2082519968562537
  (942, 15)	3.407537547009803
  (942, 14)	3.827701839528784
  (942, 13)	4.071961301271364
  (942, 12)	3.4636568782159944
  (942, 11)	4.435018175109645
  (942, 10)	3.9409001460285875
  (942, 9)	3.8501267770085157
  (942, 8)	3.9926906113020313
  (942, 7)	4.0921063717875175
  (942, 6)	3.8880272702905456
  (942, 5)	3.689313596964161
  (942, 4)	3.378997494906598
  (942, 3)	3.596211051263016
  (942, 2)	3.1383887839102855
  (942, 1)	3.304812003728992
  (942, 0)	3.9511973583934044
this is the 113 epoch
rmse loss on training set is 0.9287981305120488
rmse loss on test set is 0.9469952987261454
for this epoch using 75.22581100463867 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2670832469686886
  (0, 1680)	3.2789541833243323
  (0, 1679)	3.2320855486209537
  (0, 1678)	3.2697755388535086
  (0, 1677)	3.1943955583883907
  (0, 1676)	3.2721535695441784
  (0, 1675)	3.2719790511821727
  (0, 1674)	3.2719790511821727
  (0, 1673)	3.2719790511821727
  (0, 1672)	3.2514268623779667
  (0, 1671)	3.2109516866693544
  (0, 1670)	3.2719790511821727
  (0, 1669)	3.2719790511821727
  (0, 1668)	3.246979308678523
  (0, 1667)	3.2719790511821727
  (0, 1666)	3.2719790511821727
  (0, 1665)	3.246979308678523
  (0, 1664)	3.2719790511821727
  (0, 1663)	3.2316935637972275
  (0, 1662)	3.246979308678523
  (0, 1661)	3.2411435703018014
  (0, 1660)	3.18611077545139
  (0, 1659)	3.202940737558269
  (0, 1658)	3.2719790511821727
  (0, 1657)	3.280855094703792
  :	:
  (942, 24)	3.5601993403351515
  (942, 23)	3.5551846653545587
  (942, 22)	4.213613749819187
  (942, 21)	4.254524237646323
  (942, 20)	2.851779485395189
  (942, 19)	3.627258482509904
  (942, 18)	3.9305765021281855
  (942, 17)	3.207540054754166
  (942, 16)	3.208624519363651
  (942, 15)	3.408817542762523
  (942, 14)	3.8280832855005
  (942, 13)	4.072836570994149
  (942, 12)	3.464368885945041
  (942, 11)	4.436026090368415
  (942, 10)	3.9417356108806922
  (942, 9)	3.851823527158782
  (942, 8)	3.9933028379743387
  (942, 7)	4.093065961186344
  (942, 6)	3.8885608790307282
  (942, 5)	3.6925632052221977
  (942, 4)	3.3796722860615094
  (942, 3)	3.597114116423778
  (942, 2)	3.138676791235073
  (942, 1)	3.30553927462897
  (942, 0)	3.9517400661529356
this is the 114 epoch
rmse loss on training set is 0.9286631198078936
rmse loss on test set is 0.9468813601839774
for this epoch using 74.95397186279297 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.266793659157006
  (0, 1680)	3.278781266873376
  (0, 1679)	3.2314899430628974
  (0, 1678)	3.2695000442451834
  (0, 1677)	3.193479841880607
  (0, 1676)	3.271920258058973
  (0, 1675)	3.271726310891519
  (0, 1674)	3.271726310891519
  (0, 1673)	3.271726310891519
  (0, 1672)	3.250936904623835
  (0, 1671)	3.210253137172574
  (0, 1670)	3.271726310891519
  (0, 1669)	3.271726310891519
  (0, 1668)	3.2465370121851738
  (0, 1667)	3.271726310891519
  (0, 1666)	3.271726310891519
  (0, 1665)	3.2465370121851738
  (0, 1664)	3.271726310891519
  (0, 1663)	3.2311129190423444
  (0, 1662)	3.2465370121851738
  (0, 1661)	3.2406552098436303
  (0, 1660)	3.185142259380847
  (0, 1659)	3.2021163179722087
  (0, 1658)	3.271726310891519
  (0, 1657)	3.2807190391197745
  :	:
  (942, 24)	3.5607132335088116
  (942, 23)	3.555628894309915
  (942, 22)	4.21485479193864
  (942, 21)	4.255521825511316
  (942, 20)	2.8514509120454536
  (942, 19)	3.628872802373667
  (942, 18)	3.9329551140713512
  (942, 17)	3.2076303236682366
  (942, 16)	3.2089896284880353
  (942, 15)	3.4100811848502235
  (942, 14)	3.828453963696867
  (942, 13)	4.073692917755571
  (942, 12)	3.4650676390134687
  (942, 11)	4.437016487670881
  (942, 10)	3.942555755944466
  (942, 9)	3.85348629053997
  (942, 8)	3.9939014817596252
  (942, 7)	4.094009107915264
  (942, 6)	3.8890820518445275
  (942, 5)	3.695786610496172
  (942, 4)	3.3803323395274427
  (942, 3)	3.598001694430741
  (942, 2)	3.1389588519745204
  (942, 1)	3.3062534027916857
  (942, 0)	3.9522706264134513
this is the 115 epoch
rmse loss on training set is 0.9285303333258291
rmse loss on test set is 0.9467694896476511
for this epoch using 75.46426892280579 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.266507896414405
  (0, 1680)	3.2786120357891244
  (0, 1679)	3.2308980897262747
  (0, 1678)	3.269228195202612
  (0, 1677)	3.1925679842499384
  (0, 1676)	3.2716907186585322
  (0, 1675)	3.271477214895446
  (0, 1674)	3.271477214895446
  (0, 1673)	3.271477214895446
  (0, 1672)	3.250450546526691
  (0, 1671)	3.2095590160696745
  (0, 1670)	3.271477214895446
  (0, 1669)	3.271477214895446
  (0, 1668)	3.2460983987881127
  (0, 1667)	3.271477214895446
  (0, 1666)	3.271477214895446
  (0, 1665)	3.2460983987881127
  (0, 1664)	3.271477214895446
  (0, 1663)	3.2305362740542805
  (0, 1662)	3.2460983987881127
  (0, 1661)	3.2401708282524364
  (0, 1660)	3.1841779105335197
  (0, 1659)	3.2012961746491277
  (0, 1658)	3.271477214895446
  (0, 1657)	3.2805868323565672
  :	:
  (942, 24)	3.5612156448935335
  (942, 23)	3.5560612562519194
  (942, 22)	4.216074198241588
  (942, 21)	4.256502349434374
  (942, 20)	2.851130145710005
  (942, 19)	3.6304602668958457
  (942, 18)	3.935293652243571
  (942, 17)	3.2077119614740077
  (942, 16)	3.2093474480695052
  (942, 15)	3.4113287037484437
  (942, 14)	3.82881408989581
  (942, 13)	4.074530799072872
  (942, 12)	3.4657533612991958
  (942, 11)	4.437989673984348
  (942, 10)	3.943360855837573
  (942, 9)	3.8551157550372137
  (942, 8)	3.994486810740443
  (942, 7)	4.0949360944826605
  (942, 6)	3.8895910179366457
  (942, 5)	3.6989840870099937
  (942, 4)	3.3809779483942974
  (942, 3)	3.5988740401903017
  (942, 2)	3.1392350391016715
  (942, 1)	3.3069545905114923
  (942, 0)	3.9527892531961544
this is the 116 epoch
rmse loss on training set is 0.9283997198324515
rmse loss on test set is 0.9466596385727013
for this epoch using 76.0228579044342 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.266225871940514
  (0, 1680)	3.278446403757895
  (0, 1679)	3.230309903303957
  (0, 1678)	3.268959906545093
  (0, 1677)	3.191659900062827
  (0, 1676)	3.271464863694467
  (0, 1675)	3.27123167802808
  (0, 1674)	3.27123167802808
  (0, 1673)	3.27123167802808
  (0, 1672)	3.2499677117962698
  (0, 1671)	3.208869230604934
  (0, 1670)	3.27123167802808
  (0, 1669)	3.27123167802808
  (0, 1668)	3.2456633819998473
  (0, 1667)	3.27123167802808
  (0, 1666)	3.27123167802808
  (0, 1665)	3.2456633819998473
  (0, 1664)	3.27123167802808
  (0, 1663)	3.22996354163248
  (0, 1662)	3.2456633819998473
  (0, 1661)	3.239690338644328
  (0, 1660)	3.1832176395898655
  (0, 1659)	3.2004802164015853
  (0, 1658)	3.27123167802808
  (0, 1657)	3.2804583832939316
  :	:
  (942, 24)	3.561706788717895
  (942, 23)	3.55648202402188
  (942, 22)	4.217272433357008
  (942, 21)	4.257466082290756
  (942, 20)	2.8508169690663645
  (942, 19)	3.6320213023656858
  (942, 18)	3.9375928055016276
  (942, 17)	3.2077851605771968
  (942, 16)	3.209698100020858
  (942, 15)	3.4125603264981326
  (942, 14)	3.8291638757698747
  (942, 13)	4.075350658160516
  (942, 12)	3.466426273300604
  (942, 11)	4.438945949960596
  (942, 10)	3.9441511794754804
  (942, 9)	3.8567125945566385
  (942, 8)	3.995059087105624
  (942, 7)	4.09584719741763
  (942, 6)	3.890088003067542
  (942, 5)	3.7021559055762103
  (942, 4)	3.3816094000591583
  (942, 3)	3.5997314047560294
  (942, 2)	3.1395054256061043
  (942, 1)	3.3076430380105433
  (942, 0)	3.9532961575421406
this is the 117 epoch
rmse loss on training set is 0.9282712296382494
rmse loss on test set is 0.9465517599184351
for this epoch using 75.37627601623535 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.265947501971172
  (0, 1680)	3.278284287536249
  (0, 1679)	3.229725301504044
  (0, 1678)	3.26869509611183
  (0, 1677)	3.190755506896253
  (0, 1676)	3.271242608612707
  (0, 1675)	3.2709896181535063
  (0, 1674)	3.2709896181535063
  (0, 1673)	3.2709896181535063
  (0, 1672)	3.2494883269077905
  (0, 1671)	3.208183691162782
  (0, 1670)	3.2709896181535063
  (0, 1669)	3.2709896181535063
  (0, 1668)	3.245231878423758
  (0, 1667)	3.2709896181535063
  (0, 1666)	3.2709896181535063
  (0, 1665)	3.245231878423758
  (0, 1664)	3.2709896181535063
  (0, 1663)	3.2293946376195826
  (0, 1662)	3.245231878423758
  (0, 1661)	3.239213657187438
  (0, 1660)	3.182261360312298
  (0, 1659)	3.1996683551895906
  (0, 1658)	3.2709896181535063
  (0, 1657)	3.280333603976276
  :	:
  (942, 24)	3.5621868755418236
  (942, 23)	3.556891463435502
  (942, 22)	4.218449947993625
  (942, 21)	4.25841329291565
  (942, 20)	2.8505111705849466
  (942, 19)	3.633556328748822
  (942, 18)	3.939853250663976
  (942, 17)	3.20785010964198
  (942, 16)	3.2100417043584195
  (942, 15)	3.4137762767619644
  (942, 14)	3.8295035289862773
  (942, 13)	4.076152924516062
  (942, 12)	3.467086592179536
  (942, 11)	4.43988561015503
  (942, 10)	3.9449269902615933
  (942, 9)	3.8582774693084954
  (942, 8)	3.9956185673449593
  (942, 7)	4.096742687499461
  (942, 6)	3.890573229571187
  (942, 5)	3.705302333642479
  (942, 4)	3.382226976333153
  (942, 3)	3.600574035372667
  (942, 2)	3.1397700844532594
  (942, 1)	3.3083189434127895
  (942, 0)	3.9537915475167873
this is the 118 epoch
rmse loss on training set is 0.9281448145392313
rmse loss on test set is 0.9464458080889248
for this epoch using 76.88698887825012 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2656727056394725
  (0, 1680)	3.278125606809417
  (0, 1679)	3.2291442049110115
  (0, 1678)	3.268433684622796
  (0, 1677)	3.1898547251992357
  (0, 1676)	3.2710238718119085
  (0, 1675)	3.2707509560260046
  (0, 1674)	3.2707509560260046
  (0, 1673)	3.2707509560260046
  (0, 1672)	3.2490123209689745
  (0, 1671)	3.2075023111260035
  (0, 1670)	3.2707509560260046
  (0, 1669)	3.2707509560260046
  (0, 1668)	3.2448038076117416
  (0, 1667)	3.2707509560260046
  (0, 1666)	3.2707509560260046
  (0, 1665)	3.2448038076117416
  (0, 1664)	3.2707509560260046
  (0, 1663)	3.2288294807620628
  (0, 1662)	3.2448038076117416
  (0, 1661)	3.2387407029615285
  (0, 1660)	3.1813089894055913
  (0, 1659)	3.1988605059779585
  (0, 1658)	3.2707509560260046
  (0, 1657)	3.2802124094698275
  :	:
  (942, 24)	3.5626561123063953
  (942, 23)	3.5572898335116396
  (942, 22)	4.219607179516366
  (942, 21)	4.259344246175207
  (942, 20)	2.850212544388916
  (942, 19)	3.6350657597746747
  (942, 18)	3.942075652727355
  (942, 17)	3.2079069936650937
  (942, 16)	3.2103783792322202
  (942, 15)	3.4149767748791855
  (942, 14)	3.8298332533019237
  (942, 13)	4.076938014477573
  (942, 12)	3.467734531803535
  (942, 11)	4.440808943231886
  (942, 10)	3.9456885462665334
  (942, 9)	3.8598110260845866
  (942, 8)	3.9961655024328637
  (942, 7)	4.0976228299721456
  (942, 6)	3.891046916375135
  (942, 5)	3.7084236353371036
  (942, 4)	3.3828309535466334
  (942, 3)	3.601402175520002
  (942, 2)	3.140029088545633
  (942, 1)	3.308982502720953
  (942, 0)	3.9542756282171747
this is the 119 epoch
rmse loss on training set is 0.9280204277611273
rmse loss on test set is 0.9463417388768112
for this epoch using 75.42911624908447 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2654014048440367
  (0, 1680)	3.2779702840570066
  (0, 1679)	3.228566536854171
  (0, 1678)	3.26817559554679
  (0, 1677)	3.1889574781615537
  (0, 1676)	3.270808574509188
  (0, 1675)	3.2705156151576475
  (0, 1674)	3.2705156151576475
  (0, 1673)	3.2705156151576475
  (0, 1672)	3.248539625594133
  (0, 1671)	3.2068250067412487
  (0, 1670)	3.2705156151576475
  (0, 1669)	3.2705156151576475
  (0, 1668)	3.2443790919292277
  (0, 1667)	3.2705156151576475
  (0, 1666)	3.2705156151576475
  (0, 1665)	3.2443790919292277
  (0, 1664)	3.2705156151576475
  (0, 1663)	3.228267992578042
  (0, 1662)	3.2443790919292277
  (0, 1661)	3.2382713978248723
  (0, 1660)	3.180360446384633
  (0, 1659)	3.198056586600978
  (0, 1658)	3.2705156151576475
  (0, 1657)	3.280094717727168
  :	:
  (942, 24)	3.5631147023839786
  (942, 23)	3.5576773866916174
  (942, 22)	4.22074455249422
  (942, 21)	4.260259203033452
  (942, 20)	2.8499208901167825
  (942, 19)	3.636550003022386
  (942, 18)	3.944260665079052
  (942, 17)	3.207955994048171
  (942, 16)	3.2107082409556553
  (942, 15)	3.416162037919263
  (942, 14)	3.8301532486538323
  (942, 13)	4.077706331754255
  (942, 12)	3.4683703027872874
  (942, 11)	4.441716232156539
  (942, 10)	3.946436100397156
  (942, 9)	3.8613138985298394
  (942, 8)	3.9967001380020863
  (942, 7)	4.098487884745296
  (942, 6)	3.891509279022527
  (942, 5)	3.71152007151388
  (942, 4)	3.3834216026525095
  (942, 3)	3.6022160649567185
  (942, 2)	3.1402825106858527
  (942, 1)	3.309633909796241
  (942, 0)	3.9547486017822
this is the 120 epoch
rmse loss on training set is 0.9278980239063159
rmse loss on test set is 0.946239509409745
for this epoch using 75.45017409324646 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.26513352412412
  (0, 1680)	3.2778182444258404
  (0, 1679)	3.22799222328294
  (0, 1678)	3.2679207549764673
  (0, 1677)	3.188063691589417
  (0, 1676)	3.270596640612815
  (0, 1675)	3.27028352169272
  (0, 1674)	3.27028352169272
  (0, 1673)	3.27028352169272
  (0, 1672)	3.2480701747850627
  (0, 1671)	3.2061516969916326
  (0, 1670)	3.27028352169272
  (0, 1669)	3.27028352169272
  (0, 1668)	3.2439576564271833
  (0, 1667)	3.27028352169272
  (0, 1666)	3.27028352169272
  (0, 1665)	3.2439576564271833
  (0, 1664)	3.27028352169272
  (0, 1663)	3.22771009723209
  (0, 1662)	3.2439576564271833
  (0, 1661)	3.23780566628813
  (0, 1660)	3.1794156534488973
  (0, 1659)	3.197256517634124
  (0, 1658)	3.27028352169272
  (0, 1657)	3.2799804494588085
  :	:
  (942, 24)	3.5635628456287534
  (942, 23)	3.5580543690495516
  (942, 22)	4.221862479220966
  (942, 21)	4.26115842061565
  (942, 20)	2.8496360127877813
  (942, 19)	3.6380094600053927
  (942, 18)	3.946408929705119
  (942, 17)	3.2079972886684804
  (942, 16)	3.211031404034537
  (942, 15)	3.417332279734326
  (942, 14)	3.830463711245451
  (942, 13)	4.078458267931516
  (942, 12)	3.4689941125334127
  (942, 11)	4.442607754376018
  (942, 10)	3.947169900556347
  (942, 9)	3.86278670740849
  (942, 8)	3.9972227145079477
  (942, 7)	4.09933810658239
  (942, 6)	3.891960529696225
  (942, 5)	3.7145918997961433
  (942, 4)	3.3839991893280357
  (942, 3)	3.6030159397642367
  (942, 2)	3.1405304235415157
  (942, 1)	3.3102733563406876
  (942, 0)	3.9552106674052054
this is the 121 epoch
rmse loss on training set is 0.9277775589029202
rmse loss on test set is 0.9461390780993073
for this epoch using 75.50304794311523 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.264868990541318
  (0, 1680)	3.277669415609386
  (0, 1679)	3.2274211926487366
  (0, 1678)	3.2676690915099122
  (0, 1677)	3.187173293787555
  (0, 1676)	3.270387996601547
  (0, 1675)	3.2700546042888416
  (0, 1674)	3.2700546042888416
  (0, 1673)	3.2700546042888416
  (0, 1672)	3.247603904818354
  (0, 1671)	3.2054823034758884
  (0, 1670)	3.2700546042888416
  (0, 1669)	3.2700546042888416
  (0, 1668)	3.243539428720894
  (0, 1667)	3.2700546042888416
  (0, 1666)	3.2700546042888416
  (0, 1665)	3.243539428720894
  (0, 1664)	3.2700546042888416
  (0, 1663)	3.227155721416543
  (0, 1662)	3.243539428720894
  (0, 1661)	3.2373434353947843
  (0, 1660)	3.1784745353635286
  (0, 1659)	3.1964602222724086
  (0, 1658)	3.2700546042888416
  (0, 1657)	3.2798695280113197
  :	:
  (942, 24)	3.5640007384274623
  (942, 23)	3.5584210204940416
  (942, 22)	4.222961360210162
  (942, 21)	4.262042152268483
  (942, 20)	2.8493577226699647
  (942, 19)	3.6394445262546378
  (942, 18)	3.94852107739445
  (942, 17)	3.208031051948118
  (942, 16)	3.2113479811956673
  (942, 15)	3.4184877110103424
  (942, 14)	3.8307648336291233
  (942, 13)	4.079194202952017
  (942, 12)	3.4696061652726335
  (942, 11)	4.44348378198865
  (942, 10)	3.9478901897938914
  (942, 9)	3.8642300608646916
  (942, 8)	3.9977334673838962
  (942, 7)	4.100173745277201
  (942, 6)	3.8924008772444463
  (942, 5)	3.717639374620035
  (942, 4)	3.384563974074734
  (942, 3)	3.6038020323905005
  (942, 2)	3.140772899611795
  (942, 1)	3.3109010318819907
  (942, 0)	3.9556620213487608
this is the 122 epoch
rmse loss on training set is 0.9276589899563578
rmse loss on test set is 0.9460404045923155
for this epoch using 75.64036512374878 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.264607733567271
  (0, 1680)	3.2775237277333984
  (0, 1679)	3.2268533757928775
  (0, 1678)	3.2674205361382724
  (0, 1677)	3.1862862154474914
  (0, 1676)	3.2701825714101633
  (0, 1675)	3.269828794004082
  (0, 1674)	3.269828794004082
  (0, 1673)	3.269828794004082
  (0, 1672)	3.247140754138693
  (0, 1671)	3.20481675029376
  (0, 1670)	3.269828794004082
  (0, 1669)	3.269828794004082
  (0, 1668)	3.2431243388749014
  (0, 1667)	3.269828794004082
  (0, 1666)	3.269828794004082
  (0, 1665)	3.2431243388749014
  (0, 1664)	3.269828794004082
  (0, 1663)	3.226604794238914
  (0, 1662)	3.2431243388749014
  (0, 1661)	3.2368846346077835
  (0, 1660)	3.1775370193464663
  (0, 1659)	3.1956676262149317
  (0, 1658)	3.269828794004082
  (0, 1657)	3.2797618792517205
  :	:
  (942, 24)	3.5644285737502055
  (942, 23)	3.5587775749617707
  (942, 22)	4.224041584665822
  (942, 21)	4.262910647617282
  (942, 20)	2.8490858351510515
  (942, 19)	3.6408555914005043
  (942, 18)	3.9505977279390594
  (942, 17)	3.2080574549215664
  (942, 16)	3.211658083414809
  (942, 15)	3.419628539317305
  (942, 14)	3.831056804784999
  (942, 13)	4.079914505573728
  (942, 12)	3.4702066621034193
  (942, 11)	4.444344581903766
  (942, 10)	3.948597206449399
  (942, 9)	3.865644554677944
  (942, 8)	3.9982326271891453
  (942, 7)	4.100995045819406
  (942, 6)	3.892830527208141
  (942, 5)	3.7206627472771987
  (942, 4)	3.3851162123167473
  (942, 3)	3.604574571693702
  (942, 2)	3.1410100111956605
  (942, 1)	3.311517123760765
  (942, 0)	3.956102856961573
this is the 123 epoch
rmse loss on training set is 0.9275422755029161
rmse loss on test set is 0.9459434497243739
for this epoch using 75.44428706169128 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2643496849773457
  (0, 1680)	3.2773811132475794
  (0, 1679)	3.226288705840474
  (0, 1678)	3.2671750221393507
  (0, 1677)	3.185402389541599
  (0, 1676)	3.269980296320945
  (0, 1675)	3.269606024190103
  (0, 1674)	3.269606024190103
  (0, 1673)	3.269606024190103
  (0, 1672)	3.2466806632579113
  (0, 1671)	3.20415496393734
  (0, 1670)	3.269606024190103
  (0, 1669)	3.269606024190103
  (0, 1668)	3.242712319293963
  (0, 1667)	3.269606024190103
  (0, 1666)	3.269606024190103
  (0, 1665)	3.242712319293963
  (0, 1664)	3.269606024190103
  (0, 1663)	3.226057247115222
  (0, 1662)	3.242712319293963
  (0, 1661)	3.236429195702108
  (0, 1660)	3.1766030349614405
  (0, 1659)	3.1948786575554093
  (0, 1658)	3.269606024190103
  (0, 1657)	3.2796574314578146
  :	:
  (942, 24)	3.5648465412013945
  (942, 23)	3.5591242606033195
  (942, 22)	4.225103530930196
  (942, 21)	4.263764152620892
  (942, 20)	2.8488201706118987
  (942, 19)	3.6422430392535623
  (942, 18)	3.952639490330355
  (942, 17)	3.2080766653018675
  (942, 16)	3.211961819944144
  (942, 15)	3.42075496915828
  (942, 14)	3.83133981019676
  (942, 13)	4.080619533806383
  (942, 12)	3.4707958010310516
  (942, 11)	4.445190415992202
  (942, 10)	3.9492911842876444
  (942, 9)	3.8670307725132926
  (942, 8)	3.998720419748741
  (942, 7)	4.101802248550255
  (942, 6)	3.8932496818497433
  (942, 5)	3.723662265956683
  (942, 4)	3.38565615449749
  (942, 3)	3.6053337829859973
  (942, 2)	3.141241830361663
  (942, 1)	3.31212181712001
  (942, 0)	3.9565333646970795
this is the 124 epoch
rmse loss on training set is 0.9274273751654692
rmse loss on test set is 0.9458481754754849
for this epoch using 75.29501175880432 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2640947787496657
  (0, 1680)	3.277241506822849
  (0, 1679)	3.2257271180996967
  (0, 1678)	3.266932484976631
  (0, 1677)	3.184521751222762
  (0, 1676)	3.2697811048606913
  (0, 1675)	3.269386230390769
  (0, 1674)	3.269386230390769
  (0, 1673)	3.269386230390769
  (0, 1672)	3.246223574659506
  (0, 1671)	3.203496873188022
  (0, 1670)	3.269386230390769
  (0, 1669)	3.269386230390769
  (0, 1668)	3.2423033046197256
  (0, 1667)	3.269386230390769
  (0, 1666)	3.269386230390769
  (0, 1665)	3.2423033046197256
  (0, 1664)	3.269386230390769
  (0, 1663)	3.2255130136688233
  (0, 1662)	3.2423033046197256
  (0, 1661)	3.235977052662897
  (0, 1660)	3.175672514016432
  (0, 1659)	3.1940932466783134
  (0, 1658)	3.269386230390769
  (0, 1657)	3.279556115214089
  :	:
  (942, 24)	3.565254827070547
  (942, 23)	3.5594612999616033
  (942, 22)	4.226147566909648
  (942, 21)	4.264602909624198
  (942, 20)	2.8485605543026686
  (942, 19)	3.6436072478841344
  (942, 18)	3.9546469629517804
  (942, 17)	3.2080888475452496
  (942, 16)	3.2122592983392884
  (942, 15)	3.421867202017421
  (942, 14)	3.831614031924269
  (942, 13)	4.081309635327248
  (942, 12)	3.4713737770063697
  (942, 11)	4.446021541228325
  (942, 10)	3.9499723526269515
  (942, 9)	3.8683892861664892
  (942, 8)	3.9991970662867695
  (942, 7)	4.102595589308762
  (942, 6)	3.8936585401832198
  (942, 5)	3.7266381757862277
  (942, 4)	3.3861840461745842
  (942, 3)	3.6060798880771237
  (942, 2)	3.141468428919365
  (942, 1)	3.3127152948967415
  (942, 0)	3.9569537321338553
this is the 125 epoch
rmse loss on training set is 0.9273142497110255
rmse loss on test set is 0.9457545449277126
for this epoch using 75.61125922203064 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2638429509694147
  (0, 1680)	3.2771048452538256
  (0, 1679)	3.2251685499662823
  (0, 1678)	3.2666928622035645
  (0, 1677)	3.1836442377289904
  (0, 1676)	3.2695849327030335
  (0, 1675)	3.269169350245955
  (0, 1674)	3.269169350245955
  (0, 1673)	3.269169350245955
  (0, 1672)	3.245769432708061
  (0, 1671)	3.2028424090186403
  (0, 1670)	3.269169350245955
  (0, 1669)	3.269169350245955
  (0, 1668)	3.2418972316325085
  (0, 1667)	3.269169350245955
  (0, 1666)	3.269169350245955
  (0, 1665)	3.2418972316325085
  (0, 1664)	3.269169350245955
  (0, 1663)	3.2249720296343893
  (0, 1662)	3.2418972316325085
  (0, 1661)	3.235528141588717
  (0, 1660)	3.1747453904672702
  (0, 1659)	3.1933113261602735
  (0, 1658)	3.269169350245955
  (0, 1657)	3.2794578633129174
  :	:
  (942, 24)	3.565653614383107
  (942, 23)	3.5597889101432596
  (942, 22)	4.227174050479981
  (942, 21)	4.265427157408672
  (942, 20)	2.8483068162216276
  (942, 19)	3.6449485897006855
  (942, 18)	3.9566207337677506
  (942, 17)	3.208094162914477
  (942, 16)	3.212550624485726
  (942, 15)	3.42296543640707
  (942, 14)	3.831879648673615
  (942, 13)	4.081985147877537
  (942, 12)	3.471940781963905
  (942, 11)	4.446838209824363
  (942, 10)	3.9506409364610247
  (942, 9)	3.869720655804193
  (942, 8)	3.9996627835530543
  (942, 7)	4.103375299569484
  (942, 6)	3.8940572980052717
  (942, 5)	3.7295907188729607
  (942, 4)	3.38670012811324
  (942, 3)	3.606813105318024
  (942, 2)	3.1416898783921616
  (942, 1)	3.3132977378157067
  (942, 0)	3.957364143997437
this is the 126 epoch
rmse loss on training set is 0.9272028610102236
rmse loss on test set is 0.9456625222247332
for this epoch using 77.60813808441162 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.263594139738009
  (0, 1680)	3.2769710673663743
  (0, 1679)	3.224612940832967
  (0, 1678)	3.2664560933727325
  (0, 1677)	3.182769788293214
  (0, 1676)	3.2693917175757363
  (0, 1675)	3.268955323400367
  (0, 1674)	3.268955323400367
  (0, 1673)	3.268955323400367
  (0, 1672)	3.2453181835636675
  (0, 1671)	3.202191504500679
  (0, 1670)	3.268955323400367
  (0, 1669)	3.268955323400367
  (0, 1668)	3.241494039158316
  (0, 1667)	3.268955323400367
  (0, 1666)	3.268955323400367
  (0, 1665)	3.241494039158316
  (0, 1664)	3.268955323400367
  (0, 1663)	3.2244342327669044
  (0, 1662)	3.241494039158316
  (0, 1661)	3.2350824005999517
  (0, 1660)	3.1738216003261934
  (0, 1659)	3.192532830676503
  (0, 1658)	3.268955323400367
  (0, 1657)	3.2793626106607245
  :	:
  (942, 24)	3.5660430829510106
  (942, 23)	3.5601073029834125
  (942, 22)	4.228183329872154
  (942, 21)	4.266237131241175
  (942, 20)	2.848058790996521
  (942, 19)	3.6462674315271406
  (942, 18)	3.95856138050899
  (942, 17)	3.2080927695406807
  (942, 16)	3.212835902624794
  (942, 15)	3.424049867913865
  (942, 14)	3.8321368358644308
  (942, 13)	4.082646399640109
  (942, 12)	3.472497004859759
  (942, 11)	4.447640669357462
  (942, 10)	3.951297156574783
  (942, 9)	3.8710254301992997
  (942, 8)	4.000117783943963
  (942, 7)	4.104141606572244
  (942, 6)	3.8944461479276
  (942, 5)	3.732520134343376
  (942, 4)	3.387204636377961
  (942, 3)	3.6075336496443406
  (942, 2)	3.1419062499915325
  (942, 1)	3.313869324384904
  (942, 0)	3.9577647821834163
this is the 127 epoch
rmse loss on training set is 0.9270931719984514
rmse loss on test set is 0.9455720725331611
for this epoch using 76.79288506507874 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.263348285086965
  (0, 1680)	3.276840113929946
  (0, 1679)	3.224060232003591
  (0, 1678)	3.266222119949713
  (0, 1677)	3.1818983440574824
  (0, 1676)	3.269201399172733
  (0, 1675)	3.2687440914169685
  (0, 1674)	3.2687440914169685
  (0, 1673)	3.2687440914169685
  (0, 1672)	3.2448697751008324
  (0, 1671)	3.201544094716224
  (0, 1670)	3.2687440914169685
  (0, 1669)	3.2687440914169685
  (0, 1668)	3.2410936679804947
  (0, 1667)	3.2687440914169685
  (0, 1666)	3.2687440914169685
  (0, 1665)	3.2410936679804947
  (0, 1664)	3.2687440914169685
  (0, 1663)	3.223899562755256
  (0, 1662)	3.2410936679804947
  (0, 1661)	3.234639769751786
  (0, 1660)	3.1729010815750396
  (0, 1659)	3.191757696911999
  (0, 1658)	3.2687440914169685
  (0, 1657)	3.279270294188957
  :	:
  (942, 24)	3.566423409423036
  (942, 23)	3.560416685203904
  (942, 22)	4.229175744039605
  (942, 21)	4.267033062921226
  (942, 20)	2.8478163177685207
  (942, 19)	3.647564134679143
  (942, 18)	3.9604694708543953
  (942, 17)	3.2080848224839653
  (942, 16)	3.213115235379194
  (942, 15)	3.425120689243965
  (942, 14)	3.8323857656950184
  (942, 13)	4.083293709599828
  (942, 12)	3.4730426317090894
  (942, 11)	4.448429162890215
  (942, 10)	3.95194122965456
  (942, 9)	3.8723041469616195
  (942, 8)	4.00056227561762
  (942, 7)	4.104894733444444
  (942, 6)	3.8948252794100693
  (942, 5)	3.7354266583828015
  (942, 4)	3.387697802422635
  (942, 3)	3.608241732619821
  (942, 2)	3.1421176145927254
  (942, 1)	3.314430230893017
  (942, 0)	3.958155825781801
this is the 128 epoch
rmse loss on training set is 0.9269851466386864
rmse loss on test set is 0.9454831620055992
for this epoch using 75.98857712745667 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.263105328896059
  (0, 1680)	3.2767119275742824
  (0, 1679)	3.2235103666115044
  (0, 1678)	3.2659908852313113
  (0, 1677)	3.1810298479917067
  (0, 1676)	3.269013919070601
  (0, 1675)	3.26853559769489
  (0, 1674)	3.26853559769489
  (0, 1673)	3.26853559769489
  (0, 1672)	3.244424156831588
  (0, 1671)	3.200900116674266
  (0, 1670)	3.26853559769489
  (0, 1669)	3.26853559769489
  (0, 1668)	3.2406960607559636
  (0, 1667)	3.26853559769489
  (0, 1666)	3.26853559769489
  (0, 1665)	3.2406960607559636
  (0, 1664)	3.26853559769489
  (0, 1663)	3.223367961140229
  (0, 1662)	3.2406960607559636
  (0, 1661)	3.234200190951686
  (0, 1660)	3.1719837740827805
  (0, 1659)	3.1909858634771537
  (0, 1658)	3.26853559769489
  (0, 1657)	3.2791808527694606
  :	:
  (942, 24)	3.5667947673349243
  (942, 23)	3.5607172585656217
  (942, 22)	4.230151623007996
  (942, 21)	4.267815180826819
  (942, 20)	2.847579240078702
  (942, 19)	3.648839055039255
  (942, 18)	3.962345562609486
  (942, 17)	3.2080704737927475
  (942, 16)	3.213388723778061
  (942, 15)	3.4261780902674173
  (942, 14)	3.832626607205159
  (942, 13)	4.083927387887122
  (942, 12)	3.473577845623249
  (942, 11)	4.449203929085074
  (942, 10)	3.952573368393097
  (942, 9)	3.8735573327638724
  (942, 8)	4.000996462603832
  (942, 7)	4.1056348993166845
  (942, 6)	3.895194878794706
  (942, 5)	3.7383105242742705
  (942, 4)	3.3881798531790692
  (942, 3)	3.608937562479619
  (942, 2)	3.1423240427116914
  (942, 1)	3.314980631408583
  (942, 0)	3.9585374511025107
this is the 129 epoch
rmse loss on training set is 0.9268787498859049
rmse loss on test set is 0.9453957577452986
for this epoch using 76.092613697052 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.262865214815698
  (0, 1680)	3.2765864527104287
  (0, 1679)	3.2229632895422067
  (0, 1678)	3.2657623342679836
  (0, 1677)	3.1801642448164262
  (0, 1676)	3.268829220649254
  (0, 1675)	3.268329787391488
  (0, 1674)	3.268329787391488
  (0, 1673)	3.268329787391488
  (0, 1672)	3.2439812798327865
  (0, 1671)	3.2002595092313295
  (0, 1670)	3.268329787391488
  (0, 1669)	3.268329787391488
  (0, 1668)	3.240301161935582
  (0, 1667)	3.268329787391488
  (0, 1666)	3.268329787391488
  (0, 1665)	3.240301161935582
  (0, 1664)	3.268329787391488
  (0, 1663)	3.2228393712367143
  (0, 1662)	3.240301161935582
  (0, 1661)	3.2337636078809924
  (0, 1660)	3.1710696195272243
  (0, 1659)	3.1902172708277092
  (0, 1658)	3.268329787391488
  (0, 1657)	3.2790942271341206
  :	:
  (942, 24)	3.567157327159126
  (942, 23)	3.5610092200148973
  (942, 22)	4.231111288208364
  (942, 21)	4.268583709959063
  (942, 20)	2.847347405757012
  (942, 19)	3.6500925431312226
  (942, 18)	3.964190203881523
  (942, 17)	3.208049872561719
  (942, 16)	3.213656467281511
  (942, 15)	3.427222258061646
  (942, 14)	3.8328595263370016
  (942, 13)	4.0845477361057805
  (942, 12)	3.4741028268465053
  (942, 11)	4.449965202313109
  (942, 10)	3.953193781589621
  (942, 9)	3.874785503563155
  (942, 8)	4.001420544909356
  (942, 7)	4.106362319431916
  (942, 6)	3.8955551293404347
  (942, 5)	3.7411719624368005
  (942, 4)	3.388651011143901
  (942, 3)	3.6096213441735077
  (942, 2)	3.1425256044833594
  (942, 1)	3.315520697780738
  (942, 0)	3.9589098317016407
this is the 130 epoch
rmse loss on training set is 0.9267739476529561
rmse loss on test set is 0.9453098277723536
for this epoch using 76.78918790817261 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.262627888193209
  (0, 1680)	3.276463635455722
  (0, 1679)	3.2224189473598415
  (0, 1678)	3.2655364137901426
  (0, 1677)	3.1793014809295532
  (0, 1676)	3.268647249016588
  (0, 1675)	3.268126607348278
  (0, 1674)	3.268126607348278
  (0, 1673)	3.268126607348278
  (0, 1672)	3.2435410966771117
  (0, 1671)	3.1996222130160024
  (0, 1670)	3.268126607348278
  (0, 1669)	3.268126607348278
  (0, 1668)	3.239908917688644
  (0, 1667)	3.268126607348278
  (0, 1666)	3.268126607348278
  (0, 1665)	3.239908917688644
  (0, 1664)	3.268126607348278
  (0, 1663)	3.222313738059752
  (0, 1662)	3.239908917688644
  (0, 1661)	3.2333299659205634
  (0, 1660)	3.1701585613206347
  (0, 1659)	3.189451861188551
  (0, 1658)	3.268126607348278
  (0, 1657)	3.2790103597984306
  :	:
  (942, 24)	3.5675112563541704
  (942, 23)	3.56129276182438
  (942, 22)	4.232055052794534
  (942, 21)	4.269338871985657
  (942, 20)	2.8471206668136744
  (942, 19)	3.651324944193159
  (942, 18)	3.9660039332512875
  (942, 17)	3.208023164988695
  (942, 16)	3.213918563804796
  (942, 15)	3.4282533769541805
  (942, 14)	3.833084685993948
  (942, 13)	4.085155047645729
  (942, 12)	3.4746177527926587
  (942, 11)	4.450713212757586
  (942, 10)	3.953802674245349
  (942, 9)	3.875989164817933
  (942, 8)	4.0018347186185075
  (942, 7)	4.107077205248832
  (942, 6)	3.895906211258438
  (942, 5)	3.744011200463128
  (942, 4)	3.3891114944640206
  (942, 3)	3.610293279408916
  (942, 2)	3.1427223696410533
  (942, 1)	3.316050599641491
  (942, 0)	3.9592731384087365
this is the 131 epoch
rmse loss on training set is 0.9266707067779009
rmse loss on test set is 0.9452253409913375
for this epoch using 76.49727320671082 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2623932960027577
  (0, 1680)	3.276343423562513
  (0, 1679)	3.221877288237469
  (0, 1678)	3.265313072138205
  (0, 1677)	3.178441504336733
  (0, 1676)	3.268467950936982
  (0, 1675)	3.267926006020727
  (0, 1674)	3.267926006020727
  (0, 1673)	3.267926006020727
  (0, 1672)	3.243103561367742
  (0, 1671)	3.198988170357281
  (0, 1670)	3.267926006020727
  (0, 1669)	3.267926006020727
  (0, 1668)	3.2395192758311047
  (0, 1667)	3.267926006020727
  (0, 1666)	3.267926006020727
  (0, 1665)	3.2395192758311047
  (0, 1664)	3.267926006020727
  (0, 1663)	3.2217910082543693
  (0, 1662)	3.2395192758311047
  (0, 1661)	3.232899212080093
  (0, 1660)	3.169250544538997
  (0, 1659)	3.1886895784814633
  (0, 1658)	3.267926006020727
  (0, 1657)	3.278929194988979
  :	:
  (942, 24)	3.5678567194136925
  (942, 23)	3.561568071728736
  (942, 22)	4.232983221945672
  (942, 21)	4.270080885283491
  (942, 20)	2.846898879333063
  (942, 19)	3.6525365982498887
  (942, 18)	3.967787279941805
  (942, 17)	3.2079904944302555
  (942, 16)	3.214175109742044
  (942, 15)	3.4292716285645835
  (942, 14)	3.8333022460979294
  (942, 13)	4.085749607981602
  (942, 12)	3.4751227980811934
  (942, 11)	4.4514481865127795
  (942, 10)	3.9544002476549216
  (942, 9)	3.8771688117007876
  (942, 8)	4.00223917598961
  (942, 7)	4.1077797645397585
  (942, 6)	3.896248301747995
  (942, 5)	3.7468284631569255
  (942, 4)	3.389561517020407
  (942, 3)	3.6109535666938144
  (942, 2)	3.1429144074971433
  (942, 1)	3.316570504409542
  (942, 0)	3.9596275393546363
this is the 132 epoch
rmse loss on training set is 0.926568994992601
rmse loss on test set is 0.94514226716036
for this epoch using 75.87046504020691 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2621613867788386
  (0, 1680)	3.2762257663505654
  (0, 1679)	3.221338261890729
  (0, 1678)	3.265092259196158
  (0, 1677)	3.1775842645853047
  (0, 1676)	3.2682912747632518
  (0, 1675)	3.2677279334114404
  (0, 1674)	3.2677279334114404
  (0, 1673)	3.2677279334114404
  (0, 1672)	3.242668629276378
  (0, 1671)	3.1983573252164113
  (0, 1670)	3.2677279334114404
  (0, 1669)	3.2677279334114404
  (0, 1668)	3.239132185757404
  (0, 1667)	3.2677279334114404
  (0, 1666)	3.2677279334114404
  (0, 1665)	3.239132185757404
  (0, 1664)	3.2677279334114404
  (0, 1663)	3.2212711300288595
  (0, 1662)	3.239132185757404
  (0, 1661)	3.2324712949309835
  (0, 1660)	3.168345515854848
  (0, 1659)	3.1879303682563696
  (0, 1658)	3.2677279334114404
  (0, 1657)	3.2788506785743565
  :	:
  (942, 24)	3.568193877914966
  (942, 23)	3.5618353330551584
  (942, 22)	4.233896093154672
  (942, 21)	4.270809964980307
  (942, 20)	2.8466819033698902
  (942, 19)	3.6537278401842714
  (942, 18)	3.9695407639837934
  (942, 17)	3.207952001456166
  (942, 16)	3.214426199989513
  (942, 15)	3.430277191845626
  (942, 14)	3.833512363644908
  (942, 13)	4.086331694957751
  (942, 12)	3.475618134573199
  (942, 11)	4.452170345678262
  (942, 10)	3.9549866994936513
  (942, 9)	3.8783249293067983
  (942, 8)	4.002634105547536
  (942, 7)	4.108470201483592
  (942, 6)	3.8965815750328803
  (942, 5)	3.7496239725694767
  (942, 4)	3.3900012885104407
  (942, 3)	3.611602401379454
  (942, 2)	3.1431017869248294
  (942, 1)	3.317080577295334
  (942, 0)	3.959973200000184
this is the 133 epoch
rmse loss on training set is 0.9264687808927388
rmse loss on test set is 0.9450605768613726
for this epoch using 75.96980023384094 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.261932110553019
  (0, 1680)	3.2761106146427075
  (0, 1679)	3.2208018195149184
  (0, 1678)	3.2648739263283937
  (0, 1677)	3.176729712701444
  (0, 1676)	3.268117170372053
  (0, 1675)	3.2675323410067794
  (0, 1674)	3.2675323410067794
  (0, 1673)	3.2675323410067794
  (0, 1672)	3.2422362570845675
  (0, 1671)	3.197729623122193
  (0, 1670)	3.2675323410067794
  (0, 1669)	3.2675323410067794
  (0, 1668)	3.2387475983756864
  (0, 1667)	3.2675323410067794
  (0, 1666)	3.2675323410067794
  (0, 1665)	3.2387475983756864
  (0, 1664)	3.2675323410067794
  (0, 1663)	3.2207540530914844
  (0, 1662)	3.2387475983756864
  (0, 1661)	3.232046164542624
  (0, 1660)	3.1674434234733995
  (0, 1659)	3.1871741776259443
  (0, 1658)	3.2675323410067794
  (0, 1657)	3.278774757999531
  :	:
  (942, 24)	3.568522890566944
  (942, 23)	3.5620947248491914
  (942, 22)	4.234793956503192
  (942, 21)	4.271526322995544
  (942, 20)	2.8464696028477934
  (942, 19)	3.654898999807705
  (942, 18)	3.9712648963781354
  (942, 17)	3.2079078239027736
  (942, 16)	3.21467192796851
  (942, 15)	3.431270243123728
  (942, 14)	3.83371519275888
  (942, 13)	4.0869015790604655
  (942, 12)	3.4761039314070543
  (942, 11)	4.452879908449069
  (942, 10)	3.955562223901231
  (942, 9)	3.87945799285785
  (942, 8)	4.0030196921725105
  (942, 7)	4.109148716753945
  (942, 6)	3.896906202398108
  (942, 5)	3.7523979480358336
  (942, 4)	3.390431014528783
  (942, 3)	3.612239975702875
  (942, 2)	3.1432845763409714
  (942, 1)	3.3175809813075214
  (942, 0)	3.9603102831652364
this is the 134 epoch
rmse loss on training set is 0.9263700339088825
rmse loss on test set is 0.9449802414717992
for this epoch using 75.63457822799683 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.261705418793832
  (0, 1680)	3.275997920703722
  (0, 1679)	3.220267913725079
  (0, 1678)	3.264658026319694
  (0, 1677)	3.1758778011304734
  (0, 1676)	3.2679455891023776
  (0, 1675)	3.2673391817165114
  (0, 1674)	3.2673391817165114
  (0, 1673)	3.2673391817165114
  (0, 1672)	3.2418064027279367
  (0, 1671)	3.197105011109318
  (0, 1670)	3.2673391817165114
  (0, 1669)	3.2673391817165114
  (0, 1668)	3.238365466046211
  (0, 1667)	3.2673391817165114
  (0, 1666)	3.2673391817165114
  (0, 1665)	3.238365466046211
  (0, 1664)	3.2673391817165114
  (0, 1663)	3.2202397285901347
  (0, 1662)	3.238365466046211
  (0, 1661)	3.231623772421682
  (0, 1660)	3.1665442170717224
  (0, 1659)	3.1864209552034573
  (0, 1658)	3.2673391817165114
  (0, 1657)	3.2787013822233924
  :	:
  (942, 24)	3.568843913257846
  (942, 23)	3.562346421995912
  (942, 22)	4.235677094923979
  (942, 21)	4.272230168080588
  (942, 20)	2.846261845460198
  (942, 19)	3.6560504019296896
  (942, 18)	3.9729601792553475
  (942, 17)	3.2078580969252024
  (942, 16)	3.21491238564781
  (942, 15)	3.432250956138689
  (942, 14)	3.833910884744474
  (942, 13)	4.087459523678
  (942, 12)	3.4765803550338488
  (942, 11)	4.453577089202183
  (942, 10)	3.9561270115620037
  (942, 9)	3.880568467902795
  (942, 8)	4.0033961171855035
  (942, 7)	4.109815507603127
  (942, 6)	3.897222352226919
  (942, 5)	3.7551506062105005
  (942, 4)	3.3908508966467075
  (942, 3)	3.6128664788292517
  (942, 2)	3.143462843689997
  (942, 1)	3.3180718772605706
  (942, 0)	3.9606389490584206
this is the 135 epoch
rmse loss on training set is 0.9262727242789212
rmse loss on test set is 0.9449012331372842
for this epoch using 75.30402088165283 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2614812643495803
  (0, 1680)	3.2758876381822666
  (0, 1679)	3.2197364984991528
  (0, 1678)	3.264444513318183
  (0, 1677)	3.1750284836801197
  (0, 1676)	3.267776483697155
  (0, 1675)	3.2671484098165453
  (0, 1674)	3.2671484098165453
  (0, 1673)	3.2671484098165453
  (0, 1672)	3.2413790253433987
  (0, 1671)	3.1964834376597984
  (0, 1670)	3.2671484098165453
  (0, 1669)	3.2671484098165453
  (0, 1668)	3.237985742522786
  (0, 1667)	3.2671484098165453
  (0, 1666)	3.2671484098165453
  (0, 1665)	3.237985742522786
  (0, 1664)	3.2671484098165453
  (0, 1663)	3.2197281090551035
  (0, 1662)	3.237985742522786
  (0, 1661)	3.231204071454539
  (0, 1660)	3.1656478477409444
  (0, 1659)	3.1856706510436634
  (0, 1658)	3.2671484098165453
  (0, 1657)	3.278630501659313
  :	:
  (942, 24)	3.5691570991022097
  (942, 23)	3.562590595336696
  (942, 22)	4.236545784451157
  (942, 21)	4.272921705858337
  (942, 20)	2.846058502573467
  (942, 19)	3.6571823664265577
  (942, 18)	3.974627106032118
  (942, 17)	3.2078029530485237
  (942, 16)	3.2151476635657716
  (942, 15)	3.433219502082772
  (942, 14)	3.8340995881381668
  (942, 13)	4.088005785348963
  (942, 12)	3.477047569252466
  (942, 11)	4.454262098579303
  (942, 10)	3.9566812497818846
  (942, 9)	3.8816568105136504
  (942, 8)	4.003763558430416
  (942, 7)	4.110470767941911
  (942, 6)	3.8975301900382227
  (942, 5)	3.7578821611025996
  (942, 4)	3.3912611324900217
  (942, 3)	3.6134820968940047
  (942, 2)	3.1436366564287677
  (942, 1)	3.318553423783534
  (942, 0)	3.960959355307026
this is the 136 epoch
rmse loss on training set is 0.9261768230213773
rmse loss on test set is 0.9448235247456248
for this epoch using 75.39721822738647 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2612596013939896
  (0, 1680)	3.275779722055618
  (0, 1679)	3.21920752912383
  (0, 1678)	3.2642333427811354
  (0, 1677)	3.1741817154665286
  (0, 1676)	3.267609808247629
  (0, 1675)	3.266959980894419
  (0, 1674)	3.266959980894419
  (0, 1673)	3.266959980894419
  (0, 1672)	3.240954085218978
  (0, 1671)	3.195864852647283
  (0, 1670)	3.266959980894419
  (0, 1669)	3.266959980894419
  (0, 1668)	3.2376083828971227
  (0, 1667)	3.266959980894419
  (0, 1666)	3.266959980894419
  (0, 1665)	3.2376083828971227
  (0, 1664)	3.266959980894419
  (0, 1663)	3.2192191483446053
  (0, 1662)	3.2376083828971227
  (0, 1661)	3.2307870158524428
  (0, 1660)	3.164754267931236
  (0, 1659)	3.1849232165864776
  (0, 1658)	3.266959980894419
  (0, 1657)	3.278562068118591
  :	:
  (942, 24)	3.5694625984873767
  (942, 23)	3.5628274117817997
  (942, 22)	4.237400294459139
  (942, 21)	4.273601138862175
  (942, 20)	2.845859449132224
  (942, 19)	3.658295208309315
  (942, 18)	3.976266161564969
  (942, 17)	3.2077425222179174
  (942, 16)	3.2153778508520467
  (942, 15)	3.434176049639042
  (942, 14)	3.8342814487581967
  (942, 13)	4.0885406139998075
  (942, 12)	3.4775057352444807
  (942, 11)	4.454935143566413
  (942, 10)	3.957225122562442
  (942, 9)	3.882723467477872
  (942, 8)	4.004122190353131
  (942, 7)	4.1111146884157455
  (942, 6)	3.8978298785239613
  (942, 5)	3.7605928241105646
  (942, 4)	3.3916619158155408
  (942, 3)	3.614087013044626
  (942, 2)	3.143806081512507
  (942, 1)	3.3190257773298697
  (942, 0)	3.961271656987518
this is the 137 epoch
rmse loss on training set is 0.9260823019099855
rmse loss on test set is 0.9447470899017206
for this epoch using 75.20536208152771 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2610403853744323
  (0, 1680)	3.2756741285771387
  (0, 1679)	3.21868096214309
  (0, 1678)	3.264024471423249
  (0, 1677)	3.173337452862939
  (0, 1676)	3.2674455181404443
  (0, 1675)	3.266773851797427
  (0, 1674)	3.266773851797427
  (0, 1673)	3.266773851797427
  (0, 1672)	3.2405315437462394
  (0, 1671)	3.1952492072838745
  (0, 1670)	3.266773851797427
  (0, 1669)	3.266773851797427
  (0, 1668)	3.237233343545803
  (0, 1667)	3.266773851797427
  (0, 1666)	3.266773851797427
  (0, 1665)	3.237233343545803
  (0, 1664)	3.266773851797427
  (0, 1663)	3.2187128015929374
  (0, 1662)	3.237233343545803
  (0, 1661)	3.230372561099376
  (0, 1660)	3.163863431399412
  (0, 1659)	3.184178604603451
  (0, 1658)	3.266773851797427
  (0, 1657)	3.2784960347565613
  :	:
  (942, 24)	3.5697605591194184
  (942, 23)	3.563057034419009
  (942, 22)	4.23824088789069
  (942, 21)	4.274268666574497
  (942, 20)	2.845664563566926
  (942, 19)	3.659389237790728
  (942, 18)	3.977877822301101
  (942, 17)	3.2076769318477356
  (942, 16)	3.2156030352488387
  (942, 15)	3.4351207650191444
  (942, 14)	3.8344566097533215
  (942, 13)	4.089064253171772
  (942, 12)	3.477955011608835
  (942, 11)	4.455596427570289
  (942, 10)	3.957758810671935
  (942, 9)	3.8837688764867804
  (942, 8)	4.004472184077823
  (942, 7)	4.111747456477359
  (942, 6)	3.8981215775868616
  (942, 5)	3.763282804056356
  (942, 4)	3.3920534365861066
  (942, 3)	3.614681407482362
  (942, 2)	3.1439711853815218
  (942, 1)	3.3194890921882645
  (942, 0)	3.961576006656058
this is the 138 epoch
rmse loss on training set is 0.925989133449151
rmse loss on test set is 0.944671902903635
for this epoch using 76.59548902511597 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2608235729627277
  (0, 1680)	3.2755708152262257
  (0, 1679)	3.218156755309232
  (0, 1678)	3.263817857167667
  (0, 1677)	3.1724956534508064
  (0, 1676)	3.267283570007295
  (0, 1675)	3.2665899805833054
  (0, 1674)	3.2665899805833054
  (0, 1673)	3.2665899805833054
  (0, 1672)	3.2401113633751213
  (0, 1671)	3.194636454069723
  (0, 1670)	3.2665899805833054
  (0, 1669)	3.2665899805833054
  (0, 1668)	3.236860582079909
  (0, 1667)	3.2665899805833054
  (0, 1666)	3.2665899805833054
  (0, 1665)	3.236860582079909
  (0, 1664)	3.2665899805833054
  (0, 1663)	3.2182090251611286
  (0, 1662)	3.236860582079909
  (0, 1661)	3.229960663902448
  (0, 1660)	3.1629752931590707
  (0, 1659)	3.183436769146748
  (0, 1658)	3.2665899805833054
  (0, 1657)	3.2784323560212836
  :	:
  (942, 24)	3.57005112606852
  (942, 23)	3.563279622618332
  (942, 22)	4.239067821474698
  (942, 21)	4.274924485464721
  (942, 20)	2.8454737277035766
  (942, 19)	3.6604647603514944
  (942, 18)	3.9794625564264887
  (942, 17)	3.2076063068696192
  (942, 16)	3.2158233031319106
  (942, 15)	3.436053812000413
  (942, 14)	3.834625211650406
  (942, 13)	4.08957694023802
  (942, 12)	3.4783955543961946
  (942, 11)	4.456246150492095
  (942, 10)	3.9582824917139545
  (942, 9)	3.8847934663202035
  (942, 8)	4.004813707480559
  (942, 7)	4.112369256456239
  (942, 6)	3.8984054443781124
  (942, 5)	3.76595230721925
  (942, 4)	3.392435881044304
  (942, 3)	3.615265457503504
  (942, 2)	3.1441320339489156
  (942, 1)	3.319943520494445
  (942, 0)	3.9618725543795135
this is the 139 epoch
rmse loss on training set is 0.9258972908503823
rmse loss on test set is 0.9445979387194886
for this epoch using 75.95598411560059 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2606091220081552
  (0, 1680)	3.275469740660732
  (0, 1679)	3.217634867536205
  (0, 1678)	3.263613459099114
  (0, 1677)	3.1716562759732887
  (0, 1676)	3.2671239216769163
  (0, 1675)	3.266408326473245
  (0, 1674)	3.266408326473245
  (0, 1673)	3.266408326473245
  (0, 1672)	3.239693507570983
  (0, 1671)	3.1940265467447886
  (0, 1670)	3.266408326473245
  (0, 1669)	3.266408326473245
  (0, 1668)	3.2364900572969595
  (0, 1667)	3.266408326473245
  (0, 1666)	3.266408326473245
  (0, 1665)	3.2364900572969595
  (0, 1664)	3.266408326473245
  (0, 1663)	3.217707776589983
  (0, 1662)	3.2364900572969595
  (0, 1661)	3.2295512821446164
  (0, 1660)	3.162089809433005
  (0, 1659)	3.182697665500517
  (0, 1658)	3.266408326473245
  (0, 1657)	3.2783709876046565
  :	:
  (942, 24)	3.570334441813759
  (942, 23)	3.5634953321331433
  (942, 22)	4.239881345934298
  (942, 21)	4.275568789026913
  (942, 20)	2.8452868266754656
  (942, 19)	3.6615220768056846
  (942, 18)	3.981020824011305
  (942, 17)	3.2075307697796434
  (942, 16)	3.2160387395311516
  (942, 15)	3.4369753519623742
  (942, 14)	3.8347873924009295
  (942, 13)	4.090078906611238
  (942, 12)	3.478827517143079
  (942, 11)	4.456884508798426
  (942, 10)	3.958796340193383
  (942, 9)	3.885797657027545
  (942, 8)	4.005146925260345
  (942, 7)	4.112980269625055
  (942, 6)	3.8986816333351766
  (942, 5)	3.768601537369105
  (942, 4)	3.392809431784722
  (942, 3)	3.6158393375404816
  (942, 2)	3.144288692589115
  (942, 1)	3.320389212243786
  (942, 0)	3.96216144776642
this is the 140 epoch
rmse loss on training set is 0.9258067480097014
rmse loss on test set is 0.9445251729654435
for this epoch using 76.27241802215576 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2603969914928923
  (0, 1680)	3.2753708646716513
  (0, 1679)	3.217115258855235
  (0, 1678)	3.2634112374194877
  (0, 1677)	3.1708192802909863
  (0, 1676)	3.2669665321294543
  (0, 1675)	3.266228849807205
  (0, 1674)	3.266228849807205
  (0, 1673)	3.266228849807205
  (0, 1672)	3.2392779407738765
  (0, 1671)	3.1934194402430447
  (0, 1670)	3.266228849807205
  (0, 1669)	3.266228849807205
  (0, 1668)	3.2361217291352613
  (0, 1667)	3.266228849807205
  (0, 1666)	3.266228849807205
  (0, 1665)	3.2361217291352613
  (0, 1664)	3.266228849807205
  (0, 1663)	3.2172090145553387
  (0, 1662)	3.2361217291352613
  (0, 1661)	3.2291443748397586
  (0, 1660)	3.161206937608012
  (0, 1659)	3.181961250134637
  (0, 1658)	3.266228849807205
  (0, 1657)	3.278311886395801
  :	:
  (942, 24)	3.5706106462871867
  (942, 23)	3.5637043151977004
  (942, 22)	4.240681706185657
  (942, 21)	4.276201767816958
  (942, 20)	2.8451037488371096
  (942, 19)	3.6625614833653892
  (942, 18)	3.9825530771526774
  (942, 17)	3.207450440684534
  (942, 16)	3.2162494281507974
  (942, 15)	3.4378855439226146
  (942, 14)	3.834943287426508
  (942, 13)	4.090570377942331
  (942, 12)	3.4792510509057646
  (942, 11)	4.457511695589764
  (942, 10)	3.95930052758009
  (942, 9)	3.886781860105053
  (942, 8)	4.005471999007787
  (942, 7)	4.113580674263329
  (942, 6)	3.8989502962195393
  (942, 5)	3.7712306957992756
  (942, 4)	3.3931742678248593
  (942, 3)	3.6164032192026183
  (942, 2)	3.1444412261272103
  (942, 1)	3.32082631530482
  (942, 0)	3.962442831998221
this is the 141 epoch
rmse loss on training set is 0.9257174794858438
rmse loss on test set is 0.9444535818844472
for this epoch using 77.56444692611694 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2601871414894052
  (0, 1680)	3.2752741481399283
  (0, 1679)	3.2165978903725465
  (0, 1678)	3.2632111534053783
  (0, 1677)	3.1699846273397214
  (0, 1676)	3.266811361452887
  (0, 1675)	3.2660515120012996
  (0, 1674)	3.2660515120012996
  (0, 1673)	3.2660515120012996
  (0, 1672)	3.238864628359805
  (0, 1671)	3.192815090648721
  (0, 1670)	3.2660515120012996
  (0, 1669)	3.2660515120012996
  (0, 1668)	3.2357555586303373
  (0, 1667)	3.2660515120012996
  (0, 1666)	3.2660515120012996
  (0, 1665)	3.2357555586303373
  (0, 1664)	3.2660515120012996
  (0, 1663)	3.2167126988254804
  (0, 1662)	3.2357555586303373
  (0, 1661)	3.228739902089777
  (0, 1660)	3.1603266361916282
  (0, 1659)	3.1812274806605867
  (0, 1658)	3.2660515120012996
  (0, 1657)	3.2782550104366437
  :	:
  (942, 24)	3.570879876917488
  (942, 23)	3.5639067206213846
  (942, 22)	4.241469141528049
  (942, 21)	4.276823609489405
  (942, 20)	2.8449243856800925
  (942, 19)	3.663583271704528
  (942, 18)	3.984059760114866
  (942, 17)	3.207365437346883
  (942, 16)	3.2164554513893755
  (942, 15)	3.438784544572144
  (942, 14)	3.835093029663383
  (942, 13)	4.09105157431055
  (942, 12)	3.4796663042939326
  (942, 11)	4.458127900666684
  (942, 10)	3.95979522237047
  (942, 9)	3.887746478669735
  (942, 8)	4.005789087271626
  (942, 7)	4.114170645718501
  (942, 6)	3.8992115821544284
  (942, 5)	3.7738399813589893
  (942, 4)	3.3935305646747578
  (942, 3)	3.616957271316617
  (942, 2)	3.1445896988291158
  (942, 1)	3.321254975433428
  (942, 0)	3.9627168498605325
this is the 142 epoch
rmse loss on training set is 0.92562946047937
rmse loss on test set is 0.9443831423258674
for this epoch using 75.40849304199219 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2599795331198775
  (0, 1680)	3.2751795529953216
  (0, 1679)	3.2160827242290417
  (0, 1678)	3.26301316936774
  (0, 1677)	3.1691522790903526
  (0, 1676)	3.2666583708015615
  (0, 1675)	3.2658762755072064
  (0, 1674)	3.2658762755072064
  (0, 1673)	3.2658762755072064
  (0, 1672)	3.2384535366039007
  (0, 1671)	3.192213455154641
  (0, 1670)	3.2658762755072064
  (0, 1669)	3.2658762755072064
  (0, 1668)	3.2353915078734197
  (0, 1667)	3.2658762755072064
  (0, 1666)	3.2658762755072064
  (0, 1665)	3.2353915078734197
  (0, 1664)	3.2658762755072064
  (0, 1663)	3.2162187902204704
  (0, 1662)	3.2353915078734197
  (0, 1661)	3.228337825043809
  (0, 1660)	3.1594488647710177
  (0, 1659)	3.180496315789332
  (0, 1658)	3.2658762755072064
  (0, 1657)	3.2782003188795255
  :	:
  (942, 24)	3.5711422686728507
  (942, 23)	3.564102693879721
  (942, 22)	4.242243885825589
  (942, 21)	4.27743449883404
  (942, 20)	2.8447486317509925
  (942, 19)	3.6645877290219793
  (942, 18)	3.985541309466889
  (942, 17)	3.2072758752295694
  (942, 16)	3.2166568903592148
  (942, 15)	3.439672508310148
  (942, 14)	3.835236749606025
  (942, 13)	4.0915227104056
  (942, 12)	3.480073423504043
  (942, 11)	4.458733310593902
  (942, 10)	3.960280590146924
  (942, 9)	3.8886919076296595
  (942, 8)	4.006098345622976
  (942, 7)	4.11475035646456
  (942, 6)	3.8994656376625234
  (942, 5)	3.776429590485409
  (942, 4)	3.393878494405311
  (942, 3)	3.617501659966747
  (942, 2)	3.144734174392434
  (942, 1)	3.3216753362877975
  (942, 0)	3.9629836417744704
this is the 143 epoch
rmse loss on training set is 0.9255426668125178
rmse loss on test set is 0.9443138317259413
for this epoch using 75.27117419242859 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.259774128517596
  (0, 1680)	3.2750870421772276
  (0, 1679)	3.2155697235619107
  (0, 1678)	3.2628172486133473
  (0, 1677)	3.1683221985104666
  (0, 1676)	3.2665075223566147
  (0, 1675)	3.2657031037735194
  (0, 1674)	3.2657031037735194
  (0, 1673)	3.2657031037735194
  (0, 1672)	3.2380446326454098
  (0, 1671)	3.19161449202247
  (0, 1670)	3.2657031037735194
  (0, 1669)	3.2657031037735194
  (0, 1668)	3.2350295399719506
  (0, 1667)	3.2657031037735194
  (0, 1666)	3.2657031037735194
  (0, 1665)	3.2350295399719506
  (0, 1664)	3.2657031037735194
  (0, 1663)	3.215727250573491
  (0, 1662)	3.2350295399719506
  (0, 1661)	3.2279381058593066
  (0, 1660)	3.158573583973684
  (0, 1659)	3.179767715291226
  (0, 1658)	3.2657031037735194
  (0, 1657)	3.2781477719467493
  :	:
  (942, 24)	3.5713979541033054
  (942, 23)	3.5642923772023
  (942, 22)	4.243006167681094
  (942, 21)	4.278034617811959
  (942, 20)	2.8445763845712007
  (942, 19)	3.665575138103899
  (942, 18)	3.9869981542177078
  (942, 17)	3.20718186753919
  (942, 16)	3.21685382490573
  (942, 15)	3.4405495872781806
  (942, 14)	3.8353745753498134
  (942, 13)	4.091983995701959
  (942, 12)	3.480472552352459
  (942, 11)	4.459328108762224
  (942, 10)	3.960756793635299
  (942, 9)	3.8896185338509515
  (942, 8)	4.0063999267177195
  (942, 7)	4.1153199761584816
  (942, 6)	3.8997126067034302
  (942, 5)	3.778999717235138
  (942, 4)	3.3942182257152114
  (942, 3)	3.618036548534564
  (942, 2)	3.1448747159380894
  (942, 1)	3.3220875394440292
  (942, 0)	3.9632433458279377
this is the 144 epoch
rmse loss on training set is 0.9254570749098509
rmse loss on test set is 0.9442456280889568
for this epoch using 74.9322452545166 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2595708907900107
  (0, 1680)	3.2749965795972837
  (0, 1679)	3.215058852467976
  (0, 1678)	3.2626233554081026
  (0, 1677)	3.1674943495278396
  (0, 1676)	3.2663587792882236
  (0, 1675)	3.2655319612088247
  (0, 1674)	3.2655319612088247
  (0, 1673)	3.2655319612088247
  (0, 1672)	3.237637884454416
  (0, 1671)	3.1910181605447248
  (0, 1670)	3.2655319612088247
  (0, 1669)	3.2655319612088247
  (0, 1668)	3.2346696190118363
  (0, 1667)	3.2655319612088247
  (0, 1666)	3.2655319612088247
  (0, 1665)	3.2346696190118363
  (0, 1664)	3.2655319612088247
  (0, 1663)	3.2152380426938802
  (0, 1662)	3.2346696190118363
  (0, 1661)	3.2275407076649127
  (0, 1660)	3.1577007554299876
  (0, 1659)	3.1790416399577093
  (0, 1658)	3.2655319612088247
  (0, 1657)	3.2780973308920163
  :	:
  (942, 24)	3.5716470633824424
  (942, 23)	3.564475909657721
  (942, 22)	4.24375621060238
  (942, 21)	4.278624145591531
  (942, 20)	2.844407544558682
  (942, 19)	3.6665457773852994
  (942, 18)	3.988430715948922
  (942, 17)	3.2070835252687497
  (942, 16)	3.2170463336263
  (942, 15)	3.4414159313938435
  (942, 14)	3.8355066326328555
  (942, 13)	4.092435634625892
  (942, 12)	3.4808638323083656
  (942, 11)	4.459912475448673
  (942, 10)	3.961223992760665
  (942, 9)	3.8905267363213976
  (942, 8)	4.006693980356895
  (942, 7)	4.115879671694466
  (942, 6)	3.8999526307111236
  (942, 5)	3.7815505533154163
  (942, 4)	3.3945499239967196
  (942, 3)	3.6185620977384816
  (942, 2)	3.145011386002629
  (942, 1)	3.322491724412353
  (942, 0)	3.963496097806997
this is the 145 epoch
rmse loss on training set is 0.9253726617796062
rmse loss on test set is 0.9441785099691975
for this epoch using 76.24797415733337 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.259369783983585
  (0, 1680)	3.2749081301037157
  (0, 1679)	3.214550075968804
  (0, 1678)	3.262431454942034
  (0, 1677)	3.1666686969955777
  (0, 1676)	3.266212105719639
  (0, 1675)	3.265362813146579
  (0, 1674)	3.265362813146579
  (0, 1673)	3.265362813146579
  (0, 1672)	3.2372332608001377
  (0, 1671)	3.190424421008629
  (0, 1670)	3.265362813146579
  (0, 1669)	3.265362813146579
  (0, 1668)	3.2343117100214664
  (0, 1667)	3.265362813146579
  (0, 1666)	3.265362813146579
  (0, 1665)	3.2343117100214664
  (0, 1664)	3.265362813146579
  (0, 1663)	3.214751130331922
  (0, 1662)	3.2343117100214664
  (0, 1661)	3.2271455945251044
  (0, 1660)	3.156830341737393
  (0, 1659)	3.178318051564786
  (0, 1658)	3.265362813146579
  (0, 1657)	3.2780489579635534
  :	:
  (942, 24)	3.5718897243484093
  (942, 23)	3.564653427235804
  (942, 22)	4.24449423316151
  (942, 21)	4.27920325858397
  (942, 20)	2.8442420149516208
  (942, 19)	3.667499921010919
  (942, 18)	3.9898394089451057
  (942, 17)	3.206980957239369
  (942, 16)	3.217234493888903
  (942, 15)	3.442271688383908
  (942, 14)	3.835633044877085
  (942, 13)	4.0928778267155685
  (942, 12)	3.4812474025263724
  (942, 11)	4.460486587874762
  (942, 10)	3.9616823447012495
  (942, 9)	3.891416886310782
  (942, 8)	4.006980653545393
  (942, 7)	4.1164296072563324
  (942, 6)	3.9001858486311645
  (942, 5)	3.7840822881149037
  (942, 4)	3.3948737514001133
  (942, 3)	3.6190784656728887
  (942, 2)	3.145144246531228
  (942, 1)	3.3228880286539018
  (942, 0)	3.9637420312270635
this is the 146 epoch
rmse loss on training set is 0.925289404995738
rmse loss on test set is 0.9441124564535639
for this epoch using 74.71204805374146 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2591707730501795
  (0, 1680)	3.27482165944734
  (0, 1679)	3.2140433599773477
  (0, 1678)	3.2622415132958587
  (0, 1677)	3.1658452066588403
  (0, 1676)	3.266067466692773
  (0, 1675)	3.2651956258114905
  (0, 1674)	3.2651956258114905
  (0, 1673)	3.2651956258114905
  (0, 1672)	3.2368307312207616
  (0, 1671)	3.189833234661428
  (0, 1670)	3.2651956258114905
  (0, 1669)	3.2651956258114905
  (0, 1668)	3.233955778937436
  (0, 1667)	3.2651956258114905
  (0, 1666)	3.2651956258114905
  (0, 1665)	3.233955778937436
  (0, 1664)	3.2651956258114905
  (0, 1663)	3.2142664781452166
  (0, 1662)	3.233955778937436
  (0, 1661)	3.226752731406357
  (0, 1660)	3.1559623064262525
  (0, 1659)	3.1775969128380526
  (0, 1658)	3.2651956258114905
  (0, 1657)	3.2780026163689087
  :	:
  (942, 24)	3.572126062544417
  (942, 23)	3.564825062926951
  (942, 22)	4.245220449147229
  (942, 21)	4.279772130478589
  (942, 20)	2.844079701733859
  (942, 19)	3.668437838895344
  (942, 18)	3.991224640321778
  (942, 17)	3.2068742701413027
  (942, 16)	3.2174183818503694
  (942, 15)	3.4431170038169405
  (942, 14)	3.835753933228435
  (942, 13)	4.093310766774396
  (942, 12)	3.4816233998788975
  (942, 11)	4.46105062026314
  (942, 10)	3.9621320039407815
  (942, 9)	3.8922893475280507
  (942, 8)	4.007260090548836
  (942, 7)	4.1169699443680265
  (942, 6)	3.900412396957688
  (942, 5)	3.7865951087339584
  (942, 4)	3.395189866897019
  (942, 3)	3.619585807846875
  (942, 2)	3.145273358871253
  (942, 1)	3.3232765875979893
  (942, 0)	3.963981277364104
this is the 147 epoch
rmse loss on training set is 0.9252072826806896
rmse loss on test set is 0.9440474471448701
for this epoch using 74.76510429382324 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.258973823815015
  (0, 1680)	3.2747371342490834
  (0, 1679)	3.213538671266127
  (0, 1678)	3.26205349740911
  (0, 1677)	3.1650238451231547
  (0, 1676)	3.265924828135429
  (0, 1675)	3.2650303662875357
  (0, 1674)	3.2650303662875357
  (0, 1673)	3.2650303662875357
  (0, 1672)	3.2364302659947604
  (0, 1671)	3.1892445636774682
  (0, 1670)	3.2650303662875357
  (0, 1669)	3.2650303662875357
  (0, 1668)	3.2336017925717444
  (0, 1667)	3.2650303662875357
  (0, 1666)	3.2650303662875357
  (0, 1665)	3.2336017925717444
  (0, 1664)	3.2650303662875357
  (0, 1663)	3.213784051666591
  (0, 1662)	3.2336017925717444
  (0, 1661)	3.2263620841449954
  (0, 1660)	3.1550966139272396
  (0, 1659)	3.1768781874194585
  (0, 1658)	3.2650303662875357
  (0, 1657)	3.277958270241353
  :	:
  (942, 24)	3.572356201258486
  (942, 23)	3.564990946799029
  (942, 22)	4.24593506771096
  (942, 21)	4.280330932277934
  (942, 20)	2.84392051356217
  (942, 19)	3.6693597967824014
  (942, 18)	3.9925868101511317
  (942, 17)	3.2067635685740625
  (942, 16)	3.217598072474442
  (942, 15)	3.443952021135431
  (942, 14)	3.8358694165963225
  (942, 13)	4.093734645018233
  (942, 12)	3.48199195898826
  (942, 11)	4.461604743892585
  (942, 10)	3.9625731223193124
  (942, 9)	3.893144476275291
  (942, 8)	4.00753243294889
  (942, 7)	4.117500841942355
  (942, 6)	3.900632409770295
  (942, 5)	3.78908920001466
  (942, 4)	3.3954984263423253
  (942, 3)	3.6200842772226856
  (942, 2)	3.145398783766545
  (942, 1)	3.3236575346599078
  (942, 0)	3.964213965285724
this is the 148 epoch
rmse loss on training set is 0.9251262734887001
rmse loss on test set is 0.9439834621457679
for this epoch using 74.68220329284668 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.258778902946034
  (0, 1680)	3.274654521969007
  (0, 1679)	3.213035977436872
  (0, 1678)	3.2618673750497003
  (0, 1677)	3.1642045798240415
  (0, 1676)	3.2657841568299273
  (0, 1675)	3.2648670024873425
  (0, 1674)	3.2648670024873425
  (0, 1673)	3.2648670024873425
  (0, 1672)	3.236031836113541
  (0, 1671)	3.1886583711265186
  (0, 1670)	3.2648670024873425
  (0, 1669)	3.2648670024873425
  (0, 1668)	3.233249718580538
  (0, 1667)	3.2648670024873425
  (0, 1666)	3.2648670024873425
  (0, 1665)	3.233249718580538
  (0, 1664)	3.2648670024873425
  (0, 1663)	3.213303817273465
  (0, 1662)	3.233249718580538
  (0, 1661)	3.225973619416344
  (0, 1660)	3.154233229540116
  (0, 1659)	3.1761618398354283
  (0, 1658)	3.2648670024873425
  (0, 1657)	3.2779158846076903
  :	:
  (942, 24)	3.572580261562686
  (942, 23)	3.5651512060717034
  (942, 22)	4.246638293506756
  (942, 21)	4.280879832332493
  (942, 20)	2.8437643616952966
  (942, 19)	3.6702660563038942
  (942, 18)	3.993926311585412
  (942, 17)	3.206648955085807
  (942, 16)	3.2177736395494265
  (942, 15)	3.4447768816873996
  (942, 14)	3.835979611692414
  (942, 13)	4.094149647216399
  (942, 12)	3.4823532122584995
  (942, 11)	4.462149127151573
  (942, 10)	3.9630058490825566
  (942, 9)	3.893982621598657
  (942, 8)	4.007797819697073
  (942, 7)	4.118022456328264
  (942, 6)	3.9008460187705
  (942, 5)	3.7915647445703238
  (942, 4)	3.3957995825351524
  (942, 3)	3.620574024253726
  (942, 2)	3.1455205813521796
  (942, 1)	3.324031001259153
  (942, 0)	3.964440221882049
this is the 149 epoch
rmse loss on training set is 0.9250463565897936
rmse loss on test set is 0.943920482043294
for this epoch using 74.90706396102905 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2585859779246324
  (0, 1680)	3.2745737908767243
  (0, 1679)	3.212535246891475
  (0, 1678)	3.2616831147848586
  (0, 1677)	3.1633873789981
  (0, 1676)	3.2656454203832124
  (0, 1675)	3.264705503123017
  (0, 1674)	3.264705503123017
  (0, 1673)	3.264705503123017
  (0, 1672)	3.2356354132554
  (0, 1671)	3.188074620943659
  (0, 1670)	3.264705503123017
  (0, 1669)	3.264705503123017
  (0, 1668)	3.232899525434234
  (0, 1667)	3.264705503123017
  (0, 1666)	3.264705503123017
  (0, 1665)	3.232899525434234
  (0, 1664)	3.264705503123017
  (0, 1663)	3.212825742158533
  (0, 1662)	3.232899525434234
  (0, 1661)	3.225587304705375
  (0, 1660)	3.1533721194039255
  (0, 1659)	3.1754478354664095
  (0, 1658)	3.264705503123017
  (0, 1657)	3.2778754253575944
  :	:
  (942, 24)	3.5727983623516493
  (942, 23)	3.565305965188424
  (942, 22)	4.247330326825382
  (942, 21)	4.281418996375214
  (942, 20)	2.8436111599247145
  (942, 19)	3.6711568750375787
  (942, 18)	3.995243530978199
  (942, 17)	3.206530530211936
  (942, 16)	3.2179451557056575
  (942, 15)	3.4455917247575347
  (942, 14)	3.836084633068676
  (942, 13)	4.094555954827194
  (942, 12)	3.4827072899070037
  (942, 11)	4.46268393559039
  (942, 10)	3.9634303309299175
  (942, 9)	3.894804125436258
  (942, 8)	4.008056387167076
  (942, 7)	4.1185349413565016
  (942, 6)	3.9010533533181406
  (942, 5)	3.794021922814728
  (942, 4)	3.3960934852785
  (942, 3)	3.6210551969222387
  (942, 2)	3.1456388111498885
  (942, 1)	3.324397116838009
  (942, 0)	3.96466017189656
this is the 150 epoch
rmse loss on training set is 0.9249675116543009
rmse loss on test set is 0.9438584878939906
for this epoch using 74.73294520378113 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2583950170177007
  (0, 1680)	3.274494910023072
  (0, 1679)	3.212036448804306
  (0, 1678)	3.2615006859533
  (0, 1677)	3.1625722116553217
  (0, 1676)	3.265508587198162
  (0, 1675)	3.2645458376781966
  (0, 1674)	3.2645458376781966
  (0, 1673)	3.2645458376781966
  (0, 1672)	3.2352409697606612
  (0, 1671)	3.1874932779003564
  (0, 1670)	3.2645458376781966
  (0, 1669)	3.2645458376781966
  (0, 1668)	3.23255118238896
  (0, 1667)	3.2645458376781966
  (0, 1666)	3.2645458376781966
  (0, 1665)	3.23255118238896
  (0, 1664)	3.2645458376781966
  (0, 1663)	3.212349794301811
  (0, 1662)	3.23255118238896
  (0, 1661)	3.2252031082786066
  (0, 1660)	3.152513250468486
  (0, 1659)	3.174736140517775
  (0, 1658)	3.2645458376781966
  (0, 1657)	3.2778368592141223
  :	:
  (942, 24)	3.573010620380517
  (942, 23)	3.5654553458860367
  (942, 22)	4.2480113637229096
  (942, 21)	4.281948587555772
  (942, 20)	2.8434608245070443
  (942, 19)	3.6720325065644706
  (942, 18)	3.9965388480034387
  (942, 17)	3.2064083925129157
  (942, 16)	3.2181126924326007
  (942, 15)	3.4463966875978596
  (942, 14)	3.836184593154706
  (942, 13)	4.094953745127711
  (942, 12)	3.483054319995717
  (942, 11)	4.4632093319718775
  (942, 10)	3.9638467120611196
  (942, 9)	3.895609322763077
  (942, 8)	4.008308269205601
  (942, 7)	4.119038448383932
  (942, 6)	3.9012545404672974
  (942, 5)	3.7964609129908635
  (942, 4)	3.396380281437785
  (942, 3)	3.621527940776542
  (942, 2)	3.1457535320639423
  (942, 1)	3.3247560088805637
  (942, 0)	3.964873937956665
this is the 151 epoch
rmse loss on training set is 0.9248897188380218
rmse loss on test set is 0.9437974612095664
for this epoch using 74.71653294563293 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.258205989250877
  (0, 1680)	3.274417849213112
  (0, 1679)	3.2115395530956703
  (0, 1678)	3.2613200586386997
  (0, 1677)	3.1617590475526427
  (0, 1676)	3.265373626446284
  (0, 1675)	3.264387976381405
  (0, 1674)	3.264387976381405
  (0, 1673)	3.264387976381405
  (0, 1672)	3.234848478608043
  (0, 1671)	3.1869143075769144
  (0, 1670)	3.264387976381405
  (0, 1669)	3.264387976381405
  (0, 1668)	3.232204659459298
  (0, 1667)	3.264387976381405
  (0, 1666)	3.264387976381405
  (0, 1665)	3.232204659459298
  (0, 1664)	3.264387976381405
  (0, 1663)	3.2118759424438603
  (0, 1662)	3.232204659459298
  (0, 1661)	3.2248209991572203
  (0, 1660)	3.1516565904671068
  (0, 1659)	3.1740267219920075
  (0, 1658)	3.264387976381405
  (0, 1657)	3.277800153705684
  :	:
  (942, 24)	3.573217150302271
  (942, 23)	3.5655994672622753
  (942, 22)	4.24868159614409
  (942, 21)	4.282468766474618
  (942, 20)	2.8433132740981897
  (942, 19)	3.672893200525506
  (942, 18)	3.9978126357723687
  (942, 17)	3.2062826386114516
  (942, 16)	3.2182763200957765
  (942, 15)	3.4471919054579487
  (942, 14)	3.83627960229444
  (942, 13)	4.095343191338708
  (942, 12)	3.4833944284622826
  (942, 11)	4.463725476320974
  (942, 10)	3.964255134221699
  (942, 9)	3.8963985417330247
  (942, 8)	4.00855359718204
  (942, 7)	4.1195331263365045
  (942, 6)	3.9014497050020593
  (942, 5)	3.798881891199407
  (942, 4)	3.3966601149982827
  (942, 3)	3.621992398967922
  (942, 2)	3.1458648023775724
  (942, 1)	3.3251078029320205
  (942, 0)	3.9650816406041782
this is the 152 epoch
rmse loss on training set is 0.9248129587677627
rmse loss on test set is 0.9437373839431261
for this epoch using 74.6712908744812 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2580188643829517
  (0, 1680)	3.2743425789802934
  (0, 1679)	3.211044530406475
  (0, 1678)	3.2611412036442915
  (0, 1677)	3.1609478571686505
  (0, 1676)	3.265240508041532
  (0, 1675)	3.264231890180526
  (0, 1674)	3.264231890180526
  (0, 1673)	3.264231890180526
  (0, 1672)	3.2344579133920597
  (0, 1671)	3.1863376763359663
  (0, 1670)	3.264231890180526
  (0, 1669)	3.264231890180526
  (0, 1668)	3.2318599273921604
  (0, 1667)	3.264231890180526
  (0, 1666)	3.264231890180526
  (0, 1665)	3.2318599273921604
  (0, 1664)	3.264231890180526
  (0, 1663)	3.211404156060205
  (0, 1662)	3.2318599273921604
  (0, 1661)	3.22444094709145
  (0, 1660)	3.150802107890494
  (0, 1659)	3.1733195476620613
  (0, 1658)	3.264231890180526
  (0, 1657)	3.2777652771390384
  :	:
  (942, 24)	3.5734180647044087
  (942, 23)	3.565738445841132
  (942, 22)	4.249341212040679
  (942, 21)	4.282979691216691
  (942, 20)	2.8431684296890154
  (942, 19)	3.673739202677438
  (942, 18)	3.9990652609483983
  (942, 17)	3.206153363228848
  (942, 16)	3.218436107953322
  (942, 15)	3.44797751161463
  (942, 14)	3.836369768782206
  (942, 13)	4.09572446274442
  (942, 12)	3.4837277391506865
  (942, 11)	4.464232525973018
  (942, 10)	3.9646557367472472
  (942, 9)	3.8971721038180425
  (942, 8)	4.008792500036649
  (942, 7)	4.120019121750975
  (942, 6)	3.9016389694719558
  (942, 5)	3.8012850314267372
  (942, 4)	3.3969331271213883
  (942, 3)	3.622448712287101
  (942, 2)	3.1459726797499195
  (942, 1)	3.325452622618274
  (942, 0)	3.9652833983254916
this is the 153 epoch
rmse loss on training set is 0.9247372125276271
rmse loss on test set is 0.9436782384758498
for this epoch using 74.71439003944397 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.257833612881433
  (0, 1680)	3.27426907056172
  (0, 1679)	3.2105513520739963
  (0, 1678)	3.2609640924686034
  (0, 1677)	3.1601386116793875
  (0, 1676)	3.265109202615224
  (0, 1675)	3.2640775507184254
  (0, 1674)	3.2640775507184254
  (0, 1673)	3.2640775507184254
  (0, 1672)	3.2340692483015028
  (0, 1671)	3.1857633512972345
  (0, 1670)	3.2640775507184254
  (0, 1669)	3.2640775507184254
  (0, 1668)	3.231516957641856
  (0, 1667)	3.2640775507184254
  (0, 1666)	3.2640775507184254
  (0, 1665)	3.231516957641856
  (0, 1664)	3.2640775507184254
  (0, 1663)	3.210934405336834
  (0, 1662)	3.231516957641856
  (0, 1661)	3.2240629225359623
  (0, 1660)	3.149949771961741
  (0, 1659)	3.1726145860458304
  (0, 1658)	3.2640775507184254
  (0, 1657)	3.277732198573574
  :	:
  (942, 24)	3.5736134741450702
  (942, 23)	3.5658723956360845
  (942, 22)	4.2499903954850575
  (942, 21)	4.283481517384914
  (942, 20)	2.843026214542708
  (942, 19)	3.674570754948124
  (942, 18)	4.000297083859872
  (942, 17)	3.206020659220694
  (942, 16)	3.2185921241723467
  (942, 15)	3.44875363740129
  (942, 14)	3.8364551988981463
  (942, 13)	4.096097724807636
  (942, 12)	3.4840543738417558
  (942, 11)	4.464730635620874
  (942, 10)	3.9650486566065415
  (942, 9)	3.8979303239445664
  (942, 8)	4.009025104327728
  (942, 7)	4.120496578815526
  (942, 6)	3.9018224542269886
  (942, 5)	3.803670505572663
  (942, 4)	3.3971994561998793
  (942, 3)	3.6228970192003094
  (942, 2)	3.146077221213384
  (942, 1)	3.3257905896658286
  (942, 0)	3.9654793275816433
this is the 154 epoch
rmse loss on training set is 0.9246624616455106
rmse loss on test set is 0.9436200076042434
for this epoch using 74.7680299282074 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2576502058990697
  (0, 1680)	3.274197295874531
  (0, 1679)	3.2100599901086806
  (0, 1678)	3.2607886972821625
  (0, 1677)	3.1593312829351965
  (0, 1676)	3.2649796814921466
  (0, 1675)	3.2639249303096034
  (0, 1674)	3.2639249303096034
  (0, 1673)	3.2639249303096034
  (0, 1672)	3.2336824580988575
  (0, 1671)	3.185191300313257
  (0, 1670)	3.2639249303096034
  (0, 1669)	3.2639249303096034
  (0, 1668)	3.2311757223462356
  (0, 1667)	3.2639249303096034
  (0, 1666)	3.2639249303096034
  (0, 1665)	3.2311757223462356
  (0, 1664)	3.2639249303096034
  (0, 1663)	3.210466661146778
  (0, 1662)	3.2311757223462356
  (0, 1661)	3.2236868966263916
  (0, 1660)	3.1490995526124017
  (0, 1659)	3.171911806381809
  (0, 1658)	3.2639249303096034
  (0, 1657)	3.277700887796597
  :	:
  (942, 24)	3.573803487188543
  (942, 23)	3.5660014282115573
  (942, 22)	4.250629326779358
  (942, 21)	4.283974398133481
  (942, 20)	2.842886554133555
  (942, 19)	3.6753880954911486
  (942, 18)	4.001508458610891
  (942, 17)	3.205884617611908
  (942, 16)	3.2187444358450157
  (942, 15)	3.4495204122367413
  (942, 14)	3.836535996943019
  (942, 13)	4.096463139280422
  (942, 12)	3.484374452283358
  (942, 11)	4.465219957361026
  (942, 10)	3.9654340284436693
  (942, 9)	3.898673510627093
  (942, 8)	4.009251534277535
  (942, 7)	4.120965639409223
  (942, 6)	3.9020002774523994
  (942, 5)	3.806038483477754
  (942, 4)	3.3974592379120767
  (942, 3)	3.6233374558849287
  (942, 2)	3.1461784831715116
  (942, 1)	3.3261218239219112
  (942, 0)	3.9656695428380306
this is the 155 epoch
rmse loss on training set is 0.9245886880803286
rmse loss on test set is 0.9435626745277481
for this epoch using 75.0001277923584 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.257468615251446
  (0, 1680)	3.274127227493234
  (0, 1679)	3.2095704171719346
  (0, 1678)	3.260614990905309
  (0, 1677)	3.1585258434385577
  (0, 1676)	3.2648519166675443
  (0, 1675)	3.2637740019178634
  (0, 1674)	3.2637740019178634
  (0, 1673)	3.2637740019178634
  (0, 1672)	3.2332975181007018
  (0, 1671)	3.184621491946167
  (0, 1670)	3.2637740019178634
  (0, 1669)	3.2637740019178634
  (0, 1668)	3.2308361943037993
  (0, 1667)	3.2637740019178634
  (0, 1666)	3.2637740019178634
  (0, 1665)	3.2308361943037993
  (0, 1664)	3.2637740019178634
  (0, 1663)	3.2100008950276986
  (0, 1662)	3.2308361943037993
  (0, 1661)	3.2233128411568432
  (0, 1660)	3.148251420459582
  (0, 1659)	3.1712111786056387
  (0, 1658)	3.2637740019178634
  (0, 1657)	3.2776713152996577
  :	:
  (942, 24)	3.573988210440121
  (942, 23)	3.5661256527423295
  (942, 22)	4.251258182560268
  (942, 21)	4.2844584842008215
  (942, 20)	2.8427493760873928
  (942, 19)	3.6761914587397624
  (942, 18)	4.002699733190135
  (942, 17)	3.205745327631027
  (942, 16)	3.218893109004404
  (942, 15)	3.450277963653648
  (942, 14)	3.836612265272427
  (942, 13)	4.0968208643104305
  (942, 12)	3.4846880922202876
  (942, 11)	4.465700640738593
  (942, 10)	3.9658119846190454
  (942, 9)	3.899401966099153
  (942, 8)	4.009471911817019
  (942, 7)	4.121426443140464
  (942, 6)	3.902172555203049
  (942, 5)	3.8083891329503183
  (942, 4)	3.3977126052748825
  (942, 3)	3.6237701562648224
  (942, 2)	3.146276521397207
  (942, 1)	3.3264464433747705
  (942, 0)	3.9658541565939847
this is the 156 epoch
rmse loss on training set is 0.9245158742094756
rmse loss on test set is 0.9435062228368907
for this epoch using 74.76322197914124 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2572888133954923
  (0, 1680)	3.2740588386280582
  (0, 1679)	3.209082606554853
  (0, 1678)	3.2604429467868683
  (0, 1677)	3.1577222663228333
  (0, 1676)	3.2647258807851856
  (0, 1675)	3.2636247391349125
  (0, 1674)	3.2636247391349125
  (0, 1673)	3.2636247391349125
  (0, 1672)	3.232914404158931
  (0, 1671)	3.1840538954454485
  (0, 1670)	3.2636247391349125
  (0, 1669)	3.2636247391349125
  (0, 1668)	3.2304983469518582
  (0, 1667)	3.2636247391349125
  (0, 1666)	3.2636247391349125
  (0, 1665)	3.2304983469518582
  (0, 1664)	3.2636247391349125
  (0, 1663)	3.2095370791603473
  (0, 1662)	3.2304983469518582
  (0, 1661)	3.222940728558355
  (0, 1660)	3.1474053467839287
  (0, 1659)	3.170512673327774
  (0, 1658)	3.2636247391349125
  (0, 1657)	3.277643452255919
  :	:
  (942, 24)	3.5741677485804533
  (942, 23)	3.5662451760712472
  (942, 22)	4.251877135899724
  (942, 21)	4.284933923942374
  (942, 20)	2.8426146101233987
  (942, 19)	3.6769810754601715
  (942, 18)	4.00387124957773
  (942, 17)	3.205602876743925
  (942, 16)	3.2190382086400686
  (942, 15)	3.4510264173264877
  (942, 14)	3.8366841043304674
  (942, 13)	4.097171054543279
  (942, 12)	3.484995409423846
  (942, 11)	4.46617283279131
  (942, 10)	3.966182655249578
  (942, 9)	3.900115986441645
  (942, 8)	4.009686356629589
  (942, 7)	4.121879127384486
  (942, 6)	3.902339401437495
  (942, 5)	3.810722619793045
  (942, 4)	3.397959688695917
  (942, 3)	3.624195252045071
  (942, 2)	3.146371391031473
  (942, 1)	3.3267645641742245
  (942, 0)	3.966033279412078
this is the 157 epoch
rmse loss on training set is 0.9244440028169025
rmse loss on test set is 0.943450636501813
for this epoch using 74.57719087600708 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2571107734088907
  (0, 1680)	3.2739921031041934
  (0, 1679)	3.2085965321578573
  (0, 1678)	3.2602725389837333
  (0, 1677)	3.1569205253319788
  (0, 1676)	3.2646015471162544
  (0, 1675)	3.263477116159879
  (0, 1674)	3.263477116159879
  (0, 1673)	3.263477116159879
  (0, 1672)	3.2325330926428695
  (0, 1671)	3.183488480726553
  (0, 1670)	3.263477116159879
  (0, 1669)	3.263477116159879
  (0, 1668)	3.2301621543455297
  (0, 1667)	3.263477116159879
  (0, 1666)	3.263477116159879
  (0, 1665)	3.2301621543455297
  (0, 1664)	3.263477116159879
  (0, 1663)	3.209075186348009
  (0, 1662)	3.2301621543455297
  (0, 1661)	3.222570531878266
  (0, 1660)	3.1465613035085713
  (0, 1659)	3.1698162618119365
  (0, 1658)	3.263477116159879
  (0, 1657)	3.277617270498357
  :	:
  (942, 24)	3.574342204399252
  (942, 23)	3.566360102765159
  (942, 22)	4.252486356401825
  (942, 21)	4.2854008633630585
  (942, 20)	2.8424821879974322
  (942, 19)	3.677757172804181
  (942, 18)	4.005023343850285
  (942, 17)	3.205457350686819
  (942, 16)	3.2191797987134385
  (942, 15)	3.451765897099173
  (942, 14)	3.836751612682797
  (942, 13)	4.097513861220882
  (942, 12)	3.485296517721204
  (942, 11)	4.466636678092638
  (942, 10)	3.966546168247786
  (942, 9)	3.9008158617085344
  (942, 8)	4.009894986193779
  (942, 7)	4.12232382731988
  (942, 6)	3.9025009280516234
  (942, 5)	3.8130391078292813
  (942, 4)	3.3982006160245586
  (942, 3)	3.6246128727465083
  (942, 2)	3.146463146582452
  (942, 1)	3.327076300652314
  (942, 0)	3.9662070199470985
this is the 158 epoch
rmse loss on training set is 0.9243730570814924
rmse loss on test set is 0.943395899861212
for this epoch using 75.17093014717102 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2569344689703446
  (0, 1680)	3.273926995341901
  (0, 1679)	3.208112168471172
  (0, 1678)	3.260103742141342
  (0, 1677)	3.1561205948010085
  (0, 1676)	3.264478889539246
  (0, 1675)	3.263331107779677
  (0, 1674)	3.263331107779677
  (0, 1673)	3.263331107779677
  (0, 1672)	3.232153560422184
  (0, 1671)	3.1829252183504786
  (0, 1670)	3.263331107779677
  (0, 1669)	3.263331107779677
  (0, 1668)	3.229827591137729
  (0, 1667)	3.263331107779677
  (0, 1666)	3.263331107779677
  (0, 1665)	3.229827591137729
  (0, 1664)	3.263331107779677
  (0, 1663)	3.2086151899967565
  (0, 1662)	3.229827591137729
  (0, 1661)	3.22220222476044
  (0, 1660)	3.1457192631789312
  (0, 1659)	3.1691219159545962
  (0, 1658)	3.263331107779677
  (0, 1657)	3.2775927424989533
  :	:
  (942, 24)	3.574511678828472
  (942, 23)	3.5664705351691803
  (942, 22)	4.253086010295836
  (942, 21)	4.285859446149474
  (942, 20)	2.8423520434467533
  (942, 19)	3.6785199743612176
  (942, 18)	4.006156346283961
  (942, 17)	3.2053088334986564
  (942, 16)	3.2193179421728706
  (942, 15)	3.4524965250121995
  (942, 14)	3.8368148870491403
  (942, 13)	4.097849432276273
  (942, 12)	3.485591529024363
  (942, 11)	4.4670923187939255
  (942, 10)	3.9669026493600867
  (942, 9)	3.9015018760500495
  (942, 8)	4.010097915825001
  (942, 7)	4.122760675964327
  (942, 6)	3.902657244911967
  (942, 5)	3.815338758928992
  (942, 4)	3.398435512601989
  (942, 3)	3.625023145739649
  (942, 2)	3.1465518419248784
  (942, 1)	3.3273817653440623
  (942, 0)	3.9663754849748223
this is the 159 epoch
rmse loss on training set is 0.924303020565826
rmse loss on test set is 0.9433419976116653
for this epoch using 74.60606288909912 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2567598743406254
  (0, 1680)	3.2738634903374715
  (0, 1679)	3.2076294905561302
  (0, 1678)	3.259936531474933
  (0, 1677)	3.155322449637328
  (0, 1676)	3.264357882520528
  (0, 1675)	3.2631866893502175
  (0, 1674)	3.2631866893502175
  (0, 1673)	3.2631866893502175
  (0, 1672)	3.231775784850448
  (0, 1671)	3.182364079504091
  (0, 1670)	3.2631866893502175
  (0, 1669)	3.2631866893502175
  (0, 1668)	3.229494632559866
  (0, 1667)	3.2631866893502175
  (0, 1666)	3.2631866893502175
  (0, 1665)	3.229494632559866
  (0, 1664)	3.2631866893502175
  (0, 1663)	3.208157064096555
  (0, 1662)	3.229494632559866
  (0, 1661)	3.2218357814263343
  (0, 1660)	3.1448791989433293
  (0, 1659)	3.168429608265176
  (0, 1658)	3.2631866893502175
  (0, 1657)	3.2775698413486802
  :	:
  (942, 24)	3.5746762709748476
  (942, 23)	3.5665765734593795
  (942, 22)	4.253676260525912
  (942, 21)	4.286309813701903
  (942, 20)	2.842224112136097
  (942, 19)	3.6792697002097037
  (942, 18)	4.007270581455826
  (942, 17)	3.205157407552923
  (942, 16)	3.2194527009685943
  (942, 15)	3.453218421329394
  (942, 14)	3.836874022335285
  (942, 13)	4.0981779124247035
  (942, 12)	3.4858805533588995
  (942, 11)	4.467539894665641
  (942, 10)	3.9672522222042605
  (942, 9)	3.9021743078334175
  (942, 8)	4.010295258716189
  (942, 7)	4.123189804209381
  (942, 6)	3.9028084598886177
  (942, 5)	3.8176217330343887
  (942, 4)	3.3986645013103014
  (942, 3)	3.6254261962783536
  (942, 2)	3.146637530299891
  (942, 1)	3.327681069008472
  (942, 0)	3.9665387794204863
this is the 160 epoch
rmse loss on training set is 0.9242338772054334
rmse loss on test set is 0.9432889147973844
for this epoch using 75.46843814849854 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2565869643444527
  (0, 1680)	3.273801563644935
  (0, 1679)	3.2071484740271665
  (0, 1678)	3.2597708827515266
  (0, 1677)	3.15452606530282
  (0, 1676)	3.2642385010958126
  (0, 1675)	3.2630438367783134
  (0, 1674)	3.2630438367783134
  (0, 1673)	3.2630438367783134
  (0, 1672)	3.231399743749524
  (0, 1671)	3.181805035981245
  (0, 1670)	3.2630438367783134
  (0, 1669)	3.2630438367783134
  (0, 1668)	3.2291632544034092
  (0, 1667)	3.2630438367783134
  (0, 1666)	3.2630438367783134
  (0, 1665)	3.2291632544034092
  (0, 1664)	3.2630438367783134
  (0, 1663)	3.207700783203032
  (0, 1662)	3.2291632544034092
  (0, 1661)	3.221471176656787
  (0, 1660)	3.144041084534344
  (0, 1659)	3.1677393118471047
  (0, 1658)	3.2630438367783134
  (0, 1657)	3.277548540738229
  :	:
  (942, 24)	3.574836078151971
  (942, 23)	3.5666783156939035
  (942, 22)	4.2542572668373
  (942, 21)	4.286752105165979
  (942, 20)	2.842098331605188
  (942, 19)	3.680006566967762
  (942, 18)	4.008366368343343
  (942, 17)	3.205003153588804
  (942, 16)	3.2195841360673554
  (942, 15)	3.4539317045643334
  (942, 14)	3.8369291116645328
  (942, 13)	4.098499443251515
  (942, 12)	3.486163698892414
  (942, 11)	4.46797954313783
  (942, 10)	3.9675950083060396
  (942, 9)	3.902833429761142
  (942, 8)	4.010487125977734
  (942, 7)	4.123611340854633
  (942, 6)	3.902954678887793
  (942, 5)	3.8198881881851676
  (942, 4)	3.398887702620646
  (942, 3)	3.625822147532976
  (942, 2)	3.1467202643151797
  (942, 1)	3.3279743206494627
  (942, 0)	3.9666970063870153
this is the 161 epoch
rmse loss on training set is 0.9241656112982727
rmse loss on test set is 0.9432366368002431
for this epoch using 75.09453296661377 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2564157143530608
  (0, 1680)	3.2737411913585475
  (0, 1679)	3.2066690950347017
  (0, 1678)	3.2596067722727664
  (0, 1677)	3.1537314177966387
  (0, 1676)	3.264120720852404
  (0, 1675)	3.2629025265044502
  (0, 1674)	3.2629025265044502
  (0, 1673)	3.2629025265044502
  (0, 1672)	3.2310254153946176
  (0, 1671)	3.1812480601647337
  (0, 1670)	3.2629025265044502
  (0, 1669)	3.2629025265044502
  (0, 1668)	3.2288334330021997
  (0, 1667)	3.2629025265044502
  (0, 1666)	3.2629025265044502
  (0, 1665)	3.2288334330021997
  (0, 1664)	3.2629025265044502
  (0, 1663)	3.207246322420192
  (0, 1662)	3.2288334330021997
  (0, 1661)	3.2211083857746665
  (0, 1660)	3.1432048942510176
  (0, 1659)	3.1670510003796597
  (0, 1658)	3.2629025265044502
  (0, 1657)	3.277528814939679
  :	:
  (942, 24)	3.5749911959117378
  (942, 23)	3.5667758578625746
  (942, 22)	4.254829185859356
  (942, 21)	4.287186457464125
  (942, 20)	2.8419746412175155
  (942, 19)	3.6807307878433844
  (942, 18)	4.00944402042212
  (942, 17)	3.2048461507417674
  (942, 16)	3.2197123074668776
  (942, 15)	3.4546364915062964
  (942, 14)	3.836980246408612
  (942, 13)	4.09881416329674
  (942, 12)	3.4864410719626258
  (942, 11)	4.468411399339761
  (942, 10)	3.967931127134984
  (942, 9)	3.903479508986858
  (942, 8)	4.010673626676335
  (942, 7)	4.124025412641002
  (942, 6)	3.903096005883948
  (942, 5)	3.8221382805435193
  (942, 4)	3.399105234640398
  (942, 3)	3.6262111206231116
  (942, 2)	3.1468000959454785
  (942, 1)	3.3282616275369654
  (942, 0)	3.966850267182881
this is the 162 epoch
rmse loss on training set is 0.9240982074947086
rmse loss on test set is 0.9431851493302257
for this epoch using 75.04710412025452 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2562461002674397
  (0, 1680)	3.2736823500959455
  (0, 1679)	3.2061913302484872
  (0, 1678)	3.2594441768583
  (0, 1677)	3.152938483638683
  (0, 1676)	3.2640045179120003
  (0, 1675)	3.262762735486075
  (0, 1674)	3.262762735486075
  (0, 1673)	3.262762735486075
  (0, 1672)	3.2306527784998758
  (0, 1671)	3.180693125008809
  (0, 1670)	3.262762735486075
  (0, 1669)	3.262762735486075
  (0, 1668)	3.2285051452154603
  (0, 1667)	3.262762735486075
  (0, 1666)	3.262762735486075
  (0, 1665)	3.2285051452154603
  (0, 1664)	3.262762735486075
  (0, 1663)	3.206793657383543
  (0, 1662)	3.2285051452154603
  (0, 1661)	3.2207473846280297
  (0, 1660)	3.1423706029416176
  (0, 1659)	3.1663646481004335
  (0, 1658)	3.262762735486075
  (0, 1657)	3.2775106387886708
  :	:
  (942, 24)	3.5751417180752756
  (942, 23)	3.56686929393511
  (942, 22)	4.255392171185555
  (942, 21)	4.287613005326712
  (942, 20)	2.8418529821103995
  (942, 19)	3.6814425726839075
  (942, 18)	4.010503845761939
  (942, 17)	3.2046864765735634
  (942, 16)	3.219837274210054
  (942, 15)	3.455332897245867
  (942, 14)	3.837027516218122
  (942, 13)	4.09912220813662
  (942, 12)	3.4867127771051947
  (942, 11)	4.468835596138731
  (942, 10)	3.9682606961395317
  (942, 9)	3.9041128072289055
  (942, 8)	4.0108548678731415
  (942, 7)	4.124432144283336
  (942, 6)	3.9032325429515944
  (942, 5)	3.8243721644187376
  (942, 4)	3.3993172131594314
  (942, 3)	3.6265932346499548
  (942, 2)	3.1468770765333147
  (942, 1)	3.3285430952280533
  (942, 0)	3.9669986613497032
this is the 163 epoch
rmse loss on training set is 0.9240316507877074
rmse loss on test set is 0.9431344384161655
for this epoch using 75.05613708496094 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.256078098502326
  (0, 1680)	3.273625016982036
  (0, 1679)	3.2057151568418862
  (0, 1678)	3.25928307382995
  (0, 1677)	3.15214723985382
  (0, 1676)	3.263889868914366
  (0, 1675)	3.2626244411817935
  (0, 1674)	3.2626244411817935
  (0, 1673)	3.2626244411817935
  (0, 1672)	3.2302818122047063
  (0, 1671)	3.180140204022508
  (0, 1670)	3.2626244411817935
  (0, 1669)	3.2626244411817935
  (0, 1668)	3.2281783684114993
  (0, 1667)	3.2626244411817935
  (0, 1666)	3.2626244411817935
  (0, 1665)	3.2281783684114993
  (0, 1664)	3.2626244411817935
  (0, 1663)	3.206342764244179
  (0, 1662)	3.2281783684114993
  (0, 1661)	3.220388149574177
  (0, 1660)	3.1415381859872133
  (0, 1659)	3.1656802297886424
  (0, 1658)	3.2626244411817935
  (0, 1657)	3.2774939876674414
  :	:
  (942, 24)	3.5752877367633604
  (942, 23)	3.5669587159079748
  (942, 22)	4.255946373450565
  (942, 21)	4.288031881322924
  (942, 20)	2.841733297146363
  (942, 19)	3.682142128024896
  (942, 18)	4.011546147121031
  (942, 17)	3.2045242071016613
  (942, 16)	3.219959094399005
  (942, 15)	3.456021035200158
  (942, 14)	3.837071009052419
  (942, 13)	4.0994237104622115
  (942, 12)	3.4869789170812515
  (942, 11)	4.4692522641781345
  (942, 10)	3.96858383078138
  (942, 9)	3.90473358088157
  (942, 8)	4.0110309546609555
  (942, 7)	4.124831658502436
  (942, 6)	3.903364390296554
  (942, 5)	3.8265899922915305
  (942, 4)	3.399523751695516
  (942, 3)	3.626968606728219
  (942, 2)	3.14695125679012
  (942, 1)	3.3288188275880817
  (942, 0)	3.9671422866896173
this is the 164 epoch
rmse loss on training set is 0.9239659265034021
rmse loss on test set is 0.9430844903967964
for this epoch using 75.26920890808105 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2559116859707693
  (0, 1680)	3.2735691696335225
  (0, 1679)	3.2052405524765444
  (0, 1678)	3.25912344099646
  (0, 1677)	3.1513576639566216
  (0, 1676)	3.26377675100154
  (0, 1675)	3.262487621535957
  (0, 1674)	3.262487621535957
  (0, 1673)	3.262487621535957
  (0, 1672)	3.2299124960606322
  (0, 1671)	3.1795892712535907
  (0, 1670)	3.262487621535957
  (0, 1669)	3.262487621535957
  (0, 1668)	3.227853080452083
  (0, 1667)	3.262487621535957
  (0, 1666)	3.262487621535957
  (0, 1665)	3.227853080452083
  (0, 1664)	3.262487621535957
  (0, 1663)	3.205893619653289
  (0, 1662)	3.227853080452083
  (0, 1661)	3.220030657464185
  (0, 1660)	3.1407076192858154
  (0, 1659)	3.1649977207489255
  (0, 1658)	3.262487621535957
  (0, 1657)	3.2774788374884856
  :	:
  (942, 24)	3.5754293424262227
  (942, 23)	3.567044213849796
  (942, 22)	4.256491940404579
  (942, 21)	4.288443215891411
  (942, 20)	2.8416155308657047
  (942, 19)	3.6828296571384427
  (942, 18)	4.01257122203882
  (942, 17)	3.204359416828144
  (942, 16)	3.220077825208839
  (942, 15)	3.4567010171376693
  (942, 14)	3.8371108112091004
  (942, 13)	4.099718800155189
  (942, 12)	3.4872395929045945
  (942, 11)	4.4696615319148645
  (942, 10)	3.968900644569161
  (942, 9)	3.9053420811240973
  (942, 8)	4.011201990200728
  (942, 7)	4.125224076056287
  (942, 6)	3.903491646287051
  (942, 5)	3.828791914838026
  (942, 4)	3.399724961538752
  (942, 3)	3.6273373520176357
  (942, 2)	3.1470226867975843
  (942, 1)	3.3290889268118793
  (942, 0)	3.967281239292225
this is the 165 epoch
rmse loss on training set is 0.9239010202919954
rmse loss on test set is 0.9430352919121583
for this epoch using 74.85299682617188 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.255746840069262
  (0, 1680)	3.27351478614395
  (0, 1679)	3.20476749528779
  (0, 1678)	3.2589652566388243
  (0, 1677)	3.150569733936748
  (0, 1676)	3.263665141802703
  (0, 1675)	3.2623522549640227
  (0, 1674)	3.2623522549640227
  (0, 1673)	3.2623522549640227
  (0, 1672)	3.229544810018648
  (0, 1671)	3.179040301273044
  (0, 1670)	3.2623522549640227
  (0, 1669)	3.2623522549640227
  (0, 1668)	3.227529259677392
  (0, 1667)	3.2623522549640227
  (0, 1666)	3.2623522549640227
  (0, 1665)	3.227529259677392
  (0, 1664)	3.2623522549640227
  (0, 1663)	3.2054462007473705
  (0, 1662)	3.227529259677392
  (0, 1661)	3.219674885628088
  (0, 1660)	3.139878879237144
  (0, 1659)	3.1643170967959193
  (0, 1658)	3.2623522549640227
  (0, 1657)	3.2774651646787727
  :	:
  (942, 24)	3.5755666238729487
  (942, 23)	3.5671258759456252
  (942, 22)	4.257029016984932
  (942, 21)	4.288847137370539
  (942, 20)	2.8414996294403156
  (942, 19)	3.6835053600808183
  (942, 18)	4.013579362926839
  (942, 17)	3.2041921787680105
  (942, 16)	3.220193522901325
  (942, 15)	3.457372953202758
  (942, 14)	3.837147007352909
  (942, 13)	4.1000076043610045
  (942, 12)	3.4874949038685914
  (942, 11)	4.470063525655953
  (942, 10)	3.9692112490914195
  (942, 9)	3.9059385540274505
  (942, 8)	4.011368075757194
  (942, 7)	4.125609515770788
  (942, 6)	3.903614407484186
  (942, 5)	3.8309780809534515
  (942, 4)	3.399920951795221
  (942, 3)	3.6276995837540404
  (942, 2)	3.147091416009283
  (942, 1)	3.3293534934449194
  (942, 0)	3.9674156135613154
this is the 166 epoch
rmse loss on training set is 0.9238369181189027
rmse loss on test set is 0.9429868298952366
for this epoch using 75.27127027511597 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2555835386635374
  (0, 1680)	3.2734618450694923
  (0, 1679)	3.2042959638705804
  (0, 1678)	3.2588084994962445
  (0, 1677)	3.149783428244925
  (0, 1676)	3.2635550194196377
  (0, 1675)	3.2622183203384174
  (0, 1674)	3.2622183203384174
  (0, 1673)	3.2622183203384174
  (0, 1672)	3.2291787344172156
  (0, 1671)	3.1784932691602417
  (0, 1670)	3.2622183203384174
  (0, 1669)	3.2622183203384174
  (0, 1668)	3.2272068848915763
  (0, 1667)	3.2622183203384174
  (0, 1666)	3.2622183203384174
  (0, 1665)	3.2272068848915763
  (0, 1664)	3.2622183203384174
  (0, 1663)	3.2050004851339855
  (0, 1662)	3.2272068848915763
  (0, 1661)	3.2193208118606864
  (0, 1660)	3.1390519427279817
  (0, 1659)	3.163638334239292
  (0, 1658)	3.2622183203384174
  (0, 1657)	3.277452946164659
  :	:
  (942, 24)	3.5756996683002935
  (942, 23)	3.5672037885398695
  (942, 22)	4.257557745385279
  (942, 21)	4.289243772028481
  (942, 20)	2.841385540628649
  (942, 19)	3.684169433739569
  (942, 18)	4.014570857158235
  (942, 17)	3.204022564476982
  (942, 16)	3.220306242838222
  (942, 15)	3.4580369519397567
  (942, 14)	3.8371796805441836
  (942, 13)	4.1002902475594025
  (942, 12)	3.4877449475728013
  (942, 11)	4.470458369594476
  (942, 10)	3.9695157540489747
  (942, 9)	3.906523240658944
  (942, 8)	4.011529310733896
  (942, 7)	4.125988094569879
  (942, 6)	3.903732768672092
  (942, 5)	3.8331486377755284
  (942, 4)	3.4001118294297132
  (942, 3)	3.6280554132800344
  (942, 2)	3.147157493252556
  (942, 1)	3.3296126264044386
  (942, 0)	3.967545502241253
this is the 167 epoch
rmse loss on training set is 0.9237736062562621
rmse loss on test set is 0.9429390915639149
for this epoch using 75.11853098869324 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2554217600748507
  (0, 1680)	3.273410325415133
  (0, 1679)	3.2038259372659823
  (0, 1678)	3.2586531487525554
  (0, 1677)	3.1489987257794128
  (0, 1676)	3.263446362412675
  (0, 1675)	3.262085796974978
  (0, 1674)	3.262085796974978
  (0, 1673)	3.262085796974978
  (0, 1672)	3.2288142499706134
  (0, 1671)	3.1779481504885982
  (0, 1670)	3.262085796974978
  (0, 1669)	3.262085796974978
  (0, 1668)	3.2268859353489154
  (0, 1667)	3.262085796974978
  (0, 1666)	3.262085796974978
  (0, 1665)	3.2268859353489154
  (0, 1664)	3.262085796974978
  (0, 1663)	3.204556450878042
  (0, 1662)	3.2268859353489154
  (0, 1661)	3.2189684144078234
  (0, 1660)	3.138226787118076
  (0, 1659)	3.1629614098694625
  (0, 1658)	3.262085796974978
  (0, 1657)	3.2774421593572955
  :	:
  (942, 24)	3.5758285613210137
  (942, 23)	3.5672780361780894
  (942, 22)	4.2580782651222835
  (942, 21)	4.289633244092977
  (942, 20)	2.8412732137318226
  (942, 19)	3.684822071880006
  (942, 18)	4.01554598715552
  (942, 17)	3.203850644078793
  (942, 16)	3.2204160394945465
  (942, 15)	3.4586931203167857
  (942, 14)	3.8372089122669766
  (942, 13)	4.100566851632598
  (942, 12)	3.4879898199492394
  (942, 11)	4.470846185844928
  (942, 10)	3.9698142672866186
  (942, 9)	3.9070963771847875
  (942, 8)	4.011685792707249
  (942, 7)	4.12635992750505
  (942, 6)	3.9038468228877976
  (942, 5)	3.8353037307075275
  (942, 4)	3.400297699307631
  (942, 3)	3.6284049500752364
  (942, 2)	3.1472209667306403
  (942, 1)	3.3298664230006154
  (942, 0)	3.9676709964430414
this is the 168 epoch
rmse loss on training set is 0.9237110712746408
rmse loss on test set is 0.9428920644131734
for this epoch using 75.13479495048523 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2552614830667914
  (0, 1680)	3.2733602066215224
  (0, 1679)	3.203357394948163
  (0, 1678)	3.2584991840232984
  (0, 1677)	3.1482156058730237
  (0, 1676)	3.263339149787343
  (0, 1675)	3.2619546646198723
  (0, 1674)	3.2619546646198723
  (0, 1673)	3.2619546646198723
  (0, 1672)	3.228451337757881
  (0, 1671)	3.177404921311844
  (0, 1670)	3.2619546646198723
  (0, 1669)	3.2619546646198723
  (0, 1668)	3.2265663907404374
  (0, 1667)	3.2619546646198723
  (0, 1666)	3.2619546646198723
  (0, 1665)	3.2265663907404374
  (0, 1664)	3.2619546646198723
  (0, 1663)	3.204114076488669
  (0, 1662)	3.2265663907404374
  (0, 1661)	3.2186176719532766
  (0, 1660)	3.137403390226605
  (0, 1659)	3.1622863009437965
  (0, 1658)	3.2619546646198723
  (0, 1657)	3.2774327821386615
  :	:
  (942, 24)	3.5759533869916598
  (942, 23)	3.5673487016475898
  (942, 22)	4.258590713100069
  (942, 21)	4.29001567578078
  (942, 20)	2.8411625995509318
  (942, 19)	3.685463465191097
  (942, 18)	4.01650503047693
  (942, 17)	3.203676486291938
  (942, 16)	3.2205229664715787
  (942, 15)	3.4593415637491347
  (942, 14)	3.8372347824564956
  (942, 13)	4.100837535931044
  (942, 12)	3.4882296152883847
  (942, 11)	4.471227094477855
  (942, 10)	3.9701068948242644
  (942, 9)	3.907658194970459
  (942, 8)	4.011837617460158
  (942, 7)	4.126725127784338
  (942, 6)	3.903956661450447
  (942, 5)	3.837443503441064
  (942, 4)	3.4004786642361235
  (942, 3)	3.6287483017861386
  (942, 2)	3.1472818840250287
  (942, 1)	3.3301149789576048
  (942, 0)	3.9677921856701164
this is the 169 epoch
rmse loss on training set is 0.9236493000350475
rmse loss on test set is 0.9428457362075973
for this epoch using 75.13716101646423 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.255102686832616
  (0, 1680)	3.273311468552204
  (0, 1679)	3.2028903168118683
  (0, 1678)	3.2583465853431033
  (0, 1677)	3.1474340482806342
  (0, 1676)	3.2632333609813386
  (0, 1675)	3.2618249034370876
  (0, 1674)	3.2618249034370876
  (0, 1673)	3.2618249034370876
  (0, 1672)	3.2280899792121125
  (0, 1671)	3.1768635581506843
  (0, 1670)	3.2618249034370876
  (0, 1669)	3.2618249034370876
  (0, 1668)	3.226248231181133
  (0, 1667)	3.2618249034370876
  (0, 1666)	3.2618249034370876
  (0, 1665)	3.226248231181133
  (0, 1664)	3.2618249034370876
  (0, 1663)	3.2036733409065192
  (0, 1662)	3.226248231181133
  (0, 1661)	3.2182685636060753
  (0, 1660)	3.1365817303190773
  (0, 1659)	3.1616129851733437
  (0, 1658)	3.2618249034370876
  (0, 1657)	3.2774247928480547
  :	:
  (942, 24)	3.5760742278399875
  (942, 23)	3.56741586601697
  (942, 22)	4.259095223672443
  (942, 21)	4.290391187326831
  (942, 20)	2.8410536503453283
  (942, 19)	3.6860938013308195
  (942, 18)	4.017448259901174
  (942, 17)	3.203500158455918
  (942, 16)	3.2206270765096594
  (942, 15)	3.459982386122356
  (942, 14)	3.837257369526231
  (942, 13)	4.101102417337032
  (942, 12)	3.4884644262648092
  (942, 11)	4.471601213553874
  (942, 10)	3.970393740887435
  (942, 9)	3.908208920679112
  (942, 8)	4.011984879014798
  (942, 7)	4.1270838068008295
  (942, 6)	3.9040623739903686
  (942, 5)	3.8395680979785864
  (942, 4)	3.4006548250043394
  (942, 3)	3.629085574255497
  (942, 2)	3.1473402920980424
  (942, 1)	3.330358388434585
  (942, 0)	3.967909157843795
this is the 170 epoch
rmse loss on training set is 0.9235882796812294
rmse loss on test set is 0.9428000949740677
for this epoch using 75.21696519851685 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.254945350983001
  (0, 1680)	3.2732640914814475
  (0, 1679)	3.2024246831604386
  (0, 1678)	3.2581953331537465
  (0, 1677)	3.146654033167138
  (0, 1676)	3.2631289758521036
  (0, 1675)	3.261696493996318
  (0, 1674)	3.261696493996318
  (0, 1673)	3.261696493996318
  (0, 1672)	3.227730156110285
  (0, 1671)	3.176324037980077
  (0, 1670)	3.261696493996318
  (0, 1669)	3.261696493996318
  (0, 1668)	3.225931437197581
  (0, 1667)	3.261696493996318
  (0, 1666)	3.261696493996318
  (0, 1665)	3.225931437197581
  (0, 1664)	3.261696493996318
  (0, 1663)	3.2032342234915583
  (0, 1662)	3.225931437197581
  (0, 1661)	3.2179210688883635
  (0, 1660)	3.1357617860948044
  (0, 1659)	3.1609414407100194
  (0, 1658)	3.261696493996318
  (0, 1657)	3.277418170269099
  :	:
  (942, 24)	3.5761911648917395
  (942, 23)	3.5674796086745193
  (942, 22)	4.259591928703005
  (942, 21)	4.290759897013147
  (942, 20)	2.8409463197921405
  (942, 19)	3.686713264970833
  (942, 18)	4.018375943510661
  (942, 17)	3.2033217265570406
  (942, 16)	3.220728421500879
  (942, 15)	3.460615689815016
  (942, 14)	3.837276750394697
  (942, 13)	4.10136161032608
  (942, 12)	3.4886943439625946
  (942, 11)	4.4719686591571275
  (942, 10)	3.9706749079372594
  (942, 9)	3.9087487763679536
  (942, 8)	4.012127669664749
  (942, 7)	4.127436074160644
  (942, 6)	3.904164048477571
  (942, 5)	3.8416776546555274
  (942, 4)	3.4008262804229146
  (942, 3)	3.6294168715513835
  (942, 2)	3.14739623729557
  (942, 1)	3.330596744046715
  (942, 0)	3.9680219993283696
this is the 171 epoch
rmse loss on training set is 0.9235279976321548
rmse loss on test set is 0.942755128994742
for this epoch using 75.19606804847717 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2547894555343477
  (0, 1680)	3.2732180560824653
  (0, 1679)	3.2019604746941948
  (0, 1678)	3.2580454082925088
  (0, 1677)	3.14587554109589
  (0, 1676)	3.263025974664851
  (0, 1675)	3.2615694172613736
  (0, 1674)	3.2615694172613736
  (0, 1673)	3.2615694172613736
  (0, 1672)	3.2273718505633857
  (0, 1671)	3.17578633821689
  (0, 1670)	3.2615694172613736
  (0, 1669)	3.2615694172613736
  (0, 1668)	3.2256159897161125
  (0, 1667)	3.2615694172613736
  (0, 1666)	3.2615694172613736
  (0, 1665)	3.2256159897161125
  (0, 1664)	3.2615694172613736
  (0, 1663)	3.2027967040113725
  (0, 1662)	3.2256159897161125
  (0, 1661)	3.2175751677236573
  (0, 1660)	3.134943536674777
  (0, 1659)	3.1602716461343783
  (0, 1658)	3.2615694172613736
  (0, 1657)	3.2774128936172553
  :	:
  (942, 24)	3.5763042776971274
  (942, 23)	3.5675400073656323
  (942, 22)	4.260080957623335
  (942, 21)	4.291121921197425
  (942, 20)	2.8408405629466653
  (942, 19)	3.6873220378407514
  (942, 18)	4.019288344773365
  (942, 17)	3.2031412552536715
  (942, 16)	3.2208270525015017
  (942, 15)	3.461241575721076
  (942, 14)	3.837293000511548
  (942, 13)	4.101615227026322
  (942, 12)	3.4889194579003298
  (942, 11)	4.472329545428059
  (942, 10)	3.970950496699866
  (942, 9)	3.909277979582671
  (942, 8)	4.012266080006511
  (942, 7)	4.127782037710386
  (942, 6)	3.9042617712498937
  (942, 5)	3.8437723121622196
  (942, 4)	3.4009931273627267
  (942, 3)	3.6297422959957912
  (942, 2)	3.147449765350123
  (942, 1)	3.330830136885993
  (942, 0)	3.9681307949559974
this is the 172 epoch
rmse loss on training set is 0.9234684415747813
rmse loss on test set is 0.9427108268002272
for this epoch using 75.95985722541809 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2546349808974258
  (0, 1680)	3.273173343416075
  (0, 1679)	3.2014976724992876
  (0, 1678)	3.2578967919810142
  (0, 1677)	3.145098553017565
  (0, 1676)	3.262924338080975
  (0, 1675)	3.2614436545789953
  (0, 1674)	3.2614436545789953
  (0, 1673)	3.2614436545789953
  (0, 1672)	3.227015045006991
  (0, 1671)	3.175250436708012
  (0, 1670)	3.2614436545789953
  (0, 1669)	3.2614436545789953
  (0, 1668)	3.2253018700513443
  (0, 1667)	3.2614436545789953
  (0, 1666)	3.2614436545789953
  (0, 1665)	3.2253018700513443
  (0, 1664)	3.2614436545789953
  (0, 1663)	3.2023607626297914
  (0, 1662)	3.2253018700513443
  (0, 1661)	3.2172308404255774
  (0, 1660)	3.1341269615899674
  (0, 1659)	3.1596035804436924
  (0, 1658)	3.2614436545789953
  (0, 1657)	3.2774089425277433
  :	:
  (942, 24)	3.576413644356679
  (942, 23)	3.567597138229211
  (942, 22)	4.260562437489107
  (942, 21)	4.291477374341318
  (942, 20)	2.840736336203919
  (942, 19)	3.6879202987716737
  (942, 18)	4.020185722623169
  (942, 17)	3.2029588079010467
  (942, 16)	3.220923019744275
  (942, 15)	3.461860143272005
  (942, 14)	3.8373061938834327
  (942, 13)	4.10186337727594
  (942, 12)	3.4891398560559064
  (942, 11)	4.472683984595751
  (942, 10)	3.971220606195214
  (942, 9)	3.9097967434499337
  (942, 8)	4.012400198970421
  (942, 7)	4.128121803564229
  (942, 6)	3.90435562704079
  (942, 5)	3.8458522075655273
  (942, 4)	3.401155460792799
  (942, 3)	3.6300619481928025
  (942, 2)	3.147500921383901
  (942, 1)	3.331058656542046
  (942, 0)	3.968235628051181
this is the 173 epoch
rmse loss on training set is 0.9234095994570141
rmse loss on test set is 0.9426671771630244
for this epoch using 75.90395307540894 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.254481907866441
  (0, 1680)	3.273129934919811
  (0, 1679)	3.2010362580369383
  (0, 1678)	3.257749465814525
  (0, 1677)	3.144323050259356
  (0, 1676)	3.2628240471469794
  (0, 1675)	3.2613191876680543
  (0, 1674)	3.2613191876680543
  (0, 1673)	3.2613191876680543
  (0, 1672)	3.2266597221921876
  (0, 1671)	3.1747163117189268
  (0, 1670)	3.2613191876680543
  (0, 1669)	3.2613191876680543
  (0, 1668)	3.224989059895191
  (0, 1667)	3.2613191876680543
  (0, 1666)	3.2613191876680543
  (0, 1665)	3.224989059895191
  (0, 1664)	3.2613191876680543
  (0, 1663)	3.201926379896047
  (0, 1662)	3.224989059895191
  (0, 1661)	3.2168880676869684
  (0, 1660)	3.1333120407701216
  (0, 1659)	3.158937223040526
  (0, 1658)	3.2613191876680543
  (0, 1657)	3.277406297043901
  :	:
  (942, 24)	3.5765193415467738
  (942, 23)	3.567651075833122
  (942, 22)	4.261036493034555
  (942, 21)	4.291826369038418
  (942, 20)	2.8406335972611423
  (942, 19)	3.6885082237392344
  (942, 18)	4.021068331538813
  (942, 17)	3.2027744465756407
  (942, 16)	3.2210163726505248
  (942, 15)	3.4624714904584857
  (942, 14)	3.8373164030993885
  (942, 13)	4.102106168678727
  (942, 12)	3.4893556248909214
  (942, 11)	4.473032087009572
  (942, 10)	3.9714853337655063
  (942, 9)	3.910305276768006
  (942, 8)	4.0125301138508584
  (942, 7)	4.128455476130459
  (942, 6)	3.9044456990066743
  (942, 5)	3.847917476330155
  (942, 4)	3.4013133738175556
  (942, 3)	3.630375927056462
  (942, 2)	3.1475497499122107
  (942, 1)	3.3312823911228358
  (942, 0)	3.9683365804549235
this is the 174 epoch
rmse loss on training set is 0.923351459480935
rmse loss on test set is 0.9426241690911193
for this epoch using 75.06614875793457 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2543302176085693
  (0, 1680)	3.273087812397413
  (0, 1679)	3.2005762131331235
  (0, 1678)	3.257603411751548
  (0, 1677)	3.1435490145147034
  (0, 1676)	3.262725083283742
  (0, 1675)	3.2611959986091845
  (0, 1674)	3.2611959986091845
  (0, 1673)	3.2611959986091845
  (0, 1672)	3.2263058651768923
  (0, 1671)	3.1741839419226365
  (0, 1670)	3.2611959986091845
  (0, 1669)	3.2611959986091845
  (0, 1668)	3.2246775413062863
  (0, 1667)	3.2611959986091845
  (0, 1666)	3.2611959986091845
  (0, 1665)	3.2246775413062863
  (0, 1664)	3.2611959986091845
  (0, 1663)	3.201493536734239
  (0, 1662)	3.2246775413062863
  (0, 1661)	3.2165468305694884
  (0, 1660)	3.1324987545329033
  (0, 1659)	3.1582725537217855
  (0, 1658)	3.2611959986091845
  (0, 1657)	3.2774049376060503
  :	:
  (942, 24)	3.576621444544631
  (942, 23)	3.5677018932086364
  (942, 22)	4.2615032467250495
  (942, 21)	4.29216901604197
  (942, 20)	2.840532305081241
  (942, 19)	3.6890859859061584
  (942, 18)	4.021936421621476
  (942, 17)	3.2025882320990307
  (942, 16)	3.2211071598420964
  (942, 15)	3.4630757138519157
  (942, 14)	3.8373236993557436
  (942, 13)	4.102343706657813
  (942, 12)	3.4895668493748038
  (942, 11)	4.473373961170295
  (942, 10)	3.9717447751030046
  (942, 9)	3.910803784095501
  (942, 8)	4.0126559103359885
  (942, 7)	4.128783158137649
  (942, 6)	3.9045320687538476
  (942, 5)	3.8499682523396976
  (942, 4)	3.4014669577133043
  (942, 3)	3.6306843298380858
  (942, 2)	3.147596294846894
  (942, 1)	3.3315014272751906
  (942, 0)	3.968433732548647
this is the 175 epoch
rmse loss on training set is 0.9232940100962325
rmse loss on test set is 0.9425817918218462
for this epoch using 74.94474816322327 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2541798916537914
  (0, 1680)	3.2730469580087185
  (0, 1679)	3.200117519968582
  (0, 1678)	3.2574586121038913
  (0, 1677)	3.142776427833277
  (0, 1676)	3.2626274282761867
  (0, 1675)	3.2610740698348035
  (0, 1674)	3.2610740698348035
  (0, 1673)	3.2610740698348035
  (0, 1672)	3.2259534573174053
  (0, 1671)	3.1736533063890344
  (0, 1670)	3.2610740698348035
  (0, 1669)	3.2610740698348035
  (0, 1668)	3.2243672966997208
  (0, 1667)	3.2610740698348035
  (0, 1666)	3.2610740698348035
  (0, 1665)	3.2243672966997208
  (0, 1664)	3.2610740698348035
  (0, 1663)	3.2010622144332213
  (0, 1662)	3.2243672966997208
  (0, 1661)	3.2162071104934564
  (0, 1660)	3.1316870835734147
  (0, 1659)	3.1576095526680223
  (0, 1658)	3.2610740698348035
  (0, 1657)	3.2774048450406217
  :	:
  (942, 24)	3.5767200272529496
  (942, 23)	3.5677496618841107
  (942, 22)	4.26196281880808
  (942, 21)	4.292505424292267
  (942, 20)	2.8404324198572755
  (942, 19)	3.689653755664119
  (942, 18)	4.022790238670961
  (942, 17)	3.2024002240613765
  (942, 16)	3.221195429153141
  (942, 15)	3.463672908625481
  (942, 14)	3.837328152480747
  (942, 13)	4.102576094507749
  (942, 12)	3.489773613008664
  (942, 11)	4.473709713760805
  (942, 10)	3.9719990242773795
  (942, 9)	3.9112924658384163
  (942, 8)	4.01277767253681
  (942, 7)	4.129104950660341
  (942, 6)	3.9046148163651093
  (942, 5)	3.8520046679174205
  (942, 4)	3.4016163019639407
  (942, 3)	3.63098725215336
  (942, 2)	3.147640599500034
  (942, 1)	3.331715850205314
  (942, 0)	3.9685271632777357
this is the 176 epoch
rmse loss on training set is 0.9232372399937213
rmse loss on test set is 0.9425400348158899
for this epoch using 75.11615204811096 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.254030911885125
  (0, 1680)	3.2730073542598888
  (0, 1679)	3.199660161069184
  (0, 1678)	3.257315049527005
  (0, 1677)	3.1420052726113545
  (0, 1676)	3.2625310642633143
  (0, 1675)	3.260953384119469
  (0, 1674)	3.260953384119469
  (0, 1673)	3.260953384119469
  (0, 1672)	3.225602482260424
  (0, 1671)	3.173124384574583
  (0, 1670)	3.260953384119469
  (0, 1669)	3.260953384119469
  (0, 1668)	3.2240583088372516
  (0, 1667)	3.260953384119469
  (0, 1666)	3.260953384119469
  (0, 1665)	3.2240583088372516
  (0, 1664)	3.260953384119469
  (0, 1663)	3.2006323946368616
  (0, 1662)	3.2240583088372516
  (0, 1661)	3.2158688892281813
  (0, 1660)	3.1308770089541347
  (0, 1659)	3.156948200433256
  (0, 1658)	3.260953384119469
  (0, 1657)	3.277406000549748
  :	:
  (942, 24)	3.5768151622239617
  (942, 23)	3.567794451917618
  (942, 22)	4.262415327362535
  (942, 21)	4.292835700943682
  (942, 20)	2.8403339029777337
  (942, 19)	3.6902117006751882
  (942, 18)	4.023630024260561
  (942, 17)	3.202210480844385
  (942, 16)	3.221281227641672
  (942, 15)	3.4642631685749707
  (942, 14)	3.837329830958637
  (942, 13)	4.102803433444844
  (942, 12)	3.4899759978487706
  (942, 11)	4.474039449676065
  (942, 10)	3.972248173762577
  (942, 9)	3.911771518335212
  (942, 8)	4.012895483015716
  (942, 7)	4.129420953144368
  (942, 6)	3.9046940204259033
  (942, 5)	3.854026853846766
  (942, 4)	3.4017614942960734
  (942, 3)	3.631284788008887
  (942, 2)	3.147682706587716
  (942, 1)	3.3319257436990646
  (942, 0)	3.9686169501747846
this is the 177 epoch
rmse loss on training set is 0.923181138099278
rmse loss on test set is 0.9424988877515108
for this epoch using 75.01705598831177 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.253883260529183
  (0, 1680)	3.2729689839940006
  (0, 1679)	3.1992041192966396
  (0, 1678)	3.2571727070107412
  (0, 1677)	3.141235531582542
  (0, 1676)	3.2624359737286324
  (0, 1675)	3.260833924570527
  (0, 1674)	3.260833924570527
  (0, 1673)	3.260833924570527
  (0, 1672)	3.225252923935178
  (0, 1671)	3.172597156312394
  (0, 1670)	3.260833924570527
  (0, 1669)	3.260833924570527
  (0, 1668)	3.2237505608177566
  (0, 1667)	3.260833924570527
  (0, 1666)	3.260833924570527
  (0, 1665)	3.2237505608177566
  (0, 1664)	3.260833924570527
  (0, 1663)	3.2002040593345593
  (0, 1662)	3.2237505608177566
  (0, 1661)	3.215532148882556
  (0, 1660)	3.130068512095124
  (0, 1659)	3.15628847793501
  (0, 1658)	3.260833924570527
  (0, 1657)	3.2774083857011806
  :	:
  (942, 24)	3.5769069206832644
  (942, 23)	3.5678363319289024
  (942, 22)	4.262860888346602
  (942, 21)	4.293159951391528
  (942, 20)	2.840236716992887
  (942, 19)	3.690759985912678
  (942, 18)	4.0244560158106015
  (942, 17)	3.202019059643907
  (942, 16)	3.2213646016010444
  (942, 15)	3.4648465861393025
  (942, 14)	3.8373288019534493
  (942, 13)	4.103025822656021
  (942, 12)	3.490174084529763
  (942, 11)	4.47436327205282
  (942, 10)	3.97249231446324
  (942, 9)	3.91224113394031
  (942, 8)	4.013009422814485
  (942, 7)	4.129731263431811
  (942, 6)	3.904769758050114
  (942, 5)	3.856034939391556
  (942, 4)	3.401902620713337
  (942, 3)	3.6315770298284424
  (942, 2)	3.1477226582339775
  (942, 1)	3.332131190142174
  (942, 0)	3.968703169382516
this is the 178 epoch
rmse loss on training set is 0.9231256935677805
rmse loss on test set is 0.9424583405189703
for this epoch using 75.01130104064941 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2537369201471056
  (0, 1680)	3.2729318303819976
  (0, 1679)	3.198749377839621
  (0, 1678)	3.257031567870406
  (0, 1677)	3.140467187808843
  (0, 1676)	3.262342139490861
  (0, 1675)	3.2607156746192456
  (0, 1674)	3.2607156746192456
  (0, 1673)	3.2607156746192456
  (0, 1672)	3.2249047665460715
  (0, 1671)	3.172071601802619
  (0, 1670)	3.2607156746192456
  (0, 1669)	3.2607156746192456
  (0, 1668)	3.223444036068157
  (0, 1667)	3.2607156746192456
  (0, 1666)	3.2607156746192456
  (0, 1665)	3.223444036068157
  (0, 1664)	3.2607156746192456
  (0, 1663)	3.199777190852226
  (0, 1662)	3.223444036068157
  (0, 1661)	3.215196871896049
  (0, 1660)	3.1292615747647194
  (0, 1659)	3.155630366444877
  (0, 1658)	3.2607156746192456
  (0, 1657)	3.277411982418638
  :	:
  (942, 24)	3.5769953725530947
  (942, 23)	3.5678753691304137
  (942, 22)	4.263299615644039
  (942, 21)	4.293478279298491
  (942, 20)	2.840140825581868
  (942, 19)	3.691298773701418
  (942, 18)	4.025268446660692
  (942, 17)	3.201826016492128
  (942, 16)	3.2214455965711886
  (942, 15)	3.465423252420718
  (942, 14)	3.8373251313323644
  (942, 13)	4.103243359346104
  (942, 12)	3.4903679522875666
  (942, 11)	4.474681282298557
  (942, 10)	3.9727315357406687
  (942, 9)	3.91270150110587
  (942, 8)	4.013119571481689
  (942, 7)	4.130035977785446
  (942, 6)	3.9048421049054305
  (942, 5)	3.85802905231603
  (942, 4)	3.4020397655301133
  (942, 3)	3.6318640684788233
  (942, 2)	3.1477604959749157
  (942, 1)	3.3323322705403076
  (942, 0)	3.968785895676459
this is the 179 epoch
rmse loss on training set is 0.923070895777318
rmse loss on test set is 0.9424183832150603
for this epoch using 75.08002996444702 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.253591873625728
  (0, 1680)	3.2728958769139114
  (0, 1679)	3.1982959202050343
  (0, 1678)	3.256891615738083
  (0, 1677)	3.1397002246719814
  (0, 1676)	3.262249544695028
  (0, 1675)	3.2605986180120676
  (0, 1674)	3.2605986180120676
  (0, 1673)	3.2605986180120676
  (0, 1672)	3.224557994565419
  (0, 1671)	3.1715477016031963
  (0, 1670)	3.2605986180120676
  (0, 1669)	3.2605986180120676
  (0, 1668)	3.2231387183345115
  (0, 1667)	3.2605986180120676
  (0, 1666)	3.2605986180120676
  (0, 1665)	3.2231387183345115
  (0, 1664)	3.2605986180120676
  (0, 1663)	3.1993517718434674
  (0, 1662)	3.2231387183345115
  (0, 1661)	3.2148630410299344
  (0, 1660)	3.1284561790703536
  (0, 1659)	3.1549738475791886
  (0, 1658)	3.2605986180120676
  (0, 1657)	3.2774167729723365
  :	:
  (942, 24)	3.5770805864752355
  (942, 23)	3.5679116293575732
  (942, 22)	4.2637316211090965
  (942, 21)	4.293790786620823
  (942, 20)	2.8400461935207475
  (942, 19)	3.6918282237575935
  (942, 18)	4.026067546140739
  (942, 17)	3.2016314062792772
  (942, 16)	3.221524257349799
  (942, 15)	3.465993257204697
  (942, 14)	3.8373188836886802
  (942, 13)	4.1034561387836455
  (942, 12)	3.4905576789819857
  (942, 11)	4.474993580120163
  (942, 10)	3.972965925438278
  (942, 9)	3.913152804461779
  (942, 8)	4.013226007099653
  (942, 7)	4.13033519091295
  (942, 6)	3.9049111352384136
  (942, 5)	3.8600093189044684
  (942, 4)	3.402173011404554
  (942, 3)	3.6321459932952656
  (942, 2)	3.1477962607627976
  (942, 1)	3.332529064538975
  (942, 0)	3.968865202487164
this is the 180 epoch
rmse loss on training set is 0.9230167343235182
rmse loss on test set is 0.9423790061378869
for this epoch using 76.06727623939514 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.253448104169145
  (0, 1680)	3.2728611073904474
  (0, 1679)	3.197843730209728
  (0, 1678)	3.2567528345543604
  (0, 1677)	3.1389346258651027
  (0, 1676)	3.2621581728038027
  (0, 1675)	3.260482738802352
  (0, 1674)	3.260482738802352
  (0, 1673)	3.260482738802352
  (0, 1672)	3.224212592726537
  (0, 1671)	3.1710254366208734
  (0, 1670)	3.260482738802352
  (0, 1669)	3.260482738802352
  (0, 1668)	3.222834591673564
  (0, 1667)	3.260482738802352
  (0, 1666)	3.260482738802352
  (0, 1665)	3.222834591673564
  (0, 1664)	3.260482738802352
  (0, 1663)	3.1989277852811417
  (0, 1662)	3.222834591673564
  (0, 1661)	3.214530639358902
  (0, 1660)	3.127652307449846
  (0, 1659)	3.154318903290215
  (0, 1658)	3.260482738802352
  (0, 1657)	3.2774227399700195
  :	:
  (942, 24)	3.577162629833524
  (942, 23)	3.5679451770982857
  (942, 22)	4.264157014610175
  (942, 21)	4.29409757363421
  (942, 20)	2.8399527866513528
  (942, 19)	3.692348493227992
  (942, 18)	4.0268535396406495
  (942, 17)	3.201435282774989
  (942, 16)	3.221600628003209
  (942, 15)	3.4665566889795767
  (942, 14)	3.8373101223644137
  (942, 13)	4.10366425434543
  (942, 12)	3.4907433411189626
  (942, 11)	4.4753002635520485
  (942, 10)	3.9731955699067387
  (942, 9)	3.9135952248941623
  (942, 8)	4.013328806310868
  (942, 7)	4.13062899599068
  (942, 6)	3.9049769218991046
  (942, 5)	3.861975863980694
  (942, 4)	3.402302439370943
  (942, 3)	3.6324228921065447
  (942, 2)	3.147829992970432
  (942, 1)	3.3327216504432506
  (942, 0)	3.968941161922324
this is the 181 epoch
rmse loss on training set is 0.9229631990141538
rmse loss on test set is 0.9423401997817552
for this epoch using 76.22840404510498 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.253305595290488
  (0, 1680)	3.272827505914799
  (0, 1679)	3.1973927919724625
  (0, 1678)	3.256615208560241
  (0, 1677)	3.1381703753846852
  (0, 1676)	3.2620680075892072
  (0, 1675)	3.2603680213422477
  (0, 1674)	3.2603680213422477
  (0, 1673)	3.2603680213422477
  (0, 1672)	3.2238685460170546
  (0, 1671)	3.1705047881025394
  (0, 1670)	3.2603680213422477
  (0, 1669)	3.2603680213422477
  (0, 1668)	3.222531640444481
  (0, 1667)	3.2603680213422477
  (0, 1666)	3.2603680213422477
  (0, 1665)	3.222531640444481
  (0, 1664)	3.2603680213422477
  (0, 1663)	3.1985052144491526
  (0, 1662)	3.222531640444481
  (0, 1661)	3.2141996502629264
  (0, 1660)	3.126849942662907
  (0, 1659)	3.1536655158575195
  (0, 1658)	3.2603680213422477
  (0, 1657)	3.2774298663481076
  :	:
  (942, 24)	3.57724156877594
  (942, 23)	3.5679760755217
  (942, 22)	4.264575904072008
  (942, 21)	4.294398738959295
  (942, 20)	2.83986057185095
  (942, 19)	3.692859736728725
  (942, 18)	4.027626648678845
  (942, 17)	3.201237698649234
  (942, 16)	3.22167475187729
  (942, 15)	3.4671136349558647
  (942, 14)	3.8372989094725365
  (942, 13)	4.103867797559533
  (942, 12)	3.4909250138726273
  (942, 11)	4.475601428983718
  (942, 10)	3.973420554028534
  (942, 9)	3.9140289396221593
  (942, 8)	4.013428044343905
  (942, 7)	4.130917484687034
  (942, 6)	3.90503953636525
  (942, 5)	3.8639288109272303
  (942, 4)	3.402428128871443
  (942, 3)	3.632694851259655
  (942, 2)	3.1478617323955476
  (942, 1)	3.3329101052374193
  (942, 0)	3.9690138447883783
this is the 182 epoch
rmse loss on training set is 0.9229102798637427
rmse loss on test set is 0.9423019548322529
for this epoch using 77.03075003623962 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2531643308040055
  (0, 1680)	3.2727950568847812
  (0, 1679)	3.1969430899060636
  (0, 1678)	3.2564787222893736
  (0, 1677)	3.1374074575227615
  (0, 1676)	3.2619790331245238
  (0, 1675)	3.2602544502749424
  (0, 1674)	3.2602544502749424
  (0, 1673)	3.2602544502749424
  (0, 1672)	3.2235258396724924
  (0, 1671)	3.1699857376268414
  (0, 1670)	3.2602544502749424
  (0, 1669)	3.2602544502749424
  (0, 1668)	3.2222298493009167
  (0, 1667)	3.2602544502749424
  (0, 1666)	3.2602544502749424
  (0, 1665)	3.2222298493009167
  (0, 1664)	3.2602544502749424
  (0, 1663)	3.198084042934555
  (0, 1662)	3.2222298493009167
  (0, 1661)	3.2138700574193995
  (0, 1660)	3.12604906778297
  (0, 1659)	3.153013667879678
  (0, 1658)	3.2602544502749424
  (0, 1657)	3.2774381353633184
  :	:
  (942, 24)	3.5773174682363456
  (942, 23)	3.56800438650628
  (942, 22)	4.264988395516772
  (942, 21)	4.29469437958703
  (942, 20)	2.839769517002753
  (942, 19)	3.6933621063834683
  (942, 18)	4.028387090969615
  (942, 17)	3.201038705492909
  (942, 16)	3.2217466716080234
  (942, 15)	3.4676641810852895
  (942, 14)	3.8372853059188294
  (942, 13)	4.1040668581471875
  (942, 12)	3.4911027711069513
  (942, 11)	4.475897171186999
  (942, 10)	3.9736409612422636
  (942, 9)	3.9144541222731855
  (942, 8)	4.013523795038827
  (942, 7)	4.131200747185575
  (942, 6)	3.905099048766231
  (942, 5)	3.865868281704253
  (942, 4)	3.4025501577872084
  (942, 3)	3.6329619556441712
  (942, 2)	3.1478915182653107
  (942, 1)	3.333094504604367
  (942, 0)	3.9690833206119227
this is the 183 epoch
rmse loss on training set is 0.9228579670885237
rmse loss on test set is 0.9422642621614487
for this epoch using 76.52906608581543 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.253024294817464
  (0, 1680)	3.272763744985258
  (0, 1679)	3.1964946087099895
  (0, 1678)	3.2563433605605745
  (0, 1677)	3.136645856859421
  (0, 1676)	3.2618912337765797
  (0, 1675)	3.2601420105271557
  (0, 1674)	3.2601420105271557
  (0, 1673)	3.2601420105271557
  (0, 1672)	3.223184459170053
  (0, 1671)	3.169468267096114
  (0, 1670)	3.2601420105271557
  (0, 1669)	3.2601420105271557
  (0, 1668)	3.2219292031833753
  (0, 1667)	3.2601420105271557
  (0, 1666)	3.2601420105271557
  (0, 1665)	3.2219292031833753
  (0, 1664)	3.2601420105271557
  (0, 1663)	3.197664254619916
  (0, 1662)	3.2219292031833753
  (0, 1661)	3.21354184479557
  (0, 1660)	3.125249666189239
  (0, 1659)	3.1523633422662236
  (0, 1658)	3.2601420105271557
  (0, 1657)	3.2774475305844386
  :	:
  (942, 24)	3.57739039195581
  (942, 23)	3.568030170667142
  (942, 22)	4.265394593103917
  (942, 21)	4.294984590903541
  (942, 20)	2.8396795909671586
  (942, 19)	3.6938557518611685
  (942, 18)	4.029135080489183
  (942, 17)	3.200838353837998
  (942, 16)	3.2218164291321005
  (942, 15)	3.4682084120795826
  (942, 14)	3.837269371423363
  (942, 13)	4.104261524063378
  (942, 12)	3.491276685397127
  (942, 11)	4.476187583342785
  (942, 10)	3.97385687356646
  (942, 9)	3.9148709429566826
  (942, 8)	4.013616130872145
  (942, 7)	4.131478872207755
  (942, 6)	3.905155527906557
  (942, 5)	3.867794396868262
  (942, 4)	3.4026686024688773
  (942, 3)	3.6332242887161743
  (942, 2)	3.147919389240905
  (942, 1)	3.3332749229448604
  (942, 0)	3.96914965766086
this is the 184 epoch
rmse loss on training set is 0.9228062511013589
rmse loss on test set is 0.9422271128232733
for this epoch using 76.59960913658142 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.252885471724693
  (0, 1680)	3.2727335551807455
  (0, 1679)	3.1960473333630266
  (0, 1678)	3.2562091084705482
  (0, 1677)	3.1358855582555036
  (0, 1676)	3.2618045941981824
  (0, 1675)	3.2600306873018496
  (0, 1674)	3.2600306873018496
  (0, 1673)	3.2600306873018496
  (0, 1672)	3.222844390222623
  (0, 1671)	3.1689523587284785
  (0, 1670)	3.2600306873018496
  (0, 1669)	3.2600306873018496
  (0, 1668)	3.2216296873117733
  (0, 1667)	3.2600306873018496
  (0, 1666)	3.2600306873018496
  (0, 1665)	3.2216296873117733
  (0, 1664)	3.2600306873018496
  (0, 1663)	3.1972458336759546
  (0, 1662)	3.2216296873117733
  (0, 1661)	3.213214996641194
  (0, 1660)	3.1244517215590784
  (0, 1659)	3.151714522229911
  (0, 1658)	3.2600306873018496
  (0, 1657)	3.2774580358844565
  :	:
  (942, 24)	3.577460402503617
  (942, 23)	3.5680534873827607
  (942, 22)	4.265794599168866
  (942, 21)	4.295269466714815
  (942, 20)	2.8395907635537947
  (942, 19)	3.694340820413261
  (942, 18)	4.029870827540733
  (942, 17)	3.2006366931773678
  (942, 16)	3.2218840656971963
  (942, 15)	3.468746411428953
  (942, 14)	3.8372511645416383
  (942, 13)	4.104451881536248
  (942, 12)	3.49144682805071
  (942, 11)	4.476472757067255
  (942, 10)	3.9740683716229728
  (942, 9)	3.915279568336244
  (942, 8)	4.013705122981341
  (942, 7)	4.131751947035295
  (942, 6)	3.9052090412890137
  (942, 5)	3.869707275590545
  (942, 4)	3.402783537766492
  (942, 3)	3.6334819325218635
  (942, 2)	3.1479453834222455
  (942, 1)	3.3334514333966268
  (942, 0)	3.969212922965083
this is the 185 epoch
rmse loss on training set is 0.9227551225069639
rmse loss on test set is 0.9421904980489955
for this epoch using 75.85668611526489 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.252747846198474
  (0, 1680)	3.272704472708361
  (0, 1679)	3.1956012491162578
  (0, 1678)	3.2560759513868835
  (0, 1677)	3.135126546845624
  (0, 1676)	3.261719099320915
  (0, 1675)	3.259920466071226
  (0, 1674)	3.259920466071226
  (0, 1673)	3.259920466071226
  (0, 1672)	3.222505618772999
  (0, 1671)	3.168437995050317
  (0, 1670)	3.259920466071226
  (0, 1669)	3.259920466071226
  (0, 1668)	3.2213312871783213
  (0, 1667)	3.259920466071226
  (0, 1666)	3.259920466071226
  (0, 1665)	3.2213312871783213
  (0, 1664)	3.259920466071226
  (0, 1663)	3.196828764554344
  (0, 1662)	3.2213312871783213
  (0, 1661)	3.212889497481441
  (0, 1660)	3.1236552178605614
  (0, 1659)	3.151067191279222
  (0, 1658)	3.259920466071226
  (0, 1657)	3.27746963543285
  :	:
  (942, 24)	3.577527561297805
  (942, 23)	3.5680743948209397
  (942, 22)	4.26618851426062
  (942, 21)	4.295549099271033
  (942, 20)	2.839503005494285
  (942, 19)	3.6948174569103434
  (942, 18)	4.030594538818205
  (942, 17)	3.2004337719842404
  (942, 16)	3.221949621872293
  (942, 15)	3.469278261420278
  (942, 14)	3.837230742685428
  (942, 13)	4.104638015105384
  (942, 12)	3.4916132691283748
  (942, 11)	4.476752782437795
  (942, 10)	3.9742755346600336
  (942, 9)	3.915680161700412
  (942, 8)	4.013790841188851
  (942, 7)	4.1320200575322135
  (942, 6)	3.9052596551373986
  (942, 5)	3.87160703567533
  (942, 4)	3.402895037058789
  (942, 3)	3.6337349677207906
  (942, 2)	3.1479695383527244
  (942, 1)	3.333624107853294
  (942, 0)	3.9692731823370857
this is the 186 epoch
rmse loss on training set is 0.9227045720971545
rmse loss on test set is 0.9421544092428896
for this epoch using 75.95974087715149 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.252611403183604
  (0, 1680)	3.272676483070926
  (0, 1679)	3.1951563414862982
  (0, 1678)	3.255943874941274
  (0, 1677)	3.1343688080313226
  (0, 1676)	3.261634734348062
  (0, 1675)	3.259811332569962
  (0, 1674)	3.259811332569962
  (0, 1673)	3.259811332569962
  (0, 1672)	3.2221681309883214
  (0, 1671)	3.1679251588888637
  (0, 1670)	3.259811332569962
  (0, 1669)	3.259811332569962
  (0, 1668)	3.2210339885405666
  (0, 1667)	3.259811332569962
  (0, 1666)	3.259811332569962
  (0, 1665)	3.2210339885405666
  (0, 1664)	3.259811332569962
  (0, 1663)	3.1964130319808586
  (0, 1662)	3.2210339885405666
  (0, 1661)	3.2125653321100787
  (0, 1660)	3.122860139345351
  (0, 1659)	3.1504213332110464
  (0, 1658)	3.259811332569962
  (0, 1657)	3.2774823136882354
  :	:
  (942, 24)	3.5775919286254116
  (942, 23)	3.568092949964251
  (942, 22)	4.266576437178359
  (942, 21)	4.295823579290619
  (942, 20)	2.8394162884157463
  (942, 19)	3.6952858038784515
  (942, 18)	4.031306417469048
  (942, 17)	3.200229637731213
  (942, 16)	3.2220131375576537
  (942, 15)	3.469804043155111
  (942, 14)	3.8372081621431406
  (942, 13)	4.104820007658993
  (942, 12)	3.4917760774644684
  (942, 11)	4.477027748018386
  (942, 10)	3.9744784405749463
  (942, 9)	3.916072883031886
  (942, 8)	4.013873354025676
  (942, 7)	4.132283288166617
  (942, 6)	3.9053074344190533
  (942, 5)	3.8734937935777967
  (942, 4)	3.4030031722819203
  (942, 3)	3.6339834736087258
  (942, 2)	3.147991891024062
  (942, 1)	3.3337930169830834
  (942, 0)	3.969330500392072
this is the 187 epoch
rmse loss on training set is 0.9226545908463565
rmse loss on test set is 0.9421188379779861
for this epoch using 76.29114890098572 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.252476127890229
  (0, 1680)	3.272649572030349
  (0, 1679)	3.194712596248728
  (0, 1678)	3.2558128650229445
  (0, 1677)	3.1336123274745162
  (0, 1676)	3.2615514847478555
  (0, 1675)	3.2597032727886104
  (0, 1674)	3.2597032727886104
  (0, 1673)	3.2597032727886104
  (0, 1672)	3.2218319132546673
  (0, 1671)	3.1674138333651176
  (0, 1670)	3.2597032727886104
  (0, 1669)	3.2597032727886104
  (0, 1668)	3.220737777414719
  (0, 1667)	3.2597032727886104
  (0, 1666)	3.2597032727886104
  (0, 1665)	3.220737777414719
  (0, 1664)	3.2597032727886104
  (0, 1663)	3.1959986209486573
  (0, 1662)	3.220737777414719
  (0, 1661)	3.2122424855828284
  (0, 1660)	3.1220664705417236
  (0, 1659)	3.1497769321037223
  (0, 1658)	3.2597032727886104
  (0, 1657)	3.277496055391205
  :	:
  (942, 24)	3.577653563662414
  (942, 23)	3.5681092086348336
  (942, 22)	4.2669584650069154
  (942, 21)	4.296092995983971
  (942, 20)	2.8393305848150048
  (942, 19)	3.6957460015346997
  (942, 18)	4.032006663155752
  (942, 17)	3.2000243369090673
  (942, 16)	3.2220746519948595
  (942, 15)	3.470323836567297
  (942, 14)	3.8371834780999374
  (942, 13)	4.1049979404700325
  (942, 12)	3.491935320687166
  (942, 11)	4.477297740884615
  (942, 10)	3.9746771659363147
  (942, 9)	3.9164578890754145
  (942, 8)	4.013952728754532
  (942, 7)	4.132541722032107
  (942, 6)	3.9053524428667874
  (942, 5)	3.8753676644217094
  (942, 4)	3.4031080139576515
  (942, 3)	3.6342275281401974
  (942, 2)	3.148012477881214
  (942, 1)	3.333958230247382
  (942, 0)	3.9693849405678665
this is the 188 epoch
rmse loss on training set is 0.9226051699071002
rmse loss on test set is 0.9420837759919811
for this epoch using 76.36757898330688 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2523420057873436
  (0, 1680)	3.2726237256011825
  (0, 1679)	3.194269999431754
  (0, 1678)	3.255682907772355
  (0, 1677)	3.1328570910911626
  (0, 1676)	3.26146933624693
  (0, 1675)	3.259596272967282
  (0, 1674)	3.259596272967282
  (0, 1673)	3.259596272967282
  (0, 1672)	3.2214969521718855
  (0, 1671)	3.1669040018869494
  (0, 1670)	3.259596272967282
  (0, 1669)	3.259596272967282
  (0, 1668)	3.2204426400692228
  (0, 1667)	3.259596272967282
  (0, 1666)	3.259596272967282
  (0, 1665)	3.2204426400692228
  (0, 1664)	3.259596272967282
  (0, 1663)	3.195585516711846
  (0, 1662)	3.2204426400692228
  (0, 1661)	3.2119209432109668
  (0, 1660)	3.1212741962479096
  (0, 1659)	3.1491339723102088
  (0, 1658)	3.259596272967282
  (0, 1657)	3.2775108455573783
  :	:
  (942, 24)	3.5777125244931933
  (942, 23)	3.5681232255185384
  (942, 22)	4.267334693151416
  (942, 21)	4.296357437076898
  (942, 20)	2.8392458680335
  (942, 19)	3.6961981878225845
  (942, 18)	4.03269547211647
  (942, 17)	3.199817915045067
  (942, 16)	3.2221342037765504
  (942, 15)	3.4708377204404623
  (942, 14)	3.8371567446575674
  (942, 13)	4.105171893231324
  (942, 12)	3.4920910652384722
  (942, 11)	4.477562846648311
  (942, 10)	3.9748717860060174
  (942, 9)	3.91683533340419
  (942, 8)	4.014029031392591
  (942, 7)	4.132795440868902
  (942, 6)	3.905394743000756
  (942, 5)	3.8772287620169723
  (942, 4)	3.4032096312209656
  (942, 3)	3.6344672079506863
  (942, 2)	3.1480313348273263
  (942, 1)	3.3341198159191126
  (942, 0)	3.969436565144596
this is the 189 epoch
rmse loss on training set is 0.92255630060577
rmse loss on test set is 0.9420492151832355
for this epoch using 75.72232508659363 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.252209022596553
  (0, 1680)	3.272598930044473
  (0, 1679)	3.193828537310028
  (0, 1678)	3.255553989575
  (0, 1677)	3.1321030850450566
  (0, 1676)	3.261388274823911
  (0, 1675)	3.2594903195895193
  (0, 1674)	3.2594903195895193
  (0, 1673)	3.2594903195895193
  (0, 1672)	3.22116323454855
  (0, 1671)	3.166395648142408
  (0, 1670)	3.2594903195895193
  (0, 1669)	3.2594903195895193
  (0, 1668)	3.2201485630184603
  (0, 1667)	3.2594903195895193
  (0, 1666)	3.2594903195895193
  (0, 1665)	3.2201485630184603
  (0, 1664)	3.2594903195895193
  (0, 1663)	3.1951737047792137
  (0, 1662)	3.2201485630184603
  (0, 1661)	3.211600690555122
  (0, 1660)	3.1204833015255518
  (0, 1659)	3.1484924384514934
  (0, 1658)	3.2594903195895193
  (0, 1657)	3.277526669470676
  :	:
  (942, 24)	3.577768868129789
  (942, 23)	3.5681350541885797
  (942, 22)	4.26770521537086
  (942, 21)	4.296616988833726
  (942, 20)	2.8391621122328217
  (942, 19)	3.6966424984467006
  (942, 18)	4.033373037224443
  (942, 17)	3.1996104167210713
  (942, 16)	3.2221918308561475
  (942, 15)	3.471345772425132
  (942, 14)	3.837128014853735
  (942, 13)	4.105341944089734
  (942, 12)	3.492243376393828
  (942, 11)	4.477823149481679
  (942, 10)	3.975062374760724
  (942, 9)	3.9172053664850117
  (942, 8)	4.01410232673378
  (942, 7)	4.133044525084612
  (942, 6)	3.905434396149671
  (942, 5)	3.8790771988768515
  (942, 4)	3.4033080918471224
  (942, 3)	3.63470258837843
  (942, 2)	3.1480484972287597
  (942, 1)	3.334277841100876
  (942, 0)	3.9694854352639193
this is the 190 epoch
rmse loss on training set is 0.9225079744384107
rmse loss on test set is 0.942015147606925
for this epoch using 75.57852005958557 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2520771642859923
  (0, 1680)	3.2725751718616576
  (0, 1679)	3.193388196398701
  (0, 1678)	3.255426097055515
  (0, 1677)	3.1313502957418966
  (0, 1676)	3.261308286703307
  (0, 1675)	3.259385399376298
  (0, 1674)	3.259385399376298
  (0, 1673)	3.259385399376298
  (0, 1672)	3.2208307473970947
  (0, 1671)	3.165888756093256
  (0, 1670)	3.259385399376298
  (0, 1669)	3.259385399376298
  (0, 1668)	3.219855533016691
  (0, 1667)	3.259385399376298
  (0, 1666)	3.259385399376298
  (0, 1665)	3.219855533016691
  (0, 1664)	3.259385399376298
  (0, 1663)	3.194763170908128
  (0, 1662)	3.219855533016691
  (0, 1661)	3.2112817134192615
  (0, 1660)	3.1196937716934268
  (0, 1659)	3.147852315410214
  (0, 1658)	3.259385399376298
  (0, 1657)	3.27754351267686
  :	:
  (942, 24)	3.5778226505307056
  (942, 23)	3.568144747128543
  (942, 22)	4.26807012381089
  (942, 21)	4.296871736080216
  (942, 20)	2.8390792923709793
  (942, 19)	3.6970790669070372
  (942, 18)	4.034039548046424
  (942, 17)	3.1994018855911857
  (942, 16)	3.2222475705573346
  (942, 15)	3.471848069055627
  (942, 14)	3.837097340681184
  (942, 13)	4.1055081696792906
  (942, 12)	3.492392318281469
  (942, 11)	4.478078732141143
  (942, 10)	3.975249004913127
  (942, 9)	3.9175681357419774
  (942, 8)	4.014172678370652
  (942, 7)	4.133289053774808
  (942, 6)	3.9054714624719113
  (942, 5)	3.88091308623495
  (942, 4)	3.4034034622781655
  (942, 3)	3.6349337434859126
  (942, 2)	3.148063999920179
  (942, 1)	3.3344323717429574
  (942, 0)	3.969531610948124
this is the 191 epoch
rmse loss on training set is 0.9224601830666697
rmse loss on test set is 0.9419815654712784
for this epoch using 75.72346687316895 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2519464170644277
  (0, 1680)	3.2725524377888275
  (0, 1679)	3.1929489634477006
  (0, 1678)	3.255299217071905
  (0, 1677)	3.1305987098235013
  (0, 1676)	3.2612293583495617
  (0, 1675)	3.259281499280342
  (0, 1674)	3.259281499280342
  (0, 1673)	3.259281499280342
  (0, 1672)	3.220499477929128
  (0, 1671)	3.1653833099686737
  (0, 1670)	3.259281499280342
  (0, 1669)	3.259281499280342
  (0, 1668)	3.2195635370522386
  (0, 1667)	3.259281499280342
  (0, 1666)	3.259281499280342
  (0, 1665)	3.2195635370522386
  (0, 1664)	3.259281499280342
  (0, 1663)	3.1943539010987285
  (0, 1662)	3.2195635370522386
  (0, 1661)	3.2109639978449014
  (0, 1660)	3.1189055923213362
  (0, 1659)	3.147213588324489
  (0, 1658)	3.259281499280342
  (0, 1657)	3.2775613609771885
  :	:
  (942, 24)	3.5778739266194965
  (942, 23)	3.568152355754923
  (942, 22)	4.26842950903563
  (942, 21)	4.297121762225961
  (942, 20)	2.838997384179252
  (942, 19)	3.697508024532753
  (942, 18)	4.0346951909000905
  (942, 17)	3.1991923643991904
  (942, 16)	3.2223014595834942
  (942, 15)	3.472344685766788
  (942, 14)	3.8370647731065675
  (942, 13)	4.105670645153564
  (942, 12)	3.4925379539014982
  (942, 11)	4.4783296759907305
  (942, 10)	3.9754317479328
  (942, 9)	3.917923785618903
  (942, 8)	4.014240148715941
  (942, 7)	4.133529104743178
  (942, 6)	3.905506000976233
  (942, 5)	3.8827365340620603
  (942, 4)	3.403495807648998
  (942, 3)	3.6351607460810773
  (942, 2)	3.148077877209671
  (942, 1)	3.334583472661089
  (942, 0)	3.969575151118848
this is the 192 epoch
rmse loss on training set is 0.9224129183138676
rmse loss on test set is 0.9419484611339384
for this epoch using 75.54259920120239 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.25181676737561
  (0, 1680)	3.2725307147910714
  (0, 1679)	3.1925108254361017
  (0, 1678)	3.2551733367099693
  (0, 1677)	3.129848314162237
  (0, 1676)	3.261151476461281
  (0, 1675)	3.259178606480513
  (0, 1674)	3.259178606480513
  (0, 1673)	3.259178606480513
  (0, 1672)	3.2201694135509205
  (0, 1671)	3.164879294259208
  (0, 1670)	3.259178606480513
  (0, 1669)	3.259178606480513
  (0, 1668)	3.219272562341795
  (0, 1667)	3.259178606480513
  (0, 1666)	3.259178606480513
  (0, 1665)	3.219272562341795
  (0, 1664)	3.259178606480513
  (0, 1663)	3.193945881588196
  (0, 1662)	3.219272562341795
  (0, 1661)	3.210647530105486
  (0, 1660)	3.1181187492242466
  (0, 1659)	3.146576242581972
  (0, 1658)	3.259178606480513
  (0, 1657)	3.2775802004223715
  :	:
  (942, 24)	3.5779227503029083
  (942, 23)	3.568157930439114
  (942, 22)	4.268783460058747
  (942, 21)	4.2973671492867505
  (942, 20)	2.8389163641396657
  (942, 19)	3.6979295005155746
  (942, 18)	4.035340148910432
  (942, 17)	3.1989818949955726
  (942, 16)	3.2223535340270004
  (942, 15)	3.4728356969103498
  (942, 14)	3.8370303620888393
  (942, 13)	4.1058294442170515
  (942, 12)	3.4926803451446893
  (942, 11)	4.478576061025125
  (942, 10)	3.975610674066715
  (942, 9)	3.9182724576405374
  (942, 8)	4.014304799023626
  (942, 7)	4.133764754521495
  (942, 6)	3.9055380695420583
  (942, 5)	3.8845476510826984
  (942, 4)	3.4035851918128253
  (942, 3)	3.6353836677380853
  (942, 2)	3.148090162883903
  (942, 1)	3.33473120755406
  (942, 0)	3.9696161136156154
this is the 193 epoch
rmse loss on training set is 0.9223661721611536
rmse loss on test set is 0.9419158270984231
for this epoch using 75.66707301139832 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.251688201892727
  (0, 1680)	3.2725099900569994
  (0, 1679)	3.1920737695667443
  (0, 1678)	3.25504844327791
  (0, 1677)	3.129099095855585
  (0, 1676)	3.2610746279656095
  (0, 1675)	3.259076708376441
  (0, 1674)	3.259076708376441
  (0, 1673)	3.259076708376441
  (0, 1672)	3.2198405418589533
  (0, 1671)	3.1643766937108064
  (0, 1670)	3.259076708376441
  (0, 1669)	3.259076708376441
  (0, 1668)	3.2189825963249157
  (0, 1667)	3.259076708376441
  (0, 1666)	3.259076708376441
  (0, 1665)	3.2189825963249157
  (0, 1664)	3.259076708376441
  (0, 1663)	3.193539098845255
  (0, 1662)	3.2189825963249157
  (0, 1661)	3.2103322967009125
  (0, 1660)	3.1173332284564874
  (0, 1659)	3.145940263813969
  (0, 1658)	3.259076708376441
  (0, 1657)	3.2776000173066078
  :	:
  (942, 24)	3.577969174488827
  (942, 23)	3.568161520528817
  (942, 22)	4.269132064373673
  (942, 21)	4.297607977906457
  (942, 20)	2.8388362094631323
  (942, 19)	3.698343621942629
  (942, 18)	4.035974602065212
  (942, 17)	3.198770518354294
  (942, 16)	3.222403829378329
  (942, 15)	3.473321175771111
  (942, 14)	3.8369941565974623
  (942, 13)	4.1059846391558175
  (942, 12)	3.4928195528110213
  (942, 11)	4.478817965892305
  (942, 10)	3.975785852359488
  (942, 9)	3.9186142904724206
  (942, 8)	4.014366689409688
  (942, 7)	4.133996078389285
  (942, 6)	3.905567724939525
  (942, 5)	3.8863465447914134
  (942, 4)	3.403671677366193
  (942, 3)	3.6356025788178976
  (942, 2)	3.1481008902133327
  (942, 1)	3.334875639021127
  (942, 0)	3.9696545552139653
this is the 194 epoch
rmse loss on training set is 0.9223199367438161
rmse loss on test set is 0.9418836560106958
for this epoch using 75.6088478565216 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2515607075130526
  (0, 1680)	3.272490250993493
  (0, 1679)	3.1916377832609917
  (0, 1678)	3.2549245243011176
  (0, 1677)	3.1283510422208667
  (0, 1676)	3.2609988000128927
  (0, 1675)	3.2589757925832736
  (0, 1674)	3.2589757925832736
  (0, 1673)	3.2589757925832736
  (0, 1672)	3.2195128506357102
  (0, 1671)	3.1638754933191415
  (0, 1670)	3.2589757925832736
  (0, 1669)	3.2589757925832736
  (0, 1668)	3.2186936266587414
  (0, 1667)	3.2589757925832736
  (0, 1666)	3.2589757925832736
  (0, 1665)	3.2186936266587414
  (0, 1664)	3.2589757925832736
  (0, 1663)	3.193133539564823
  (0, 1662)	3.2186936266587414
  (0, 1661)	3.2100182843522718
  (0, 1660)	3.1165490163062635
  (0, 1659)	3.145305637889884
  (0, 1658)	3.2589757925832736
  (0, 1657)	3.2776207981618515
  :	:
  (942, 24)	3.5780132511038283
  (942, 23)	3.568163174369093
  (942, 22)	4.269475407983058
  (942, 21)	4.297844327378674
  (942, 20)	2.83875689806811
  (942, 19)	3.6987505138288617
  (942, 18)	4.036598727269313
  (942, 17)	3.1985582745892156
  (942, 16)	3.2224523805351137
  (942, 15)	3.4738011945828866
  (942, 14)	3.836956204630254
  (942, 13)	4.106136300867223
  (942, 12)	3.4929556366278987
  (942, 11)	4.479055467915806
  (942, 10)	3.9759573506731494
  (942, 9)	3.9189494199795227
  (942, 8)	4.014425878872458
  (942, 7)	4.1342231503931135
  (942, 6)	3.905595022849173
  (942, 5)	3.888133321469001
  (942, 4)	3.403755325673454
  (942, 3)	3.635817548488361
  (942, 2)	3.1481100919574274
  (942, 1)	3.3350168285791453
  (942, 0)	3.9696905316434163
this is the 195 epoch
rmse loss on training set is 0.9222742043476293
rmse loss on test set is 0.9418519406558271
for this epoch using 75.58619284629822 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.25143427135281
  (0, 1680)	3.272471485220563
  (0, 1679)	3.1912028541536612
  (0, 1678)	3.2548015675170956
  (0, 1677)	3.127604140790228
  (0, 1676)	3.260923979971398
  (0, 1675)	3.258875846926651
  (0, 1674)	3.258875846926651
  (0, 1673)	3.258875846926651
  (0, 1672)	3.2191863278455757
  (0, 1671)	3.1633756783240696
  (0, 1670)	3.258875846926651
  (0, 1669)	3.258875846926651
  (0, 1668)	3.2184056412128226
  (0, 1667)	3.258875846926651
  (0, 1666)	3.258875846926651
  (0, 1665)	3.2184056412128226
  (0, 1664)	3.258875846926651
  (0, 1663)	3.192729190662853
  (0, 1662)	3.2184056412128226
  (0, 1661)	3.209705479996743
  (0, 1660)	3.115766099290251
  (0, 1659)	3.144672350911754
  (0, 1658)	3.258875846926651
  (0, 1657)	3.2776425297523275
  :	:
  (942, 24)	3.578055031110439
  (942, 23)	3.5681629393227783
  (942, 22)	4.269813575427478
  (942, 21)	4.298076275668093
  (942, 20)	2.8386784085598853
  (942, 19)	3.6991502991490512
  (942, 18)	4.037212698398313
  (942, 17)	3.1983452029702586
  (942, 16)	3.222499221811039
  (942, 15)	3.4742758245441645
  (942, 14)	3.8369165532309015
  (942, 13)	4.10628449888894
  (942, 12)	3.4930886552681413
  (942, 11)	4.479288643116685
  (942, 10)	3.9761252357067667
  (942, 9)	3.9192779792837475
  (942, 8)	4.014482425312569
  (942, 7)	4.134446043365749
  (942, 6)	3.905620017881328
  (942, 5)	3.889908086198313
  (942, 4)	3.403836196890841
  (942, 3)	3.6360286447441266
  (942, 2)	3.148117800369936
  (942, 1)	3.3351548366796306
  (942, 0)	3.969724097605099
this is the 196 epoch
rmse loss on training set is 0.9222289674053362
rmse loss on test set is 0.9418206739547471
for this epoch using 76.10066390037537 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2513088807420703
  (0, 1680)	3.27245368056639
  (0, 1679)	3.190768970088069
  (0, 1678)	3.2546795608705166
  (0, 1677)	3.126858379305614
  (0, 1676)	3.260850155422219
  (0, 1675)	3.2587768594377553
  (0, 1674)	3.2587768594377553
  (0, 1673)	3.2587768594377553
  (0, 1672)	3.2188609616307984
  (0, 1671)	3.1628772342041267
  (0, 1670)	3.2587768594377553
  (0, 1669)	3.2587768594377553
  (0, 1668)	3.218118628064098
  (0, 1667)	3.2587768594377553
  (0, 1666)	3.2587768594377553
  (0, 1665)	3.218118628064098
  (0, 1664)	3.2587768594377553
  (0, 1663)	3.1923260392712876
  (0, 1662)	3.218118628064098
  (0, 1661)	3.20939387078259
  (0, 1660)	3.1149844641483666
  (0, 1659)	3.1440403892089237
  (0, 1658)	3.2587768594377553
  (0, 1657)	3.27766519906904
  :	:
  (942, 24)	3.578094564524154
  (942, 23)	3.56816086179055
  (942, 22)	4.270146649813446
  (942, 21)	4.2983038994315494
  (942, 20)	2.838600720210412
  (942, 19)	3.6995430988693276
  (942, 18)	4.0378166863509755
  (942, 17)	3.198131341939203
  (942, 16)	3.222544386944605
  (942, 15)	3.4747451358336394
  (942, 14)	3.8368752485062485
  (942, 13)	4.106429301427235
  (942, 12)	3.4932186663677083
  (942, 11)	4.479517566235029
  (942, 10)	3.976289573015658
  (942, 9)	3.9196000988201263
  (942, 8)	4.01453638555262
  (942, 7)	4.134664828944935
  (942, 6)	3.9056427635951514
  (942, 5)	3.891670942880027
  (942, 4)	3.403914349989951
  (942, 3)	3.6362359344261903
  (942, 2)	3.148124047204177
  (942, 1)	3.335289722725522
  (942, 0)	3.969755306789163
this is the 197 epoch
rmse loss on training set is 0.9221842184933077
rmse loss on test set is 0.9417898489610964
for this epoch using 75.50207090377808 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2511845232199517
  (0, 1680)	3.2724368250625298
  (0, 1679)	3.190336119111288
  (0, 1678)	3.25455849250853
  (0, 1677)	3.1261137457140546
  (0, 1676)	3.2607773141543945
  (0, 1675)	3.258678818348587
  (0, 1674)	3.258678818348587
  (0, 1673)	3.258678818348587
  (0, 1672)	3.2185367403076754
  (0, 1671)	3.162380146671429
  (0, 1670)	3.258678818348587
  (0, 1669)	3.258678818348587
  (0, 1668)	3.2178325754921318
  (0, 1667)	3.258678818348587
  (0, 1666)	3.258678818348587
  (0, 1665)	3.2178325754921318
  (0, 1664)	3.258678818348587
  (0, 1663)	3.191924072733203
  (0, 1662)	3.2178325754921318
  (0, 1661)	3.2090834440644245
  (0, 1660)	3.1142040978387118
  (0, 1659)	3.1434097393329803
  (0, 1658)	3.258678818348587
  (0, 1657)	3.2776887933246184
  :	:
  (942, 24)	3.5781319004300536
  (942, 23)	3.568156987230458
  (942, 22)	4.270474712840706
  (942, 21)	4.298527274038833
  (942, 20)	2.8385238129387043
  (942, 19)	3.6999290319782054
  (942, 18)	4.038410859100948
  (942, 17)	3.1979167291252897
  (942, 16)	3.2225879091078102
  (942, 15)	3.4752091976253854
  (942, 14)	3.836832335643253
  (942, 13)	4.106570775384437
  (942, 12)	3.4933457265430716
  (942, 11)	4.479742310751207
  (942, 10)	3.9764504270302985
  (942, 9)	3.9199159063920006
  (942, 8)	4.014587815356402
  (942, 7)	4.13487957759196
  (942, 6)	3.9056633125173548
  (942, 5)	3.893421994248071
  (942, 4)	3.4039898427808986
  (942, 3)	3.6364394832411064
  (942, 2)	3.1481288637183575
  (942, 1)	3.335421545087793
  (942, 0)	3.9697842118918927
this is the 198 epoch
rmse loss on training set is 0.9221399503280973
rmse loss on test set is 0.9417594588581703
for this epoch using 76.41738200187683 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2510611865298675
  (0, 1680)	3.2724209069392374
  (0, 1679)	3.1899042894695318
  (0, 1678)	3.2544383507760735
  (0, 1677)	3.125370228162994
  (0, 1676)	3.26070544416009
  (0, 1675)	3.25858171208737
  (0, 1674)	3.25858171208737
  (0, 1673)	3.25858171208737
  (0, 1672)	3.2182136523628095
  (0, 1671)	3.161884401666486
  (0, 1670)	3.25858171208737
  (0, 1669)	3.25858171208737
  (0, 1668)	3.2175474719743646
  (0, 1667)	3.25858171208737
  (0, 1666)	3.25858171208737
  (0, 1665)	3.2175474719743646
  (0, 1664)	3.25858171208737
  (0, 1663)	3.1915232785980696
  (0, 1662)	3.2175474719743646
  (0, 1661)	3.208774187398473
  (0, 1660)	3.11342498753268
  (0, 1659)	3.142780388052735
  (0, 1658)	3.25858171208737
  (0, 1657)	3.2777132999482377
  :	:
  (942, 24)	3.5781670869992275
  (942, 23)	3.5681513601770534
  (942, 22)	4.27079784482885
  (942, 21)	4.298746473593123
  (942, 20)	2.838447667291732
  (942, 19)	3.7003082155173224
  (942, 18)	4.038995381747386
  (942, 17)	3.1977014013604577
  (942, 16)	3.2226298209146593
  (942, 15)	3.4756680781038827
  (942, 14)	3.8367878589256437
  (942, 13)	4.106708986385834
  (942, 12)	3.4934698914084565
  (942, 11)	4.479962948906716
  (942, 10)	3.9766078610749256
  (942, 9)	3.9202255272249342
  (942, 8)	4.014636769447886
  (942, 7)	4.135090358609928
  (942, 6)	3.9056817161606627
  (942, 5)	3.895161341884967
  (942, 4)	3.4040627319349186
  (942, 3)	3.6366393557799364
  (942, 2)	3.1481322806808505
  (942, 1)	3.3355503611218102
  (942, 0)	3.969810864632571
this is the 199 epoch
rmse loss on training set is 0.9220961557633446
rmse loss on test set is 0.9417294969559515
for this epoch using 76.23088502883911 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2509388586149104
  (0, 1680)	3.2724059146209243
  (0, 1679)	3.189473469603604
  (0, 1678)	3.2543191242114338
  (0, 1677)	3.1246278149957787
  (0, 1676)	3.2606345336299896
  (0, 1675)	3.2584855292739974
  (0, 1674)	3.2584855292739974
  (0, 1673)	3.2584855292739974
  (0, 1672)	3.217891686449457
  (0, 1671)	3.1613899853532748
  (0, 1670)	3.2584855292739974
  (0, 1669)	3.2584855292739974
  (0, 1668)	3.217263306181571
  (0, 1667)	3.2584855292739974
  (0, 1666)	3.2584855292739974
  (0, 1665)	3.217263306181571
  (0, 1664)	3.2584855292739974
  (0, 1663)	3.1911236446171793
  (0, 1662)	3.217263306181571
  (0, 1661)	3.2084660885381022
  (0, 1660)	3.1126471206101303
  (0, 1659)	3.142152322349394
  (0, 1658)	3.2584855292739974
  (0, 1657)	3.277738706580651
  :	:
  (942, 24)	3.5782001715048524
  (942, 23)	3.568144024260069
  (942, 22)	4.27111612474333
  (942, 21)	4.298961570951263
  (942, 20)	2.8383722644258906
  (942, 19)	3.7006807646115623
  (942, 18)	4.039570416564869
  (942, 17)	3.1974853946943105
  (942, 16)	3.2226701544296246
  (942, 15)	3.476121844478802
  (942, 14)	3.8367418617502973
  (942, 13)	4.1068439988057595
  (942, 12)	3.4935912155927222
  (942, 11)	4.480179551724726
  (942, 10)	3.9767619373858976
  (942, 9)	3.9205290840196096
  (942, 8)	4.014683301529696
  (942, 7)	4.135297240161819
  (942, 6)	3.905698025041943
  (942, 5)	3.896889086236838
  (942, 4)	3.404133073006548
  (942, 3)	3.6368356155368535
  (942, 2)	3.1481343283756114
  (942, 1)	3.335676227183561
  (942, 0)	3.9698353157700432
this is the 200 epoch
rmse loss on training set is 0.9220528277865289
rmse loss on test set is 0.941699956688205
for this epoch using 76.58078122138977 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2508175276134463
  (0, 1680)	3.2723918367218277
  (0, 1679)	3.1890436481445854
  (0, 1678)	3.254200801541884
  (0, 1677)	3.123886494747292
  (0, 1676)	3.260564570948787
  (0, 1675)	3.2583902587158087
  (0, 1674)	3.2583902587158087
  (0, 1673)	3.2583902587158087
  (0, 1672)	3.217570831384054
  (0, 1671)	3.1608968841144893
  (0, 1670)	3.2583902587158087
  (0, 1669)	3.2583902587158087
  (0, 1668)	3.2169800669734623
  (0, 1667)	3.2583902587158087
  (0, 1666)	3.2583902587158087
  (0, 1665)	3.2169800669734623
  (0, 1664)	3.2583902587158087
  (0, 1663)	3.1907251587391885
  (0, 1662)	3.2169800669734623
  (0, 1661)	3.208159135429401
  (0, 1660)	3.111870484654842
  (0, 1659)	3.141525529411891
  (0, 1658)	3.2583902587158087
  (0, 1657)	3.2777650010694597
  :	:
  (942, 24)	3.5782312003380503
  (942, 23)	3.568135022222702
  (942, 22)	4.271429630220781
  (942, 21)	4.299172637743596
  (942, 20)	2.8382975860889337
  (942, 19)	3.701046792498913
  (942, 18)	4.040136123052362
  (942, 17)	3.197268744408867
  (942, 16)	3.222708941175917
  (942, 15)	3.476570562999575
  (942, 14)	3.836694386643419
  (942, 13)	4.106975875793093
  (942, 12)	3.4937097527560304
  (942, 11)	4.48039218903023
  (942, 10)	3.9769127171296708
  (942, 9)	3.920826697003572
  (942, 8)	4.014727464301471
  (942, 7)	4.135500289288218
  (942, 6)	3.905712288699959
  (942, 5)	3.8986053266282967
  (942, 4)	3.4042009204553754
  (942, 3)	3.637028324927489
  (942, 2)	3.148135036607445
  (942, 1)	3.335799198645622
  (942, 0)	3.9698576151191043
this is the 201 epoch
rmse loss on training set is 0.9220099595159392
rmse loss on test set is 0.941670831609669
for this epoch using 75.72943305969238 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.25069718185474
  (0, 1680)	3.272378662041681
  (0, 1679)	3.1886148139095902
  (0, 1678)	3.254083371679457
  (0, 1677)	3.1231462561397194
  (0, 1676)	3.260495544690834
  (0, 1675)	3.2582958894032523
  (0, 1674)	3.2582958894032523
  (0, 1673)	3.2582958894032523
  (0, 1672)	3.2172510761427855
  (0, 1671)	3.1604050845467953
  (0, 1670)	3.2582958894032523
  (0, 1669)	3.2582958894032523
  (0, 1668)	3.216697743394394
  (0, 1667)	3.2582958894032523
  (0, 1666)	3.2582958894032523
  (0, 1665)	3.216697743394394
  (0, 1664)	3.2582958894032523
  (0, 1663)	3.19032780910577
  (0, 1662)	3.216697743394394
  (0, 1661)	3.2078533162069416
  (0, 1660)	3.1110950674499107
  (0, 1659)	3.1408999966323012
  (0, 1658)	3.2582958894032523
  (0, 1657)	3.277792171464444
  :	:
  (942, 24)	3.5782602190234045
  (942, 23)	3.5681243959394155
  (942, 22)	4.2717384375938465
  (942, 21)	4.2993797443937005
  (942, 20)	2.8382236146024273
  (942, 19)	3.7014064105597986
  (942, 18)	4.0406926579812765
  (942, 17)	3.1970514850329743
  (942, 16)	3.222746212143712
  (942, 15)	3.477014298969744
  (942, 14)	3.8366454752762458
  (942, 13)	4.107104679296157
  (942, 12)	3.4938255556062208
  (942, 11)	4.480600929469963
  (942, 10)	3.9770602604205494
  (942, 9)	3.92111848398191
  (942, 8)	4.014769309477705
  (942, 7)	4.135699571924828
  (942, 6)	3.905724555713004
  (942, 5)	3.9003101612771607
  (942, 4)	3.4042663276674108
  (942, 3)	3.637217545306925
  (942, 2)	3.1481344347074076
  (942, 1)	3.3359193299129304
  (942, 0)	3.9698778115665703
this is the 202 epoch
rmse loss on training set is 0.9219675441977753
rmse loss on test set is 0.9416421153933316
for this epoch using 75.12219500541687 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2505778098548213
  (0, 1680)	3.2723663795616362
  (0, 1679)	3.1881869558976583
  (0, 1678)	3.2539668237168966
  (0, 1677)	3.122407088078422
  (0, 1676)	3.260427443615919
  (0, 1675)	3.2582024105059224
  (0, 1674)	3.2582024105059224
  (0, 1673)	3.2582024105059224
  (0, 1672)	3.216932409858282
  (0, 1671)	3.159914573456348
  (0, 1670)	3.2582024105059224
  (0, 1669)	3.2582024105059224
  (0, 1668)	3.216416324669248
  (0, 1667)	3.2582024105059224
  (0, 1666)	3.2582024105059224
  (0, 1665)	3.216416324669248
  (0, 1664)	3.2582024105059224
  (0, 1663)	3.1899315840474567
  (0, 1662)	3.216416324669248
  (0, 1661)	3.2075486191896356
  (0, 1660)	3.1103208569734972
  (0, 1659)	3.140275711601477
  (0, 1658)	3.2582024105059224
  (0, 1657)	3.277820206013084
  :	:
  (942, 24)	3.578287272234236
  (942, 23)	3.568112186433497
  (942, 22)	4.272042621915278
  (942, 21)	4.299582960137706
  (942, 20)	2.838150332844675
  (942, 19)	3.701759728346054
  (942, 18)	4.04124017544278
  (942, 17)	3.196833650356472
  (942, 16)	3.222781997798202
  (942, 15)	3.477453116761088
  (942, 14)	3.8365951684807227
  (942, 13)	4.107230470086925
  (942, 12)	3.4939386759149644
  (942, 11)	4.480805840531897
  (942, 10)	3.9772046263381533
  (942, 9)	3.9214045603869443
  (942, 8)	4.014808887805387
  (942, 7)	4.135895152919772
  (942, 6)	3.9057348737160105
  (942, 5)	3.9020036873088206
  (942, 4)	3.404329346975921
  (942, 3)	3.637403336987515
  (942, 2)	3.148132551538185
  (942, 1)	3.336036674438408
  (942, 0)	3.969895953087145
this is the 203 epoch
rmse loss on training set is 0.921925575203134
rmse loss on test set is 0.941613801827767
for this epoch using 75.10311031341553 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.250459400312344
  (0, 1680)	3.2723549784402337
  (0, 1679)	3.18776006328576
  (0, 1678)	3.253851146923598
  (0, 1677)	3.121668979647924
  (0, 1676)	3.2603602566651197
  (0, 1675)	3.258109811368499
  (0, 1674)	3.258109811368499
  (0, 1673)	3.258109811368499
  (0, 1672)	3.216614821816433
  (0, 1671)	3.159425337854388
  (0, 1670)	3.258109811368499
  (0, 1669)	3.258109811368499
  (0, 1668)	3.2161358001993507
  (0, 1667)	3.258109811368499
  (0, 1666)	3.258109811368499
  (0, 1665)	3.2161358001993507
  (0, 1664)	3.258109811368499
  (0, 1663)	3.1895364720795505
  (0, 1662)	3.2161358001993507
  (0, 1661)	3.207245032876727
  (0, 1660)	3.1095478413945004
  (0, 1659)	3.1396526621046976
  (0, 1658)	3.258109811368499
  (0, 1657)	3.2778490931561817
  :	:
  (942, 24)	3.578312403807617
  (942, 23)	3.5680984338940496
  (942, 22)	4.272342256981625
  (942, 21)	4.299782353043356
  (942, 20)	2.838077724234122
  (942, 19)	3.7021068536094535
  (942, 18)	4.041778826894225
  (942, 17)	3.1966152734441238
  (942, 16)	3.2228163280875872
  (942, 15)	3.477887079827546
  (942, 14)	3.8365435062647664
  (942, 13)	4.107353307784734
  (942, 12)	3.4940491645336635
  (942, 11)	4.481006988564465
  (942, 10)	3.9773458729445768
  (942, 9)	3.92168503932684
  (942, 8)	4.014846249081278
  (942, 7)	4.136087096050595
  (942, 6)	3.9057432894175963
  (942, 5)	3.9036860007706227
  (942, 4)	3.4043900296819793
  (942, 3)	3.63758575925624
  (942, 2)	3.148129415499384
  (942, 1)	3.3361512847382966
  (942, 0)	3.9699120867589803
this is the 204 epoch
rmse loss on training set is 0.9218840460253075
rmse loss on test set is 0.941585884814534
for this epoch using 75.1228437423706 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2503419421046726
  (0, 1680)	3.2723444480095027
  (0, 1679)	3.1873341254249397
  (0, 1678)	3.253736330741824
  (0, 1677)	3.1209319201080565
  (0, 1676)	3.2602939729568785
  (0, 1675)	3.2580180815069477
  (0, 1674)	3.2580180815069477
  (0, 1673)	3.2580180815069477
  (0, 1672)	3.2162983014532536
  (0, 1671)	3.1589373649529127
  (0, 1670)	3.2580180815069477
  (0, 1669)	3.2580180815069477
  (0, 1668)	3.2158561595585997
  (0, 1667)	3.2580180815069477
  (0, 1666)	3.2580180815069477
  (0, 1665)	3.2158561595585997
  (0, 1664)	3.2580180815069477
  (0, 1663)	3.189142461898137
  (0, 1662)	3.2158561595585997
  (0, 1661)	3.2069425459438983
  (0, 1660)	3.1087760090684853
  (0, 1659)	3.1390308361175276
  (0, 1658)	3.2580180815069477
  (0, 1657)	3.2778788215235877
  :	:
  (942, 24)	3.5783356567591738
  (942, 23)	3.568083177692703
  (942, 22)	4.272637415356239
  (942, 21)	4.299977990028885
  (942, 20)	2.8380057727132018
  (942, 19)	3.702447892329825
  (942, 18)	4.04230876120477
  (942, 17)	3.19639638664928
  (942, 16)	3.2228492324509324
  (942, 15)	3.4783162507189274
  (942, 14)	3.8364905278272365
  (942, 13)	4.1074732508793
  (942, 12)	3.494157071409116
  (942, 11)	4.4812044387954995
  (942, 10)	3.9774840573012287
  (942, 9)	3.9219600316332093
  (942, 8)	4.014881442168862
  (942, 7)	4.136275464041023
  (942, 6)	3.9057498486166673
  (942, 5)	3.905357196645864
  (942, 4)	3.404448426074524
  (942, 3)	3.6377648703920022
  (942, 2)	3.148125054532968
  (942, 1)	3.3362632124073492
  (942, 0)	3.9699262587790103
this is the 205 epoch
rmse loss on training set is 0.9218429502769689
rmse loss on test set is 0.9415583583656914
for this epoch using 75.34052085876465 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.250225424283994
  (0, 1680)	3.2723347777711735
  (0, 1679)	3.1869091318365173
  (0, 1678)	3.253622364782904
  (0, 1677)	3.1201958988901266
  (0, 1676)	3.2602285817830157
  (0, 1675)	3.257927210604737
  (0, 1674)	3.257927210604737
  (0, 1673)	3.257927210604737
  (0, 1672)	3.2159828383518665
  (0, 1671)	3.1584506421604983
  (0, 1670)	3.257927210604737
  (0, 1669)	3.257927210604737
  (0, 1668)	3.2155773924896267
  (0, 1667)	3.257927210604737
  (0, 1666)	3.257927210604737
  (0, 1665)	3.2155773924896267
  (0, 1664)	3.257927210604737
  (0, 1663)	3.188749542376247
  (0, 1662)	3.2155773924896267
  (0, 1661)	3.2066411472394547
  (0, 1660)	3.108005348533616
  (0, 1659)	3.1384102218017245
  (0, 1658)	3.257927210604737
  (0, 1657)	3.2779093799300667
  :	:
  (942, 24)	3.5783570732974783
  (942, 23)	3.568066456399982
  (942, 22)	4.272928168391886
  (942, 21)	4.300169936881543
  (942, 20)	2.837934462732645
  (942, 19)	3.7027829487428057
  (942, 18)	4.042830124700194
  (942, 17)	3.1961770216272667
  (942, 16)	3.2228807398259116
  (942, 15)	3.478740691094456
  (942, 14)	3.836436271572795
  (942, 13)	4.107590356753319
  (942, 12)	3.494262445598871
  (942, 11)	4.481398255350817
  (942, 10)	3.9776192354855415
  (942, 9)	3.9222296459077555
  (942, 8)	4.014914515015095
  (942, 7)	4.1364603185775275
  (942, 6)	3.905754596218801
  (942, 5)	3.907017368867738
  (942, 4)	3.404504585450074
  (942, 3)	3.637940727682398
  (942, 2)	3.1481194961285435
  (942, 1)	3.3363725081338553
  (942, 0)	3.9699385144781316
this is the 206 epoch
rmse loss on training set is 0.9218022816875314
rmse loss on test set is 0.9415312166013362
for this epoch using 75.07537817955017 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2501098360736402
  (0, 1680)	3.272325957393019
  (0, 1679)	3.1864850722084666
  (0, 1678)	3.253509238823617
  (0, 1677)	3.119460905593317
  (0, 1676)	3.260164072605121
  (0, 1675)	3.2578371885092476
  (0, 1674)	3.2578371885092476
  (0, 1673)	3.2578371885092476
  (0, 1672)	3.2156684222395775
  (0, 1671)	3.1579651570783285
  (0, 1670)	3.2578371885092476
  (0, 1669)	3.2578371885092476
  (0, 1668)	3.215299488900158
  (0, 1667)	3.2578371885092476
  (0, 1666)	3.2578371885092476
  (0, 1665)	3.215299488900158
  (0, 1664)	3.2578371885092476
  (0, 1663)	3.188357702560161
  (0, 1662)	3.215299488900158
  (0, 1661)	3.206340825780707
  (0, 1660)	3.1072358485068734
  (0, 1659)	3.1377908075013785
  (0, 1658)	3.2578371885092476
  (0, 1657)	3.2779407573713573
  :	:
  (942, 24)	3.578376694838408
  (942, 23)	3.5680483078012686
  (942, 22)	4.273214586252713
  (942, 21)	4.300358258275859
  (942, 20)	2.8378637792362276
  (942, 19)	3.7031121253671633
  (942, 18)	4.043343061206996
  (942, 17)	3.1959572093485713
  (942, 16)	3.2229108786564695
  (942, 15)	3.4791604617360194
  (942, 14)	3.8363807751263845
  (942, 13)	4.107704681704426
  (942, 12)	3.494365335286436
  (942, 11)	4.48158850127251
  (942, 10)	3.977751462607261
  (942, 9)	3.9224939885679495
  (942, 8)	4.014945514666662
  (942, 7)	4.136641720325597
  (942, 6)	3.9057575762523724
  (942, 5)	3.9086666103330048
  (942, 4)	3.404558556132041
  (942, 3)	3.6381133874404274
  (942, 2)	3.1481127673287754
  (942, 1)	3.336479221714324
  (942, 0)	3.969948898336023
this is the 207 epoch
rmse loss on training set is 0.9217620341005625
rmse loss on test set is 0.9415044537472049
for this epoch using 76.12223696708679 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.249995166864389
  (0, 1680)	3.2723179767052852
  (0, 1679)	3.186061936391838
  (0, 1678)	3.253396942802644
  (0, 1677)	3.118726929981037
  (0, 1676)	3.2601004350507443
  (0, 1675)	3.257748005228216
  (0, 1674)	3.257748005228216
  (0, 1673)	3.257748005228216
  (0, 1672)	3.2153550429850397
  (0, 1671)	3.1574808974961215
  (0, 1670)	3.257748005228216
  (0, 1669)	3.257748005228216
  (0, 1668)	3.2150224388593824
  (0, 1667)	3.257748005228216
  (0, 1666)	3.257748005228216
  (0, 1665)	3.2150224388593824
  (0, 1664)	3.257748005228216
  (0, 1663)	3.187966931665674
  (0, 1662)	3.2150224388593824
  (0, 1661)	3.2060415707503136
  (0, 1660)	3.1064674978801516
  (0, 1659)	3.137172581738979
  (0, 1658)	3.257748005228216
  (0, 1657)	3.277972943020174
  :	:
  (942, 24)	3.578394562019073
  (942, 23)	3.568028768912401
  (942, 22)	4.273496737935847
  (942, 21)	4.300543017791641
  (942, 20)	2.8377937076459196
  (942, 19)	3.7034355230317177
  (942, 18)	4.0438477120956
  (942, 17)	3.1957369801117315
  (942, 16)	3.2229396769003475
  (942, 15)	3.4795756225613435
  (942, 14)	3.8363240753475036
  (942, 13)	4.10781628096672
  (942, 12)	3.494465787796173
  (942, 11)	4.481775238536923
  (942, 10)	3.9778807928245783
  (942, 9)	3.9227531638917887
  (942, 8)	4.0149744872861834
  (942, 7)	4.136819728945839
  (942, 6)	3.9057588318843486
  (942, 5)	3.910305012915537
  (942, 4)	3.404610385489633
  (942, 3)	3.638282905020834
  (942, 2)	3.1481048947346557
  (942, 1)	3.33658340206817
  (942, 0)	3.969957453995797
this is the 208 epoch
rmse loss on training set is 0.9217222014712693
rmse loss on test set is 0.9414780641323918
for this epoch using 77.46950888633728 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.249881406210957
  (0, 1680)	3.2723108256971956
  (0, 1679)	3.1856397143973205
  (0, 1678)	3.2532854668171063
  (0, 1677)	3.117993961977544
  (0, 1676)	3.260037658909942
  (0, 1675)	3.257659650926305
  (0, 1674)	3.257659650926305
  (0, 1673)	3.257659650926305
  (0, 1672)	3.2150426905954332
  (0, 1671)	3.1569978513883874
  (0, 1670)	3.257659650926305
  (0, 1669)	3.257659650926305
  (0, 1668)	3.2147462325945004
  (0, 1667)	3.257659650926305
  (0, 1666)	3.257659650926305
  (0, 1665)	3.2147462325945004
  (0, 1664)	3.257659650926305
  (0, 1663)	3.187577219074655
  (0, 1662)	3.2147462325945004
  (0, 1661)	3.205743371492902
  (0, 1660)	3.105700285716662
  (0, 1659)	3.1365555332117716
  (0, 1658)	3.257659650926305
  (0, 1657)	3.278005926222478
  :	:
  (942, 24)	3.57841071471161
  (942, 23)	3.5680078759950056
  (942, 22)	4.273774691292463
  (942, 21)	4.300724277931802
  (942, 20)	2.837724233847472
  (942, 19)	3.703753240901913
  (942, 18)	4.044344216322913
  (942, 17)	3.195516363556077
  (942, 16)	3.222967162036539
  (942, 15)	3.47998623263688
  (942, 14)	3.8362662083442243
  (942, 13)	4.107925208731693
  (942, 12)	3.4945638496080016
  (942, 11)	4.481958528072442
  (942, 10)	3.97800727935993
  (942, 9)	3.923007274061524
  (942, 8)	4.015001478167934
  (942, 7)	4.136994403109794
  (942, 6)	3.905758405435877
  (942, 5)	3.911932667479607
  (942, 4)	3.404660119956466
  (942, 3)	3.6384493348361695
  (942, 2)	3.148095904510906
  (942, 1)	3.3366850972520026
  (942, 0)	3.969964224278395
this is the 209 epoch
rmse loss on training set is 0.9216827778639918
rmse loss on test set is 0.9414520421870606
for this epoch using 78.36043190956116 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2497685438285746
  (0, 1680)	3.272304494513632
  (0, 1679)	3.1852183963918703
  (0, 1678)	3.2531748011192407
  (0, 1677)	3.117261991664504
  (0, 1676)	3.2599757341317708
  (0, 1675)	3.2575721159217936
  (0, 1674)	3.2575721159217936
  (0, 1673)	3.2575721159217936
  (0, 1672)	3.214731355213862
  (0, 1671)	3.156516006910646
  (0, 1670)	3.2575721159217936
  (0, 1669)	3.2575721159217936
  (0, 1668)	3.214470860487338
  (0, 1667)	3.2575721159217936
  (0, 1666)	3.2575721159217936
  (0, 1665)	3.214470860487338
  (0, 1664)	3.2575721159217936
  (0, 1663)	3.1871885543315552
  (0, 1662)	3.214470860487338
  (0, 1661)	3.2054462175116
  (0, 1660)	3.104934201247312
  (0, 1659)	3.1359396507880892
  (0, 1658)	3.2575721159217936
  (0, 1657)	3.2780396964937837
  :	:
  (942, 24)	3.5784251920366446
  (942, 23)	3.56798566457144
  (942, 22)	4.27404851304831
  (942, 21)	4.3009021001397585
  (942, 20)	2.837655344176373
  (942, 19)	3.704065376505961
  (942, 18)	4.04483271047409
  (942, 17)	3.1952953886740927
  (942, 16)	3.2229933610726196
  (942, 15)	3.480392350190504
  (942, 14)	3.8362072094869655
  (942, 13)	4.1080315181687705
  (942, 12)	3.494659566371849
  (942, 11)	4.482138429776805
  (942, 10)	3.978130974515605
  (942, 9)	3.9232564192066386
  (942, 8)	4.01502653175339
  (942, 7)	4.137165800515491
  (942, 6)	3.9057563383975586
  (942, 5)	3.913549663893101
  (942, 4)	3.404707805048712
  (942, 3)	3.638612730372627
  (942, 2)	3.1480858223912116
  (942, 1)	3.336784354473867
  (942, 0)	3.9699692511967704
this is the 210 epoch
rmse loss on training set is 0.9216437574498728
rmse loss on test set is 0.9414263824402715
for this epoch using 77.08957171440125 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2496565695896424
  (0, 1680)	3.2722989734517762
  (0, 1679)	3.1847979726954256
  (0, 1678)	3.2530649361131463
  (0, 1677)	3.116531009277714
  (0, 1676)	3.259914650820962
  (0, 1675)	3.257485390683292
  (0, 1674)	3.257485390683292
  (0, 1673)	3.257485390683292
  (0, 1672)	3.2144210271166376
  (0, 1671)	3.156035352395769
  (0, 1670)	3.257485390683292
  (0, 1669)	3.257485390683292
  (0, 1668)	3.2141963130710267
  (0, 1667)	3.257485390683292
  (0, 1666)	3.257485390683292
  (0, 1665)	3.2141963130710267
  (0, 1664)	3.257485390683292
  (0, 1663)	3.186800927140076
  (0, 1662)	3.2141963130710267
  (0, 1661)	3.205150098464828
  (0, 1660)	3.1041692338672324
  (0, 1659)	3.1353249235038403
  (0, 1658)	3.257485390683292
  (0, 1657)	3.2780742435155226
  :	:
  (942, 24)	3.5784380323766736
  (942, 23)	3.567962169439441
  (942, 22)	4.274318268823941
  (942, 21)	4.301076544816705
  (942, 20)	2.837587025404242
  (942, 19)	3.7043720257606174
  (942, 18)	4.045313328803584
  (942, 17)	3.1950740838237413
  (942, 16)	3.2230183005519826
  (942, 15)	3.480794032624068
  (942, 14)	3.836147113422063
  (942, 13)	4.108135261445295
  (942, 12)	3.4947529829218396
  (942, 11)	4.482315002534317
  (942, 10)	3.9782519296890597
  (942, 9)	3.9235006974458044
  (942, 8)	4.015049691646482
  (942, 7)	4.137333977902928
  (942, 6)	3.90575267144449
  (942, 5)	3.915156091040422
  (942, 4)	3.404753485382939
  (942, 3)	3.638773144205621
  (942, 2)	3.148074673683571
  (942, 1)	3.3368812201072022
  (942, 0)	3.969972575969889
this is the 211 epoch
rmse loss on training set is 0.9216051345044567
rmse loss on test set is 0.9414010795178219
for this epoch using 77.31771802902222 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.249545473520447
  (0, 1680)	3.2722942529580017
  (0, 1679)	3.18437843377777
  (0, 1678)	3.2529558623515866
  (0, 1677)	3.115801005203965
  (0, 1676)	3.25985439923462
  (0, 1675)	3.2573994658266154
  (0, 1674)	3.2573994658266154
  (0, 1673)	3.2573994658266154
  (0, 1672)	3.214111696710804
  (0, 1671)	3.1555558763504634
  (0, 1670)	3.2573994658266154
  (0, 1669)	3.2573994658266154
  (0, 1668)	3.2139225810268384
  (0, 1667)	3.2573994658266154
  (0, 1666)	3.2573994658266154
  (0, 1665)	3.2139225810268384
  (0, 1664)	3.2573994658266154
  (0, 1663)	3.186414327359888
  (0, 1662)	3.2139225810268384
  (0, 1661)	3.2048550041630546
  (0, 1660)	3.103405373132406
  (0, 1659)	3.1347113405590727
  (0, 1658)	3.2573994658266154
  (0, 1657)	3.278109557131631
  :	:
  (942, 24)	3.5784492733890336
  (942, 23)	3.5679374246864177
  (942, 22)	4.274584023154421
  (942, 21)	4.30124767133861
  (942, 20)	2.837519264725554
  (942, 19)	3.7046732829966236
  (942, 18)	4.045786203275465
  (942, 17)	3.1948524767403996
  (942, 16)	3.2230420065609455
  (942, 15)	3.481191336525741
  (942, 14)	3.8360859540850445
  (942, 13)	4.108236489746122
  (942, 12)	3.4948441432903548
  (942, 11)	4.482488304232642
  (942, 10)	3.978370195388005
  (942, 9)	3.9237402049280505
  (942, 8)	4.015071000628543
  (942, 7)	4.137498991069168
  (942, 6)	3.9057474444510674
  (942, 5)	3.916752036835326
  (942, 4)	3.404797204693645
  (942, 3)	3.6389306280151037
  (942, 2)	3.1480624832755657
  (942, 1)	3.3369757397046333
  (942, 0)	3.9699742390363513
this is the 212 epoch
rmse loss on training set is 0.9215669034054883
rmse loss on test set is 0.9413761281401829
for this epoch using 77.42136001586914 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2494352457980398
  (0, 1680)	3.2722903236247274
  (0, 1679)	3.183959770255412
  (0, 1678)	3.252847570532963
  (0, 1677)	3.1150719699778677
  (0, 1676)	3.2597949697790836
  (0, 1675)	3.2573143321117155
  (0, 1674)	3.2573143321117155
  (0, 1673)	3.2573143321117155
  (0, 1672)	3.213803354531659
  (0, 1671)	3.1550775674518143
  (0, 1670)	3.2573143321117155
  (0, 1669)	3.2573143321117155
  (0, 1668)	3.213649655181065
  (0, 1667)	3.2573143321117155
  (0, 1666)	3.2573143321117155
  (0, 1665)	3.213649655181065
  (0, 1664)	3.2573143321117155
  (0, 1663)	3.1860287450035125
  (0, 1662)	3.213649655181065
  (0, 1661)	3.204560924565714
  (0, 1660)	3.1026426087563457
  (0, 1659)	3.1340988913146623
  (0, 1658)	3.2573143321117155
  (0, 1657)	3.2781456273450957
  :	:
  (942, 24)	3.5784589520187375
  (942, 23)	3.567911463703543
  (942, 22)	4.274845839508574
  (942, 21)	4.3014155380729004
  (942, 20)	2.8374520497447926
  (942, 19)	3.7049692409837176
  (942, 18)	4.046251463603022
  (942, 17)	3.1946305945486464
  (942, 16)	3.2230645047358553
  (942, 15)	3.48158431768218
  (942, 14)	3.8360237647137256
  (942, 13)	4.108335253292722
  (942, 12)	3.494933090721752
  (942, 11)	4.482658391779444
  (942, 10)	3.9784858212452745
  (942, 9)	3.92397503587303
  (942, 8)	4.015090500673018
  (942, 7)	4.137660894883261
  (942, 6)	3.9057406965054438
  (942, 5)	3.9183375882335714
  (942, 4)	3.404839005850358
  (942, 3)	3.6390852326006136
  (942, 2)	3.148049275639593
  (942, 1)	3.337067958011563
  (942, 0)	3.969974280068005
this is the 213 epoch
rmse loss on training set is 0.9215290586306235
rmse loss on test set is 0.9413515231204738
for this epoch using 77.29625415802002 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.249325876747155
  (0, 1680)	3.2722871761874215
  (0, 1679)	3.1835419728885723
  (0, 1678)	3.2527400514982703
  (0, 1677)	3.114343894278886
  (0, 1676)	3.259736353006798
  (0, 1675)	3.2572299804396905
  (0, 1674)	3.2572299804396905
  (0, 1673)	3.2572299804396905
  (0, 1672)	3.213495991240316
  (0, 1671)	3.154600414543895
  (0, 1670)	3.2572299804396905
  (0, 1669)	3.2572299804396905
  (0, 1668)	3.213377526501991
  (0, 1667)	3.2572299804396905
  (0, 1666)	3.2572299804396905
  (0, 1665)	3.213377526501991
  (0, 1664)	3.2572299804396905
  (0, 1663)	3.185644170233194
  (0, 1662)	3.213377526501991
  (0, 1661)	3.2042678497781845
  (0, 1660)	3.101880930606919
  (0, 1659)	3.1334875652890166
  (0, 1658)	3.2572299804396905
  (0, 1657)	3.278182444314676
  :	:
  (942, 24)	3.5784671045111516
  (942, 23)	3.567884319199432
  (942, 22)	4.275103780307931
  (942, 21)	4.301580202394967
  (942, 20)	2.8373853684638957
  (942, 19)	3.7052599909553066
  (942, 18)	4.04670923728774
  (942, 17)	3.1944084637738515
  (942, 16)	3.2230858202699486
  (942, 15)	3.4819730310904813
  (942, 14)	3.835960577861043
  (942, 13)	4.108431601361872
  (942, 12)	3.4950198676859285
  (942, 11)	4.482825321118654
  (942, 10)	3.978598856033378
  (942, 9)	3.9242052826105223
  (942, 8)	4.015108232959942
  (942, 7)	4.137819743301032
  (942, 6)	3.90573246592389
  (942, 5)	3.9199128312453047
  (942, 4)	3.4048789308744816
  (942, 3)	3.6392370078960794
  (942, 2)	3.148035074838146
  (942, 1)	3.3371579189795937
  (942, 0)	3.969972737983207
this is the 214 epoch
rmse loss on training set is 0.9214915947553467
rmse loss on test set is 0.9413272593624604
for this epoch using 76.96572184562683 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2492173568371694
  (0, 1680)	3.2722848015216477
  (0, 1679)	3.183125032578277
  (0, 1678)	3.252633296228204
  (0, 1677)	3.1136167689283565
  (0, 1676)	3.2596785396133328
  (0, 1675)	3.2571464018498917
  (0, 1674)	3.2571464018498917
  (0, 1673)	3.2571464018498917
  (0, 1672)	3.2131895976213793
  (0, 1671)	3.154124406634496
  (0, 1670)	3.2571464018498917
  (0, 1669)	3.2571464018498917
  (0, 1668)	3.2131061860969523
  (0, 1667)	3.2571464018498917
  (0, 1666)	3.2571464018498917
  (0, 1665)	3.2131061860969523
  (0, 1664)	3.2571464018498917
  (0, 1663)	3.185260593357907
  (0, 1662)	3.2131061860969523
  (0, 1661)	3.2039757700488214
  (0, 1660)	3.101120328703179
  (0, 1659)	3.132877352154952
  (0, 1658)	3.2571464018498917
  (0, 1657)	3.278219998351679
  :	:
  (942, 24)	3.5784737664243265
  (942, 23)	3.567856023213573
  (942, 22)	4.275357906945175
  (942, 21)	4.301741720704394
  (942, 20)	2.837319209270114
  (942, 19)	3.7055456226327945
  (942, 18)	4.047159649657519
  (942, 17)	3.19418611035352
  (942, 16)	3.2231059779202544
  (942, 15)	3.4823575309699755
  (942, 14)	3.835896425407709
  (942, 13)	4.108525582303951
  (942, 12)	3.4951045158917
  (942, 11)	4.4829891472465
  (942, 10)	3.9787093476789046
  (942, 9)	3.9244310356190075
  (942, 8)	4.0151242378901
  (942, 7)	4.137975589379522
  (942, 6)	3.905722790264771
  (942, 5)	3.921477850947369
  (942, 4)	3.404917020955734
  (942, 3)	3.6393860029844367
  (942, 2)	3.1480199045289976
  (942, 1)	3.3372456657797107
  (942, 0)	3.9699696509598867
this is the 215 epoch
rmse loss on training set is 0.92145450645082
rmse loss on test set is 0.9413033318586699
for this epoch using 77.87620496749878 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2491096766792644
  (0, 1680)	3.272283190640257
  (0, 1679)	3.1827089403635056
  (0, 1678)	3.2525272958403555
  (0, 1677)	3.112890584886668
  (0, 1676)	3.2596215204344854
  (0, 1675)	3.257063587517119
  (0, 1674)	3.257063587517119
  (0, 1673)	3.257063587517119
  (0, 1672)	3.212884164580693
  (0, 1671)	3.1536495328919734
  (0, 1670)	3.257063587517119
  (0, 1669)	3.257063587517119
  (0, 1668)	3.2128356252094936
  (0, 1667)	3.257063587517119
  (0, 1666)	3.257063587517119
  (0, 1665)	3.2128356252094936
  (0, 1664)	3.257063587517119
  (0, 1663)	3.184878004830449
  (0, 1662)	3.2128356252094936
  (0, 1661)	3.20368467576615
  (0, 1660)	3.1003607932124084
  (0, 1659)	3.132268241736626
  (0, 1658)	3.257063587517119
  (0, 1657)	3.2782582799168796
  :	:
  (942, 24)	3.578478972641181
  (942, 23)	3.5678266071295313
  (942, 22)	4.275608279802247
  (942, 21)	4.3019001484409385
  (942, 20)	2.837253560924193
  (942, 19)	3.7058262242495252
  (942, 18)	4.047602823904241
  (942, 17)	3.193963559648429
  (942, 16)	3.223125002014317
  (942, 15)	3.482737870773866
  (942, 14)	3.8358313385745686
  (942, 13)	4.108617243560796
  (942, 12)	3.4951870762998167
  (942, 11)	4.483149924227343
  (942, 10)	3.978817343276658
  (942, 9)	3.924652383563548
  (942, 8)	4.015138555098946
  (942, 7)	4.1381284852913325
  (942, 6)	3.9057117063423687
  (942, 5)	3.923032731495456
  (942, 4)	3.4049533164683714
  (942, 3)	3.639532266111934
  (942, 2)	3.1480037879703926
  (942, 1)	3.337331240815338
  (942, 0)	3.969965056448443
this is the 216 epoch
rmse loss on training set is 0.9214177884818594
rmse loss on test set is 0.9412797356884891
for this epoch using 77.32175779342651 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.24900282702351
  (0, 1680)	3.2722823346905257
  (0, 1679)	3.182293687418387
  (0, 1678)	3.2524220415863554
  (0, 1677)	3.1121653332504278
  (0, 1676)	3.259565286443349
  (0, 1675)	3.2569815287488195
  (0, 1674)	3.2569815287488195
  (0, 1673)	3.2569815287488195
  (0, 1672)	3.212579683143058
  (0, 1671)	3.1531757826420685
  (0, 1670)	3.2569815287488195
  (0, 1669)	3.2569815287488195
  (0, 1668)	3.2125658352165476
  (0, 1667)	3.2569815287488195
  (0, 1666)	3.2569815287488195
  (0, 1665)	3.2125658352165476
  (0, 1664)	3.2569815287488195
  (0, 1663)	3.1844963952445626
  (0, 1662)	3.2125658352165476
  (0, 1661)	3.2033945574560185
  (0, 1660)	3.099602314447037
  (0, 1659)	3.131660224006483
  (0, 1658)	3.2569815287488195
  (0, 1657)	3.278297279617371
  :	:
  (942, 24)	3.578482757381485
  (942, 23)	3.5677961016877764
  (942, 22)	4.275854958268121
  (942, 21)	4.302055540100255
  (942, 20)	2.837188412548868
  (942, 19)	3.7061018825743637
  (942, 18)	4.048038881120731
  (942, 17)	3.193740836453585
  (942, 16)	3.2231429164568675
  (942, 15)	3.4831141032006556
  (942, 14)	3.8357653479348386
  (942, 13)	4.108706631683173
  (942, 12)	3.4952675891360023
  (942, 11)	4.483307705209148
  (942, 10)	3.97892288910357
  (942, 9)	3.924869413332882
  (942, 8)	4.01515122347038
  (942, 7)	4.138278482338655
  (942, 6)	3.905699250240402
  (942, 5)	3.924577556135973
  (942, 4)	3.4049878569869523
  (942, 3)	3.639675844702233
  (942, 2)	3.147986748026226
  (942, 1)	3.3374146857351166
  (942, 0)	3.9699589911843742
this is the 217 epoch
rmse loss on training set is 0.9213814357049307
rmse loss on test set is 0.9412564660163326
for this epoch using 77.20244598388672 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2488967987561272
  (0, 1680)	3.2722822249515437
  (0, 1679)	3.1818792650495347
  (0, 1678)	3.2523175248492913
  (0, 1677)	3.1114410052497767
  (0, 1676)	3.259509828747614
  (0, 1675)	3.2569002169824395
  (0, 1674)	3.2569002169824395
  (0, 1673)	3.2569002169824395
  (0, 1672)	3.212276144450143
  (0, 1671)	3.1527031453648897
  (0, 1670)	3.2569002169824395
  (0, 1669)	3.2569002169824395
  (0, 1668)	3.212296807625758
  (0, 1667)	3.2569002169824395
  (0, 1666)	3.2569002169824395
  (0, 1665)	3.212296807625758
  (0, 1664)	3.2569002169824395
  (0, 1663)	3.1841157553321957
  (0, 1662)	3.212296807625758
  (0, 1661)	3.203105405778921
  (0, 1660)	3.0988448828618727
  (0, 1659)	3.1310532890823706
  (0, 1658)	3.2569002169824395
  (0, 1657)	3.278336988203699
  :	:
  (942, 24)	3.5784851542136127
  (942, 23)	3.5677645369983133
  (942, 22)	4.276098000756081
  (942, 21)	4.302207949249428
  (942, 20)	2.837123753617695
  (942, 19)	3.706372682934989
  (942, 18)	4.048467940336977
  (942, 17)	3.1935179650089363
  (942, 16)	3.2231597447363636
  (942, 15)	3.483486280205412
  (942, 14)	3.835698483426063
  (942, 13)	4.108793792347875
  (942, 12)	3.495346093903497
  (942, 11)	4.48346254243875
  (942, 10)	3.9790260306323364
  (942, 9)	3.9250822100756304
  (942, 8)	4.015162281150088
  (942, 7)	4.138425630967223
  (942, 6)	3.905685457325375
  (942, 5)	3.926112407217898
  (942, 4)	3.4050206813019495
  (942, 3)	3.6398167853702583
  (942, 2)	3.1479688071711576
  (942, 1)	3.3374960414455828
  (942, 0)	3.969951491200764
this is the 218 epoch
rmse loss on training set is 0.9213454430662235
rmse loss on test set is 0.9412335180898999
for this epoch using 77.12971210479736 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2487915828968146
  (0, 1680)	3.272282852831499
  (0, 1679)	3.181465664693373
  (0, 1678)	3.252213737141024
  (0, 1677)	3.110717592245726
  (0, 1676)	3.2594551385868584
  (0, 1675)	3.256819643782854
  (0, 1674)	3.256819643782854
  (0, 1673)	3.256819643782854
  (0, 1672)	3.211973539758313
  (0, 1671)	3.1522316106920028
  (0, 1670)	3.256819643782854
  (0, 1669)	3.256819643782854
  (0, 1668)	3.2120285340728016
  (0, 1667)	3.256819643782854
  (0, 1666)	3.256819643782854
  (0, 1665)	3.2120285340728016
  (0, 1664)	3.256819643782854
  (0, 1663)	3.183736075960784
  (0, 1662)	3.2120285340728016
  (0, 1661)	3.202817211527338
  (0, 1660)	3.0980884890512206
  (0, 1659)	3.1304474272247083
  (0, 1658)	3.256819643782854
  (0, 1657)	3.2783773965669116
  :	:
  (942, 24)	3.5784861960660828
  (942, 23)	3.567731942553021
  (942, 22)	4.276337464720806
  (942, 21)	4.302357428542253
  (942, 20)	2.837059573944239
  (942, 19)	3.706638709240789
  (942, 18)	4.0488901185558435
  (942, 17)	3.1932949690099526
  (942, 16)	3.2231755099314685
  (942, 15)	3.483854453010909
  (942, 14)	3.8356307743618587
  (942, 13)	4.108878770374423
  (942, 12)	3.49542262939569
  (942, 11)	4.483614487276928
  (942, 10)	3.979126812544971
  (942, 9)	3.9252908572358693
  (942, 8)	4.015171765558835
  (942, 7)	4.1385699807799226
  (942, 6)	3.9056703622596616
  (942, 5)	3.9276373662043795
  (942, 4)	3.4050518274348924
  (942, 3)	3.6399551339358687
  (942, 2)	3.1479499874957297
  (942, 1)	3.3375753481236434
  (942, 0)	3.9699425918405407
this is the 219 epoch
rmse loss on training set is 0.9213098055997232
rmse loss on test set is 0.9412108872383969
for this epoch using 78.9707019329071 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.248687170596098
  (0, 1680)	3.2722842098651785
  (0, 1679)	3.181052877913622
  (0, 1678)	3.252110670099657
  (0, 1677)	3.1099950857275998
  (0, 1676)	3.2594012073298977
  (0, 1675)	3.256739800839758
  (0, 1674)	3.256739800839758
  (0, 1673)	3.256739800839758
  (0, 1672)	3.2116718604366423
  (0, 1671)	3.1517611684034708
  (0, 1670)	3.256739800839758
  (0, 1669)	3.256739800839758
  (0, 1668)	3.211761006318859
  (0, 1667)	3.256739800839758
  (0, 1666)	3.256739800839758
  (0, 1665)	3.211761006318859
  (0, 1664)	3.256739800839758
  (0, 1663)	3.1833573481305932
  (0, 1662)	3.211761006318859
  (0, 1661)	3.2025299656231803
  (0, 1660)	3.0973331237461768
  (0, 1659)	3.1298426288336683
  (0, 1658)	3.256739800839758
  (0, 1657)	3.2784184957357794
  :	:
  (942, 24)	3.578485915238933
  (942, 23)	3.5676983472377857
  (942, 22)	4.2765734066749825
  (942, 21)	4.30250402973422
  (942, 20)	2.836995863671491
  (942, 19)	3.7069000440053963
  (942, 18)	4.049305530788041
  (942, 17)	3.193071871617964
  (942, 16)	3.223190234717449
  (942, 15)	3.484218672118478
  (942, 14)	3.8355622494434862
  (942, 13)	4.108961609741459
  (942, 12)	3.4954972337083063
  (942, 11)	4.483763590213114
  (942, 10)	3.9792252787459725
  (942, 9)	3.925495436587961
  (942, 8)	4.015179713405413
  (942, 7)	4.138711580550324
  (942, 6)	3.9056539990143637
  (942, 5)	3.929152513684171
  (942, 4)	3.4050813326534017
  (942, 3)	3.640090935437268
  (942, 2)	3.147930310711455
  (942, 1)	3.3376526452287854
  (942, 0)	3.9699323277685212
this is the 220 epoch
rmse loss on training set is 0.9212745184253657
rmse loss on test set is 0.9411885688708828
for this epoch using 78.49472427368164 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.248583553132783
  (0, 1680)	3.272286287711414
  (0, 1679)	3.180640896398773
  (0, 1678)	3.252008315487048
  (0, 1677)	3.109273477310494
  (0, 1676)	3.259348026472215
  (0, 1675)	3.2566606799652615
  (0, 1674)	3.2566606799652615
  (0, 1673)	3.2566606799652615
  (0, 1672)	3.2113710979648395
  (0, 1671)	3.1512918084250674
  (0, 1670)	3.2566606799652615
  (0, 1669)	3.2566606799652615
  (0, 1668)	3.2114942162480915
  (0, 1667)	3.2566606799652615
  (0, 1666)	3.2566606799652615
  (0, 1665)	3.2114942162480915
  (0, 1664)	3.2566606799652615
  (0, 1663)	3.1829795629721973
  (0, 1662)	3.2114942162480915
  (0, 1661)	3.2022436591152714
  (0, 1660)	3.096578777811948
  (0, 1659)	3.1292388844465164
  (0, 1658)	3.2566606799652615
  (0, 1657)	3.278460276874024
  :	:
  (942, 24)	3.578484343414917
  (942, 23)	3.567663779344297
  (942, 22)	4.276805882205689
  (942, 21)	4.302647803697384
  (942, 20)	2.8369326132616575
  (942, 19)	3.7071567683689706
  (942, 18)	4.0497142900865795
  (942, 17)	3.1928486954703015
  (942, 16)	3.2232039413724562
  (942, 15)	3.4845789873188813
  (942, 14)	3.8354929367712733
  (942, 13)	4.109042353602766
  (942, 12)	3.495569944251526
  (942, 11)	4.483909900879921
  (942, 10)	3.979321472375413
  (942, 9)	3.925696028270637
  (942, 8)	4.015186160699384
  (942, 7)	4.138850478235902
  (942, 6)	3.905636400881913
  (942, 5)	3.9306579293829813
  (942, 4)	3.4051092334857143
  (942, 3)	3.6402242341441418
  (942, 2)	3.1479097981558217
  (942, 1)	3.3377279715152524
  (942, 0)	3.9699207329832356
this is the 221 epoch
rmse loss on training set is 0.9212395767472871
rmse loss on test set is 0.941166558474586
for this epoch using 80.061763048172 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.248480721911478
  (0, 1680)	3.272289078150699
  (0, 1679)	3.180229711959635
  (0, 1678)	3.2519066651863837
  (0, 1677)	3.10855275873288
  (0, 1676)	3.259295587633531
  (0, 1675)	3.2565822730914458
  (0, 1674)	3.2565822730914458
  (0, 1673)	3.2565822730914458
  (0, 1672)	3.21107124393139
  (0, 1671)	3.1508235208255635
  (0, 1670)	3.2565822730914458
  (0, 1669)	3.2565822730914458
  (0, 1668)	3.2112281558652156
  (0, 1667)	3.2565822730914458
  (0, 1666)	3.2565822730914458
  (0, 1665)	3.2112281558652156
  (0, 1664)	3.2565822730914458
  (0, 1663)	3.182602711743938
  (0, 1662)	3.2112281558652156
  (0, 1661)	3.2019582831768862
  (0, 1660)	3.0958254422452636
  (0, 1659)	3.128636184734955
  (0, 1658)	3.2565822730914458
  (0, 1657)	3.278502731277679
  :	:
  (942, 24)	3.5784815116703714
  (942, 23)	3.5676282665816337
  (942, 22)	4.277034945990322
  (942, 21)	4.302788800434926
  (942, 20)	2.836869813486224
  (942, 19)	3.707408962120091
  (942, 18)	4.050116507580514
  (942, 17)	3.1926254626903234
  (942, 16)	3.22321665178374
  (942, 15)	3.4849354477028243
  (942, 14)	3.835422863855653
  (942, 13)	4.109121044302872
  (942, 12)	3.495640797761856
  (942, 11)	4.4840534680675255
  (942, 10)	3.9794154358217257
  (942, 9)	3.925892710820306
  (942, 8)	4.01519114276365
  (942, 7)	4.138986720991173
  (942, 6)	3.9056176004886187
  (942, 5)	3.9321536921745945
  (942, 4)	3.405135565735124
  (942, 3)	3.6403550735707166
  (942, 2)	3.1478884707973447
  (942, 1)	3.3378013650438527
  (942, 0)	3.96990784082869
this is the 222 epoch
rmse loss on training set is 0.92120497585201
rmse loss on test set is 0.9411448516133403
for this epoch using 78.38313913345337 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2483786684601226
  (0, 1680)	3.272292573082786
  (0, 1679)	3.179819316526999
  (0, 1678)	3.2518057111998306
  (0, 1677)	3.1078329218541696
  (0, 1676)	3.2592438825552907
  (0, 1675)	3.256504572268027
  (0, 1674)	3.256504572268027
  (0, 1673)	3.256504572268027
  (0, 1672)	3.210772290031577
  (0, 1671)	3.1503562958139946
  (0, 1670)	3.256504572268027
  (0, 1669)	3.256504572268027
  (0, 1668)	3.2109628172931104
  (0, 1667)	3.256504572268027
  (0, 1666)	3.256504572268027
  (0, 1665)	3.2109628172931104
  (0, 1664)	3.256504572268027
  (0, 1663)	3.1822267858295286
  (0, 1662)	3.2109628172931104
  (0, 1661)	3.2016738291034184
  (0, 1660)	3.0950731081718312
  (0, 1659)	3.1280345205025597
  (0, 1658)	3.256504572268027
  (0, 1657)	3.2785458503724607
  :	:
  (942, 24)	3.5784774504861008
  (942, 23)	3.567591836087686
  (942, 22)	4.277260651812355
  (942, 21)	4.302927069095476
  (942, 20)	2.8368074554162495
  (942, 19)	3.707656703717306
  (942, 18)	4.05051229250824
  (942, 17)	3.1924021948971646
  (942, 16)	3.2232283874537524
  (942, 15)	3.4852881016714594
  (942, 14)	3.8353520576282367
  (942, 13)	4.109197723392442
  (942, 12)	3.4957098303138405
  (942, 11)	4.484194339737629
  (942, 10)	3.9795072107343623
  (942, 9)	3.9260855612038186
  (942, 8)	4.015194694246689
  (942, 7)	4.139120355180498
  (942, 6)	3.905597629806695
  (942, 5)	3.9336398800919046
  (942, 4)	3.4051603644940327
  (942, 3)	3.640483496488439
  (942, 2)	3.1478663492405303
  (942, 1)	3.337872863193802
  (942, 0)	3.969893684005753
this is the 223 epoch
rmse loss on training set is 0.921170711106749
rmse loss on test set is 0.9411234439259624
for this epoch using 78.87305521965027 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2482773844276775
  (0, 1680)	3.272296764524368
  (0, 1679)	3.179409702149318
  (0, 1678)	3.251705445646236
  (0, 1677)	3.107113958652412
  (0, 1676)	3.259192903098367
  (0, 1675)	3.2564275696600857
  (0, 1674)	3.2564275696600857
  (0, 1673)	3.2564275696600857
  (0, 1672)	3.2104742280656846
  (0, 1671)	3.149890123737076
  (0, 1670)	3.2564275696600857
  (0, 1669)	3.2564275696600857
  (0, 1668)	3.210698192770518
  (0, 1667)	3.2564275696600857
  (0, 1666)	3.2564275696600857
  (0, 1665)	3.210698192770518
  (0, 1664)	3.2564275696600857
  (0, 1663)	3.1818517767356242
  (0, 1662)	3.210698192770518
  (0, 1661)	3.2013902883100296
  (0, 1660)	3.0943217668438927
  (0, 1659)	3.1274338826822863
  (0, 1658)	3.2564275696600857
  (0, 1657)	3.2785896257112372
  :	:
  (942, 24)	3.5784721897579304
  (942, 23)	3.5675545144402467
  (942, 22)	4.277483052576672
  (942, 21)	4.303062657987302
  (942, 20)	2.8367455304130225
  (942, 19)	3.7079000703104166
  (942, 18)	4.050901752250092
  (942, 17)	3.192178913215373
  (942, 16)	3.2232391695061913
  (942, 15)	3.485636996946679
  (942, 14)	3.8352805444525067
  (942, 13)	4.1092724316432685
  (942, 12)	3.495777077331525
  (942, 11)	4.484332563037307
  (942, 10)	3.97959683803613
  (942, 9)	3.9262746548504532
  (942, 8)	4.015196849134693
  (942, 7)	4.139251426390909
  (942, 6)	3.905576520166409
  (942, 5)	3.93511657033772
  (942, 4)	3.4051836641577244
  (942, 3)	3.640609544938567
  (942, 2)	3.1478434537308035
  (942, 1)	3.33794250267418
  (942, 0)	3.969878294583484
this is the 224 epoch
rmse loss on training set is 0.9211367779577204
rmse loss on test set is 0.9411023311247774
for this epoch using 78.0227620601654 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2481768615817694
  (0, 1680)	3.272301644606857
  (0, 1679)	3.1790008609904334
  (0, 1678)	3.2516058607588554
  (0, 1677)	3.106395861222017
  (0, 1676)	3.259142641240697
  (0, 1675)	3.2563512575457962
  (0, 1674)	3.2563512575457962
  (0, 1673)	3.2563512575457962
  (0, 1672)	3.210177049937142
  (0, 1671)	3.1494249950766435
  (0, 1670)	3.2563512575457962
  (0, 1669)	3.2563512575457962
  (0, 1668)	3.210434274649797
  (0, 1667)	3.2563512575457962
  (0, 1666)	3.2563512575457962
  (0, 1665)	3.210434274649797
  (0, 1664)	3.2563512575457962
  (0, 1663)	3.181477676089545
  (0, 1662)	3.210434274649797
  (0, 1661)	3.2011076523293696
  (0, 1660)	3.0935714096377533
  (0, 1659)	3.1268342623340204
  (0, 1658)	3.2563512575457962
  (0, 1657)	3.278634048971552
  :	:
  (942, 24)	3.578465758807091
  (942, 23)	3.567516327667924
  (942, 22)	4.2777022003246445
  (942, 21)	4.3031956145921795
  (942, 20)	2.8366840301189336
  (942, 19)	3.708139137761418
  (942, 18)	4.0512849923604
  (942, 17)	3.191955638284354
  (942, 16)	3.223249018691932
  (942, 15)	3.4859821805811815
  (942, 14)	3.8352083501344665
  (942, 13)	4.109345209062971
  (942, 12)	3.4958425735998007
  (942, 11)	4.484468184312644
  (942, 10)	3.979684357935515
  (942, 9)	3.9264600656832513
  (942, 8)	4.015197640763434
  (942, 7)	4.139379979444448
  (942, 6)	3.9055543022677788
  (942, 5)	3.9365838392954764
  (942, 4)	3.4052054984379025
  (942, 3)	3.6407332602444984
  (942, 2)	3.1478198041594294
  (942, 1)	3.3380103195353565
  (942, 0)	3.969861704010236
this is the 225 epoch
rmse loss on training set is 0.9211031719285845
rmse loss on test set is 0.9410815089940995
for this epoch using 78.98411512374878 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2480770918064614
  (0, 1680)	3.27230720557416
  (0, 1679)	3.178592785327387
  (0, 1678)	3.251506948883209
  (0, 1677)	3.1056786217715624
  (0, 1676)	3.259093089075077
  (0, 1675)	3.2562756283142984
  (0, 1674)	3.2562756283142984
  (0, 1673)	3.2562756283142984
  (0, 1672)	3.209880747650808
  (0, 1671)	3.148960900447141
  (0, 1670)	3.2562756283142984
  (0, 1669)	3.2562756283142984
  (0, 1668)	3.210171055394693
  (0, 1667)	3.2562756283142984
  (0, 1666)	3.2562756283142984
  (0, 1665)	3.210171055394693
  (0, 1664)	3.2562756283142984
  (0, 1663)	3.181104475636977
  (0, 1662)	3.210171055394693
  (0, 1661)	3.2008259128093925
  (0, 1660)	3.0928220280515024
  (0, 1659)	3.1262356506421676
  (0, 1658)	3.2562756283142984
  (0, 1657)	3.2786791119532155
  :	:
  (942, 24)	3.578458186390493
  (942, 23)	3.5674773012607903
  (942, 22)	4.27791814624894
  (942, 21)	4.303325985579123
  (942, 20)	2.836622946448599
  (942, 19)	3.7083739806650824
  (942, 18)	4.051662116599024
  (942, 17)	3.1917323902676054
  (942, 16)	3.2232579553949314
  (942, 15)	3.486323698968546
  (942, 14)	3.8351354999329517
  (942, 13)	4.109416094909423
  (942, 12)	3.4959063532754797
  (942, 11)	4.484601249122085
  (942, 10)	3.9797698099385768
  (942, 9)	3.9266418661497258
  (942, 8)	4.015197101829914
  (942, 7)	4.139506058410648
  (942, 6)	3.905531006192198
  (942, 5)	3.938041762539822
  (942, 4)	3.4052259003759726
  (942, 3)	3.640854683023892
  (942, 2)	3.147795420068378
  (942, 1)	3.3380763491802017
  (942, 0)	3.969843943124584
this is the 226 epoch
rmse loss on training set is 0.9210698886187478
rmse loss on test set is 0.9410609733887749
for this epoch using 78.43554878234863 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.247978067100066
  (0, 1680)	3.272313439780559
  (0, 1679)	3.1781854675482686
  (0, 1678)	3.2514087024749183
  (0, 1677)	3.1049622326216237
  (0, 1676)	3.259044238806946
  (0, 1675)	3.256200674463577
  (0, 1674)	3.256200674463577
  (0, 1673)	3.256200674463577
  (0, 1672)	3.2095853133112358
  (0, 1671)	3.1484978305932487
  (0, 1670)	3.256200674463577
  (0, 1669)	3.256200674463577
  (0, 1668)	3.209908527578238
  (0, 1667)	3.256200674463577
  (0, 1666)	3.256200674463577
  (0, 1665)	3.209908527578238
  (0, 1664)	3.256200674463577
  (0, 1663)	3.1807321672398126
  (0, 1662)	3.209908527578238
  (0, 1661)	3.2005450615112463
  (0, 1660)	3.0920736137026954
  (0, 1659)	3.1256380389134075
  (0, 1658)	3.256200674463577
  (0, 1657)	3.2787248065759673
  :	:
  (942, 24)	3.578449500710778
  (942, 23)	3.5674374601808876
  (942, 22)	4.278130940707975
  (942, 21)	4.3034538168178464
  (942, 20)	2.836562271580297
  (942, 19)	3.7086046723693307
  (942, 18)	4.052033226962309
  (942, 17)	3.1915091888618634
  (942, 16)	3.2232659996379605
  (942, 15)	3.4866615978529785
  (942, 14)	3.835062018569936
  (942, 13)	4.109485127704765
  (942, 12)	3.4959684498982586
  (942, 11)	4.484731802249591
  (942, 10)	3.9798532328608744
  (942, 9)	3.926820127251896
  (942, 8)	4.015195264403832
  (942, 7)	4.139629706618543
  (942, 6)	3.9055066614137615
  (942, 5)	3.9394904148469525
  (942, 4)	3.4052449023560243
  (942, 3)	3.6409738532006295
  (942, 2)	3.147770320655163
  (942, 1)	3.3381406263750795
  (942, 0)	3.969825042166053
this is the 227 epoch
rmse loss on training set is 0.9210369237018913
rmse loss on test set is 0.9410407202327846
for this epoch using 78.8973958492279 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2478797795729726
  (0, 1680)	3.2723203396885996
  (0, 1679)	3.177778900150163
  (0, 1678)	3.2513111140976596
  (0, 1677)	3.104246686202668
  (0, 1676)	3.2589960827522573
  (0, 1675)	3.256126388598364
  (0, 1674)	3.256126388598364
  (0, 1673)	3.256126388598364
  (0, 1672)	3.209290739120953
  (0, 1671)	3.1480357763874203
  (0, 1670)	3.256126388598364
  (0, 1669)	3.256126388598364
  (0, 1668)	3.209646683880642
  (0, 1667)	3.256126388598364
  (0, 1666)	3.256126388598364
  (0, 1665)	3.209646683880642
  (0, 1664)	3.256126388598364
  (0, 1663)	3.180360742873932
  (0, 1662)	3.209646683880642
  (0, 1661)	3.200265090307088
  (0, 1660)	3.091326158326087
  (0, 1659)	3.1250414185743254
  (0, 1658)	3.256126388598364
  (0, 1657)	3.2787711248771494
  :	:
  (942, 24)	3.578439729426147
  (942, 23)	3.567396828872462
  (942, 22)	4.27834063324018
  (942, 21)	4.303579153392054
  (942, 20)	2.83650199794759
  (942, 19)	3.7088312849951746
  (942, 18)	4.052398423713504
  (942, 17)	3.191286053305993
  (942, 16)	3.2232731710883535
  (942, 15)	3.486995922339037
  (942, 14)	3.8349879302404837
  (942, 13)	4.109552345249263
  (942, 12)	3.496028896401477
  (942, 11)	4.484859887717601
  (942, 10)	3.979934664839012
  (942, 9)	3.9269949185757937
  (942, 8)	4.015192159938823
  (942, 7)	4.139750966668677
  (942, 6)	3.9054812968105197
  (942, 5)	3.9409298702049522
  (942, 4)	3.4052625361176077
  (942, 3)	3.641090810016507
  (942, 2)	3.1477445247776163
  (942, 1)	3.3382031852607468
  (942, 0)	3.969805030785696
this is the 228 epoch
rmse loss on training set is 0.9210042729244263
rmse loss on test set is 0.9410207455178313
for this epoch using 78.84521698951721 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.247782221445596
  (0, 1680)	3.2723278978670836
  (0, 1679)	3.177373075737045
  (0, 1678)	3.251214176421086
  (0, 1677)	3.103531975053014
  (0, 1676)	3.258948613335372
  (0, 1675)	3.2560527634281726
  (0, 1674)	3.2560527634281726
  (0, 1673)	3.2560527634281726
  (0, 1672)	3.20899701737891
  (0, 1671)	3.1475747288276454
  (0, 1670)	3.2560527634281726
  (0, 1669)	3.2560527634281726
  (0, 1668)	3.2093855170872554
  (0, 1667)	3.2560527634281726
  (0, 1666)	3.2560527634281726
  (0, 1665)	3.2093855170872554
  (0, 1664)	3.2560527634281726
  (0, 1663)	3.1799901946271736
  (0, 1662)	3.2093855170872554
  (0, 1661)	3.1999859911781154
  (0, 1660)	3.0905796537715085
  (0, 1659)	3.12444578116929
  (0, 1658)	3.2560527634281726
  (0, 1657)	3.2788180590094864
  :	:
  (942, 24)	3.5784288996601368
  (942, 23)	3.5673554312720186
  (942, 22)	4.278547272577907
  (942, 21)	4.303702039612523
  (942, 20)	2.8364421182312354
  (942, 19)	3.7090538894564995
  (942, 18)	4.052757805412638
  (942, 17)	3.1910630023897877
  (942, 16)	3.2232794890635854
  (942, 15)	3.4873267169011752
  (942, 14)	3.8349132586226355
  (942, 13)	4.109617784634854
  (942, 12)	3.496087725122648
  (942, 11)	4.484985548799719
  (942, 10)	3.9800141433421086
  (942, 9)	3.9271663083202135
  (942, 8)	4.015187819283579
  (942, 7)	4.139869880444881
  (942, 6)	3.905454940675374
  (942, 5)	3.942360201823879
  (942, 4)	3.4052788327682144
  (942, 3)	3.6412055920428172
  (942, 2)	3.147718050958664
  (942, 1)	3.3382640593630226
  (942, 0)	3.969783938056469
this is the 229 epoch
rmse loss on training set is 0.9209719321040188
rmse loss on test set is 0.9410010453020183
for this epoch using 79.58400273323059 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.247685385046316
  (0, 1680)	3.272336106989065
  (0, 1679)	3.1769679870178478
  (0, 1678)	3.251117882218901
  (0, 1677)	3.1028180918168005
  (0, 1676)	3.2589018230870574
  (0, 1675)	3.2559797917652675
  (0, 1674)	3.2559797917652675
  (0, 1673)	3.2559797917652675
  (0, 1672)	3.2087041404787793
  (0, 1671)	3.14711467903513
  (0, 1670)	3.2559797917652675
  (0, 1669)	3.2559797917652675
  (0, 1668)	3.209125020086589
  (0, 1667)	3.2559797917652675
  (0, 1666)	3.2559797917652675
  (0, 1665)	3.209125020086589
  (0, 1664)	3.2559797917652675
  (0, 1663)	3.179620514697223
  (0, 1662)	3.209125020086589
  (0, 1661)	3.1997077562125065
  (0, 1660)	3.089834092001692
  (0, 1659)	3.123851118358247
  (0, 1658)	3.2559797917652675
  (0, 1657)	3.2788656012389112
  :	:
  (942, 24)	3.578417038011145
  (942, 23)	3.5673132908181433
  (942, 22)	4.278750906661142
  (942, 21)	4.303822519029944
  (942, 20)	2.8363826253512854
  (942, 19)	3.709272555479376
  (942, 18)	4.053111468945909
  (942, 17)	3.190840054462545
  (942, 16)	3.2232849725368387
  (942, 15)	3.487654025393085
  (942, 14)	3.8348380268871103
  (942, 13)	4.109681482258322
  (942, 12)	3.496144967813897
  (942, 11)	4.4851088280333045
  (942, 10)	3.980091705183093
  (942, 9)	3.9273343633250146
  (942, 8)	4.015182272692636
  (942, 7)	4.139986489125836
  (942, 6)	3.905427620726938
  (942, 5)	3.9437814821457358
  (942, 4)	3.4052938227955516
  (942, 3)	3.64131823719165
  (942, 2)	3.147690917391038
  (942, 1)	3.3383232816033344
  (942, 0)	3.96976179248345
this is the 230 epoch
rmse loss on training set is 0.9209398971281708
rmse loss on test set is 0.9409816157084979
for this epoch using 77.33820390701294 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2475892628094734
  (0, 1680)	3.2723449598299075
  (0, 1679)	3.1765636268044743
  (0, 1678)	3.251022224366886
  (0, 1677)	3.102105029242069
  (0, 1676)	3.258855704642483
  (0, 1675)	3.255907466522824
  (0, 1674)	3.255907466522824
  (0, 1673)	3.255907466522824
  (0, 1672)	3.208412100907471
  (0, 1671)	3.1466556182521197
  (0, 1670)	3.255907466522824
  (0, 1669)	3.255907466522824
  (0, 1668)	3.2088651858683597
  (0, 1667)	3.255907466522824
  (0, 1666)	3.255907466522824
  (0, 1665)	3.2088651858683597
  (0, 1664)	3.255907466522824
  (0, 1663)	3.1792516953896452
  (0, 1662)	3.2088651858683597
  (0, 1661)	3.199430377603551
  (0, 1660)	3.089089465090206
  (0, 1659)	3.123257421914621
  (0, 1658)	3.255907466522824
  (0, 1657)	3.278913743942419
  :	:
  (942, 24)	3.5784041705617713
  (942, 23)	3.5672704304611886
  (942, 22)	4.278951582650901
  (942, 21)	4.303940634447588
  (942, 20)	2.8363235124594603
  (942, 19)	3.7094873516212834
  (942, 18)	4.053459509554509
  (942, 17)	3.1906172274415323
  (942, 16)	3.2232896401424616
  (942, 15)	3.487977891056994
  (942, 14)	3.834762257706764
  (942, 13)	4.109743473834321
  (942, 12)	3.496200655652171
  (942, 11)	4.485229767231711
  (942, 10)	3.980167386529671
  (942, 9)	3.92749914909873
  (942, 8)	4.015175549837085
  (942, 7)	4.140100833196531
  (942, 6)	3.9053993641201146
  (942, 5)	3.9451937828543406
  (942, 4)	3.405307536079551
  (942, 3)	3.6414287827271017
  (942, 2)	3.147663141941927
  (942, 1)	3.3383808843090663
  (942, 0)	3.969738622013935
this is the 231 epoch
rmse loss on training set is 0.9209081639527626
rmse loss on test set is 0.9409624529242279
for this epoch using 76.87202095985413 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2474938472734474
  (0, 1680)	3.2723544492653915
  (0, 1679)	3.1761599880099305
  (0, 1678)	3.2509271958410424
  (0, 1677)	3.101392780178825
  (0, 1676)	3.2588102507392653
  (0, 1675)	3.2558357807129994
  (0, 1674)	3.2558357807129994
  (0, 1673)	3.2558357807129994
  (0, 1672)	3.2081208912435546
  (0, 1671)	3.1461975378396905
  (0, 1670)	3.2558357807129994
  (0, 1669)	3.2558357807129994
  (0, 1668)	3.20860600752162
  (0, 1667)	3.2558357807129994
  (0, 1666)	3.2558357807129994
  (0, 1665)	3.20860600752162
  (0, 1664)	3.2558357807129994
  (0, 1663)	3.1788837291159067
  (0, 1662)	3.20860600752162
  (0, 1661)	3.1991538476476453
  (0, 1660)	3.088345765219429
  (0, 1659)	3.1226646837232415
  (0, 1658)	3.2558357807129994
  (0, 1657)	3.2789624796059753
  :	:
  (942, 24)	3.5783903228880907
  (942, 23)	3.5672268726726792
  (942, 22)	4.279149346942407
  (942, 21)	4.304056427933764
  (942, 20)	2.8362647729317354
  (942, 19)	3.7096983452898242
  (942, 18)	4.053802020863001
  (942, 17)	3.1903945388202852
  (942, 16)	3.223293510181336
  (942, 15)	3.488298356532732
  (942, 14)	3.8346859732659704
  (942, 13)	4.109803794408041
  (942, 12)	3.496254819249283
  (942, 11)	4.485348407496441
  (942, 10)	3.9802412229153368
  (942, 9)	3.9276607298456505
  (942, 8)	4.0151676798150735
  (942, 7)	4.140212952459456
  (942, 6)	3.9053701974565143
  (942, 5)	3.9465971748850355
  (942, 4)	3.4053200019041725
  (942, 3)	3.641537265276186
  (942, 2)	3.147634742157646
  (942, 1)	3.3384368992237508
  (942, 0)	3.9697144540472626
this is the 232 epoch
rmse loss on training set is 0.9208767286007167
rmse loss on test set is 0.9409435531986732
for this epoch using 76.4319519996643 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.247399131078772
  (0, 1680)	3.2723645682698974
  (0, 1679)	3.1757570636464627
  (0, 1678)	3.250832789715741
  (0, 1677)	3.100681337577194
  (0, 1676)	3.2587654542156335
  (0, 1675)	3.2557647274451256
  (0, 1674)	3.2557647274451256
  (0, 1673)	3.2557647274451256
  (0, 1672)	3.207830504155801
  (0, 1671)	3.145740429275689
  (0, 1670)	3.2557647274451256
  (0, 1669)	3.2557647274451256
  (0, 1668)	3.2083474782329104
  (0, 1667)	3.2557647274451256
  (0, 1666)	3.2557647274451256
  (0, 1665)	3.2083474782329104
  (0, 1664)	3.2557647274451256
  (0, 1663)	3.178516608391485
  (0, 1662)	3.2083474782329104
  (0, 1661)	3.198878158742537
  (0, 1660)	3.0876029846785777
  (0, 1659)	3.1220728957783703
  (0, 1658)	3.2557647274451256
  (0, 1657)	3.2790118008225355
  :	:
  (942, 24)	3.5783755200686533
  (942, 23)	3.5671826394546295
  (942, 22)	4.279344245178042
  (942, 21)	4.304169940834092
  (942, 20)	2.836206400361114
  (942, 19)	3.709905602761364
  (942, 18)	4.054139094907177
  (942, 17)	3.1901720056767666
  (942, 16)	3.22329660062623
  (942, 15)	3.488615463866738
  (942, 14)	3.834609195269773
  (942, 13)	4.109862478367755
  (942, 12)	3.496307488661787
  (942, 11)	4.485464789229063
  (942, 10)	3.980313249249984
  (942, 9)	3.927819168492368
  (942, 8)	4.015158691162067
  (942, 7)	4.140322886045778
  (942, 6)	3.90534014679465
  (942, 5)	3.94799172843423
  (942, 4)	3.4053312489689516
  (942, 3)	3.641643720839705
  (942, 2)	3.1476057352682063
  (942, 1)	3.3384913575171375
  (942, 0)	3.9696893154445676
this is the 233 epoch
rmse loss on training set is 0.920845587160666
rmse loss on test set is 0.9409249128426072
for this epoch using 76.6490969657898 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2473051069662713
  (0, 1680)	3.272375309914577
  (0, 1679)	3.175354846823758
  (0, 1678)	3.250738999161928
  (0, 1677)	3.099970694485592
  (0, 1676)	3.2587213080085116
  (0, 1675)	3.2556942999239453
  (0, 1674)	3.2556942999239453
  (0, 1673)	3.2556942999239453
  (0, 1672)	3.2075409324017135
  (0, 1671)	3.145284284152637
  (0, 1670)	3.2556942999239453
  (0, 1669)	3.2556942999239453
  (0, 1668)	3.2080895912844674
  (0, 1667)	3.2556942999239453
  (0, 1666)	3.2556942999239453
  (0, 1665)	3.2080895912844674
  (0, 1664)	3.2556942999239453
  (0, 1663)	3.1781503258339945
  (0, 1662)	3.2080895912844674
  (0, 1661)	3.1986033033854615
  (0, 1660)	3.0868611158617614
  (0, 1659)	3.1214820501817173
  (0, 1658)	3.2556942999239453
  (0, 1657)	3.2790617002900206
  :	:
  (942, 24)	3.578359786693452
  (942, 23)	3.5671377523485757
  (942, 22)	4.2795363222599905
  (942, 21)	4.304281213783589
  (942, 20)	2.8361483885506416
  (942, 19)	3.710109189199208
  (942, 18)	4.054470822161436
  (942, 17)	3.1899496446813167
  (942, 16)	3.2232989291269827
  (942, 15)	3.488929254520851
  (942, 14)	3.834531944952952
  (942, 13)	4.109919559456925
  (942, 12)	3.4963586934007256
  (942, 11)	4.485578952142906
  (942, 10)	3.980383499830503
  (942, 9)	3.9279745267137223
  (942, 8)	4.015148611860987
  (942, 7)	4.140430672426127
  (942, 6)	3.9053092376600813
  (942, 5)	3.9493775129688884
  (942, 4)	3.4053413054003117
  (942, 3)	3.6417481848027626
  (942, 2)	3.147576138191875
  (942, 1)	3.3385442897950597
  (942, 0)	3.969663232538317
this is the 234 epoch
rmse loss on training set is 0.9208147357856205
rmse loss on test set is 0.9409065282268877
for this epoch using 77.02509999275208 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.247211767775232
  (0, 1680)	3.2723866673655855
  (0, 1679)	3.1749533307471487
  (0, 1678)	3.250645817445363
  (0, 1677)	3.09926084404894
  (0, 1676)	3.258677805151789
  (0, 1675)	3.2556244914478567
  (0, 1674)	3.2556244914478567
  (0, 1673)	3.2556244914478567
  (0, 1672)	3.2072521688260758
  (0, 1671)	3.144829094175707
  (0, 1670)	3.2556244914478567
  (0, 1669)	3.2556244914478567
  (0, 1668)	3.2078323400524242
  (0, 1667)	3.2556244914478567
  (0, 1666)	3.2556244914478567
  (0, 1665)	3.2078323400524242
  (0, 1664)	3.2556244914478567
  (0, 1663)	3.1777848741613446
  (0, 1662)	3.2078323400524242
  (0, 1661)	3.198329274171363
  (0, 1660)	3.0861201512661025
  (0, 1659)	3.120892139140514
  (0, 1658)	3.2556244914478567
  (0, 1657)	3.279112170809382
  :	:
  (942, 24)	3.5783431468725984
  (942, 23)	3.5670922324445073
  (942, 22)	4.2797256223627
  (942, 21)	4.30439028671849
  (942, 20)	2.8360907315066055
  (942, 19)	3.7103091686716274
  (942, 18)	4.0547972915656105
  (942, 17)	3.1897274721045377
  (942, 16)	3.2233005130156704
  (942, 15)	3.4892397693810477
  (942, 14)	3.834454243088746
  (942, 13)	4.10997507078621
  (942, 12)	3.496408462441148
  (942, 11)	4.485690935274578
  (942, 10)	3.9804520083511266
  (942, 9)	3.9281268649582213
  (942, 8)	4.015137469352157
  (942, 7)	4.140536349421419
  (942, 6)	3.9052774950551647
  (942, 5)	3.950754597235816
  (942, 4)	3.4053501987627186
  (942, 3)	3.641850691945247
  (942, 2)	3.1475459675396555
  (942, 1)	3.3385957261091455
  (942, 0)	3.9696362311417484
this is the 235 epoch
rmse loss on training set is 0.9207841706916736
rmse loss on test set is 0.9408883957813285
for this epoch using 78.02395486831665 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.247119106441665
  (0, 1680)	3.272398633882406
  (0, 1679)	3.1745525087159288
  (0, 1678)	3.2505532379249154
  (0, 1677)	3.0985517795069533
  (0, 1676)	3.2586349387745166
  (0, 1675)	3.2555552954072144
  (0, 1674)	3.2555552954072144
  (0, 1673)	3.2555552954072144
  (0, 1672)	3.2069642063596246
  (0, 1671)	3.144374851160792
  (0, 1670)	3.2555552954072144
  (0, 1669)	3.2555552954072144
  (0, 1668)	3.207575718005162
  (0, 1667)	3.2555552954072144
  (0, 1666)	3.2555552954072144
  (0, 1665)	3.207575718005162
  (0, 1664)	3.2555552954072144
  (0, 1663)	3.177420246190012
  (0, 1662)	3.207575718005162
  (0, 1661)	3.1980560637911974
  (0, 1660)	3.085380083489879
  (0, 1659)	3.1203031549656775
  (0, 1658)	3.2555552954072144
  (0, 1657)	3.279163205282737
  :	:
  (942, 24)	3.5783256242449872
  (942, 23)	3.5670461003895877
  (942, 22)	4.279912188945128
  (942, 21)	4.304497198888008
  (942, 20)	2.836033423431957
  (942, 19)	3.710505604169524
  (942, 18)	4.055118590551482
  (942, 17)	3.1895055038249964
  (942, 16)	3.2233013693117267
  (942, 15)	3.4895470487659854
  (942, 14)	3.834376109997688
  (942, 13)	4.110029044845204
  (942, 12)	3.4964568242315357
  (942, 11)	4.48580077699532
  (942, 10)	3.980518807913614
  (942, 9)	3.928276242472956
  (942, 8)	4.015125290543064
  (942, 7)	4.140639954213393
  (942, 6)	3.905244943468884
  (942, 5)	3.952123049270835
  (942, 4)	3.4053579560695484
  (942, 3)	3.6419512764520827
  (942, 2)	3.1475152396198043
  (942, 1)	3.338645695966382
  (942, 0)	3.9696083365580397
this is the 236 epoch
rmse loss on training set is 0.9207538881568185
rmse loss on test set is 0.9408705119935151
for this epoch using 78.04300117492676 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2470271159965876
  (0, 1680)	3.2724112028161443
  (0, 1679)	3.1741523741216846
  (0, 1678)	3.250461254050929
  (0, 1677)	3.097843494192443
  (0, 1676)	3.258592702099206
  (0, 1675)	3.2554867052826837
  (0, 1674)	3.2554867052826837
  (0, 1673)	3.2554867052826837
  (0, 1672)	3.206677038017625
  (0, 1671)	3.143921547032536
  (0, 1670)	3.2554867052826837
  (0, 1669)	3.2554867052826837
  (0, 1668)	3.2073197187016
  (0, 1667)	3.2554867052826837
  (0, 1666)	3.2554867052826837
  (0, 1665)	3.2073197187016
  (0, 1664)	3.2554867052826837
  (0, 1663)	3.1770564348332653
  (0, 1662)	3.2073197187016
  (0, 1661)	3.197783665030245
  (0, 1660)	3.0846409052307493
  (0, 1659)	3.119715090069963
  (0, 1658)	3.2554867052826837
  (0, 1657)	3.2792147967115377
  :	:
  (942, 24)	3.5783072419866895
  (942, 23)	3.5669993763967285
  (942, 22)	4.2800960647627155
  (942, 21)	4.304601988865799
  (942, 20)	2.8359764587199194
  (942, 19)	3.7106985576239357
  (942, 18)	4.055434805068718
  (942, 17)	3.189283755336765
  (942, 16)	3.2233015147269226
  (942, 15)	3.4898511324354557
  (942, 14)	3.834297565556084
  (942, 13)	4.110081513513906
  (942, 12)	3.496503806702972
  (942, 11)	4.48590851502215
  (942, 10)	3.9805839310373248
  (942, 9)	3.928422717328023
  (942, 8)	4.015112101817958
  (942, 7)	4.140741523355083
  (942, 6)	3.9052116068862777
  (942, 5)	3.9534829364078874
  (942, 4)	3.405364603793764
  (942, 3)	3.642049971923316
  (942, 2)	3.1474839704422215
  (942, 1)	3.3386942283385883
  (942, 0)	3.969579573589481
this is the 237 epoch
rmse loss on training set is 0.9207238845196397
rmse loss on test set is 0.9408528734077194
for this epoch using 78.4193468093872 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2469357895643
  (0, 1680)	3.2724243676078792
  (0, 1679)	3.173752920446554
  (0, 1678)	3.2503698593634907
  (0, 1677)	3.097135981529625
  (0, 1676)	3.2585510884401536
  (0, 1675)	3.255418714643603
  (0, 1674)	3.255418714643603
  (0, 1673)	3.255418714643603
  (0, 1672)	3.2063906568985594
  (0, 1671)	3.1434691738224445
  (0, 1670)	3.255418714643603
  (0, 1669)	3.255418714643603
  (0, 1668)	3.207064335789529
  (0, 1667)	3.255418714643603
  (0, 1666)	3.255418714643603
  (0, 1665)	3.207064335789529
  (0, 1664)	3.255418714643603
  (0, 1663)	3.176693433099453
  (0, 1662)	3.207064335789529
  (0, 1661)	3.197512070766417
  (0, 1660)	3.083902609283951
  (0, 1659)	3.1191279369661373
  (0, 1658)	3.255418714643603
  (0, 1657)	3.2792669381947084
  :	:
  (942, 24)	3.578288022819297
  (942, 23)	3.5669520802529058
  (942, 22)	4.280277291879145
  (942, 21)	4.304704694561304
  (942, 20)	2.8359198319477548
  (942, 19)	3.7108880899230825
  (942, 18)	4.055746019610357
  (942, 17)	3.1890622417568797
  (942, 16)	3.2233009656703104
  (942, 15)	3.4901520595986817
  (942, 14)	3.8342186292043885
  (942, 13)	4.110132508073998
  (942, 12)	3.496549437278323
  (942, 11)	4.486014186428807
  (942, 10)	3.980647409669015
  (942, 9)	3.9285663464403657
  (942, 8)	4.015097929047279
  (942, 7)	4.14084109278099
  (942, 6)	3.905177508797863
  (942, 5)	3.9548343252879135
  (942, 4)	3.405370167878407
  (942, 3)	3.6421468113840123
  (942, 2)	3.147452175722815
  (942, 1)	3.3387413516715982
  (942, 0)	3.969549966546371
this is the 238 epoch
rmse loss on training set is 0.9206941561782204
rmse loss on test set is 0.9408354766237879
for this epoch using 79.20371580123901 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.246845120360796
  (0, 1680)	3.2724381217870957
  (0, 1679)	3.173354141261742
  (0, 1678)	3.2502790474909555
  (0, 1677)	3.0964292350325424
  (0, 1676)	3.2585100912018095
  (0, 1675)	3.2553513171464212
  (0, 1674)	3.2553513171464212
  (0, 1673)	3.2553513171464212
  (0, 1672)	3.2061050561828193
  (0, 1671)	3.1430177236670893
  (0, 1670)	3.2553513171464212
  (0, 1669)	3.2553513171464212
  (0, 1668)	3.206809563004098
  (0, 1667)	3.2553513171464212
  (0, 1666)	3.2553513171464212
  (0, 1665)	3.206809563004098
  (0, 1664)	3.2553513171464212
  (0, 1663)	3.1763312340903727
  (0, 1662)	3.206809563004098
  (0, 1661)	3.19724127396872
  (0, 1660)	3.0831651885406393
  (0, 1659)	3.1185416882653088
  (0, 1658)	3.2553513171464212
  (0, 1657)	3.2793196229269577
  :	:
  (942, 24)	3.5782679890180353
  (942, 23)	3.566904231327461
  (942, 22)	4.280455911677962
  (942, 21)	4.304805353230854
  (942, 20)	2.8358635378707735
  (942, 19)	3.711074260929402
  (942, 18)	4.0560523172378735
  (942, 17)	3.188840977832601
  (942, 16)	3.2232997382530844
  (942, 15)	3.4904498689224845
  (942, 14)	3.8341393199554594
  (942, 13)	4.1101820592199125
  (942, 12)	3.4965937428810325
  (942, 11)	4.486117827656554
  (942, 10)	3.980709275192634
  (942, 9)	3.9287071855971964
  (942, 8)	4.0150827975968815
  (942, 7)	4.1409386978172655
  (942, 6)	3.9051426722088225
  (942, 5)	3.9561772818677015
  (942, 4)	3.4053746737468855
  (942, 3)	3.6422418272940233
  (942, 2)	3.147419870887884
  (942, 1)	3.338787093894437
  (942, 0)	3.969519539255778
this is the 239 epoch
rmse loss on training set is 0.9206646995888743
rmse loss on test set is 0.940818318296097
for this epoch using 78.8096981048584 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2467551016920844
  (0, 1680)	3.272452458970097
  (0, 1679)	3.172956030225869
  (0, 1678)	3.250188812148285
  (0, 1677)	3.0957232483034556
  (0, 1676)	3.258469703877152
  (0, 1675)	3.2552845065331417
  (0, 1674)	3.2552845065331417
  (0, 1673)	3.2552845065331417
  (0, 1672)	3.2058202291314712
  (0, 1671)	3.142567188806234
  (0, 1670)	3.2552845065331417
  (0, 1669)	3.2552845065331417
  (0, 1668)	3.2065553941661666
  (0, 1667)	3.2552845065331417
  (0, 1666)	3.2552845065331417
  (0, 1665)	3.2065553941661666
  (0, 1664)	3.2552845065331417
  (0, 1663)	3.1759698309996347
  (0, 1662)	3.2065553941661666
  (0, 1661)	3.1969712676956084
  (0, 1660)	3.0824286359861546
  (0, 1659)	3.117956336675171
  (0, 1658)	3.2552845065331417
  (0, 1657)	3.2793728441970202
  :	:
  (942, 24)	3.5782471624198178
  (942, 23)	3.566855848580099
  (942, 22)	4.280631964873866
  (942, 21)	4.304904001488645
  (942, 20)	2.835807571416436
  (942, 19)	3.7112571294960763
  (942, 18)	4.0563537796058755
  (942, 17)	3.1886199779485707
  (942, 16)	3.2232978482934267
  (942, 15)	3.4907445985393797
  (942, 14)	3.834059656402649
  (942, 13)	4.1102301970696145
  (942, 12)	3.496636749944009
  (942, 11)	4.486219474524762
  (942, 10)	3.980769558438774
  (942, 9)	3.928845289478894
  (942, 8)	4.015066732337207
  (942, 7)	4.141034373191601
  (942, 6)	3.905107119648016
  (942, 5)	3.9575118714285638
  (942, 4)	3.405378146313008
  (942, 3)	3.642335051557572
  (942, 2)	3.1473870710783545
  (942, 1)	3.3388314824282785
  (942, 0)	3.9694883150702287
this is the 240 epoch
rmse loss on training set is 0.9206355112651098
rmse loss on test set is 0.9408013951324988
for this epoch using 78.36861276626587 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2466657269526893
  (0, 1680)	3.2724673728584843
  (0, 1679)	3.1725585810834493
  (0, 1678)	3.2500991471355722
  (0, 1677)	3.0950180150313296
  (0, 1676)	3.258429920046148
  (0, 1675)	3.2552182766298228
  (0, 1674)	3.2552182766298228
  (0, 1673)	3.2552182766298228
  (0, 1672)	3.205536169084922
  (0, 1671)	3.1421175615811423
  (0, 1670)	3.2552182766298228
  (0, 1669)	3.2552182766298228
  (0, 1668)	3.2063018231808305
  (0, 1667)	3.2552182766298228
  (0, 1666)	3.2552182766298228
  (0, 1665)	3.2063018231808305
  (0, 1664)	3.2552182766298228
  (0, 1663)	3.1756092171110692
  (0, 1662)	3.2063018231808305
  (0, 1661)	3.196702045093487
  (0, 1660)	3.081692944698378
  (0, 1659)	3.1173718749983257
  (0, 1658)	3.2552182766298228
  (0, 1657)	3.2794265953859796
  :	:
  (942, 24)	3.5782255644311474
  (942, 23)	3.566806950568841
  (942, 22)	4.280805491523894
  (942, 21)	4.3050006753175545
  (942, 20)	2.8357519276787375
  (942, 19)	3.7114367534835155
  (942, 18)	4.056650486986223
  (942, 17)	3.1883992561338776
  (942, 16)	3.223295311321171
  (942, 15)	3.4910362860554938
  (942, 14)	3.8339796567277653
  (942, 13)	4.110276951175272
  (942, 12)	3.4966784844181755
  (942, 11)	4.486319162241353
  (942, 10)	3.9808282896941045
  (942, 9)	3.9289807116814175
  (942, 8)	4.015049757652163
  (942, 7)	4.141128153043045
  (942, 6)	3.9050708731768426
  (942, 5)	3.9588381585848706
  (942, 4)	3.405380609990888
  (942, 3)	3.6424265155326756
  (942, 2)	3.1473537911540723
  (942, 1)	3.338874544195238
  (942, 0)	3.9694563168761574
this is the 241 epoch
rmse loss on training set is 0.9206065877764291
rmse loss on test set is 0.9407847038933159
for this epoch using 79.44239902496338 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.246576989624052
  (0, 1680)	3.2724828572376845
  (0, 1679)	3.1721617876634194
  (0, 1678)	3.250010046336577
  (0, 1677)	3.094313528990276
  (0, 1676)	3.2583907333742457
  (0, 1675)	3.2551526213450823
  (0, 1674)	3.2551526213450823
  (0, 1673)	3.2551526213450823
  (0, 1672)	3.2052528694617997
  (0, 1671)	3.141668834432804
  (0, 1670)	3.2551526213450823
  (0, 1669)	3.2551526213450823
  (0, 1668)	3.2060488440359403
  (0, 1667)	3.2551526213450823
  (0, 1666)	3.2551526213450823
  (0, 1665)	3.2060488440359403
  (0, 1664)	3.2551526213450823
  (0, 1663)	3.175249385797201
  (0, 1662)	3.2060488440359403
  (0, 1661)	3.1964335993952115
  (0, 1660)	3.080958107846186
  (0, 1659)	3.1167882961306974
  (0, 1658)	3.2551526213450823
  (0, 1657)	3.2794808699656324
  :	:
  (942, 24)	3.578203216035775
  (942, 23)	3.5667575554577238
  (942, 22)	4.28097653103838
  (942, 21)	4.305095410079701
  (942, 20)	2.835696601912676
  (942, 19)	3.7116131897754197
  (942, 18)	4.056942518291852
  (942, 17)	3.1881788260688926
  (942, 16)	3.2232921425825016
  (942, 15)	3.491324968558357
  (942, 14)	3.8338993387088576
  (942, 13)	4.1103223505336395
  (942, 12)	3.496718971780983
  (942, 11)	4.486416925413071
  (942, 10)	3.980885498710629
  (942, 9)	3.9291135047383245
  (942, 8)	4.015031897447878
  (942, 7)	4.1412200709316265
  (942, 6)	3.905033954398031
  (942, 5)	3.960156207292577
  (942, 4)	3.4053820887046222
  (942, 3)	3.642516250040379
  (942, 2)	3.1473200456979784
  (942, 1)	3.338916305627103
  (942, 0)	3.9694235671022993
this is the 242 epoch
rmse loss on training set is 0.9205779257473434
rmse loss on test set is 0.9407682413903377
for this epoch using 78.63494920730591 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2464888832730816
  (0, 1680)	3.2724989059754512
  (0, 1679)	3.1717656438776496
  (0, 1678)	3.2499215037171956
  (0, 1677)	3.093609784038115
  (0, 1676)	3.258352137610832
  (0, 1675)	3.2550875346686823
  (0, 1674)	3.2550875346686823
  (0, 1673)	3.2550875346686823
  (0, 1672)	3.204970323757678
  (0, 1671)	3.141220999900256
  (0, 1670)	3.2550875346686823
  (0, 1669)	3.2550875346686823
  (0, 1668)	3.2057964508005914
  (0, 1667)	3.2550875346686823
  (0, 1666)	3.2550875346686823
  (0, 1665)	3.2057964508005914
  (0, 1664)	3.2550875346686823
  (0, 1663)	3.174890330517677
  (0, 1662)	3.2057964508005914
  (0, 1661)	3.196165923918588
  (0, 1660)	3.080224118687804
  (0, 1659)	3.116205593059897
  (0, 1658)	3.2550875346686823
  (0, 1657)	3.279535661496886
  :	:
  (942, 24)	3.578180137802406
  (942, 23)	3.5667076810244294
  (942, 22)	4.2811451221916705
  (942, 21)	4.305188240526922
  (942, 20)	2.835641589528922
  (942, 19)	3.711786494294693
  (942, 18)	4.057229951100159
  (942, 17)	3.1879587010920907
  (942, 16)	3.223288357044558
  (942, 15)	3.491610682624646
  (942, 14)	3.833818719727872
  (942, 13)	4.110366423596306
  (942, 12)	3.4967582370446935
  (942, 11)	4.486512798055519
  (942, 10)	3.9809412147147287
  (942, 9)	3.929243720142271
  (942, 8)	4.01501317516144
  (942, 7)	4.141310159847845
  (942, 6)	3.9049963844641375
  (942, 5)	3.961466080857474
  (942, 4)	3.4053826058977945
  (942, 3)	3.642604285373952
  (942, 2)	3.1472858490203026
  (942, 1)	3.3389567926738257
  (942, 0)	3.9693900877278536
this is the 243 epoch
rmse loss on training set is 0.920549521856193
rmse loss on test set is 0.9407520044858575
for this epoch using 79.7516598701477 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.246401401550658
  (0, 1680)	3.2725155130204815
  (0, 1679)	3.1713701437195114
  (0, 1678)	3.249833513324114
  (0, 1677)	3.0929067741149185
  (0, 1676)	3.258314126587808
  (0, 1675)	3.2550230106701052
  (0, 1674)	3.2550230106701052
  (0, 1673)	3.2550230106701052
  (0, 1672)	3.2046885255439572
  (0, 1671)	3.1407740506189388
  (0, 1670)	3.2550230106701052
  (0, 1669)	3.2550230106701052
  (0, 1668)	3.205544637623785
  (0, 1667)	3.2550230106701052
  (0, 1666)	3.2550230106701052
  (0, 1665)	3.205544637623785
  (0, 1664)	3.2550230106701052
  (0, 1663)	3.1745320448178567
  (0, 1662)	3.205544637623785
  (0, 1661)	3.195899012064969
  (0, 1660)	3.0794909705693425
  (0, 1659)	3.1156237588636895
  (0, 1658)	3.2550230106701052
  (0, 1657)	3.279590963628214
  :	:
  (942, 24)	3.57815634989212
  (942, 23)	3.5666573446677226
  (942, 22)	4.281311303132737
  (942, 21)	4.305279200811035
  (942, 20)	2.8355868860886195
  (942, 19)	3.7119567220190994
  (942, 18)	4.0575128616758995
  (942, 17)	3.1877388942066642
  (942, 16)	3.2232839693999327
  (942, 15)	3.491893464327705
  (942, 14)	3.833737816778204
  (942, 13)	4.110409198279654
  (942, 12)	3.4967963047646324
  (942, 11)	4.486606813603133
  (942, 10)	3.980995466416121
  (942, 9)	3.9293714083660443
  (942, 8)	4.01499361376923
  (942, 7)	4.141398452222051
  (942, 6)	3.904958184085961
  (942, 5)	3.962767841943432
  (942, 4)	3.4053821845427805
  (942, 3)	3.642690651307755
  (942, 2)	3.147251215162623
  (942, 1)	3.3389960308119755
  (942, 0)	3.9693559002905996
this is the 244 epoch
rmse loss on training set is 0.9205213728342349
rmse loss on test set is 0.9407359900917267
for this epoch using 79.00518298149109 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2463145381901812
  (0, 1680)	3.272532672400998
  (0, 1679)	3.1709752812624874
  (0, 1678)	3.2497460692833817
  (0, 1677)	3.092204493241596
  (0, 1676)	3.258276694218149
  (0, 1675)	3.2549590434971725
  (0, 1674)	3.2549590434971725
  (0, 1673)	3.2549590434971725
  (0, 1672)	3.2044074684666852
  (0, 1671)	3.1403279793190855
  (0, 1670)	3.2549590434971725
  (0, 1669)	3.2549590434971725
  (0, 1668)	3.2052933987329464
  (0, 1667)	3.2549590434971725
  (0, 1666)	3.2549590434971725
  (0, 1665)	3.2052933987329464
  (0, 1664)	3.2549590434971725
  (0, 1663)	3.1741745223272884
  (0, 1662)	3.2052933987329464
  (0, 1661)	3.195632857317833
  (0, 1660)	3.078758656923235
  (0, 1659)	3.1150427867084387
  (0, 1658)	3.2549590434971725
  (0, 1657)	3.2796467700940637
  :	:
  (942, 24)	3.578131872065725
  (942, 23)	3.566606563414726
  (942, 22)	4.2814751113954985
  (942, 21)	4.305368324493935
  (942, 20)	2.8355324872983774
  (942, 19)	3.7121239269966297
  (942, 18)	4.057791324993799
  (942, 17)	3.1875194180870605
  (942, 16)	3.2232789940711535
  (942, 15)	3.492173349245074
  (942, 14)	3.8336566464721002
  (942, 13)	4.110450701974734
  (942, 12)	3.4968331990472112
  (942, 11)	4.48669900491893
  (942, 10)	3.981048282016618
  (942, 9)	3.9294966188832703
  (942, 8)	4.014973235795362
  (942, 7)	4.14148497993358
  (942, 6)	3.9049193735408103
  (942, 5)	3.964061552580555
  (942, 4)	3.4053808471498797
  (942, 3)	3.6427753771060876
  (942, 2)	3.1472161579019953
  (942, 1)	3.339034045052935
  (942, 0)	3.9693210258948004
this is the 245 epoch
rmse loss on training set is 0.9204934754645296
rmse loss on test set is 0.9407201951684135
for this epoch using 79.27317690849304 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.246228287006219
  (0, 1680)	3.2725503782234027
  (0, 1679)	3.1705810506587713
  (0, 1678)	3.24965916579903
  (0, 1677)	3.0915029355185144
  (0, 1676)	3.258239834494543
  (0, 1675)	3.254895627374708
  (0, 1674)	3.254895627374708
  (0, 1673)	3.254895627374708
  (0, 1672)	3.2041271462454657
  (0, 1671)	3.139882778824117
  (0, 1670)	3.254895627374708
  (0, 1669)	3.254895627374708
  (0, 1668)	3.2050427284326704
  (0, 1667)	3.254895627374708
  (0, 1666)	3.254895627374708
  (0, 1665)	3.2050427284326704
  (0, 1664)	3.254895627374708
  (0, 1663)	3.17381775675834
  (0, 1662)	3.2050427284326704
  (0, 1661)	3.195367453241411
  (0, 1660)	3.0780271712668106
  (0, 1659)	3.114462669847651
  (0, 1658)	3.254895627374708
  (0, 1657)	3.2797030747134293
  :	:
  (942, 24)	3.5781067236909823
  (942, 23)	3.5665553539281407
  (942, 22)	4.281636583909057
  (942, 21)	4.305455644557553
  (942, 20)	2.835478389005403
  (942, 19)	3.7122881623606707
  (942, 18)	4.058065414760721
  (942, 17)	3.187300285085397
  (942, 16)	3.2232734452150535
  (942, 15)	3.4924503724657656
  (942, 14)	3.8335752250478743
  (942, 13)	4.110490961556862
  (942, 12)	3.496868943557812
  (942, 11)	4.4867894043040435
  (942, 10)	3.9810996892188077
  (942, 9)	3.9296194001885834
  (942, 8)	4.014952063319786
  (942, 7)	4.141569774319852
  (942, 6)	3.904879972680658
  (942, 5)	3.965347274173065
  (942, 4)	3.405378615776283
  (942, 3)	3.642858491531848
  (942, 2)	3.1471806907549302
  (942, 1)	3.3390708599510814
  (942, 0)	3.969285485219021
this is the 246 epoch
rmse loss on training set is 0.920465826581022
rmse loss on test set is 0.9407046167241193
for this epoch using 80.19381976127625 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2461426418930746
  (0, 1680)	3.2725686246709134
  (0, 1679)	3.1701874461379718
  (0, 1678)	3.24957279715181
  (0, 1677)	3.0908020951241397
  (0, 1676)	3.2582035414879873
  (0, 1675)	3.2548327566032307
  (0, 1674)	3.2548327566032307
  (0, 1673)	3.2548327566032307
  (0, 1672)	3.2038475526723347
  (0, 1671)	3.139438442049131
  (0, 1670)	3.2548327566032307
  (0, 1669)	3.2548327566032307
  (0, 1668)	3.20479262110329
  (0, 1667)	3.2548327566032307
  (0, 1666)	3.2548327566032307
  (0, 1665)	3.20479262110329
  (0, 1664)	3.2548327566032307
  (0, 1663)	3.1734617419047972
  (0, 1662)	3.20479262110329
  (0, 1661)	3.1951027934793648
  (0, 1660)	3.0772965072008533
  (0, 1659)	3.113883401620504
  (0, 1658)	3.2548327566032307
  (0, 1657)	3.279759871388334
  :	:
  (942, 24)	3.578080923749716
  (942, 23)	3.566503732513216
  (942, 22)	4.281795757007673
  (942, 21)	4.305541193413598
  (942, 20)	2.8354245871927493
  (942, 19)	3.7124494803449317
  (942, 18)	4.058335203437396
  (942, 17)	3.1870815072377146
  (942, 16)	3.223267336727154
  (942, 15)	3.4927245685975556
  (942, 14)	3.8334935683770954
  (942, 13)	4.110530003395117
  (942, 12)	3.4969035615286144
  (942, 11)	4.486878043507227
  (942, 10)	3.981149715234554
  (942, 9)	3.92973979981739
  (942, 8)	4.014930117986353
  (942, 7)	4.14165286618529
  (942, 6)	3.904840000940045
  (942, 5)	3.966625067507308
  (942, 4)	3.4053755120348423
  (942, 3)	3.6429400228550555
  (942, 2)	3.1471448269814033
  (942, 1)	3.339106499611756
  (942, 0)	3.9692492985238013
this is the 247 epoch
rmse loss on training set is 0.9204384230675208
rmse loss on test set is 0.9406892518138658
for this epoch using 79.12063884735107 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2460575968234986
  (0, 1680)	3.2725874060023146
  (0, 1679)	3.16979446200576
  (0, 1678)	3.2494869576978
  (0, 1677)	3.090101966313735
  (0, 1676)	3.2581678093464745
  (0, 1675)	3.25477042555764
  (0, 1674)	3.25477042555764
  (0, 1673)	3.25477042555764
  (0, 1672)	3.203568681610708
  (0, 1671)	3.1389949619993254
  (0, 1670)	3.25477042555764
  (0, 1669)	3.25477042555764
  (0, 1668)	3.204543071199646
  (0, 1667)	3.25477042555764
  (0, 1666)	3.25477042555764
  (0, 1665)	3.204543071199646
  (0, 1664)	3.25477042555764
  (0, 1663)	3.173106471640479
  (0, 1662)	3.204543071199646
  (0, 1661)	3.1948388717534244
  (0, 1660)	3.076566658408171
  (0, 1659)	3.113304975450393
  (0, 1658)	3.25477042555764
  (0, 1657)	3.2798171541024383
  :	:
  (942, 24)	3.578054490844786
  (942, 23)	3.566451715124665
  (942, 22)	4.281952666440646
  (942, 21)	4.305625002913244
  (942, 20)	2.8353710779747723
  (942, 19)	3.7126079322981496
  (942, 18)	4.0586007622599025
  (942, 17)	3.186863096270187
  (942, 16)	3.223260682245883
  (942, 15)	3.4929959717741252
  (942, 14)	3.8334116919715493
  (942, 13)	4.1105678533615695
  (942, 12)	3.496937075766198
  (942, 11)	4.486964953734151
  (942, 10)	3.98119838679329
  (942, 9)	3.929857864365376
  (942, 8)	4.014907421010743
  (942, 7)	4.141734285810077
  (942, 6)	3.904799477343946
  (942, 5)	3.9678949927594074
  (942, 4)	3.4053715571026992
  (942, 3)	3.643019998861203
  (942, 2)	3.147108579588798
  (942, 1)	3.339140987699147
  (942, 0)	3.969212485659174
this is the 248 epoch
rmse loss on training set is 0.9204112618567994
rmse loss on test set is 0.9406740975386536
for this epoch using 79.3000431060791 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2459731458473144
  (0, 1680)	3.2726067165506296
  (0, 1679)	3.169402092642619
  (0, 1678)	3.2494016418672067
  (0, 1677)	3.08940254341803
  (0, 1676)	3.2581326322936848
  (0, 1675)	3.2547086286859757
  (0, 1674)	3.2547086286859757
  (0, 1673)	3.2547086286859757
  (0, 1672)	3.203290526994285
  (0, 1671)	3.138552331768583
  (0, 1670)	3.2547086286859757
  (0, 1669)	3.2547086286859757
  (0, 1668)	3.204294073249802
  (0, 1667)	3.2547086286859757
  (0, 1666)	3.2547086286859757
  (0, 1665)	3.204294073249802
  (0, 1664)	3.2547086286859757
  (0, 1663)	3.1727519399179287
  (0, 1662)	3.204294073249802
  (0, 1661)	3.1945756818621494
  (0, 1660)	3.075837618652266
  (0, 1659)	3.1127273848435766
  (0, 1658)	3.2547086286859757
  (0, 1657)	3.2798749169195958
  :	:
  (942, 24)	3.578027443206922
  (942, 23)	3.566399317373414
  (942, 22)	4.282107347381922
  (942, 21)	4.305707104356522
  (942, 20)	2.8353178575926337
  (942, 19)	3.7127635686985125
  (942, 18)	4.058862161260629
  (942, 17)	3.18664506360516
  (942, 16)	3.2232534951568135
  (942, 15)	3.4932646156619964
  (942, 14)	3.8333296109901163
  (942, 13)	4.110604536840402
  (942, 12)	3.496969508659054
  (942, 11)	4.487050165656427
  (942, 10)	3.9812457301503112
  (942, 9)	3.929973639507334
  (942, 8)	4.014883993188151
  (942, 7)	4.141814062958753
  (942, 6)	3.9047584205154697
  (942, 5)	3.9691571095030294
  (942, 4)	3.405366771729696
  (942, 3)	3.6430984468594843
  (942, 2)	3.1470719613357527
  (942, 1)	3.3391743474439965
  (942, 0)	3.969175066072085
this is the 249 epoch
rmse loss on training set is 0.9203843399296446
rmse loss on test set is 0.9406591510445976
for this epoch using 83.15639805793762 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.245889283090197
  (0, 1680)	3.2726265507218915
  (0, 1679)	3.1690103325025425
  (0, 1678)	3.2493168441630953
  (0, 1677)	3.088703820842004
  (0, 1676)	3.258098004627707
  (0, 1675)	3.254647360508178
  (0, 1674)	3.254647360508178
  (0, 1673)	3.254647360508178
  (0, 1672)	3.203013082826066
  (0, 1671)	3.1381105445379487
  (0, 1670)	3.254647360508178
  (0, 1669)	3.254647360508178
  (0, 1668)	3.2040456218537736
  (0, 1667)	3.254647360508178
  (0, 1666)	3.254647360508178
  (0, 1665)	3.2040456218537736
  (0, 1664)	3.254647360508178
  (0, 1663)	3.1723981407671245
  (0, 1662)	3.2040456218537736
  (0, 1661)	3.1943132176796607
  (0, 1660)	3.075109381775933
  (0, 1659)	3.1121506233877643
  (0, 1658)	3.254647360508178
  (0, 1657)	3.2799331539825185
  :	:
  (942, 24)	3.5779997987014647
  (942, 23)	3.5663465545332076
  (942, 22)	4.282259834439634
  (942, 21)	4.305787528501704
  (942, 20)	2.8352649224100337
  (942, 19)	3.7129164391679343
  (942, 18)	4.059119469288946
  (942, 17)	3.1864274203671012
  (942, 16)	3.223245788596779
  (942, 15)	3.493530533467531
  (942, 14)	3.8332473402455727
  (942, 13)	4.110640078736826
  (942, 12)	3.497000882185009
  (942, 11)	4.487133709420689
  (942, 10)	3.981291771094854
  (942, 9)	3.9300871700158626
  (942, 8)	4.0148598549009495
  (942, 7)	4.141892226888809
  (942, 6)	3.9047168486833663
  (942, 5)	3.970411476716845
  (942, 4)	3.405361176246707
  (942, 3)	3.6431753936909232
  (942, 2)	3.147034984736068
  (942, 1)	3.339206601651206
  (942, 0)	3.9691370588137196
this is the 250 epoch
rmse loss on training set is 0.9203576543139584
rmse loss on test set is 0.940644409522103
for this epoch using 79.75286507606506 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.245806002752356
  (0, 1680)	3.272646902993958
  (0, 1679)	3.168619176111871
  (0, 1678)	3.2492325591601476
  (0, 1677)	3.0880057930636067
  (0, 1676)	3.258063920719812
  (0, 1675)	3.254586615614887
  (0, 1674)	3.254586615614887
  (0, 1673)	3.254586615614887
  (0, 1672)	3.2027363431772993
  (0, 1671)	3.1376695935742878
  (0, 1670)	3.254586615614887
  (0, 1669)	3.254586615614887
  (0, 1668)	3.203797711682371
  (0, 1667)	3.254586615614887
  (0, 1666)	3.254586615614887
  (0, 1665)	3.203797711682371
  (0, 1664)	3.254586615614887
  (0, 1663)	3.172045068294177
  (0, 1662)	3.203797711682371
  (0, 1661)	3.1940514731543894
  (0, 1660)	3.074381941700015
  (0, 1659)	3.1115746847508134
  (0, 1658)	3.254586615614887
  (0, 1657)	3.2799918595114272
  :	:
  (942, 24)	3.5779715748349914
  (942, 23)	3.566293441547153
  (942, 22)	4.282410161665412
  (942, 21)	4.305866305574396
  (942, 20)	2.835212268909015
  (942, 19)	3.7130665924860637
  (942, 18)	4.059372754031566
  (942, 17)	3.1862101773884484
  (942, 16)	3.223237575457992
  (942, 15)	3.493793757943697
  (942, 14)	3.8331648942111762
  (942, 13)	4.110674503485816
  (942, 12)	3.497031217918446
  (942, 11)	4.48721561465737
  (942, 10)	3.98133653495802
  (942, 9)	3.9301984997795567
  (942, 8)	4.01483502612618
  (942, 7)	4.141968806358977
  (942, 6)	3.9046747796894943
  (942, 5)	3.971658152792078
  (942, 4)	3.4053547905737176
  (942, 3)	3.6432508657362708
  (942, 2)	3.1469976620624394
  (942, 1)	3.3392377727073215
  (942, 0)	3.9690984825465834
this is the 251 epoch
rmse loss on training set is 0.92033120208387
rmse loss on test set is 0.9406298702050583
for this epoch using 77.53529381752014 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.245723299107373
  (0, 1680)	3.2726677679152774
  (0, 1679)	3.1682286180680457
  (0, 1678)	3.249148781503525
  (0, 1677)	3.08730845463257
  (0, 1676)	3.2580303750132362
  (0, 1675)	3.2545263886662843
  (0, 1674)	3.2545263886662843
  (0, 1673)	3.2545263886662843
  (0, 1672)	3.202460302186537
  (0, 1671)	3.1372294722288103
  (0, 1670)	3.2545263886662843
  (0, 1669)	3.2545263886662843
  (0, 1668)	3.2035503374759484
  (0, 1667)	3.2545263886662843
  (0, 1666)	3.2545263886662843
  (0, 1665)	3.2035503374759484
  (0, 1664)	3.2545263886662843
  (0, 1663)	3.1716927166801034
  (0, 1662)	3.2035503374759484
  (0, 1661)	3.193790442307898
  (0, 1660)	3.07365529242205
  (0, 1659)	3.1109995626794342
  (0, 1658)	3.2545263886662843
  (0, 1657)	3.280051027802739
  :	:
  (942, 24)	3.577942788761796
  (942, 23)	3.5662399930340642
  (942, 22)	4.282558362563551
  (942, 21)	4.305943465276601
  (942, 20)	2.835159893685903
  (942, 19)	3.713214076604053
  (942, 18)	4.059622082032428
  (942, 17)	3.1859933452153193
  (942, 16)	3.223228868392043
  (942, 15)	3.494054321396756
  (942, 14)	3.8330822870271883
  (942, 13)	4.110707835060754
  (942, 12)	3.4970605370374446
  (942, 11)	4.487295910489372
  (942, 10)	3.9813800466205915
  (942, 9)	3.930307671820815
  (942, 8)	4.014809526442846
  (942, 7)	4.142043829637516
  (942, 6)	3.9046322309960466
  (942, 5)	3.9728971955397654
  (942, 4)	3.4053476342278164
  (942, 3)	3.6433248889238725
  (942, 2)	3.146960005350301
  (942, 1)	3.339267882587898
  (942, 0)	3.9690593555516136
this is the 252 epoch
rmse loss on training set is 0.9203049803588802
rmse loss on test set is 0.9406155303700382
for this epoch using 78.09437203407288 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2456411665009077
  (0, 1680)	3.2726891401037173
  (0, 1679)	3.1678386530384173
  (0, 1678)	3.249065505907624
  (0, 1677)	3.086611800169209
  (0, 1676)	3.2579973620219196
  (0, 1675)	3.2544666743908865
  (0, 1674)	3.2544666743908865
  (0, 1673)	3.2544666743908865
  (0, 1672)	3.202184954058575
  (0, 1671)	3.1367901739357555
  (0, 1670)	3.2544666743908865
  (0, 1669)	3.2544666743908865
  (0, 1668)	3.2033034940432903
  (0, 1667)	3.2544666743908865
  (0, 1666)	3.2544666743908865
  (0, 1665)	3.2033034940432903
  (0, 1664)	3.2544666743908865
  (0, 1663)	3.171341080179586
  (0, 1662)	3.2033034940432903
  (0, 1661)	3.193530119233689
  (0, 1660)	3.072929428015042
  (0, 1659)	3.1104252509978276
  (0, 1658)	3.2544666743908865
  (0, 1657)	3.280110653227775
  :	:
  (942, 24)	3.5779134572903097
  (942, 23)	3.5661862232946766
  (942, 22)	4.282704470100057
  (942, 21)	4.306019036795544
  (942, 20)	2.8351077934474076
  (942, 19)	3.71335893865818
  (942, 18)	4.059867518712341
  (942, 17)	3.1857769341131497
  (942, 16)	3.2232196798138877
  (942, 15)	3.4943122556929156
  (942, 14)	3.8329995325072637
  (942, 13)	4.110740096981786
  (942, 12)	3.4970888603307944
  (942, 11)	4.487374625540655
  (942, 10)	3.9814223305207843
  (942, 9)	3.930414728313375
  (942, 8)	4.0147833750392445
  (942, 7)	4.142117324510268
  (942, 6)	3.904589219692806
  (942, 5)	3.974128662198079
  (942, 4)	3.4053397263309697
  (942, 3)	3.643397488737349
  (942, 2)	3.146922026401455
  (942, 1)	3.3392969528647227
  (942, 0)	3.969019695735092
this is the 253 epoch
rmse loss on training set is 0.9202789863030175
rmse loss on test set is 0.9406013873355377
for this epoch using 78.15033602714539 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2455595993496216
  (0, 1680)	3.272711014245466
  (0, 1679)	3.1674492757591532
  (0, 1678)	3.248982727155031
  (0, 1677)	3.085915824363278
  (0, 1676)	3.25796487632945
  (0, 1675)	3.254407467584468
  (0, 1674)	3.254407467584468
  (0, 1673)	3.254407467584468
  (0, 1672)	3.201910293063624
  (0, 1671)	3.1363516922110484
  (0, 1670)	3.254407467584468
  (0, 1669)	3.254407467584468
  (0, 1668)	3.2030571762604394
  (0, 1667)	3.254407467584468
  (0, 1666)	3.254407467584468
  (0, 1665)	3.2030571762604394
  (0, 1664)	3.254407467584468
  (0, 1663)	3.170990153119806
  (0, 1662)	3.2030571762604394
  (0, 1661)	3.1932704980960565
  (0, 1660)	3.072204342626243
  (0, 1659)	3.1098517436065345
  (0, 1658)	3.254407467584468
  (0, 1657)	3.280170730231526
  :	:
  (942, 24)	3.5778835968893747
  (942, 23)	3.566132146317852
  (942, 22)	4.2828485167114145
  (942, 21)	4.306093048812397
  (942, 20)	2.8350559650067795
  (942, 19)	3.7135012249831942
  (942, 18)	4.060109128388236
  (942, 17)	3.1855609540722476
  (942, 16)	3.2232100219057256
  (942, 15)	3.4945675922647585
  (942, 14)	3.832916644144773
  (942, 13)	4.110771312324184
  (942, 12)	3.497116208204874
  (942, 11)	4.487451787944562
  (942, 10)	3.9814634106617275
  (942, 9)	3.930519710599339
  (942, 8)	4.01475659071995
  (942, 7)	4.142189318288708
  (942, 6)	3.904545762504025
  (942, 5)	3.9753526094394185
  (942, 4)	3.405331085617736
  (942, 3)	3.643468690223139
  (942, 2)	3.1468837367877995
  (942, 1)	3.3393250047129013
  (942, 0)	3.968979520635396
this is the 254 epoch
rmse loss on training set is 0.9202532171240109
rmse loss on test set is 0.9405874384611913
for this epoch using 77.06719899177551 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.245478592139905
  (0, 1680)	3.2727333850938627
  (0, 1679)	3.167060481034036
  (0, 1678)	3.248900440095294
  (0, 1677)	3.0852205219727926
  (0, 1676)	3.2579329125878074
  (0, 1675)	3.2543487631089114
  (0, 1674)	3.2543487631089114
  (0, 1673)	3.2543487631089114
  (0, 1672)	3.2016363135362265
  (0, 1671)	3.135914020650965
  (0, 1670)	3.2543487631089114
  (0, 1669)	3.2543487631089114
  (0, 1668)	3.2028113790696078
  (0, 1667)	3.2543487631089114
  (0, 1666)	3.2543487631089114
  (0, 1665)	3.2028113790696078
  (0, 1664)	3.2543487631089114
  (0, 1663)	3.1706399298992123
  (0, 1662)	3.2028113790696078
  (0, 1661)	3.19301157312893
  (0, 1660)	3.071480030475898
  (0, 1659)	3.1092790344811116
  (0, 1658)	3.2543487631089114
  (0, 1657)	3.280231253331396
  :	:
  (942, 24)	3.577853223694388
  (942, 23)	3.566077775786542
  (942, 22)	4.282990534313385
  (942, 21)	4.306165529510883
  (942, 20)	2.8350044052801344
  (942, 19)	3.713640981125454
  (942, 18)	4.060346974292097
  (942, 17)	3.185345414813146
  (942, 16)	3.2231999066208616
  (942, 15)	3.4948203621177023
  (942, 14)	3.8328336351189054
  (942, 13)	4.1108015037263534
  (942, 12)	3.4971426006904287
  (942, 11)	4.48752742535213
  (942, 10)	3.981503310618993
  (942, 9)	3.930622659205957
  (942, 8)	4.014729191912863
  (942, 7)	4.14225983781771
  (942, 6)	3.9045018757954475
  (942, 5)	3.9765690933774898
  (942, 4)	3.4053217304427235
  (942, 3)	3.643538517997929
  (942, 2)	3.1468451478549264
  (942, 1)	3.339352058917882
  (942, 0)	3.968938847429726
this is the 255 epoch
rmse loss on training set is 0.9202276700724564
rmse loss on test set is 0.9405736811470554
for this epoch using 77.28354501724243 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.245398139426858
  (0, 1680)	3.2727562474683434
  (0, 1679)	3.1666722637334335
  (0, 1678)	3.2488186396439227
  (0, 1677)	3.0845258878229536
  (0, 1676)	3.2579014655163236
  (0, 1675)	3.254290555891176
  (0, 1674)	3.254290555891176
  (0, 1673)	3.254290555891176
  (0, 1672)	3.2013630098744583
  (0, 1671)	3.135477152930861
  (0, 1670)	3.254290555891176
  (0, 1669)	3.254290555891176
  (0, 1668)	3.202566097478044
  (0, 1667)	3.254290555891176
  (0, 1666)	3.254290555891176
  (0, 1665)	3.202566097478044
  (0, 1664)	3.254290555891176
  (0, 1663)	3.170290404986449
  (0, 1662)	3.202566097478044
  (0, 1661)	3.192753338634809
  (0, 1660)	3.0707564858561023
  (0, 1659)	3.1087071176709964
  (0, 1658)	3.254290555891176
  (0, 1657)	3.280292217116026
  :	:
  (942, 24)	3.5778223535133598
  (942, 23)	3.566023125083679
  (942, 22)	4.28313055430949
  (942, 21)	4.306236506585658
  (942, 20)	2.834953111282886
  (942, 19)	3.71377825185592
  (942, 18)	4.060581118589559
  (942, 17)	3.1851303257919894
  (942, 16)	3.2231893456875054
  (942, 15)	3.4950705958362858
  (942, 14)	3.8327505183008035
  (942, 13)	4.110830693397878
  (942, 12)	3.4971680574492354
  (942, 11)	4.487601564940185
  (942, 10)	3.9815420535478157
  (942, 9)	3.9307236138620807
  (942, 8)	4.0147011966760235
  (942, 7)	4.142328909483356
  (942, 6)	3.9044575755810436
  (942, 5)	3.9777781695742487
  (942, 4)	3.405311678787992
  (942, 3)	3.643606996255988
  (942, 2)	3.1468062707256976
  (942, 1)	3.3393781358822983
  (942, 0)	3.9688976929406876
this is the 256 epoch
rmse loss on training set is 0.9202023424410886
rmse loss on test set is 0.9405601128328623
for this epoch using 77.7475438117981 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.245318235833115
  (0, 1680)	3.2727795962533386
  (0, 1679)	3.1662846187931515
  (0, 1678)	3.2487373207812524
  (0, 1677)	3.0838319168050576
  (0, 1676)	3.2578705299005586
  (0, 1675)	3.254232840922194
  (0, 1674)	3.254232840922194
  (0, 1673)	3.254232840922194
  (0, 1672)	3.201090376538975
  (0, 1671)	3.135041082803936
  (0, 1670)	3.254232840922194
  (0, 1669)	3.254232840922194
  (0, 1668)	3.2023213265570445
  (0, 1667)	3.254232840922194
  (0, 1666)	3.254232840922194
  (0, 1665)	3.2023213265570445
  (0, 1664)	3.254232840922194
  (0, 1663)	3.1699415729191878
  (0, 1662)	3.2023213265570445
  (0, 1661)	3.192495788983663
  (0, 1660)	3.0700337031296363
  (0, 1659)	3.1081359872982954
  (0, 1658)	3.254232840922194
  (0, 1657)	3.280353616244087
  :	:
  (942, 24)	3.5777910018329355
  (942, 23)	3.5659682072980408
  (942, 22)	4.283268607599449
  (942, 21)	4.306306007250664
  (942, 20)	2.834902080126273
  (942, 19)	3.713913081182857
  (942, 18)	4.060811622398193
  (942, 17)	3.184915696205715
  (942, 16)	3.2231783506124985
  (942, 15)	3.49531832359034
  (942, 14)	3.8326673062594234
  (942, 13)	4.110858903127322
  (942, 12)	3.4971925977806055
  (942, 11)	4.48767423341933
  (942, 10)	3.981579662190388
  (942, 9)	3.9308226135141844
  (942, 8)	4.0146726227043645
  (942, 7)	4.14239655922049
  (942, 6)	3.90441287752965
  (942, 5)	3.9789798930467466
  (942, 4)	3.4053009482702494
  (942, 3)	3.643674148776334
  (942, 2)	3.1467671163038
  (942, 1)	3.3394032556327575
  (942, 0)	3.9688560736427223
this is the 257 epoch
rmse loss on training set is 0.920177231563901
rmse loss on test set is 0.9405467309973343
for this epoch using 77.68014001846313 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2452388760477895
  (0, 1680)	3.272803426397242
  (0, 1679)	3.1658975412134143
  (0, 1678)	3.2486564785514376
  (0, 1677)	3.083138603875406
  (0, 1676)	3.257840100591208
  (0, 1675)	3.2541756132558666
  (0, 1674)	3.2541756132558666
  (0, 1673)	3.2541756132558666
  (0, 1672)	3.2008184080521462
  (0, 1671)	3.1346058040999725
  (0, 1670)	3.2541756132558666
  (0, 1669)	3.2541756132558666
  (0, 1668)	3.2020770614408236
  (0, 1667)	3.2541756132558666
  (0, 1666)	3.2541756132558666
  (0, 1665)	3.2020770614408236
  (0, 1664)	3.2541756132558666
  (0, 1663)	3.1695934283030236
  (0, 1662)	3.2020770614408236
  (0, 1661)	3.1922389186118503
  (0, 1660)	3.0693116767288156
  (0, 1659)	3.107565637556636
  (0, 1658)	3.2541756132558666
  (0, 1657)	3.280415445443176
  :	:
  (942, 24)	3.57775918382417
  (942, 23)	3.5659130352297956
  (942, 22)	4.2834047245874345
  (942, 21)	4.306374058247255
  (942, 20)	2.8348513090139953
  (942, 19)	3.7140455123644456
  (942, 18)	4.061038545805435
  (942, 17)	3.1847015349972136
  (942, 16)	3.2231669326849826
  (942, 15)	3.495563575141158
  (942, 14)	3.832584011267448
  (942, 13)	4.110886154289874
  (942, 12)	3.497216240627837
  (942, 11)	4.487745457041797
  (942, 10)	3.981616158882823
  (942, 9)	3.9309196963421376
  (942, 8)	4.014643487336284
  (942, 7)	4.142462812520243
  (942, 6)	3.9043677969715374
  (942, 5)	3.9801743182739098
  (942, 4)	3.4052895561479453
  (942, 3)	3.6437399989297954
  (942, 2)	3.146727695277234
  (942, 1)	3.339427437826465
  (942, 0)	3.9688140056684635
this is the 258 epoch
rmse loss on training set is 0.920152334815517
rmse loss on test set is 0.9405335331574445
for this epoch using 77.78165912628174 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.245160054825402
  (0, 1680)	3.2728277329113986
  (0, 1679)	3.165511026057838
  (0, 1678)	3.248576108061413
  (0, 1677)	3.082445944054269
  (0, 1676)	3.2578101725031066
  (0, 1675)	3.2541188680080153
  (0, 1674)	3.2541188680080153
  (0, 1673)	3.2541188680080153
  (0, 1672)	3.2005470989971534
  (0, 1671)	3.1341713107241387
  (0, 1670)	3.2541188680080153
  (0, 1669)	3.2541188680080153
  (0, 1668)	3.201833297325558
  (0, 1667)	3.2541188680080153
  (0, 1666)	3.2541188680080153
  (0, 1665)	3.201833297325558
  (0, 1664)	3.2541188680080153
  (0, 1663)	3.169245965810409
  (0, 1662)	3.201833297325558
  (0, 1661)	3.1919827220211197
  (0, 1660)	3.0685904011544136
  (0, 1659)	3.106996062710034
  (0, 1658)	3.2541188680080153
  (0, 1657)	3.280477699508648
  :	:
  (942, 24)	3.5777269143483275
  (942, 23)	3.5658576213962063
  (942, 22)	4.283538935190177
  (942, 21)	4.306440685852195
  (942, 20)	2.834800795238968
  (942, 19)	3.7141755879210407
  (942, 18)	4.06126194788628
  (942, 17)	3.18448785086034
  (942, 16)	3.223155102980035
  (942, 15)	3.4958063798474597
  (942, 14)	3.8325006453069794
  (942, 13)	4.110912467854912
  (942, 12)	3.4972390045845185
  (942, 11)	4.4878152616091675
  (942, 10)	3.9816515655622444
  (942, 9)	3.931014899774593
  (942, 8)	4.014613807560165
  (942, 7)	4.142527694437353
  (942, 6)	3.904322348904805
  (942, 5)	3.9813614992031665
  (942, 4)	3.4052775193282585
  (942, 3)	3.6438045696859542
  (942, 2)	3.1466880181217465
  (942, 1)	3.339450701757745
  (942, 0)	3.9687715048149883
this is the 259 epoch
rmse loss on training set is 0.920127649610356
rmse loss on test set is 0.9405205168677915
for this epoch using 78.18446183204651 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.245081766984857
  (0, 1680)	3.2728525108690603
  (0, 1679)	3.1651250684523684
  (0, 1678)	3.2484962044798666
  (0, 1677)	3.0817539324248844
  (0, 1676)	3.2577807406141526
  (0, 1675)	3.2540626003554323
  (0, 1674)	3.2540626003554323
  (0, 1673)	3.2540626003554323
  (0, 1672)	3.200276444017208
  (0, 1671)	3.1337375966558074
  (0, 1670)	3.2540626003554323
  (0, 1669)	3.2540626003554323
  (0, 1668)	3.201590029468353
  (0, 1667)	3.2540626003554323
  (0, 1666)	3.2540626003554323
  (0, 1665)	3.201590029468353
  (0, 1664)	3.2540626003554323
  (0, 1663)	3.168899180179619
  (0, 1662)	3.201590029468353
  (0, 1661)	3.1917271937775586
  (0, 1660)	3.067869870974532
  (0, 1659)	3.1064272570917986
  (0, 1658)	3.2540626003554323
  (0, 1657)	3.280540373302504
  :	:
  (942, 24)	3.5776942079625447
  (942, 23)	3.565801978036998
  (942, 22)	4.283671268844971
  (942, 21)	4.3065059158856
  (942, 20)	2.8347505361801657
  (942, 19)	3.7143033496473965
  (942, 18)	4.061481886720614
  (942, 17)	3.1842746522448606
  (942, 16)	3.223142872362245
  (942, 15)	3.4960467666713515
  (942, 14)	3.832417220075192
  (942, 13)	4.110937864393365
  (942, 12)	3.4972609079007517
  (942, 11)	4.487883672479962
  (942, 10)	3.981685903773481
  (942, 9)	3.931108260504135
  (942, 8)	4.014583600020799
  (942, 7)	4.142591229597479
  (942, 6)	3.9042765480016772
  (942, 5)	3.982541489257069
  (942, 4)	3.405264854373822
  (942, 3)	3.643867883619961
  (942, 2)	3.146648095104277
  (942, 1)	3.339473066364502
  (942, 0)	3.968728586549947
this is the 260 epoch
rmse loss on training set is 0.9201031734019496
rmse loss on test set is 0.9405076797198769
for this epoch using 78.35838294029236 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.245004007408376
  (0, 1680)	3.2728777554044077
  (0, 1679)	3.1647396635843257
  (0, 1678)	3.2484167630362655
  (0, 1677)	3.0810625641323877
  (0, 1676)	3.257751799964298
  (0, 1675)	3.2540068055348477
  (0, 1674)	3.2540068055348477
  (0, 1673)	3.2540068055348477
  (0, 1672)	3.2000064378146242
  (0, 1671)	3.1333046559473883
  (0, 1670)	3.2540068055348477
  (0, 1669)	3.2540068055348477
  (0, 1668)	3.2013472531862375
  (0, 1667)	3.2540068055348477
  (0, 1666)	3.2540068055348477
  (0, 1665)	3.2013472531862375
  (0, 1664)	3.2540068055348477
  (0, 1663)	3.1685530662136636
  (0, 1662)	3.2013472531862375
  (0, 1661)	3.1914723285105975
  (0, 1660)	3.067150080823551
  (0, 1659)	3.1058592151034032
  (0, 1658)	3.2540068055348477
  (0, 1657)	3.280603461752347
  :	:
  (942, 24)	3.577661078925303
  (942, 23)	3.565746117119774
  (942, 22)	4.2838017545175235
  (942, 21)	4.306569773718703
  (942, 20)	2.834700529299578
  (942, 19)	3.714428838624628
  (942, 18)	4.061698419410181
  (942, 17)	3.1840619473613
  (942, 16)	3.22313025148922
  (942, 15)	3.4962847641841557
  (942, 14)	3.832333746989836
  (942, 13)	4.1109623640849895
  (942, 12)	3.497281968489239
  (942, 11)	4.48795071457713
  (942, 10)	3.9817191946759545
  (942, 9)	3.9311998145020235
  (942, 8)	4.014552881025547
  (942, 7)	4.142653442204259
  (942, 6)	3.904230408614738
  (942, 5)	3.9837143413397285
  (942, 4)	3.405251577509489
  (942, 3)	3.6439299629192736
  (942, 2)	3.1466079362862707
  (942, 1)	3.33949455023448
  (942, 0)	3.968685266017564
this is the 261 epoch
rmse loss on training set is 0.9200789036822027
rmse loss on test set is 0.940495019341508
for this epoch using 78.44278717041016 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2449267710405776
  (0, 1680)	3.272903461711623
  (0, 1679)	3.164354806701408
  (0, 1678)	3.248337779019901
  (0, 1677)	3.0803718343829205
  (0, 1676)	3.2577233456546004
  (0, 1675)	3.253951478842038
  (0, 1674)	3.253951478842038
  (0, 1673)	3.253951478842038
  (0, 1672)	3.1997370751500904
  (0, 1671)	3.132872482723181
  (0, 1670)	3.253951478842038
  (0, 1669)	3.253951478842038
  (0, 1668)	3.201104963855263
  (0, 1667)	3.253951478842038
  (0, 1666)	3.253951478842038
  (0, 1665)	3.201104963855263
  (0, 1664)	3.253951478842038
  (0, 1663)	3.1682076187793022
  (0, 1662)	3.201104963855263
  (0, 1661)	3.191218120912059
  (0, 1660)	3.0664310254011107
  (0, 1659)	3.1052919312134937
  (0, 1658)	3.253951478842038
  (0, 1657)	3.2806669598502984
  :	:
  (942, 24)	3.57762754120199
  (942, 23)	3.565690050345254
  (942, 22)	4.28393042070962
  (942, 21)	4.306632284281415
  (942, 20)	2.834650772139225
  (942, 19)	3.714552095231927
  (942, 18)	4.06191160209546
  (942, 17)	3.1838497441857276
  (942, 16)	3.2231172508150556
  (942, 15)	3.4965204005721513
  (942, 14)	3.8322502371947067
  (942, 13)	4.110985986725452
  (942, 12)	3.497302203931229
  (942, 11)	4.488016412395332
  (942, 10)	3.9817514590501357
  (942, 9)	3.9312895970326887
  (942, 8)	4.014521666550612
  (942, 7)	4.142714356046383
  (942, 6)	3.9041839447829365
  (942, 5)	3.984880107843258
  (942, 4)	3.405237704628859
  (942, 3)	3.6439908293902437
  (942, 2)	3.146567551527026
  (942, 1)	3.3395151716115277
  (942, 0)	3.968641558044618
this is the 262 epoch
rmse loss on training set is 0.9200548379807453
rmse loss on test set is 0.9404825333960961
for this epoch using 77.5629370212555 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.244850052887414
  (0, 1680)	3.272929625043892
  (0, 1679)	3.1639704931107477
  (0, 1678)	3.248259247778939
  (0, 1677)	3.079681738442574
  (0, 1676)	3.257695372846236
  (0, 1675)	3.2538966156308464
  (0, 1674)	3.2538966156308464
  (0, 1673)	3.2538966156308464
  (0, 1672)	3.199468350841801
  (0, 1671)	3.132441071178287
  (0, 1670)	3.2538966156308464
  (0, 1669)	3.2538966156308464
  (0, 1668)	3.2008631569095276
  (0, 1667)	3.2538966156308464
  (0, 1666)	3.2538966156308464
  (0, 1665)	3.2008631569095276
  (0, 1664)	3.2538966156308464
  (0, 1663)	3.167862832806072
  (0, 1662)	3.2008631569095276
  (0, 1661)	3.190964565735179
  (0, 1660)	3.0657126994710406
  (0, 1659)	3.104725399956765
  (0, 1658)	3.2538966156308464
  (0, 1657)	3.2807308626519553
  :	:
  (942, 24)	3.5775936084702082
  (942, 23)	3.5656337891523986
  (942, 22)	4.284057295466768
  (942, 21)	4.306693472069934
  (942, 20)	2.834601262318321
  (942, 19)	3.714673159158212
  (942, 18)	4.062121489971999
  (942, 17)	3.1836380504643764
  (942, 16)	3.2231038805937318
  (942, 15)	3.4967537036422143
  (942, 14)	3.832166701564904
  (942, 13)	4.111008751733363
  (942, 12)	3.4973216314824813
  (942, 11)	4.488080790008257
  (942, 10)	3.9817827173041844
  (942, 9)	3.9313776426679716
  (942, 8)	4.014489972247005
  (942, 7)	4.1427739945044895
  (942, 6)	3.9041371702376706
  (942, 5)	3.9860388406540257
  (942, 4)	3.40522325130066
  (942, 3)	3.6440505044645746
  (942, 2)	3.1465269504869884
  (942, 1)	3.3395349484016283
  (942, 0)	3.968597477146223
this is the 263 epoch
rmse loss on training set is 0.920030973864207
rmse loss on test set is 0.940470219582095
for this epoch using 78.29483985900879 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2447738480152704
  (0, 1680)	3.2729562407125257
  (0, 1679)	3.16358671817798
  (0, 1678)	3.2481811647194565
  (0, 1677)	3.0789922716365066
  (0, 1676)	3.2576678767595246
  (0, 1675)	3.2538422113122794
  (0, 1674)	3.2538422113122794
  (0, 1673)	3.2538422113122794
  (0, 1672)	3.199200259764694
  (0, 1671)	3.132010415577484
  (0, 1670)	3.2538422113122794
  (0, 1669)	3.2538422113122794
  (0, 1668)	3.2006218278402376
  (0, 1667)	3.2538422113122794
  (0, 1666)	3.2538422113122794
  (0, 1665)	3.2006218278402376
  (0, 1664)	3.2538422113122794
  (0, 1663)	3.167518703285242
  (0, 1662)	3.2006218278402376
  (0, 1661)	3.1907116577936714
  (0, 1660)	3.064995097860394
  (0, 1659)	3.1041596159329994
  (0, 1658)	3.2538422113122794
  (0, 1657)	3.280795165275391
  :	:
  (942, 24)	3.577559294125027
  (942, 23)	3.5655773447235304
  (942, 22)	4.284182406385622
  (942, 21)	4.306753361154023
  (942, 20)	2.8345519975304874
  (942, 19)	3.7147920694134977
  (942, 18)	4.062328137306625
  (942, 17)	3.1834268737182883
  (942, 16)	3.2230901508824963
  (942, 15)	3.496984700827427
  (942, 14)	3.832083150712169
  (942, 13)	4.111030678157123
  (942, 12)	3.4973402680790016
  (942, 11)	4.488143871075614
  (942, 10)	3.9818129894802596
  (942, 9)	3.931463985300927
  (942, 8)	4.014457813446535
  (942, 7)	4.142832380557953
  (942, 6)	3.9040900984084863
  (942, 5)	3.987190591158885
  (942, 4)	3.4052082327751236
  (942, 3)	3.644109009205731
  (942, 2)	3.14648614263095
  (942, 1)	3.339553898178969
  (942, 0)	3.9685530375315468
this is the 264 epoch
rmse loss on training set is 0.9200073089355687
rmse loss on test set is 0.9404580756323426
for this epoch using 75.69444823265076 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.244698151550018
  (0, 1680)	3.2729833040859875
  (0, 1679)	3.1632034773262974
  (0, 1678)	3.2481035253045953
  (0, 1677)	3.0783034293480065
  (0, 1676)	3.257640852673061
  (0, 1675)	3.2537882613536127
  (0, 1674)	3.2537882613536127
  (0, 1673)	3.2537882613536127
  (0, 1672)	3.198932796849657
  (0, 1671)	3.131580510254171
  (0, 1670)	3.2537882613536127
  (0, 1669)	3.2537882613536127
  (0, 1668)	3.200380972194837
  (0, 1667)	3.2537882613536127
  (0, 1666)	3.2537882613536127
  (0, 1665)	3.200380972194837
  (0, 1664)	3.2537882613536127
  (0, 1663)	3.1671752252689274
  (0, 1662)	3.200380972194837
  (0, 1661)	3.1904593919607924
  (0, 1660)	3.0642782154584434
  (0, 1659)	3.1035945738060238
  (0, 1658)	3.2537882613536127
  (0, 1657)	3.280859862900127
  :	:
  (942, 24)	3.577524611284201
  (942, 23)	3.5655207279892625
  (942, 22)	4.284305780621312
  (942, 21)	4.306811975184363
  (942, 20)	2.834502975541057
  (942, 19)	3.714908864340112
  (942, 18)	4.062531597453355
  (942, 17)	3.183216221247792
  (942, 16)	3.2230760715451514
  (942, 15)	3.497213419192558
  (942, 14)	3.8319995949899037
  (942, 13)	4.111051784681631
  (942, 12)	3.4973581303427475
  (942, 11)	4.488205678850202
  (942, 10)	3.9818422952608397
  (942, 9)	3.931548658159523
  (942, 8)	4.014425205167614
  (942, 7)	4.142889536791604
  (942, 6)	3.904042742428997
  (942, 5)	3.988335410251343
  (942, 4)	3.4051926639901136
  (942, 3)	3.644166364315177
  (942, 2)	3.146445137231259
  (942, 1)	3.339572038191772
  (942, 0)	3.968508253109461
this is the 265 epoch
rmse loss on training set is 0.9199838408335438
rmse loss on test set is 0.940446099313473
for this epoch using 76.5740258693695 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.244622958676069
  (0, 1680)	3.2730108105891
  (0, 1679)	3.1628207660355794
  (0, 1678)	3.2480263250536097
  (0, 1677)	3.077615207017568
  (0, 1676)	3.2576142959227568
  (0, 1675)	3.2537347612775283
  (0, 1674)	3.2537347612775283
  (0, 1673)	3.2537347612775283
  (0, 1672)	3.198665957082797
  (0, 1671)	3.1311513496093237
  (0, 1670)	3.2537347612775283
  (0, 1669)	3.2537347612775283
  (0, 1668)	3.200140585576115
  (0, 1667)	3.2537347612775283
  (0, 1666)	3.2537347612775283
  (0, 1665)	3.200140585576115
  (0, 1664)	3.2537347612775283
  (0, 1663)	3.1668323938691403
  (0, 1662)	3.200140585576115
  (0, 1661)	3.19020776316849
  (0, 1660)	3.0635620472157394
  (0, 1659)	3.1030302683027697
  (0, 1658)	3.2537347612775283
  (0, 1657)	3.280924950766218
  :	:
  (942, 24)	3.577489572793246
  (942, 23)	3.5654639496333904
  (942, 22)	4.284427444894654
  (942, 21)	4.306869337399634
  (942, 20)	2.8344541941844943
  (942, 19)	3.7150235816237607
  (942, 18)	4.062731922868985
  (942, 17)	3.1830061001369034
  (942, 16)	3.223061652255328
  (942, 15)	3.497439885439429
  (942, 14)	3.8319160444983247
  (942, 13)	4.111072089634927
  (942, 12)	3.4973752345871807
  (942, 11)	4.488266236184726
  (942, 10)	3.9818706539749287
  (942, 9)	3.9316316938199383
  (942, 8)	4.014392162121027
  (942, 7)	4.142945485402239
  (942, 6)	3.9039951151424166
  (942, 5)	3.989473348337552
  (942, 4)	3.4051765595772148
  (942, 3)	3.64422259013859
  (942, 2)	3.1464039433709856
  (942, 1)	3.33958938536812
  (942, 0)	3.9684631374940427
this is the 266 epoch
rmse loss on training set is 0.91996056723188
rmse loss on test set is 0.9404342884253492
for this epoch using 76.45616173744202 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2445482646354993
  (0, 1680)	3.273038755702063
  (0, 1679)	3.1624385798415102
  (0, 1678)	3.247949559541041
  (0, 1677)	3.0769276001419934
  (0, 1676)	3.257588201900969
  (0, 1675)	3.253681706661225
  (0, 1674)	3.253681706661225
  (0, 1673)	3.253681706661225
  (0, 1672)	3.1983997355046627
  (0, 1671)	3.1307229281104365
  (0, 1670)	3.253681706661225
  (0, 1669)	3.253681706661225
  (0, 1668)	3.199900663641324
  (0, 1667)	3.253681706661225
  (0, 1666)	3.253681706661225
  (0, 1665)	3.199900663641324
  (0, 1664)	3.253681706661225
  (0, 1663)	3.1664902042568266
  (0, 1662)	3.199900663641324
  (0, 1661)	3.189956766406456
  (0, 1660)	3.062846588143146
  (0, 1659)	3.1024666942122634
  (0, 1658)	3.253681706661225
  (0, 1657)	3.280990424173225
  :	:
  (942, 24)	3.577454191230395
  (942, 23)	3.5654070200976444
  (942, 22)	4.284547425499239
  (942, 21)	4.306925470633577
  (942, 20)	2.8344056513618594
  (942, 19)	3.715136258304375
  (942, 18)	4.062929165128427
  (942, 17)	3.182796517257701
  (942, 16)	3.223046902499699
  (942, 15)	3.497664125912279
  (942, 14)	3.8318325090893404
  (942, 13)	4.111091610994679
  (942, 12)	3.49739159682283
  (942, 11)	4.488325565538571
  (942, 10)	3.981898084604114
  (942, 9)	3.9317131242196224
  (942, 8)	4.0143586987155535
  (942, 7)	4.143000248205197
  (942, 6)	3.903947229107212
  (942, 5)	3.9906044553423166
  (942, 4)	3.4051599338676537
  (942, 3)	3.6442777066718404
  (942, 2)	3.146362569947019
  (942, 1)	3.3396059563216767
  (942, 0)	3.9684177040100357
this is the 267 epoch
rmse loss on training set is 0.9199374858387691
rmse loss on test set is 0.940422640800454
for this epoch using 77.13588285446167 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.24447406472716
  (0, 1680)	3.273067134959689
  (0, 1679)	3.162056914334693
  (0, 1678)	3.247873224395836
  (0, 1677)	3.0762406042735617
  (0, 1676)	3.2575625660556278
  (0, 1675)	3.253629093135574
  (0, 1674)	3.253629093135574
  (0, 1673)	3.253629093135574
  (0, 1672)	3.198134127209513
  (0, 1671)	3.1302952402905384
  (0, 1670)	3.253629093135574
  (0, 1669)	3.253629093135574
  (0, 1668)	3.1996612021013395
  (0, 1667)	3.253629093135574
  (0, 1666)	3.253629093135574
  (0, 1665)	3.1996612021013395
  (0, 1664)	3.253629093135574
  (0, 1663)	3.1661486516609996
  (0, 1662)	3.1996612021013395
  (0, 1661)	3.189706396721314
  (0, 1660)	3.062131833310916
  (0, 1659)	3.101903846384714
  (0, 1658)	3.253629093135574
  (0, 1657)	3.2810562784793236
  :	:
  (942, 24)	3.5774184789115773
  (942, 23)	3.5653499495863956
  (942, 22)	4.284665748308368
  (942, 21)	4.306980397321841
  (942, 20)	2.8343573450383692
  (942, 19)	3.7152469307868436
  (942, 18)	4.063123374939793
  (942, 17)	3.1825874792745563
  (942, 16)	3.223031831581109
  (942, 15)	3.4978861666029655
  (942, 14)	3.8317489983714648
  (942, 13)	4.111110366394533
  (942, 12)	3.4974072327625945
  (942, 11)	4.488383688984429
  (942, 10)	3.9819246057885462
  (942, 9)	3.931792980670062
  (942, 8)	4.014324829063477
  (942, 7)	4.143053846640639
  (942, 6)	3.903899096602453
  (942, 5)	3.991728780714916
  (942, 4)	3.4051428008981626
  (942, 3)	3.6443317335670398
  (942, 2)	3.146321025673115
  (942, 1)	3.3396217673572055
  (942, 0)	3.968371965698124
this is the 268 epoch
rmse loss on training set is 0.9199145943962486
rmse loss on test set is 0.9404111543033447
for this epoch using 76.81842803955078 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.244400354305777
  (0, 1680)	3.2730959439504934
  (0, 1679)	3.1616757651598064
  (0, 1678)	3.247797315300499
  (0, 1677)	3.0755542150191277
  (0, 1676)	3.2575373838893626
  (0, 1675)	3.2535769163843096
  (0, 1674)	3.2535769163843096
  (0, 1673)	3.2535769163843096
  (0, 1672)	3.197869127344612
  (0, 1671)	3.129868280747172
  (0, 1670)	3.2535769163843096
  (0, 1669)	3.2535769163843096
  (0, 1668)	3.199422196719832
  (0, 1667)	3.2535769163843096
  (0, 1666)	3.2535769163843096
  (0, 1665)	3.199422196719832
  (0, 1664)	3.2535769163843096
  (0, 1663)	3.165807731367853
  (0, 1662)	3.199422196719832
  (0, 1661)	3.1894566492157206
  (0, 1660)	3.0614177778477876
  (0, 1659)	3.1013417197305704
  (0, 1658)	3.2535769163843096
  (0, 1657)	3.2811225091003706
  :	:
  (942, 24)	3.577382447895185
  (942, 23)	3.5652927480712635
  (942, 22)	4.284782438781958
  (942, 21)	4.307034139508816
  (942, 20)	2.834309273241044
  (942, 19)	3.7153556348514973
  (942, 18)	4.063314602159202
  (942, 17)	3.1823789926483257
  (942, 16)	3.223016448621736
  (942, 15)	3.4981060331561693
  (942, 14)	3.831665521714543
  (942, 13)	4.111128373130385
  (942, 12)	3.497422157827095
  (942, 11)	4.488440628214853
  (942, 10)	3.9819502358328323
  (942, 9)	3.931871293869381
  (942, 8)	4.0142905669860545
  (942, 7)	4.1431063017798735
  (942, 6)	3.903850729633239
  (942, 5)	3.992846373434955
  (942, 4)	3.405125174416645
  (942, 3)	3.64438469013828
  (942, 2)	3.146279319082963
  (942, 1)	3.3396368344761562
  (942, 0)	3.96832593532026
this is the 269 epoch
rmse loss on training set is 0.9198918906795984
rmse loss on test set is 0.9403998268301086
for this epoch using 77.415363073349 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2443271287811752
  (0, 1680)	3.2731251783159494
  (0, 1679)	3.161295128014818
  (0, 1678)	3.2477218279903135
  (0, 1677)	3.0748684280393253
  (0, 1676)	3.2575126509586987
  (0, 1675)	3.253525172143234
  (0, 1674)	3.253525172143234
  (0, 1673)	3.253525172143234
  (0, 1672)	3.1976047311095104
  (0, 1671)	3.1294420441414452
  (0, 1670)	3.253525172143234
  (0, 1669)	3.253525172143234
  (0, 1668)	3.1991836433124576
  (0, 1667)	3.253525172143234
  (0, 1666)	3.253525172143234
  (0, 1665)	3.1991836433124576
  (0, 1664)	3.253525172143234
  (0, 1663)	3.1654674387198978
  (0, 1662)	3.1991836433124576
  (0, 1661)	3.189207519047581
  (0, 1660)	3.060704416940128
  (0, 1659)	3.100780309219625
  (0, 1658)	3.253525172143234
  (0, 1657)	3.281189111509007
  :	:
  (942, 24)	3.5773461099868613
  (942, 23)	3.5652354252956115
  (942, 22)	4.28489752197321
  (942, 21)	4.307086718854341
  (942, 20)	2.834261434056431
  (942, 19)	3.7154624056644545
  (942, 18)	4.063502895805347
  (942, 17)	3.1821710636404483
  (942, 16)	3.22300076256612
  (942, 15)	3.498323750874438
  (942, 14)	3.8315820882544864
  (942, 13)	4.11114564816652
  (942, 12)	3.4974363871498833
  (942, 11)	4.488496404548651
  (942, 10)	3.9819749927118218
  (942, 9)	3.9319480939145235
  (942, 8)	4.014255926018851
  (942, 7)	4.143157634331508
  (942, 6)	3.903802139935886
  (942, 5)	3.9939572820180786
  (942, 4)	3.405107067887842
  (942, 3)	3.6444365953675057
  (942, 2)	3.146237458533174
  (942, 1)	3.339651173382017
  (942, 0)	3.9682796253647683
this is the 270 epoch
rmse loss on training set is 0.9198693724966982
rmse loss on test set is 0.9403886563078045
for this epoch using 75.5444130897522 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.244254383617349
  (0, 1680)	3.2731548337496075
  (0, 1679)	3.160914998650084
  (0, 1678)	3.2476467582524715
  (0, 1677)	3.07418323904771
  (0, 1676)	3.2574883628731905
  (0, 1675)	3.253473856199361
  (0, 1674)	3.253473856199361
  (0, 1673)	3.253473856199361
  (0, 1672)	3.1973409337553367
  (0, 1671)	3.1290165251970588
  (0, 1670)	3.253473856199361
  (0, 1669)	3.253473856199361
  (0, 1668)	3.1989455377460025
  (0, 1667)	3.253473856199361
  (0, 1666)	3.253473856199361
  (0, 1665)	3.1989455377460025
  (0, 1664)	3.253473856199361
  (0, 1663)	3.165127769115083
  (0, 1662)	3.1989455377460025
  (0, 1661)	3.1889590014291906
  (0, 1660)	3.0599917458309744
  (0, 1659)	3.1002196098801114
  (0, 1658)	3.253473856199361
  (0, 1657)	3.2812560812337677
  :	:
  (942, 24)	3.577309476744101
  (942, 23)	3.565177990779021
  (942, 22)	4.2850110225353095
  (942, 21)	4.307138156640193
  (942, 20)	2.834213825628377
  (942, 19)	3.7155672777878848
  (942, 18)	4.063688304073794
  (942, 17)	3.1819636983169803
  (942, 16)	3.222984782184191
  (942, 15)	3.498539344723189
  (942, 14)	3.8314987068978335
  (942, 13)	4.111162208141648
  (942, 12)	3.4974499355825417
  (942, 11)	4.488551038937199
  (942, 10)	3.981998894076266
  (942, 9)	3.9320234103133513
  (942, 8)	4.0142209194169896
  (942, 7)	4.143207864647519
  (942, 6)	3.9037533389831833
  (942, 5)	3.995061554521567
  (942, 4)	3.4050884944988087
  (942, 3)	3.6444874679101056
  (942, 2)	3.1461954522061593
  (942, 1)	3.3396647994856417
  (942, 0)	3.968233048051428
this is the 271 epoch
rmse loss on training set is 0.919847037687557
rmse loss on test set is 0.9403776406939369
for this epoch using 75.58355808258057 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.244182114331728
  (0, 1680)	3.273184905996346
  (0, 1679)	3.160535372867646
  (0, 1678)	3.2475721019253463
  (0, 1677)	3.0734986438099523
  (0, 1676)	3.257464515294672
  (0, 1675)	3.253422964390194
  (0, 1674)	3.253422964390194
  (0, 1673)	3.253422964390194
  (0, 1672)	3.1970777305841134
  (0, 1671)	3.12859171869937
  (0, 1670)	3.253422964390194
  (0, 1669)	3.253422964390194
  (0, 1668)	3.198707875937699
  (0, 1667)	3.253422964390194
  (0, 1666)	3.253422964390194
  (0, 1665)	3.198707875937699
  (0, 1664)	3.253422964390194
  (0, 1663)	3.164788718006001
  (0, 1662)	3.198707875937699
  (0, 1661)	3.188711091626462
  (0, 1660)	3.0592797598192765
  (0, 1659)	3.0996596167978407
  (0, 1658)	3.253422964390194
  (0, 1657)	3.2813234138582286
  :	:
  (942, 24)	3.5772725594808814
  (942, 23)	3.5651204538215557
  (942, 22)	4.2851229647278295
  (942, 21)	4.307188473776618
  (942, 20)	2.8341664461558773
  (942, 19)	3.7156702851899706
  (942, 18)	4.063870874351033
  (942, 17)	3.181756902552533
  (942, 16)	3.2229685160742445
  (942, 15)	3.498752839335652
  (942, 14)	3.831415386326338
  (942, 13)	4.111178069374801
  (942, 12)	3.497462817699713
  (942, 11)	4.488604551970666
  (942, 10)	3.9820219572584303
  (942, 9)	3.9320972719963665
  (942, 8)	4.014185560160289
  (942, 7)	4.143257012729195
  (942, 6)	3.9037043379893612
  (942, 5)	3.996159238549947
  (942, 4)	3.4050694671642807
  (942, 3)	3.644537326100482
  (942, 2)	3.1461533081131363
  (942, 1)	3.3396777279104835
  (942, 0)	3.968186215336429
this is the 272 epoch
rmse loss on training set is 0.919824884123674
rmse loss on test set is 0.9403667779759477
for this epoch using 75.49284505844116 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.244110316494325
  (0, 1680)	3.273215390851597
  (0, 1679)	3.160156246520374
  (0, 1678)	3.2474978548976683
  (0, 1677)	3.0728146381430896
  (0, 1676)	3.2574411039363977
  (0, 1675)	3.2533724926029346
  (0, 1674)	3.2533724926029346
  (0, 1673)	3.2533724926029346
  (0, 1672)	3.1968151169481205
  (0, 1671)	3.1281676194944974
  (0, 1670)	3.2533724926029346
  (0, 1669)	3.2533724926029346
  (0, 1668)	3.1984706538543457
  (0, 1667)	3.2533724926029346
  (0, 1666)	3.2533724926029346
  (0, 1665)	3.1984706538543457
  (0, 1664)	3.2533724926029346
  (0, 1663)	3.164450280899038
  (0, 1662)	3.1984706538543457
  (0, 1661)	3.188463784958138
  (0, 1660)	3.058568454258988
  (0, 1659)	3.099100325115341
  (0, 1658)	3.2533724926029346
  (0, 1657)	3.281391105020155
  :	:
  (942, 24)	3.5772353692721244
  (942, 23)	3.5650628235081188
  (942, 22)	4.285233372423259
  (942, 21)	4.307237690808591
  (942, 20)	2.83411929389105
  (942, 19)	3.715771461254773
  (942, 18)	4.064050653228323
  (942, 17)	3.1815506820341555
  (942, 16)	3.2229519726658715
  (942, 15)	3.498964259017739
  (942, 14)	3.8313321350012917
  (942, 13)	4.111193247871187
  (942, 12)	3.4974750478040275
  (942, 11)	4.488656963884092
  (942, 10)	3.9820441992775955
  (942, 9)	3.9321697073282604
  (942, 8)	4.014149860958343
  (942, 7)	4.143305098233062
  (942, 6)	3.9036551479151096
  (942, 5)	3.9972503812604367
  (942, 4)	3.4050499985320175
  (942, 3)	3.6445861879575268
  (942, 2)	3.1461110340969056
  (942, 1)	3.3396899734977166
  (942, 0)	3.9681391389172704
this is the 273 epoch
rmse loss on training set is 0.919802909707493
rmse loss on test set is 0.940356066170691
for this epoch using 76.49999213218689 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.244038985726962
  (0, 1680)	3.2732462841605625
  (0, 1679)	3.1597776155112225
  (0, 1678)	3.2474240131077647
  (0, 1677)	3.072131217914681
  (0, 1676)	3.2574181245623004
  (0, 1675)	3.253322436773727
  (0, 1674)	3.253322436773727
  (0, 1673)	3.253322436773727
  (0, 1672)	3.19655308824917
  (0, 1671)	3.1277442224883445
  (0, 1670)	3.253322436773727
  (0, 1669)	3.253322436773727
  (0, 1668)	3.198233867511614
  (0, 1667)	3.253322436773727
  (0, 1666)	3.253322436773727
  (0, 1665)	3.198233867511614
  (0, 1664)	3.253322436773727
  (0, 1663)	3.164112453353558
  (0, 1662)	3.198233867511614
  (0, 1661)	3.1882170767949694
  (0, 1660)	3.057857824558275
  (0, 1659)	3.098541730031006
  (0, 1658)	3.253322436773727
  (0, 1657)	3.2814591504106536
  :	:
  (942, 24)	3.577197916958141
  (942, 23)	3.5650051087125805
  (942, 22)	4.285342269113189
  (942, 21)	4.307285827922171
  (942, 20)	2.834072367137088
  (942, 19)	3.715870838792011
  (942, 18)	4.064227686515199
  (942, 17)	3.181345042265155
  (942, 16)	3.222935160222829
  (942, 15)	3.4991736277527545
  (942, 14)	3.8312489611680043
  (942, 13)	4.111207759327845
  (942, 12)	3.4974866399310183
  (942, 11)	4.48870829456343
  (942, 10)	3.982065636845467
  (942, 9)	3.9322407441192464
  (942, 8)	4.014113834255499
  (942, 7)	4.143352140476629
  (942, 6)	3.90360577947249
  (942, 5)	3.998335029368354
  (942, 4)	3.4050301009879385
  (942, 3)	3.64463407119
  (942, 2)	3.146068637834748
  (942, 1)	3.3397015508112755
  (942, 0)	3.96809183023759
this is the 274 epoch
rmse loss on training set is 0.9197811123719137
rmse loss on test set is 0.940345503323958
for this epoch using 75.40610003471375 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.243968117702518
  (0, 1680)	3.2732775818174966
  (0, 1679)	3.159399475792492
  (0, 1678)	3.2473505725428775
  (0, 1677)	3.0714483790421205
  (0, 1676)	3.257395572986255
  (0, 1675)	3.253272792886963
  (0, 1674)	3.253272792886963
  (0, 1673)	3.253272792886963
  (0, 1672)	3.1962916399380137
  (0, 1671)	3.1273215226458313
  (0, 1670)	3.253272792886963
  (0, 1669)	3.253272792886963
  (0, 1668)	3.197997512973333
  (0, 1667)	3.253272792886963
  (0, 1666)	3.253272792886963
  (0, 1665)	3.197997512973333
  (0, 1664)	3.253272792886963
  (0, 1663)	3.1637752309811917
  (0, 1662)	3.197997512973333
  (0, 1661)	3.187970962559049
  (0, 1660)	3.0571478661787017
  (0, 1659)	3.0979838267982824
  (0, 1658)	3.253272792886963
  (0, 1657)	3.281527545773393
  :	:
  (942, 24)	3.5771602131489506
  (942, 23)	3.564947318101907
  (942, 22)	4.2854496779145705
  (942, 21)	4.3073329049505364
  (942, 20)	2.834025664246374
  (942, 19)	3.7159684500465366
  (942, 18)	4.064402019252888
  (942, 17)	3.181139988568837
  (942, 16)	3.2229180868458935
  (942, 15)	3.4993809692061655
  (942, 14)	3.8311658728599887
  (942, 13)	4.111221619139288
  (942, 12)	3.4974976078538
  (942, 11)	4.4887585635514435
  (942, 10)	3.98208628637145
  (942, 9)	3.9323104096360684
  (942, 8)	4.0140774922357405
  (942, 7)	4.143398158444084
  (942, 6)	3.9035562431296795
  (942, 5)	3.9994132291524984
  (942, 4)	3.405009786661252
  (942, 3)	3.644680993201805
  (942, 2)	3.146026126841167
  (942, 1)	3.3397124741428423
  (942, 0)	3.9680443004918673
this is the 275 epoch
rmse loss on training set is 0.9197594900796986
rmse loss on test set is 0.9403350875099468
for this epoch using 76.15429711341858 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2438977081441505
  (0, 1680)	3.273309279764967
  (0, 1679)	3.159021823365087
  (0, 1678)	3.2472775292383393
  (0, 1677)	3.0707661174918415
  (0, 1676)	3.2573734450713094
  (0, 1675)	3.253223556974503
  (0, 1674)	3.253223556974503
  (0, 1673)	3.253223556974503
  (0, 1672)	3.1960307675136743
  (0, 1671)	3.1268995149899173
  (0, 1670)	3.253223556974503
  (0, 1669)	3.253223556974503
  (0, 1668)	3.1977615863506936
  (0, 1667)	3.253223556974503
  (0, 1666)	3.253223556974503
  (0, 1665)	3.1977615863506936
  (0, 1664)	3.253223556974503
  (0, 1663)	3.163438609444968
  (0, 1662)	3.1977615863506936
  (0, 1661)	3.1877254377229933
  (0, 1660)	3.0564385746344453
  (0, 1659)	3.0974266107248583
  (0, 1658)	3.253223556974503
  (0, 1657)	3.2815962869037585
  :	:
  (942, 24)	3.577122268228544
  (942, 23)	3.5648894601401766
  (942, 22)	4.285555621575775
  (942, 21)	4.307378941380086
  (942, 20)	2.8339791836185326
  (942, 19)	3.716064326707791
  (942, 18)	4.064573695727365
  (942, 17)	3.180935526092132
  (942, 16)	3.222900760475629
  (942, 15)	3.499586306730212
  (942, 14)	3.831082877903193
  (942, 13)	4.111234842403015
  (942, 12)	3.4975079650878036
  (942, 11)	4.488807790053468
  (942, 10)	3.9821061639679423
  (942, 9)	3.9323787306128786
  (942, 8)	4.0140408468274815
  (942, 7)	4.143443170791854
  (942, 6)	3.903506549115714
  (942, 5)	4.000485026460359
  (942, 4)	3.404989067429425
  (942, 3)	3.6447269710971693
  (942, 2)	3.1459835084706635
  (942, 1)	3.3397227575166615
  (942, 0)	3.967996560630044
this is the 276 epoch
rmse loss on training set is 0.9197380408230081
rmse loss on test set is 0.9403248168308334
for this epoch using 75.88529396057129 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.243827752824541
  (0, 1680)	3.2733413739931088
  (0, 1679)	3.158644654277733
  (0, 1678)	3.2472048792769055
  (0, 1677)	3.07008442927857
  (0, 1676)	3.257351736728918
  (0, 1675)	3.2531747251149867
  (0, 1674)	3.2531747251149867
  (0, 1673)	3.2531747251149867
  (0, 1672)	3.1957704665228164
  (0, 1671)	3.126478194600785
  (0, 1670)	3.2531747251149867
  (0, 1669)	3.2531747251149867
  (0, 1668)	3.1975260838015664
  (0, 1667)	3.2531747251149867
  (0, 1666)	3.2531747251149867
  (0, 1665)	3.1975260838015664
  (0, 1664)	3.2531747251149867
  (0, 1663)	3.1631025844585823
  (0, 1662)	3.1975260838015664
  (0, 1661)	3.187480497809238
  (0, 1660)	3.0557299454914792
  (0, 1659)	3.0968700771718694
  (0, 1658)	3.2531747251149867
  (0, 1657)	3.28166536964809
  :	:
  (942, 24)	3.5770840923590783
  (942, 23)	3.564831543092552
  (942, 22)	4.285660122482592
  (942, 21)	4.307423956356329
  (942, 20)	2.833932923698675
  (942, 19)	3.7161584999190196
  (942, 18)	4.064742759482249
  (942, 17)	3.1807316598092394
  (942, 16)	3.2228831888951803
  (942, 15)	3.499789663368453
  (942, 14)	3.8309999839201305
  (942, 13)	4.111247443924857
  (942, 12)	3.497517724895388
  (942, 11)	4.4888559929431535
  (942, 10)	3.982125285455361
  (942, 9)	3.93244573326184
  (942, 8)	4.014003909708276
  (942, 7)	4.143487195854178
  (942, 6)	3.903456707425107
  (942, 5)	4.001550466713305
  (942, 4)	3.4049679549230656
  (942, 3)	3.6447720216858053
  (942, 2)	3.1459407899204317
  (942, 1)	3.3397324146943834
  (942, 0)	3.9679486213620994
this is the 277 epoch
rmse loss on training set is 0.9197167626228707
rmse loss on test set is 0.9403146894162739
for this epoch using 75.27388501167297 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2437582475651965
  (0, 1680)	3.2733738605389657
  (0, 1679)	3.1582679646263694
  (0, 1678)	3.2471326187880685
  (0, 1677)	3.069403310464673
  (0, 1676)	3.257330443918287
  (0, 1675)	3.2531262934331675
  (0, 1674)	3.2531262934331675
  (0, 1673)	3.2531262934331675
  (0, 1672)	3.1955107325591277
  (0, 1671)	3.1260575566150193
  (0, 1670)	3.2531262934331675
  (0, 1669)	3.2531262934331675
  (0, 1668)	3.1972910015298335
  (0, 1667)	3.2531262934331675
  (0, 1666)	3.2531262934331675
  (0, 1665)	3.1972910015298335
  (0, 1664)	3.2531262934331675
  (0, 1663)	3.1627671517857014
  (0, 1662)	3.1972910015298335
  (0, 1661)	3.1872361383893395
  (0, 1660)	3.0550219743668654
  (0, 1659)	3.0963142215531
  (0, 1658)	3.2531262934331675
  (0, 1657)	3.2817347899029397
  :	:
  (942, 24)	3.5770456954850043
  (942, 23)	3.5647735750291547
  (942, 22)	4.285763202664119
  (942, 21)	4.307467968689773
  (942, 20)	2.8338868829756563
  (942, 19)	3.716251000286402
  (942, 18)	4.064909253331489
  (942, 17)	3.18052839452516
  (942, 16)	3.2228653797329256
  (942, 15)	3.4999910618602765
  (942, 14)	3.8309171983338843
  (942, 13)	4.111259438224341
  (942, 12)	3.4975269002903437
  (942, 11)	4.488903190768085
  (942, 10)	3.982143666367332
  (942, 9)	3.932511443283547
  (942, 8)	4.0139666923094905
  (942, 7)	4.14353025164846
  (942, 6)	3.903406727822351
  (942, 5)	4.00260959491172
  (942, 4)	3.4049464605307604
  (942, 3)	3.644816161487864
  (942, 2)	3.145897978233037
  (942, 1)	3.339741459179724
  (942, 0)	3.967900493162573
this is the 278 epoch
rmse loss on training set is 0.9196956535286851
rmse loss on test set is 0.9403047034229323
for this epoch using 76.66517806053162 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2436891882357197
  (0, 1680)	3.273406735485789
  (0, 1679)	3.157891750553343
  (0, 1678)	3.247060743947322
  (0, 1677)	3.0687227571593705
  (0, 1676)	3.2573095626456268
  (0, 1675)	3.253078258099201
  (0, 1674)	3.253078258099201
  (0, 1673)	3.253078258099201
  (0, 1672)	3.195251561262745
  (0, 1671)	3.1256375962247724
  (0, 1670)	3.253078258099201
  (0, 1669)	3.253078258099201
  (0, 1668)	3.1970563357846644
  (0, 1667)	3.253078258099201
  (0, 1666)	3.253078258099201
  (0, 1665)	3.1970563357846644
  (0, 1664)	3.253078258099201
  (0, 1663)	3.162432307239176
  (0, 1662)	3.1970563357846644
  (0, 1661)	3.186992355083261
  (0, 1660)	3.0543146569279793
  (0, 1659)	3.0957590393342618
  (0, 1658)	3.253078258099201
  (0, 1657)	3.2818045436142635
  :	:
  (942, 24)	3.5770070873371025
  (942, 23)	3.5647155638288446
  (942, 22)	4.2858648837985385
  (942, 21)	4.3075109968616125
  (942, 20)	2.833841059980326
  (942, 19)	3.7163418578879823
  (942, 18)	4.065073219371734
  (942, 17)	3.180325734879114
  (942, 16)	3.2228473404651865
  (942, 15)	3.5001905246453204
  (942, 14)	3.830834528372158
  (942, 13)	4.111270839539859
  (942, 12)	3.4975355040423426
  (942, 11)	4.488949401755262
  (942, 10)	3.9821613219555476
  (942, 9)	3.9325758858771667
  (942, 8)	4.013929205820819
  (942, 7)	4.1435723558805915
  (942, 6)	3.903356619846464
  (942, 5)	4.00366245564005
  (942, 4)	3.4049245954037626
  (942, 3)	3.644859406738909
  (942, 2)	3.1458550802990604
  (942, 1)	3.3397499042231265
  (942, 0)	3.9678521862748464
this is the 279 epoch
rmse loss on training set is 0.9196747116177371
rmse loss on test set is 0.9402948570340556
for this epoch using 75.75662803649902 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.243620570753097
  (0, 1680)	3.273439994962307
  (0, 1679)	3.157516008246786
  (0, 1678)	3.246989250975485
  (0, 1677)	3.068042765518103
  (0, 1676)	3.257289088963477
  (0, 1675)	3.253030615327979
  (0, 1674)	3.253030615327979
  (0, 1673)	3.253030615327979
  (0, 1672)	3.1949929483195754
  (0, 1671)	3.125218308676929
  (0, 1670)	3.253030615327979
  (0, 1669)	3.253030615327979
  (0, 1668)	3.196822082859836
  (0, 1667)	3.253030615327979
  (0, 1666)	3.253030615327979
  (0, 1665)	3.196822082859836
  (0, 1664)	3.253030615327979
  (0, 1663)	3.1620980466803115
  (0, 1662)	3.196822082859836
  (0, 1661)	3.1867491435586484
  (0, 1660)	3.053607988891754
  (0, 1659)	3.0952045260321808
  (0, 1658)	3.253030615327979
  (0, 1657)	3.2818746267767134
  :	:
  (942, 24)	3.5769682774364306
  (942, 23)	3.5646575171830026
  (942, 22)	4.285965187218819
  (942, 21)	4.3075530590293845
  (942, 20)	2.8337954532839476
  (942, 19)	3.716431102282503
  (942, 18)	4.065234698994651
  (942, 17)	3.1801236853480113
  (942, 16)	3.2228290784188482
  (942, 15)	3.5003880738678124
  (942, 14)	3.830751981071074
  (942, 13)	4.11128166183383
  (942, 12)	3.497543548681304
  (942, 11)	4.488994643816583
  (942, 10)	3.982178267194714
  (942, 9)	3.932639085750517
  (942, 8)	4.013891461194747
  (942, 7)	4.143613525950235
  (942, 6)	3.903306392815263
  (942, 5)	4.004709093071751
  (942, 4)	3.404902370460599
  (942, 3)	3.6449017733947424
  (942, 2)	3.1458121028596904
  (942, 1)	3.3397577628262844
  (942, 0)	3.9678037107156334
this is the 280 epoch
rmse loss on training set is 0.9196539349947254
rmse loss on test set is 0.9402851484590274
for this epoch using 75.25170874595642 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.243552391081044
  (0, 1680)	3.2734736351421434
  (0, 1679)	3.1571407339399356
  (0, 1678)	3.2469181361380666
  (0, 1677)	3.0673633317418183
  (0, 1676)	3.257269018970012
  (0, 1675)	3.2529833613784858
  (0, 1674)	3.2529833613784858
  (0, 1673)	3.2529833613784858
  (0, 1672)	3.1947348894608054
  (0, 1671)	3.124799689272351
  (0, 1670)	3.2529833613784858
  (0, 1669)	3.2529833613784858
  (0, 1668)	3.1965882390931237
  (0, 1667)	3.2529833613784858
  (0, 1666)	3.2529833613784858
  (0, 1665)	3.1965882390931237
  (0, 1664)	3.2529833613784858
  (0, 1663)	3.1617643660182324
  (0, 1662)	3.1965882390931237
  (0, 1661)	3.1865064995302217
  (0, 1660)	3.0529019660239967
  (0, 1659)	3.0946506772141076
  (0, 1658)	3.2529833613784858
  (0, 1657)	3.281945035432903
  :	:
  (942, 24)	3.5769292750982724
  (942, 23)	3.5645994425991874
  (942, 22)	4.286064133918326
  (942, 21)	4.307594173032526
  (942, 20)	2.8337500614965685
  (942, 19)	3.7165187625180787
  (942, 18)	4.065393732898853
  (942, 17)	3.179922250249739
  (942, 16)	3.222810600773916
  (942, 15)	3.500583731380885
  (942, 14)	3.830669563279082
  (942, 13)	4.111291918797668
  (942, 12)	3.4975510465016852
  (942, 11)	4.489038934554118
  (942, 10)	3.9821945167873016
  (942, 9)	3.9327010671297113
  (942, 8)	4.013853469150979
  (942, 7)	4.143653778955959
  (942, 6)	3.9032560558297074
  (942, 5)	4.005749550974215
  (942, 4)	3.404879796391613
  (942, 3)	3.644943277136224
  (942, 2)	3.145769052509273
  (942, 1)	3.3397650477465786
  (942, 0)	3.9677550762790683
this is the 281 epoch
rmse loss on training set is 0.9196333217912996
rmse loss on test set is 0.9402755759329057
for this epoch using 76.30219388008118 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.243484645229277
  (0, 1680)	3.273507652243102
  (0, 1679)	3.156765923910454
  (0, 1678)	3.2468473957445916
  (0, 1677)	3.0666844520763195
  (0, 1676)	3.25724934880842
  (0, 1675)	3.2529364925531326
  (0, 1674)	3.2529364925531326
  (0, 1673)	3.2529364925531326
  (0, 1672)	3.194477380462257
  (0, 1671)	3.124381733365088
  (0, 1670)	3.2529364925531326
  (0, 1669)	3.2529364925531326
  (0, 1668)	3.1963548008656026
  (0, 1667)	3.2529364925531326
  (0, 1666)	3.2529364925531326
  (0, 1665)	3.1963548008656026
  (0, 1664)	3.2529364925531326
  (0, 1663)	3.161431261209129
  (0, 1662)	3.1963548008656026
  (0, 1661)	3.1862644187590607
  (0, 1660)	3.0521965841386667
  (0, 1659)	3.0940974884969883
  (0, 1658)	3.2529364925531326
  (0, 1657)	3.2820157656727025
  :	:
  (942, 24)	3.5768900894359406
  (942, 23)	3.5645413474046923
  (942, 22)	4.286161744556334
  (942, 21)	4.307634356397825
  (942, 20)	2.8337048832655247
  (942, 19)	3.716604867140671
  (942, 18)	4.065550361101761
  (942, 17)	3.1797214337464723
  (942, 16)	3.22279191456607
  (942, 15)	3.5007775187507524
  (942, 14)	3.8305872816606565
  (942, 13)	4.111301623856761
  (942, 12)	3.4975580095666876
  (942, 11)	4.489082291265396
  (942, 10)	3.9822100851683073
  (942, 9)	3.932761853768869
  (942, 8)	4.013815240180742
  (942, 7)	4.143693131700249
  (942, 6)	3.903205617778148
  (942, 5)	4.006783872713621
  (942, 4)	3.404856883663389
  (942, 3)	3.6449839333738736
  (942, 2)	3.145725935697856
  (942, 1)	3.339771771501509
  (942, 0)	3.967706292540995
this is the 282 epoch
rmse loss on training set is 0.9196128701655891
rmse loss on test set is 0.9402661377160473
for this epoch using 76.9621901512146 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.243417329252905
  (0, 1680)	3.2735420425265653
  (0, 1679)	3.1563915744797932
  (0, 1678)	3.246777026147973
  (0, 1677)	3.0660061228116113
  (0, 1676)	3.257230074666178
  (0, 1675)	3.2528900051971514
  (0, 1674)	3.2528900051971514
  (0, 1673)	3.2528900051971514
  (0, 1672)	3.1942204171438324
  (0, 1671)	3.1239644363615966
  (0, 1670)	3.2528900051971514
  (0, 1669)	3.2528900051971514
  (0, 1668)	3.1961217646010387
  (0, 1667)	3.2528900051971514
  (0, 1666)	3.2528900051971514
  (0, 1665)	3.1961217646010387
  (0, 1664)	3.2528900051971514
  (0, 1663)	3.161098728255585
  (0, 1662)	3.1961217646010387
  (0, 1661)	3.186022897051982
  (0, 1660)	3.051491839097165
  (0, 1659)	3.093544955546725
  (0, 1658)	3.2528900051971514
  (0, 1657)	3.282086813632534
  :	:
  (942, 24)	3.5768507293645397
  (942, 23)	3.564483238750133
  (942, 22)	4.286258039463403
  (942, 21)	4.30767362634477
  (942, 20)	2.833659917273956
  (942, 19)	3.7166894442025633
  (942, 18)	4.06570462295115
  (942, 17)	3.179521239847867
  (942, 16)	3.222773026689192
  (942, 15)	3.5009694572609336
  (942, 14)	3.830505142700026
  (942, 13)	4.111310790175299
  (942, 12)	3.497564449712431
  (942, 11)	4.489124730948577
  (942, 10)	3.982224986509864
  (942, 9)	3.9328214689593963
  (942, 8)	4.013776784550994
  (942, 7)	4.143731600694607
  (942, 6)	3.9031550873404095
  (942, 5)	4.007812101259665
  (942, 4)	3.40483364252316
  (942, 3)	3.6450237572525794
  (942, 2)	3.145682758733657
  (942, 1)	3.3397779463729886
  (942, 0)	3.9676573688630032
this is the 283 epoch
rmse loss on training set is 0.9195925783017542
rmse loss on test set is 0.940256832093634
for this epoch using 76.51129174232483 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.243350439251724
  (0, 1680)	3.2735768022968275
  (0, 1679)	3.1560176820125445
  (0, 1678)	3.246707023743849
  (0, 1677)	3.0653283402812423
  (0, 1676)	3.257211192774468
  (0, 1675)	3.2528438956979606
  (0, 1674)	3.2528438956979606
  (0, 1673)	3.2528438956979606
  (0, 1672)	3.1939639953689594
  (0, 1671)	3.1235477937199945
  (0, 1670)	3.2528438956979606
  (0, 1669)	3.2528438956979606
  (0, 1668)	3.1958891267652443
  (0, 1667)	3.2528438956979606
  (0, 1666)	3.2528438956979606
  (0, 1665)	3.1958891267652443
  (0, 1664)	3.2528438956979606
  (0, 1663)	3.160766763205941
  (0, 1662)	3.1958891267652443
  (0, 1661)	3.1857819302608688
  (0, 1660)	3.0507877268076693
  (0, 1659)	3.0929930740775107
  (0, 1658)	3.2528438956979606
  (0, 1657)	3.2821581754946703
  :	:
  (942, 24)	3.5768112036047115
  (942, 23)	3.5644251236128737
  (942, 22)	4.28635303864673
  (942, 21)	4.307711999790829
  (942, 20)	2.8336151622393664
  (942, 19)	3.716772521270562
  (942, 18)	4.065856557136628
  (942, 17)	3.1793216724142574
  (942, 16)	3.2227539438978146
  (942, 15)	3.5011595679163072
  (942, 14)	3.830423152704805
  (942, 13)	4.111319430660993
  (942, 12)	3.4975703785519636
  (942, 11)	4.489166270307469
  (942, 10)	3.982239234725825
  (942, 9)	3.932879935539257
  (942, 8)	4.013738112308625
  (942, 7)	4.143769202164343
  (942, 6)	3.9031044729919144
  (942, 5)	4.008834279190304
  (942, 4)	3.404810083003023
  (942, 3)	3.6450627636560546
  (942, 2)	3.145639527785533
  (942, 1)	3.3397835844115593
  (942, 0)	3.9676083143965077
this is the 284 epoch
rmse loss on training set is 0.9195724444095763
rmse loss on test set is 0.9402476573753124
for this epoch using 78.01576328277588 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2432839713696144
  (0, 1680)	3.2736119279004976
  (0, 1679)	3.1556442429158182
  (0, 1678)	3.24663738496998
  (0, 1677)	3.06465110086167
  (0, 1676)	3.2571926994075246
  (0, 1675)	3.2527981604845397
  (0, 1674)	3.2527981604845397
  (0, 1673)	3.2527981604845397
  (0, 1672)	3.193708111044045
  (0, 1671)	3.1231318009493396
  (0, 1670)	3.2527981604845397
  (0, 1669)	3.2527981604845397
  (0, 1668)	3.1956568838654786
  (0, 1667)	3.2527981604845397
  (0, 1666)	3.2527981604845397
  (0, 1665)	3.1956568838654786
  (0, 1664)	3.2527981604845397
  (0, 1663)	3.160435362153595
  (0, 1662)	3.1956568838654786
  (0, 1661)	3.185541514282075
  (0, 1660)	3.0500842432244437
  (0, 1659)	3.0924418398511118
  (0, 1658)	3.2527981604845397
  (0, 1657)	3.2822298474865836
  :	:
  (942, 24)	3.5767715206862003
  (942, 23)	3.564367008800446
  (942, 22)	4.286446761795453
  (942, 21)	4.307749493356638
  (942, 20)	2.8335706169122528
  (942, 19)	3.716854125434121
  (942, 18)	4.066006201700767
  (942, 17)	3.179122735159679
  (942, 16)	3.2227346728095143
  (942, 15)	3.501347871447136
  (942, 14)	3.8303413178094607
  (942, 13)	4.11132755796984
  (942, 12)	3.4975758074793135
  (942, 11)	4.4892069257565685
  (942, 10)	3.982252843476218
  (942, 9)	3.9329372759018946
  (942, 8)	4.013699233284497
  (942, 7)	4.143805952053457
  (942, 6)	3.903053783007598
  (942, 5)	4.009850448696394
  (942, 4)	3.404786214924148
  (942, 3)	3.6451009672112957
  (942, 2)	3.1455962488853966
  (942, 1)	3.3397886974405604
  (942, 0)	3.967559138086635
this is the 285 epoch
rmse loss on training set is 0.9195524667239697
rmse loss on test set is 0.9402386118947569
for this epoch using 75.53224992752075 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2432179217939177
  (0, 1680)	3.273647415725913
  (0, 1679)	3.155271253638679
  (0, 1678)	3.246568106305696
  (0, 1677)	3.0639744009716643
  (0, 1676)	3.257174590882038
  (0, 1675)	3.2527527960268814
  (0, 1674)	3.2527527960268814
  (0, 1673)	3.2527527960268814
  (0, 1672)	3.1934527601179252
  (0, 1671)	3.122716453608885
  (0, 1670)	3.2527527960268814
  (0, 1669)	3.2527527960268814
  (0, 1668)	3.1954250324498736
  (0, 1667)	3.2527527960268814
  (0, 1666)	3.2527527960268814
  (0, 1665)	3.1954250324498736
  (0, 1664)	3.2527527960268814
  (0, 1663)	3.160104521236401
  (0, 1662)	3.1954250324498736
  (0, 1661)	3.185301645055792
  (0, 1660)	3.0493813843472277
  (0, 1659)	3.0918912486762307
  (0, 1658)	3.2527527960268814
  (0, 1657)	3.2823018258802756
  :	:
  (942, 24)	3.576731688951473
  (942, 23)	3.5643089009538924
  (942, 22)	4.286539228285681
  (942, 21)	4.307786123371066
  (942, 20)	2.833526280074781
  (942, 19)	3.716934283313362
  (942, 18)	4.066153594050142
  (942, 17)	3.1789244316550014
  (942, 16)	3.2227152199073728
  (942, 15)	3.501534388313067
  (942, 14)	3.830259643978922
  (942, 13)	4.1113351845106285
  (942, 12)	3.4975807476733887
  (942, 11)	4.489246713425949
  (942, 10)	3.9822658261716932
  (942, 9)	3.9329935120051394
  (942, 8)	4.01366015709756
  (942, 7)	4.143841866029384
  (942, 6)	3.9030030254659107
  (942, 5)	4.010860651586244
  (942, 4)	3.4047620479008796
  (942, 3)	3.6451383822930166
  (942, 2)	3.1455529279305794
  (942, 1)	3.339793297060239
  (942, 0)	3.967509848676171
this is the 286 epoch
rmse loss on training set is 0.9195326435046234
rmse loss on test set is 0.9402296940093028
for this epoch using 75.08958411216736 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.243152286754779
  (0, 1680)	3.273683262202514
  (0, 1679)	3.154898710671426
  (0, 1678)	3.2464991842711783
  (0, 1677)	3.063298237071676
  (0, 1676)	3.2571568635564825
  (0, 1675)	3.252707798835324
  (0, 1674)	3.252707798835324
  (0, 1673)	3.252707798835324
  (0, 1672)	3.1931979385813065
  (0, 1671)	3.122301747307359
  (0, 1670)	3.252707798835324
  (0, 1669)	3.252707798835324
  (0, 1668)	3.1951935691067783
  (0, 1667)	3.252707798835324
  (0, 1666)	3.252707798835324
  (0, 1665)	3.1951935691067783
  (0, 1664)	3.252707798835324
  (0, 1663)	3.159774236635988
  (0, 1662)	3.1951935691067783
  (0, 1661)	3.185062318565413
  (0, 1660)	3.0486791462205116
  (0, 1659)	3.0913412964077995
  (0, 1658)	3.252707798835324
  (0, 1657)	3.2823741069916164
  :	:
  (942, 24)	3.5766917165592167
  (942, 23)	3.564250806551012
  (942, 22)	4.286630457185671
  (942, 21)	4.307821905876283
  (942, 20)	2.8334821505394663
  (942, 19)	3.7170130210669075
  (942, 18)	4.066298770966164
  (942, 17)	3.178726765330847
  (942, 16)	3.2226955915422444
  (942, 15)	3.5017191387070263
  (942, 14)	3.830178137011918
  (942, 13)	4.11134232244945
  (942, 12)	3.497585210101834
  (942, 11)	4.48928564916608
  (942, 10)	3.982278195977835
  (942, 9)	3.933048665379801
  (942, 8)	4.01362089315867
  (942, 7)	4.143876959487656
  (942, 6)	3.9029522082526125
  (942, 5)	4.0118649292901365
  (942, 4)	3.404737591344815
  (942, 3)	3.645175023027901
  (942, 2)	3.1455095706862006
  (942, 1)	3.339797394651733
  (942, 0)	3.9674604547093866
this is the 287 epoch
rmse loss on training set is 0.919512973035539
rmse loss on test set is 0.9402209020995383
for this epoch using 75.76778197288513 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2430870625245793
  (0, 1680)	3.2737194638002602
  (0, 1679)	3.154526610545118
  (0, 1678)	3.246430615426999
  (0, 1677)	3.0626226056632513
  (0, 1676)	3.2571395138306207
  (0, 1675)	3.2526631654600475
  (0, 1674)	3.2526631654600475
  (0, 1673)	3.2526631654600475
  (0, 1672)	3.1929436424663167
  (0, 1671)	3.121887677702297
  (0, 1670)	3.2526631654600475
  (0, 1669)	3.2526631654600475
  (0, 1668)	3.1949624904642264
  (0, 1667)	3.2526631654600475
  (0, 1666)	3.2526631654600475
  (0, 1665)	3.1949624904642264
  (0, 1664)	3.2526631654600475
  (0, 1663)	3.1594445045771984
  (0, 1662)	3.1949624904642264
  (0, 1661)	3.1848235308370207
  (0, 1660)	3.047977524932982
  (0, 1659)	3.0907919789463776
  (0, 1658)	3.2526631654600475
  (0, 1657)	3.282446687179739
  :	:
  (942, 24)	3.5766516114878084
  (942, 23)	3.564192731909621
  (942, 22)	4.2867204672607535
  (942, 21)	4.3078568566326245
  (942, 20)	2.8334382271479646
  (942, 19)	3.717090364399645
  (942, 18)	4.066441768615682
  (942, 17)	3.17852973948054
  (942, 16)	3.2226757939351214
  (942, 15)	3.5019021425590546
  (942, 14)	3.83009680254433
  (942, 13)	4.1113489837141675
  (942, 12)	3.497589205524832
  (942, 11)	4.489323748552556
  (942, 10)	3.9822899658194366
  (942, 9)	3.933102757138114
  (942, 8)	4.013581450674568
  (942, 7)	4.143911247556465
  (942, 6)	3.9029013390645515
  (942, 5)	4.012863322864814
  (942, 4)	3.4047128544687006
  (942, 3)	3.645210903298818
  (942, 2)	3.145466182787453
  (942, 1)	3.339801001381027
  (942, 0)	3.9674109645357443
this is the 288 epoch
rmse loss on training set is 0.9194934536246455
rmse loss on test set is 0.9402122345689433
for this epoch using 77.91581201553345 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2430222454173268
  (0, 1680)	3.2737560170290823
  (0, 1679)	3.154154949830956
  (0, 1678)	3.2463623963734816
  (0, 1677)	3.061947503288433
  (0, 1676)	3.257122538144846
  (0, 1675)	3.2526188924904953
  (0, 1674)	3.2526188924904953
  (0, 1673)	3.2526188924904953
  (0, 1672)	3.1926898678458886
  (0, 1671)	3.121474240499349
  (0, 1670)	3.2526188924904953
  (0, 1669)	3.2526188924904953
  (0, 1668)	3.1947317931893804
  (0, 1667)	3.2526188924904953
  (0, 1666)	3.2526188924904953
  (0, 1665)	3.1947317931893804
  (0, 1664)	3.2526188924904953
  (0, 1663)	3.159115321327437
  (0, 1662)	3.1947317931893804
  (0, 1661)	3.1845852779387074
  (0, 1660)	3.0472765166168534
  (0, 1659)	3.090243292237499
  (0, 1658)	3.2526188924904953
  (0, 1657)	3.28251956284636
  :	:
  (942, 24)	3.5766113815386205
  (942, 23)	3.564134683190639
  (942, 22)	4.286809276978248
  (942, 21)	4.307890991123476
  (942, 20)	2.8333945087698647
  (942, 19)	3.7171663385703053
  (942, 18)	4.066582622561453
  (942, 17)	3.178333357262986
  (942, 16)	3.2226558331794153
  (942, 15)	3.5020834195401456
  (942, 14)	3.830015646052581
  (942, 13)	4.111355179998737
  (942, 12)	3.49759274449884
  (942, 11)	4.489361026890797
  (942, 10)	3.9823011483846487
  (942, 9)	3.933155807982086
  (942, 8)	4.013541838651634
  (942, 7)	4.143944745101223
  (942, 6)	3.9028504254134284
  (942, 5)	4.013855872997827
  (942, 4)	3.4046878462903383
  (942, 3)	3.6452460367490667
  (942, 2)	3.1454227697418995
  (942, 1)	3.339804128202852
  (942, 0)	3.9673613863136215
this is the 289 epoch
rmse loss on training set is 0.9194740836033986
rmse loss on test set is 0.9402036898435002
for this epoch using 75.22472977638245 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2429578317880683
  (0, 1680)	3.2737929184382786
  (0, 1679)	3.1537837251396565
  (0, 1678)	3.2462945237501213
  (0, 1677)	3.061272926529195
  (0, 1676)	3.2571059329795937
  (0, 1675)	3.252574976554772
  (0, 1674)	3.252574976554772
  (0, 1673)	3.252574976554772
  (0, 1672)	3.1924366108333113
  (0, 1671)	3.1210614314515435
  (0, 1670)	3.252574976554772
  (0, 1669)	3.252574976554772
  (0, 1668)	3.194501473987904
  (0, 1667)	3.252574976554772
  (0, 1666)	3.252574976554772
  (0, 1665)	3.194501473987904
  (0, 1664)	3.252574976554772
  (0, 1663)	3.1587866831960447
  (0, 1662)	3.194501473987904
  (0, 1661)	3.184347555980065
  (0, 1660)	3.046576117447253
  (0, 1659)	3.089695232271004
  (0, 1658)	3.252574976554772
  (0, 1657)	3.2825927304352285
  :	:
  (942, 24)	3.576571034339477
  (942, 23)	3.564076666401261
  (942, 22)	4.286896904512315
  (942, 21)	4.307924324560018
  (942, 20)	2.8333509943015316
  (942, 19)	3.7172409683989764
  (942, 18)	4.0667213677724146
  (942, 17)	3.178137621705492
  (942, 16)	3.222635715243155
  (942, 15)	3.502262989065928
  (942, 14)	3.8299346728567722
  (942, 13)	4.111360922767476
  (942, 12)	3.497595837380208
  (942, 11)	4.489397499220599
  (942, 10)	3.9823117561291594
  (942, 9)	3.93320783821161
  (942, 8)	4.013502065899649
  (942, 7)	4.143977466728948
  (942, 6)	3.9027994746293486
  (942, 5)	4.014842620011877
  (942, 4)	3.404662575636392
  (942, 3)	3.6452804367863414
  (942, 2)	3.14537933693173
  (942, 1)	3.339806785864469
  (942, 0)	3.9673117280139434
this is the 290 epoch
rmse loss on training set is 0.9194548613263804
rmse loss on test set is 0.940195266371361
for this epoch using 76.03439593315125 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.242893818032316
  (0, 1680)	3.2738301646160135
  (0, 1679)	3.1534129331209675
  (0, 1678)	3.246226994235089
  (0, 1677)	3.0605988720068495
  (0, 1676)	3.2570896948548604
  (0, 1675)	3.252531414319132
  (0, 1674)	3.252531414319132
  (0, 1673)	3.252531414319132
  (0, 1672)	3.192183867581733
  (0, 1671)	3.1206492463587088
  (0, 1670)	3.252531414319132
  (0, 1669)	3.252531414319132
  (0, 1668)	3.194271529603499
  (0, 1667)	3.252531414319132
  (0, 1666)	3.252531414319132
  (0, 1665)	3.194271529603499
  (0, 1664)	3.252531414319132
  (0, 1663)	3.15845858653377
  (0, 1662)	3.194271529603499
  (0, 1661)	3.1841103611115713
  (0, 1660)	3.0458763236416453
  (0, 1659)	3.0891477950804767
  (0, 1658)	3.252531414319132
  (0, 1657)	3.2826661864314692
  :	:
  (942, 24)	3.5765305773477745
  (942, 23)	3.5640186873979514
  (942, 22)	4.286983367748663
  (942, 21)	4.307956871885893
  (942, 20)	2.8333076826649797
  (942, 19)	3.7173142782744253
  (942, 18)	4.0668580386337565
  (942, 17)	3.1779425357065283
  (942, 16)	3.2226154459712375
  (942, 15)	3.5024408703003664
  (942, 14)	3.8298538881239357
  (942, 13)	4.111366223259251
  (942, 12)	3.497598494328803
  (942, 11)	4.489433180320661
  (942, 10)	3.9823218012802184
  (942, 9)	3.9332588677323916
  (942, 8)	4.013462141035458
  (942, 7)	4.144009426792718
  (942, 6)	3.902748493864449
  (942, 5)	4.015823603869097
  (942, 4)	3.4046370511461093
  (942, 3)	3.6453141165868836
  (942, 2)	3.1453358896159407
  (942, 1)	3.3398089849093986
  (942, 0)	3.967261997423677
this is the 291 epoch
rmse loss on training set is 0.9194357851709348
rmse loss on test set is 0.9401869626224337
for this epoch using 76.05331492424011 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.242830200585496
  (0, 1680)	3.273867752188713
  (0, 1679)	3.153042570463071
  (0, 1678)	3.246159804544613
  (0, 1677)	3.059925336381532
  (0, 1676)	3.2570738203295746
  (0, 1675)	3.252488202487452
  (0, 1674)	3.252488202487452
  (0, 1673)	3.252488202487452
  (0, 1672)	3.1919316342836246
  (0, 1671)	3.120237681066772
  (0, 1670)	3.252488202487452
  (0, 1669)	3.252488202487452
  (0, 1668)	3.1940419568173004
  (0, 1667)	3.252488202487452
  (0, 1666)	3.252488202487452
  (0, 1665)	3.1940419568173004
  (0, 1664)	3.252488202487452
  (0, 1663)	3.158131027732171
  (0, 1662)	3.1940419568173004
  (0, 1661)	3.1838736895241015
  (0, 1660)	3.0451771314592206
  (0, 1659)	3.088600976742632
  (0, 1658)	3.252488202487452
  (0, 1657)	3.2827399273610167
  :	:
  (942, 24)	3.5764900178538284
  (942, 23)	3.5639607518894327
  (942, 22)	4.2870686842892285
  (942, 21)	4.307988647781833
  (942, 20)	2.8332645728067907
  (942, 19)	3.7173862921614305
  (942, 18)	4.066992668956865
  (942, 17)	3.177748102038436
  (942, 16)	3.222595031087565
  (942, 15)	3.502617082159403
  (942, 14)	3.829773296871107
  (942, 13)	4.111371092491617
  (942, 12)	3.49760072531154
  (942, 11)	4.489468084713004
  (942, 10)	3.9823312958405794
  (942, 9)	3.933308916063778
  (942, 8)	4.013422072486582
  (942, 7)	4.144040639395868
  (942, 6)	3.902697490096419
  (942, 5)	4.016798864175279
  (942, 4)	3.4046112812749816
  (942, 3)	3.645347089099299
  (942, 2)	3.145292432932541
  (942, 1)	3.339810735681153
  (942, 0)	3.9672122021494234
this is the 292 epoch
rmse loss on training set is 0.9194168535367925
rmse loss on test set is 0.9401787770880947
for this epoch using 75.38392806053162 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2427669759223847
  (0, 1680)	3.2739056778205833
  (0, 1679)	3.1526726338920676
  (0, 1678)	3.2460929514325203
  (0, 1677)	3.0592523163516234
  (0, 1676)	3.257058306001064
  (0, 1675)	3.252445337800691
  (0, 1674)	3.252445337800691
  (0, 1673)	3.252445337800691
  (0, 1672)	3.191679907170346
  (0, 1671)	3.1198267314671195
  (0, 1670)	3.252445337800691
  (0, 1669)	3.252445337800691
  (0, 1668)	3.1938127524473825
  (0, 1667)	3.252445337800691
  (0, 1666)	3.252445337800691
  (0, 1665)	3.1938127524473825
  (0, 1664)	3.252445337800691
  (0, 1663)	3.157804003223015
  (0, 1662)	3.1938127524473825
  (0, 1661)	3.1836375374483046
  (0, 1660)	3.044478537200328
  (0, 1659)	3.088054773376681
  (0, 1658)	3.252445337800691
  (0, 1657)	3.282813949790044
  :	:
  (942, 24)	3.576449362983914
  (942, 23)	3.5639028654396006
  (942, 22)	4.287152871456784
  (942, 21)	4.308019666670157
  (942, 20)	2.8332216636970835
  (942, 19)	3.7174570336078125
  (942, 18)	4.0671252919890435
  (942, 17)	3.1775543233501184
  (942, 16)	3.2225744761971833
  (942, 15)	3.5027916433144846
  (942, 14)	3.8296929039683962
  (942, 13)	4.111375541264799
  (942, 12)	3.4976025401058535
  (942, 11)	4.48950222666735
  (942, 10)	3.9823402515924546
  (942, 9)	3.933358002346372
  (942, 8)	4.013381868494779
  (942, 7)	4.144071118396277
  (942, 6)	3.9026464701319
  (942, 5)	4.017768440183994
  (942, 4)	3.404585274298338
  (942, 3)	3.645379367048562
  (942, 2)	3.145248971900677
  (942, 1)	3.3398120483267832
  (942, 0)	3.9671623496207724
this is the 293 epoch
rmse loss on training set is 0.9193980648456708
rmse loss on test set is 0.9401707082808062
for this epoch using 75.22689604759216 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2427041405565564
  (0, 1680)	3.2739439382130686
  (0, 1679)	3.1523031201714122
  (0, 1678)	3.2460264316896317
  (0, 1677)	3.058579808653204
  (0, 1676)	3.257043148504544
  (0, 1675)	3.252402817036354
  (0, 1674)	3.252402817036354
  (0, 1673)	3.252402817036354
  (0, 1672)	3.1914286825116083
  (0, 1671)	3.1194163934959978
  (0, 1670)	3.252402817036354
  (0, 1669)	3.252402817036354
  (0, 1668)	3.1935839133482076
  (0, 1667)	3.252402817036354
  (0, 1666)	3.252402817036354
  (0, 1665)	3.1935839133482076
  (0, 1664)	3.252402817036354
  (0, 1663)	3.157477509477748
  (0, 1662)	3.1935839133482076
  (0, 1661)	3.1834019011541366
  (0, 1660)	3.043780537205881
  (0, 1659)	3.0875091811437976
  (0, 1658)	3.252402817036354
  (0, 1657)	3.2828882503243606
  :	:
  (942, 24)	3.5764086197034257
  (942, 23)	3.56384503347043
  (942, 22)	4.287235946299423
  (942, 21)	4.308049942719244
  (942, 20)	2.8331789543285306
  (942, 19)	3.7175265257514623
  (942, 18)	4.067255940423103
  (942, 17)	3.177361202169642
  (942, 16)	3.2225537867884193
  (942, 15)	3.502964572196097
  (942, 14)	3.829612714142011
  (942, 13)	4.1113795801657425
  (942, 12)	3.497603948303069
  (942, 11)	4.489535620205383
  (942, 10)	3.982348680101393
  (942, 9)	3.93340614534956
  (942, 8)	4.0133415371194765
  (942, 7)	4.144100877410505
  (942, 6)	3.9025954406099075
  (942, 5)	4.018732370800686
  (942, 4)	3.4045590383148525
  (942, 3)	3.6454109629397373
  (942, 2)	3.1452055114227506
  (942, 1)	3.3398129328004584
  (942, 0)	3.9671124470936734
this is the 294 epoch
rmse loss on training set is 0.9193794175409297
rmse loss on test set is 0.9401627547337856
for this epoch using 75.26676678657532 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2426416910398492
  (0, 1680)	3.2739825301042917
  (0, 1679)	3.1519340261014275
  (0, 1678)	3.2459602421433202
  (0, 1677)	3.0579078100595405
  (0, 1676)	3.25702834451258
  (0, 1675)	3.2523606370080067
  (0, 1674)	3.2523606370080067
  (0, 1673)	3.2523606370080067
  (0, 1672)	3.1911779566150544
  (0, 1671)	3.1190066631338293
  (0, 1670)	3.2523606370080067
  (0, 1669)	3.2523606370080067
  (0, 1668)	3.1933554364101506
  (0, 1667)	3.2523606370080067
  (0, 1666)	3.2523606370080067
  (0, 1665)	3.1933554364101506
  (0, 1664)	3.2523606370080067
  (0, 1663)	3.1571515430069326
  (0, 1662)	3.1933554364101506
  (0, 1661)	3.1831667769502765
  (0, 1660)	3.0430831278568227
  (0, 1659)	3.0869641962464995
  (0, 1658)	3.2523606370080067
  (0, 1657)	3.2829628256088546
  :	:
  (942, 24)	3.576367794819911
  (942, 23)	3.563787261264762
  (942, 22)	4.287317925595008
  (942, 21)	4.308079489847884
  (942, 20)	2.8331364437153375
  (942, 19)	3.717594791327315
  (942, 18)	4.067384646406795
  (942, 17)	3.1771687409067813
  (942, 16)	3.222532968234899
  (942, 15)	3.5031358869972045
  (942, 14)	3.8295327319771704
  (942, 13)	4.111383219571962
  (942, 12)	3.4976049593117935
  (942, 11)	4.489568279104982
  (942, 10)	3.9823565927199716
  (942, 9)	3.9334533634788063
  (942, 8)	4.013301086241274
  (942, 7)	4.1441299298178915
  (942, 6)	3.902544408005082
  (942, 5)	4.019690694586784
  (942, 4)	3.4045325812500398
  (942, 3)	3.6454418890618006
  (942, 2)	3.1451620562865057
  (942, 1)	3.3398133988669736
  (942, 0)	3.967062501653841
this is the 295 epoch
rmse loss on training set is 0.919360910087242
rmse loss on test set is 0.9401549150006769
for this epoch using 75.40627002716064 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2425796239618627
  (0, 1680)	3.2740214502686333
  (0, 1679)	3.1515653485187545
  (0, 1678)	3.245894379656942
  (0, 1677)	3.0572363173805797
  (0, 1676)	3.257013890734563
  (0, 1675)	3.252318794564781
  (0, 1674)	3.252318794564781
  (0, 1673)	3.252318794564781
  (0, 1672)	3.1909277258257807
  (0, 1671)	3.11859753640469
  (0, 1670)	3.252318794564781
  (0, 1669)	3.252318794564781
  (0, 1668)	3.1931273185589792
  (0, 1667)	3.252318794564781
  (0, 1666)	3.252318794564781
  (0, 1665)	3.1931273185589792
  (0, 1664)	3.252318794564781
  (0, 1663)	3.15682610035972
  (0, 1662)	3.1931273185589792
  (0, 1661)	3.1829321611836603
  (0, 1660)	3.042386305573579
  (0, 1659)	3.0864198149281203
  (0, 1658)	3.252318794564781
  (0, 1657)	3.283037672326983
  :	:
  (942, 24)	3.5763268949860376
  (942, 23)	3.5637295539690634
  (942, 22)	4.287398825855564
  (942, 21)	4.308108321729584
  (942, 20)	2.833094130892346
  (942, 19)	3.7176618526740315
  (942, 18)	4.0675114415520195
  (942, 17)	3.17697694185557
  (942, 16)	3.2225120257976196
  (942, 15)	3.5033056056766925
  (942, 14)	3.82945296192107
  (942, 13)	4.111386469655369
  (942, 12)	3.497605582361185
  (942, 11)	4.489600216904341
  (942, 10)	3.982364000591594
  (942, 9)	3.933499674782849
  (942, 8)	4.013260523565227
  (942, 7)	4.144158288764553
  (942, 6)	3.9024933786310623
  (942, 5)	4.020643449763585
  (942, 4)	3.404505910859568
  (942, 3)	3.645472157491286
  (942, 2)	3.145118611167086
  (942, 1)	3.339813456105116
  (942, 0)	3.9670125202199134
this is the 296 epoch
rmse loss on training set is 0.9193425409702198
rmse loss on test set is 0.9401471876552262
for this epoch using 75.46910619735718 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.242517935949429
  (0, 1680)	3.2740606955161673
  (0, 1679)	3.1511970842958914
  (0, 1678)	3.245828841129363
  (0, 1677)	3.056565327462418
  (0, 1676)	3.256999783916231
  (0, 1675)	3.2522772865908607
  (0, 1674)	3.2522772865908607
  (0, 1673)	3.2522772865908607
  (0, 1672)	3.1906779865258597
  (0, 1671)	3.1181890093756435
  (0, 1670)	3.2522772865908607
  (0, 1669)	3.2522772865908607
  (0, 1668)	3.192899556755346
  (0, 1667)	3.2522772865908607
  (0, 1666)	3.2522772865908607
  (0, 1665)	3.192899556755346
  (0, 1664)	3.2522772865908607
  (0, 1663)	3.156501178123294
  (0, 1662)	3.192899556755346
  (0, 1661)	3.1826980502389355
  (0, 1660)	3.0416900668154776
  (0, 1659)	3.085876033472235
  (0, 1658)	3.2522772865908607
  (0, 1657)	3.283112787200177
  :	:
  (942, 24)	3.576285926702561
  (942, 23)	3.563671916596161
  (942, 22)	4.287478663331563
  (942, 21)	4.308136451796775
  (942, 20)	2.83305201491415
  (942, 19)	3.7177277317407453
  (942, 18)	4.067636356943955
  (942, 17)	3.17678580719678
  (942, 16)	3.2224909646269233
  (942, 15)	3.5034737459626872
  (942, 14)	3.8293734082856195
  (942, 13)	4.11138934038608
  (942, 12)	3.497605826504207
  (942, 11)	4.489631446906081
  (942, 10)	3.982370914654081
  (942, 9)	3.9335450969607764
  (942, 8)	4.013219856624178
  (942, 7)	4.144185967167348
  (942, 6)	3.9024423586435444
  (942, 5)	4.021590674216297
  (942, 4)	3.40447903473265
  (942, 3)	3.645501780095923
  (942, 2)	3.1450751806290245
  (942, 1)	3.339813113911089
  (942, 0)	3.966962509546669
this is the 297 epoch
rmse loss on training set is 0.919324308696073
rmse loss on test set is 0.9401395712909596
for this epoch using 75.30257201194763 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.242456623666074
  (0, 1680)	3.274100262692172
  (0, 1679)	3.150829230340644
  (0, 1678)	3.2457636234944904
  (0, 1677)	3.0558948371868007
  (0, 1676)	3.256986020839125
  (0, 1675)	3.252236110005018
  (0, 1674)	3.252236110005018
  (0, 1673)	3.252236110005018
  (0, 1672)	3.1904287351339256
  (0, 1671)	3.1177810781561828
  (0, 1670)	3.252236110005018
  (0, 1669)	3.252236110005018
  (0, 1668)	3.192672147994331
  (0, 1667)	3.252236110005018
  (0, 1666)	3.252236110005018
  (0, 1665)	3.192672147994331
  (0, 1664)	3.252236110005018
  (0, 1663)	3.1561767729223766
  (0, 1662)	3.192672147994331
  (0, 1661)	3.1824644405379745
  (0, 1660)	3.0409944080802704
  (0, 1659)	3.0853328482021176
  (0, 1658)	3.252236110005018
  (0, 1657)	3.283188166987345
  :	:
  (942, 24)	3.5762448963211795
  (942, 23)	3.563614354027906
  (942, 22)	4.287557454016105
  (942, 21)	4.308163893245018
  (942, 20)	2.833010094854172
  (942, 19)	3.717792450093588
  (942, 18)	4.067759423149964
  (942, 17)	3.176595339000299
  (942, 16)	3.222469789764502
  (942, 15)	3.50364032535586
  (942, 14)	3.829294075250328
  (942, 13)	4.111391841536055
  (942, 12)	3.497605700620765
  (942, 11)	4.48966198218123
  (942, 10)	3.9823773456433456
  (942, 9)	3.9335896473688345
  (942, 8)	4.013179092782021
  (942, 7)	4.144212977717805
  (942, 6)	3.902391354043549
  (942, 5)	4.022532405497794
  (942, 4)	3.40445196029528
  (942, 3)	3.645530768538213
  (942, 2)	3.1450317691282574
  (942, 1)	3.3398123815017837
  (942, 0)	3.9669124762282193
this is the 298 epoch
rmse loss on training set is 0.9193062117912606
rmse loss on test set is 0.9401320645208657
for this epoch using 75.56983494758606 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
P updating finished 62.5%!
P updating finished 75.0%!
P updating finished 87.5%!
P updating finished 100.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
Q updating finished 62.5%!
Q updating finished 75.0%!
Q updating finished 87.5%!
Q updating finished 100.0%!
  (0, 1681)	3.2423956838115724
  (0, 1680)	3.274140148676702
  (0, 1679)	3.150461783595666
  (0, 1678)	3.2456987237207198
  (0, 1677)	3.0552248434706257
  (0, 1676)	3.2569725983201185
  (0, 1675)	3.252195261760104
  (0, 1674)	3.252195261760104
  (0, 1673)	3.252195261760104
  (0, 1672)	3.1901799681046725
  (0, 1671)	3.1173737388976215
  (0, 1670)	3.252195261760104
  (0, 1669)	3.252195261760104
  (0, 1668)	3.1924450893049423
  (0, 1667)	3.252195261760104
  (0, 1666)	3.252195261760104
  (0, 1665)	3.1924450893049423
  (0, 1664)	3.252195261760104
  (0, 1663)	3.1558528814187077
  (0, 1662)	3.1924450893049423
  (0, 1661)	3.182231328539385
  (0, 1660)	3.040299325903549
  (0, 1659)	3.084790255480207
  (0, 1658)	3.252195261760104
  (0, 1657)	3.2832638084843224
  :	:
  (942, 24)	3.5762038100473754
  (942, 23)	3.563556871017797
  (942, 22)	4.28763521364917
  (942, 21)	4.308190659037009
  (942, 20)	2.8329683698038903
  (942, 19)	3.7178560289221845
  (942, 18)	4.0678806702284085
  (942, 17)	3.1764055392275554
  (942, 16)	3.2224485061452968
  (942, 15)	3.5038053611327054
  (942, 14)	3.8292149668649897
  (942, 13)	4.11139398268276
  (942, 12)	3.497605213420862
  (942, 11)	4.489691835573145
  (942, 10)	3.98238330409682
  (942, 9)	3.933633343027298
  (942, 8)	4.0131382392368335
  (942, 7)	4.144239332885858
  (942, 6)	3.9023403706803848
  (942, 5)	4.023468680832587
  (942, 4)	3.4044246948133967
  (942, 3)	3.6455591342789293
  (942, 2)	3.144988381014074
  (942, 1)	3.3398112679180487
  (942, 0)	3.966862426701029
this is the 299 epoch
rmse loss on training set is 0.9192882488022442
rmse loss on test set is 0.9401246659770958
for this epoch using 75.97636318206787 seconds

Process finished with exit code 0
