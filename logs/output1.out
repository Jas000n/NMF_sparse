nohup: ignoring input
in the movie-100k datasets, there are 943 users and 1682 items !
[[5 3 0 ... 0 0 0]
 [4 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
type1= [1, 2, 3, 7, 8, 11, 13, 14, 16, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 60, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 85, 87, 88, 92, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 178, 179, 180, 181, 182, 184, 185, 186, 189, 190, 191, 192, 194, 195, 196, 198, 201, 202, 203, 204, 205, 207, 208, 210, 211, 216, 217, 218, 219, 222, 223, 224, 225, 226, 227, 228, 230, 231, 234, 236, 237, 239, 240, 241, 242, 244, 246, 247, 250, 251, 254, 256, 257, 258, 259, 260, 264, 265, 271, 272, 273, 274, 276, 277, 280, 281, 282, 283, 284, 286, 287, 288, 293, 299, 301, 303, 305, 308, 309, 314, 315, 316, 318, 321, 322, 323, 328, 330, 332, 334, 335, 336, 337, 339, 340, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376, 380, 381, 382, 383, 385, 387, 389, 391, 394, 395, 396, 399, 401, 402, 403, 407, 409, 410, 411, 412, 413, 414, 417, 418, 419, 420, 421, 422, 423, 425, 426, 427, 429, 430, 431, 432, 433, 435, 437, 438, 439, 440, 442, 443, 444, 445, 447, 448, 450, 458, 459, 460, 461, 462, 463, 464, 465, 466, 468, 469, 470, 472, 474, 475, 476, 477, 479, 480, 481, 482, 484, 485, 488, 489, 490, 491, 493, 495, 498, 500, 501, 504, 506, 508, 509, 510, 511, 512, 514, 515, 516, 517, 518, 519, 521, 522, 524, 525, 527, 528, 529, 530, 533, 537, 538, 539, 540, 543, 545, 546, 547, 548, 549, 551, 552, 554, 555, 556, 557, 558, 559, 561, 562, 563, 564, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 578, 579, 580, 581, 582, 583, 584, 586, 588, 589, 590, 593, 594, 595, 596, 597, 598, 599, 601, 602, 603, 604, 606, 608, 609, 610, 611, 612, 613, 614, 615, 616, 618, 619, 622, 623, 624, 625, 627, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 640, 643, 645, 646, 648, 650, 651, 655, 656, 657, 661, 662, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 709, 712, 713, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 738, 739, 740, 741, 742, 743, 744, 745, 747, 749, 751, 752, 753, 754, 755, 758, 759, 760, 761, 762, 763, 764, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 786, 788, 790, 791, 792, 793, 794, 796, 797, 798, 799, 800, 801, 802, 805, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 819, 820, 821, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 840, 841, 842, 843, 844, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 881, 882, 883, 884, 885, 886, 887, 889, 890, 891, 892, 893, 894, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942]
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.0450000000000017
  (0, 1680)	3.0450000000000017
  (0, 1679)	3.0450000000000017
  (0, 1678)	3.0450000000000017
  (0, 1677)	3.0450000000000017
  (0, 1676)	3.0450000000000017
  (0, 1675)	3.0450000000000017
  (0, 1674)	3.0450000000000017
  (0, 1673)	3.0450000000000017
  (0, 1672)	3.0450000000000017
  (0, 1671)	3.0446957436000006
  (0, 1670)	3.0450000000000017
  (0, 1669)	3.0450000000000017
  (0, 1668)	3.0450000000000017
  (0, 1667)	3.0450000000000017
  (0, 1666)	3.0450000000000017
  (0, 1665)	3.0450000000000017
  (0, 1664)	3.0450000000000017
  (0, 1663)	3.045306418349997
  (0, 1662)	3.0450000000000017
  (0, 1661)	3.0450000000000017
  (0, 1660)	3.0443867370000026
  (0, 1659)	3.0446889228000025
  (0, 1658)	3.0450000000000017
  (0, 1657)	3.0450000000000017
  :	:
  (942, 24)	3.010427939999999
  (942, 23)	3.013731539999998
  (942, 22)	3.0285264899999995
  (942, 21)	3.0537419400000028
  (942, 20)	2.9978825399999978
  (942, 19)	3.0070239300000017
  (942, 18)	3.0042590699999985
  (942, 17)	3.000914940000003
  (942, 16)	2.9997327299999985
  (942, 15)	3.001231109999998
  (942, 14)	3.022229999999998
  (942, 13)	3.018300239999999
  (942, 12)	3.0103640100000035
  (942, 11)	3.057683069999999
  (942, 10)	3.0362247000000004
  (942, 9)	3.0100693200000013
  (942, 8)	3.0295579799999977
  (942, 7)	3.0404669699999998
  (942, 6)	3.040464600000002
  (942, 5)	3.0015349499999973
  (942, 4)	3.003976950000002
  (942, 3)	3.023446469999998
  (942, 2)	3.0025019400000006
  (942, 1)	3.0064866600000015
  (942, 0)	3.0459552900000015
this is the 1 epoch
rmse loss on training set is 1.1914690749871497
rmse loss on test set is 1.1735869952804459
for this epoch using 166.6490774154663 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.0857863739816485
  (0, 1680)	3.0857871132697894
  (0, 1679)	3.0857863739816485
  (0, 1678)	3.0857863739816485
  (0, 1677)	3.0857863739816485
  (0, 1676)	3.0857863739816485
  (0, 1675)	3.0857863739816485
  (0, 1674)	3.0857863739816485
  (0, 1673)	3.0857863739816485
  (0, 1672)	3.0857863739816485
  (0, 1671)	3.0851708370335307
  (0, 1670)	3.0857863739816485
  (0, 1669)	3.0857863739816485
  (0, 1668)	3.0857863739816485
  (0, 1667)	3.0857863739816485
  (0, 1666)	3.0857863739816485
  (0, 1665)	3.0857863739816485
  (0, 1664)	3.0857863739816485
  (0, 1663)	3.0864032392488543
  (0, 1662)	3.0857863739816485
  (0, 1661)	3.0857863739816485
  (0, 1660)	3.0845329756172366
  (0, 1659)	3.0851289607054304
  (0, 1658)	3.0857863739816485
  (0, 1657)	3.0857863739816485
  :	:
  (942, 24)	3.019323989164979
  (942, 23)	3.0264112365456803
  (942, 22)	3.055657064013741
  (942, 21)	3.1039911267975393
  (942, 20)	2.9953472761234705
  (942, 19)	3.0136863084768635
  (942, 18)	3.008295390684836
  (942, 17)	3.00177261490222
  (942, 16)	2.9990932868137308
  (942, 15)	3.0023156571208425
  (942, 14)	3.042929578908721
  (942, 13)	3.0357532232078372
  (942, 12)	3.0196979538860207
  (942, 11)	3.1120440449380355
  (942, 10)	3.0701061132196057
  (942, 9)	3.0196631751603746
  (942, 8)	3.0574127305263326
  (942, 7)	3.078694786282132
  (942, 6)	3.0780444560635836
  (942, 5)	3.003027204704734
  (942, 4)	3.007519036688781
  (942, 3)	3.044916544793819
  (942, 2)	3.004573495724848
  (942, 1)	3.012239971360085
  (942, 0)	3.088582821700109
this is the 2 epoch
rmse loss on training set is 1.158995975370497
rmse loss on test set is 1.144455176756236
for this epoch using 174.71300292015076 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.1226428247797657
  (0, 1680)	3.1226452131400944
  (0, 1679)	3.1226428247797657
  (0, 1678)	3.1226428247797657
  (0, 1677)	3.1226428247797657
  (0, 1676)	3.1226428247797657
  (0, 1675)	3.1226428247797657
  (0, 1674)	3.1226428247797657
  (0, 1673)	3.1226428247797657
  (0, 1672)	3.1226428247797657
  (0, 1671)	3.1217103881660058
  (0, 1670)	3.1226428247797657
  (0, 1669)	3.1226428247797657
  (0, 1668)	3.1226428247797657
  (0, 1667)	3.1226428247797657
  (0, 1666)	3.1226428247797657
  (0, 1665)	3.1226428247797657
  (0, 1664)	3.1226428247797657
  (0, 1663)	3.123573032372628
  (0, 1662)	3.1226428247797657
  (0, 1661)	3.1226428247797657
  (0, 1660)	3.120724987576734
  (0, 1659)	3.121605279536199
  (0, 1658)	3.1226428247797657
  (0, 1657)	3.1226428247797657
  :	:
  (942, 24)	3.026800675624754
  (942, 23)	3.038095665283656
  (942, 22)	3.0814234899784414
  (942, 21)	3.1508601648404526
  (942, 20)	2.9924370826873474
  (942, 19)	3.0200025093269183
  (942, 18)	3.012120250085036
  (942, 17)	3.002575649137573
  (942, 16)	2.998119225020244
  (942, 15)	3.0032643120485654
  (942, 14)	3.062170345374911
  (942, 13)	3.0523835648741224
  (942, 12)	3.0280651411105306
  (942, 11)	3.163161115696218
  (942, 10)	3.1017179287692116
  (942, 9)	3.0288024652942895
  (942, 8)	3.0836150394149646
  (942, 7)	3.114730366338032
  (942, 6)	3.112855010933931
  (942, 5)	3.004477905800828
  (942, 4)	3.0106517925484173
  (942, 3)	3.064503378175319
  (942, 2)	3.0062500835717394
  (942, 1)	3.0172991988700386
  (942, 0)	3.128015287039881
this is the 3 epoch
rmse loss on training set is 1.1309544371828117
rmse loss on test set is 1.119133777764358
for this epoch using 175.99851536750793 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.155850794123059
  (0, 1680)	3.1558558948351063
  (0, 1679)	3.155850794123059
  (0, 1678)	3.155850794123059
  (0, 1677)	3.155850794123059
  (0, 1676)	3.155850794123059
  (0, 1675)	3.155850794123059
  (0, 1674)	3.155850794123059
  (0, 1673)	3.155850794123059
  (0, 1672)	3.155850794123059
  (0, 1671)	3.154597107635103
  (0, 1670)	3.155850794123059
  (0, 1669)	3.155850794123059
  (0, 1668)	3.155850794123059
  (0, 1667)	3.155850794123059
  (0, 1666)	3.155850794123059
  (0, 1665)	3.155850794123059
  (0, 1664)	3.155850794123059
  (0, 1663)	3.1570962557405653
  (0, 1662)	3.155850794123059
  (0, 1661)	3.155850794123059
  (0, 1660)	3.153246643778695
  (0, 1659)	3.154400976261733
  (0, 1658)	3.155850794123059
  (0, 1657)	3.155850794123059
  :	:
  (942, 24)	3.032973348480088
  (942, 23)	3.048844344664346
  (942, 22)	3.105869226426254
  (942, 21)	3.194483800088888
  (942, 20)	2.9891933242537503
  (942, 19)	3.025989341639711
  (942, 18)	3.015745668524918
  (942, 17)	3.0033272549422856
  (942, 16)	2.9968467541723847
  (942, 15)	3.004087588590136
  (942, 14)	3.0800297514430515
  (942, 13)	3.0682211280590894
  (942, 12)	3.035531614123734
  (942, 11)	3.2111372513563605
  (942, 10)	3.1311504411886624
  (942, 9)	3.037510930922223
  (942, 8)	3.1082259205396703
  (942, 7)	3.148638829363477
  (942, 6)	3.1450260816788878
  (942, 5)	3.0058887336660054
  (942, 4)	3.013404553014843
  (942, 3)	3.082312047212861
  (942, 2)	3.0075673856655203
  (942, 1)	3.021710231125903
  (942, 0)	3.164402259254334
this is the 4 epoch
rmse loss on training set is 1.106752918626371
rmse loss on test set is 1.0971406549333933
for this epoch using 171.68268179893494 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.1856862217780546
  (0, 1680)	3.1856952331861015
  (0, 1679)	3.1856862217780546
  (0, 1678)	3.1856862217780546
  (0, 1677)	3.1856862217780546
  (0, 1676)	3.1856862217780546
  (0, 1675)	3.1856862217780546
  (0, 1674)	3.1856862217780546
  (0, 1673)	3.1856862217780546
  (0, 1672)	3.1856862217780546
  (0, 1671)	3.184108069122631
  (0, 1670)	3.1856862217780546
  (0, 1669)	3.1856862217780546
  (0, 1668)	3.1856862217780546
  (0, 1667)	3.1856862217780546
  (0, 1666)	3.1856862217780546
  (0, 1665)	3.1856862217780546
  (0, 1664)	3.1856862217780546
  (0, 1663)	3.187248004183989
  (0, 1662)	3.1856862217780546
  (0, 1661)	3.1856862217780546
  (0, 1660)	3.1823761597673594
  (0, 1659)	3.1837937825972706
  (0, 1658)	3.1856862217780546
  (0, 1657)	3.1856862217780546
  :	:
  (942, 24)	3.0379573454287376
  (942, 23)	3.0587180076617373
  (942, 22)	3.129045727647806
  (942, 21)	3.235012251722808
  (942, 20)	2.9856553008195346
  (942, 19)	3.0316645105868583
  (942, 18)	3.0191840450521705
  (942, 17)	3.0040310162703827
  (942, 16)	2.9953102747583835
  (942, 15)	3.00479570703806
  (942, 14)	3.0965885087714082
  (942, 13)	3.0832994481860663
  (942, 12)	3.0421642848419865
  (942, 11)	3.2560935459420133
  (942, 10)	3.1585053019272893
  (942, 9)	3.0458139073796424
  (942, 8)	3.1313137052197053
  (942, 7)	3.1804985471731957
  (942, 6)	3.1746970032182644
  (942, 5)	3.0072617580282848
  (942, 4)	3.0158083206527073
  (942, 3)	3.0984545720742047
  (942, 2)	3.008560417146699
  (942, 1)	3.0255223233733184
  (942, 0)	3.1979046389708223
this is the 5 epoch
rmse loss on training set is 1.0858711328248358
rmse loss on test set is 1.0780490085367318
for this epoch using 183.82364010810852 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.2124168417850307
  (0, 1680)	3.212431078248002
  (0, 1679)	3.2124168417850307
  (0, 1678)	3.2124168417850307
  (0, 1677)	3.2124168417850307
  (0, 1676)	3.2124168417850307
  (0, 1675)	3.2124168417850307
  (0, 1674)	3.2124168417850307
  (0, 1673)	3.2124168417850307
  (0, 1672)	3.2124168417850307
  (0, 1671)	3.210512009372829
  (0, 1670)	3.2124168417850307
  (0, 1669)	3.2124168417850307
  (0, 1668)	3.2124168417850307
  (0, 1667)	3.2124168417850307
  (0, 1666)	3.2124168417850307
  (0, 1665)	3.2124168417850307
  (0, 1664)	3.2124168417850307
  (0, 1663)	3.214295294104812
  (0, 1662)	3.2124168417850307
  (0, 1661)	3.2124168417850307
  (0, 1660)	3.208383383601099
  (0, 1659)	3.210053311415371
  (0, 1658)	3.2124168417850307
  (0, 1657)	3.2124168417850307
  :	:
  (942, 24)	3.04186576053142
  (942, 23)	3.0677772395329153
  (942, 22)	3.1510095774500706
  (942, 21)	3.2726056736926363
  (942, 20)	2.981859888199567
  (942, 19)	3.037046166929612
  (942, 18)	3.0224478697890853
  (942, 17)	3.0046907156467073
  (942, 16)	2.993542070028909
  (942, 15)	3.005398491928231
  (942, 14)	3.1119284989605576
  (942, 13)	3.097654421147223
  (942, 12)	3.0480294792405433
  (942, 11)	3.2981636598730764
  (942, 10)	3.1838912917285582
  (942, 9)	3.0537373645266612
  (942, 8)	3.1529515701814965
  (942, 7)	3.2103970966464623
  (942, 6)	3.2020125431971245
  (942, 5)	3.0085993122389647
  (942, 4)	3.0178943085907686
  (942, 3)	3.113046052327843
  (942, 2)	3.0092628576348774
  (942, 1)	3.028785778924536
  (942, 0)	3.228689944880798
this is the 6 epoch
rmse loss on training set is 1.0678519469629062
rmse loss on test set is 1.0614808916480272
for this epoch using 189.41593503952026 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.236300018368648
  (0, 1680)	3.2363208912566503
  (0, 1679)	3.236300018368648
  (0, 1678)	3.236300018368648
  (0, 1677)	3.236300018368648
  (0, 1676)	3.236300018368648
  (0, 1675)	3.236300018368648
  (0, 1674)	3.236300018368648
  (0, 1673)	3.236300018368648
  (0, 1672)	3.236300018368648
  (0, 1671)	3.2340671699707206
  (0, 1670)	3.236300018368648
  (0, 1669)	3.236300018368648
  (0, 1668)	3.236300018368648
  (0, 1667)	3.236300018368648
  (0, 1666)	3.236300018368648
  (0, 1665)	3.236300018368648
  (0, 1664)	3.236300018368648
  (0, 1663)	3.2384948875372963
  (0, 1662)	3.236300018368648
  (0, 1661)	3.236300018368648
  (0, 1660)	3.231527628044926
  (0, 1659)	3.2334388491754473
  (0, 1658)	3.236300018368648
  (0, 1657)	3.236300018368648
  :	:
  (942, 24)	3.0448077439625254
  (942, 23)	3.0760814324107
  (942, 22)	3.1718202755524008
  (942, 21)	3.307429615899428
  (942, 20)	2.977841332398963
  (942, 19)	3.042152538318181
  (942, 18)	3.025549495443441
  (942, 17)	3.0053101984810264
  (942, 16)	2.9915721236357014
  (942, 15)	3.0059052991486355
  (942, 14)	3.126131122494179
  (942, 13)	3.1113232292151443
  (942, 12)	3.0531918319741
  (942, 11)	3.337489228802347
  (942, 10)	3.207420947280547
  (942, 9)	3.0613071835373
  (942, 8)	3.1732154750374826
  (942, 7)	3.2384279695505596
  (942, 6)	3.2271195386938776
  (942, 5)	3.009903889243442
  (942, 4)	3.019692968715397
  (942, 3)	3.1262017105704514
  (942, 2)	3.0097065955629523
  (942, 1)	3.0315503277719356
  (942, 0)	3.2569284061906285
this is the 7 epoch
rmse loss on training set is 1.0522948375090753
rmse loss on test set is 1.0471022006033437
for this epoch using 180.09283757209778 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.2575810974464274
  (0, 1680)	3.257610096707781
  (0, 1679)	3.2575810974464274
  (0, 1678)	3.2575810974464274
  (0, 1677)	3.2575810974464274
  (0, 1676)	3.2575810974464274
  (0, 1675)	3.2575810974464274
  (0, 1674)	3.2575810974464274
  (0, 1673)	3.2575810974464274
  (0, 1672)	3.2575810974464274
  (0, 1671)	3.255019656259694
  (0, 1670)	3.2575810974464274
  (0, 1669)	3.2575810974464274
  (0, 1668)	3.2575810974464274
  (0, 1667)	3.2575810974464274
  (0, 1666)	3.2575810974464274
  (0, 1665)	3.2575810974464274
  (0, 1664)	3.2575810974464274
  (0, 1663)	3.260091631801003
  (0, 1662)	3.2575810974464274
  (0, 1661)	3.2575810974464274
  (0, 1660)	3.252056022283017
  (0, 1659)	3.254197670494591
  (0, 1658)	3.2575810974464274
  (0, 1657)	3.2575810974464274
  :	:
  (942, 24)	3.046887262175126
  (942, 23)	3.0836880090040864
  (942, 22)	3.191538541433168
  (942, 21)	3.339651362744879
  (942, 20)	2.973631162761465
  (942, 19)	3.0470016343888457
  (942, 18)	3.028500960808163
  (942, 17)	3.005893269457965
  (942, 16)	2.9894280365918995
  (942, 15)	3.006324967616016
  (942, 14)	3.1392760290411448
  (942, 13)	3.1243434777241914
  (942, 12)	3.0577134760491784
  (942, 11)	3.3742161215400763
  (942, 10)	3.2292079035031556
  (942, 9)	3.068548627639295
  (942, 8)	3.1921824742772404
  (942, 7)	3.264687921643206
  (942, 6)	3.2501641898486318
  (942, 5)	3.011178057100539
  (942, 4)	3.0212333657109642
  (942, 3)	3.1380346732134456
  (942, 2)	3.0099214410023616
  (942, 1)	3.0338640228246545
  (942, 0)	3.2827897935077726
this is the 8 epoch
rmse loss on training set is 1.038850232268766
rmse loss on test set is 1.0346185108076418
for this epoch using 179.23993062973022 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.27649223175493
  (0, 1680)	3.2765309084455807
  (0, 1679)	3.27649223175493
  (0, 1678)	3.27649223175493
  (0, 1677)	3.27649223175493
  (0, 1676)	3.27649223175493
  (0, 1675)	3.27649223175493
  (0, 1674)	3.27649223175493
  (0, 1673)	3.27649223175493
  (0, 1672)	3.27649223175493
  (0, 1671)	3.2736022709242976
  (0, 1670)	3.27649223175493
  (0, 1669)	3.27649223175493
  (0, 1668)	3.27649223175493
  (0, 1667)	3.27649223175493
  (0, 1666)	3.27649223175493
  (0, 1665)	3.27649223175493
  (0, 1664)	3.27649223175493
  (0, 1663)	3.279317273058285
  (0, 1662)	3.27649223175493
  (0, 1661)	3.27649223175493
  (0, 1660)	3.2702023404376614
  (0, 1659)	3.272563832753279
  (0, 1658)	3.27649223175493
  (0, 1657)	3.27649223175493
  :	:
  (942, 24)	3.048202247567035
  (942, 23)	3.090651870704282
  (942, 22)	3.2102250299832495
  (942, 21)	3.3694370339296027
  (942, 20)	2.96925819437943
  (942, 19)	3.0516110170896855
  (942, 18)	3.031313859057973
  (942, 17)	3.006443615897007
  (942, 16)	2.987135020696147
  (942, 15)	3.0066657911175185
  (942, 14)	3.1514401729598736
  (942, 13)	3.136752515437436
  (942, 12)	3.061653476954042
  (942, 11)	3.4084914365830548
  (942, 10)	3.249364833909407
  (942, 9)	3.0754859691655883
  (942, 8)	3.209929364224513
  (942, 7)	3.2892748617042784
  (942, 6)	3.271289937069927
  (942, 5)	3.0124243917929023
  (942, 4)	3.0225427972159493
  (942, 3)	3.1486543481409623
  (942, 2)	3.0099349692722206
  (942, 1)	3.035772519358206
  (942, 0)	3.30644091254473
this is the 9 epoch
rmse loss on training set is 1.0272143652050483
rmse loss on test set is 1.0237713789766956
for this epoch using 175.61542296409607 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.293251626914386
  (0, 1680)	3.293301576964131
  (0, 1679)	3.293251626914386
  (0, 1678)	3.293251626914386
  (0, 1677)	3.293251626914386
  (0, 1676)	3.293251626914386
  (0, 1675)	3.293251626914386
  (0, 1674)	3.293251626914386
  (0, 1673)	3.293251626914386
  (0, 1672)	3.293251626914386
  (0, 1671)	3.2900337691291544
  (0, 1670)	3.293251626914386
  (0, 1669)	3.293251626914386
  (0, 1668)	3.293251626914386
  (0, 1667)	3.293251626914386
  (0, 1666)	3.293251626914386
  (0, 1665)	3.293251626914386
  (0, 1664)	3.293251626914386
  (0, 1663)	3.2963896913213335
  (0, 1662)	3.293251626914386
  (0, 1661)	3.293251626914386
  (0, 1660)	3.28618625351515
  (0, 1659)	3.288757397693676
  (0, 1658)	3.293251626914386
  (0, 1657)	3.293251626914386
  :	:
  (942, 24)	3.048844070378688
  (942, 23)	3.09702502942828
  (942, 22)	3.2279393752384484
  (942, 21)	3.396949339884923
  (942, 20)	2.9647485954902684
  (942, 19)	3.0559976275720335
  (942, 18)	3.033999243925178
  (942, 17)	3.0069647533861095
  (942, 16)	2.984715949092221
  (942, 15)	3.006935506365889
  (942, 14)	3.162697141006077
  (942, 13)	3.1485869124540256
  (942, 12)	3.0650674658061257
  (942, 11)	3.440461134566724
  (942, 10)	3.26800188823364
  (942, 9)	3.0821422406379413
  (942, 8)	3.226531623691064
  (942, 7)	3.312286195410152
  (942, 6)	3.2906358456332647
  (942, 5)	3.0136454250682845
  (942, 4)	3.023646588161283
  (942, 3)	3.1581652827040965
  (942, 2)	3.009772463846091
  (942, 1)	3.037318636624155
  (942, 0)	3.328043679488352
this is the 10 epoch
rmse loss on training set is 1.0171244643854915
rmse loss on test set is 1.014334909954068
for this epoch using 171.22676038742065 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.30806315072949
  (0, 1680)	3.3081260001188046
  (0, 1679)	3.30806315072949
  (0, 1678)	3.30806315072949
  (0, 1677)	3.30806315072949
  (0, 1676)	3.30806315072949
  (0, 1675)	3.30806315072949
  (0, 1674)	3.30806315072949
  (0, 1673)	3.30806315072949
  (0, 1672)	3.30806315072949
  (0, 1671)	3.3045184771521914
  (0, 1670)	3.30806315072949
  (0, 1669)	3.30806315072949
  (0, 1668)	3.30806315072949
  (0, 1667)	3.30806315072949
  (0, 1666)	3.30806315072949
  (0, 1665)	3.30806315072949
  (0, 1664)	3.30806315072949
  (0, 1663)	3.311512499366004
  (0, 1662)	3.30806315072949
  (0, 1661)	3.30806315072949
  (0, 1660)	3.300212946435899
  (0, 1659)	3.302984021786703
  (0, 1658)	3.30806315072949
  (0, 1657)	3.30806315072949
  :	:
  (942, 24)	3.0488972711789835
  (942, 23)	3.102856387112386
  (942, 22)	3.244739495110676
  (942, 21)	3.4223458924892864
  (942, 20)	2.960126000261948
  (942, 19)	3.06017766125608
  (942, 18)	3.036567567316989
  (942, 17)	3.0074599894796012
  (942, 16)	2.982191447937254
  (942, 15)	3.0071412938013724
  (942, 14)	3.1731167037583483
  (942, 13)	3.1598820711693665
  (942, 12)	3.068007431578424
  (942, 11)	3.4702682122000943
  (942, 10)	3.2852255405101825
  (942, 9)	3.088539082650549
  (942, 8)	3.2420626075078056
  (942, 7)	3.3338175504492136
  (942, 6)	3.3083354228226742
  (942, 5)	3.0148436051318455
  (942, 4)	3.024568007212913
  (942, 3)	3.16666640497129
  (942, 2)	3.009456932704446
  (942, 1)	3.0385421254345295
  (942, 0)	3.3477536965061567
this is the 11 epoch
rmse loss on training set is 1.0083542102379406
rmse loss on test set is 1.0061124995625552
for this epoch using 173.2579047679901 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.321116247263036
  (0, 1680)	3.3211936387011876
  (0, 1679)	3.321116247263036
  (0, 1678)	3.321116247263036
  (0, 1677)	3.321116247263036
  (0, 1676)	3.321116247263036
  (0, 1675)	3.321116247263036
  (0, 1674)	3.321116247263036
  (0, 1673)	3.321116247263036
  (0, 1672)	3.321116247263036
  (0, 1671)	3.3172462157592193
  (0, 1670)	3.321116247263036
  (0, 1669)	3.321116247263036
  (0, 1668)	3.321116247263036
  (0, 1667)	3.321116247263036
  (0, 1666)	3.321116247263036
  (0, 1665)	3.321116247263036
  (0, 1664)	3.321116247263036
  (0, 1663)	3.324874947193374
  (0, 1662)	3.321116247263036
  (0, 1661)	3.321116247263036
  (0, 1660)	3.312473041120945
  (0, 1659)	3.3154348562924274
  (0, 1658)	3.321116247263036
  (0, 1657)	3.321116247263036
  :	:
  (942, 24)	3.048439499050996
  (942, 23)	3.108191631524117
  (942, 22)	3.2606811029721743
  (942, 21)	3.4457779806946314
  (942, 20)	2.955411651441929
  (942, 19)	3.064166483207553
  (942, 18)	3.039028642545066
  (942, 17)	3.0079324017726767
  (942, 16)	2.97958001614463
  (942, 15)	3.0072897881582796
  (942, 14)	3.1827645475376376
  (942, 13)	3.1706719479240046
  (942, 12)	3.0705216379772375
  (942, 11)	3.498051331943763
  (942, 10)	3.301137772886144
  (942, 9)	3.094696665934088
  (942, 8)	3.256592954117993
  (942, 7)	3.353961818984042
  (942, 6)	3.32451579701034
  (942, 5)	3.0160212681490313
  (942, 4)	3.0253282675183777
  (942, 3)	3.1742505674363484
  (942, 2)	3.009009177255774
  (942, 1)	3.0394795842218807
  (942, 0)	3.365719249179279
this is the 12 epoch
rmse loss on training set is 1.0007094626339583
rmse loss on test set is 0.9989337307689011
for this epoch using 175.06296730041504 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.332586099480728
  (0, 1680)	3.33267968060969
  (0, 1679)	3.332586099480728
  (0, 1678)	3.332586099480728
  (0, 1677)	3.332586099480728
  (0, 1676)	3.332586099480728
  (0, 1675)	3.332586099480728
  (0, 1674)	3.332586099480728
  (0, 1673)	3.332586099480728
  (0, 1672)	3.332586099480728
  (0, 1671)	3.3283924718945608
  (0, 1670)	3.332586099480728
  (0, 1669)	3.332586099480728
  (0, 1668)	3.332586099480728
  (0, 1667)	3.332586099480728
  (0, 1666)	3.332586099480728
  (0, 1665)	3.332586099480728
  (0, 1664)	3.332586099480728
  (0, 1663)	3.33665207589448
  (0, 1662)	3.332586099480728
  (0, 1661)	3.332586099480728
  (0, 1660)	3.3231427689509356
  (0, 1659)	3.3262867001614027
  (0, 1658)	3.332586099480728
  (0, 1657)	3.332586099480728
  :	:
  (942, 24)	3.04754160780259
  (942, 23)	3.113073221715894
  (942, 22)	3.275817382197761
  (942, 21)	3.4673897301076044
  (942, 20)	2.9506245608092936
  (942, 19)	3.0679785766540864
  (942, 18)	3.041391628010076
  (942, 17)	3.008384827186818
  (942, 16)	2.9768981628080167
  (942, 15)	3.00738709627925
  (942, 14)	3.1917021491346214
  (942, 13)	3.1809888653530276
  (942, 12)	3.072654635816385
  (942, 11)	3.5239438306638053
  (942, 10)	3.315835531135896
  (942, 9)	3.1006336690871428
  (942, 8)	3.27019017144119
  (942, 7)	3.3728084620556302
  (942, 6)	3.3392971941433185
  (942, 5)	3.0171806186965506
  (942, 4)	3.025946584293781
  (942, 3)	3.181004326190397
  (942, 2)	3.0084478972454436
  (942, 1)	3.0401644802079426
  (942, 0)	3.3820806534037455
this is the 13 epoch
rmse loss on training set is 0.9940242801722691
rmse loss on test set is 0.992651433289472
for this epoch using 171.90494775772095 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.342633988514681
  (0, 1680)	3.3427454016125306
  (0, 1679)	3.342633988514681
  (0, 1678)	3.342633988514681
  (0, 1677)	3.342633988514681
  (0, 1676)	3.342633988514681
  (0, 1675)	3.342633988514681
  (0, 1674)	3.342633988514681
  (0, 1673)	3.342633988514681
  (0, 1672)	3.342633988514681
  (0, 1671)	3.3381187665705143
  (0, 1670)	3.342633988514681
  (0, 1669)	3.342633988514681
  (0, 1668)	3.342633988514681
  (0, 1667)	3.342633988514681
  (0, 1666)	3.342633988514681
  (0, 1665)	3.342633988514681
  (0, 1664)	3.342633988514681
  (0, 1663)	3.347005068985465
  (0, 1662)	3.342633988514681
  (0, 1661)	3.342633988514681
  (0, 1660)	3.3323843402457367
  (0, 1659)	3.3357023531757672
  (0, 1658)	3.342633988514681
  (0, 1657)	3.342633988514681
  :	:
  (942, 24)	3.046267869698551
  (942, 23)	3.1175404408099623
  (942, 22)	3.2901987880237833
  (942, 21)	3.4873175751045222
  (942, 20)	2.9457816782596287
  (942, 19)	3.0716275182481674
  (942, 18)	3.0436650268711913
  (942, 17)	3.0088198597991793
  (942, 16)	2.9741605541892704
  (942, 15)	3.0074388200889572
  (942, 14)	3.1999867611232524
  (942, 13)	3.1908633979044416
  (942, 12)	3.07444734660532
  (942, 11)	3.548073039475774
  (942, 10)	3.3294103973601947
  (942, 9)	3.1063672970389202
  (942, 8)	3.2829183688203023
  (942, 7)	3.390443028097028
  (942, 6)	3.3527926541523163
  (942, 5)	3.0183237174979656
  (942, 4)	3.026440269317556
  (942, 3)	3.1870079003396117
  (942, 2)	3.007789818707411
  (942, 1)	3.0406272430558716
  (942, 0)	3.3969698864682702
this is the 14 epoch
rmse loss on training set is 0.988157258271026
rmse loss on test set is 0.9871389285104006
for this epoch using 174.27716064453125 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3514078030018872
  (0, 1680)	3.3515386761223516
  (0, 1679)	3.3514078030018872
  (0, 1678)	3.3514078030018872
  (0, 1677)	3.3514078030018872
  (0, 1676)	3.3514078030018872
  (0, 1675)	3.3514078030018872
  (0, 1674)	3.3514078030018872
  (0, 1673)	3.3514078030018872
  (0, 1672)	3.3514078030018872
  (0, 1671)	3.3465731722980947
  (0, 1670)	3.3514078030018872
  (0, 1669)	3.3514078030018872
  (0, 1668)	3.3514078030018872
  (0, 1667)	3.3514078030018872
  (0, 1666)	3.3514078030018872
  (0, 1665)	3.3514078030018872
  (0, 1664)	3.3514078030018872
  (0, 1663)	3.3560817546601847
  (0, 1662)	3.3514078030018872
  (0, 1661)	3.3514078030018872
  (0, 1660)	3.3403464638998286
  (0, 1659)	3.34383112216774
  (0, 1658)	3.3514078030018872
  (0, 1657)	3.3514078030018872
  :	:
  (942, 24)	3.0446762730009858
  (942, 23)	3.121629497766532
  (942, 22)	3.3038729478077173
  (942, 21)	3.5056899813896476
  (942, 20)	2.9408980627174226
  (942, 19)	3.075125974489275
  (942, 18)	3.0458566988964546
  (942, 17)	3.0092398550072503
  (942, 16)	2.9713801640743736
  (942, 15)	3.00745008302501
  (942, 14)	3.207671480695955
  (942, 13)	3.2003243154059997
  (942, 12)	3.075937197445144
  (942, 11)	3.5705598557252687
  (942, 10)	3.3419484338284073
  (942, 9)	3.1119133283619207
  (942, 8)	3.2948381067067043
  (942, 7)	3.4069468445269986
  (942, 6)	3.3651079371700803
  (942, 5)	3.0194524749857785
  (942, 4)	3.026824847914715
  (942, 3)	3.192335266501489
  (942, 2)	3.0070498350375967
  (942, 1)	3.0408954065737666
  (942, 0)	3.4105104448126426
this is the 15 epoch
rmse loss on training set is 0.9829882049158211
rmse loss on test set is 0.9822874811672069
for this epoch using 167.56384468078613 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3590426578919326
  (0, 1680)	3.359194597351077
  (0, 1679)	3.3590426578919326
  (0, 1678)	3.3590426578919326
  (0, 1677)	3.3590426578919326
  (0, 1676)	3.3590426578919326
  (0, 1675)	3.3590426578919326
  (0, 1674)	3.3590426578919326
  (0, 1673)	3.3590426578919326
  (0, 1672)	3.3590426578919326
  (0, 1671)	3.35389093938197
  (0, 1670)	3.3590426578919326
  (0, 1669)	3.3590426578919326
  (0, 1668)	3.3590426578919326
  (0, 1667)	3.3590426578919326
  (0, 1666)	3.3590426578919326
  (0, 1665)	3.3590426578919326
  (0, 1664)	3.3590426578919326
  (0, 1663)	3.3640172183239097
  (0, 1662)	3.3590426578919326
  (0, 1661)	3.3590426578919326
  (0, 1660)	3.347164976317885
  (0, 1659)	3.350809439139852
  (0, 1658)	3.3590426578919326
  (0, 1657)	3.3590426578919326
  :	:
  (942, 24)	3.042818875800869
  (942, 23)	3.125373663289326
  (942, 22)	3.316884636292554
  (942, 21)	3.5226273657721334
  (942, 20)	2.9359870499730207
  (942, 19)	3.0784857145077065
  (942, 18)	3.0479738813116457
  (942, 17)	3.009646938230788
  (942, 16)	2.9685684228924147
  (942, 15)	3.007425558561831
  (942, 14)	3.2148053796585097
  (942, 13)	3.2093985718358042
  (942, 12)	3.077158291167747
  (942, 11)	3.591518516318914
  (942, 10)	3.3535301594306017
  (942, 9)	3.1172861821185287
  (942, 8)	3.306006339573098
  (942, 7)	3.422396847503162
  (942, 6)	3.3763415766899767
  (942, 5)	3.020568649433836
  (942, 4)	3.027114188075603
  (942, 3)	3.197054351762658
  (942, 2)	3.0062411537399685
  (942, 1)	3.0409937802987455
  (942, 0)	3.422817378827305
this is the 16 epoch
rmse loss on training set is 0.9784151610731989
rmse loss on test set is 0.9780039728310473
for this epoch using 170.07953190803528 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3656615881257017
  (0, 1680)	3.365836172230658
  (0, 1679)	3.3656615881257017
  (0, 1678)	3.3656615881257017
  (0, 1677)	3.3656615881257017
  (0, 1676)	3.3656615881257017
  (0, 1675)	3.3656615881257017
  (0, 1674)	3.3656615881257017
  (0, 1673)	3.3656615881257017
  (0, 1672)	3.3656615881257017
  (0, 1671)	3.3601951964443937
  (0, 1670)	3.3656615881257017
  (0, 1669)	3.3656615881257017
  (0, 1668)	3.3656615881257017
  (0, 1667)	3.3656615881257017
  (0, 1666)	3.3656615881257017
  (0, 1665)	3.3656615881257017
  (0, 1664)	3.3656615881257017
  (0, 1663)	3.3709344907644674
  (0, 1662)	3.3656615881257017
  (0, 1661)	3.3656615881257017
  (0, 1660)	3.352963544865068
  (0, 1659)	3.3567615561776134
  (0, 1658)	3.3656615881257017
  (0, 1657)	3.3656615881257017
  :	:
  (942, 24)	3.0407421941154973
  (942, 23)	3.1288034280506043
  (942, 22)	3.3292758070296653
  (942, 21)	3.538242168149684
  (942, 20)	2.931060414044962
  (942, 19)	3.08171763515721
  (942, 18)	3.050023216028406
  (942, 17)	3.0100430167109065
  (942, 16)	2.9657353622867415
  (942, 15)	3.0073694997544194
  (942, 14)	3.2214336774000154
  (942, 13)	3.2181113285389804
  (942, 12)	3.0781415989588123
  (942, 11)	3.611056529266016
  (942, 10)	3.364230626803531
  (942, 9)	3.122498997046241
  (942, 8)	3.316476431198901
  (942, 7)	3.4368655203671943
  (942, 6)	3.3865850436068707
  (942, 5)	3.021673848594658
  (942, 4)	3.0273206343518115
  (942, 3)	3.201227295713943
  (942, 2)	3.0053754433866318
  (942, 1)	3.040944637577359
  (942, 0)	3.43399746258281
this is the 17 epoch
rmse loss on training set is 0.9743517609170033
rmse loss on test set is 0.9742088038470269
for this epoch using 169.77157759666443 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3713762883504867
  (0, 1680)	3.3715750622567358
  (0, 1679)	3.3713762883504867
  (0, 1678)	3.3713762883504867
  (0, 1677)	3.3713762883504867
  (0, 1676)	3.3713762883504867
  (0, 1675)	3.3713762883504867
  (0, 1674)	3.3713762883504867
  (0, 1673)	3.3713762883504867
  (0, 1672)	3.3713762883504867
  (0, 1671)	3.3655976963333165
  (0, 1670)	3.3713762883504867
  (0, 1669)	3.3713762883504867
  (0, 1668)	3.3713762883504867
  (0, 1667)	3.3713762883504867
  (0, 1666)	3.3713762883504867
  (0, 1665)	3.3713762883504867
  (0, 1664)	3.3713762883504867
  (0, 1663)	3.3769452830716022
  (0, 1662)	3.3713762883504867
  (0, 1661)	3.3713762883504867
  (0, 1660)	3.3578544168637876
  (0, 1659)	3.3618002878732574
  (0, 1658)	3.3713762883504867
  (0, 1657)	3.3713762883504867
  :	:
  (942, 24)	3.0384876069782236
  (942, 23)	3.1319466739862394
  (942, 22)	3.341085664867481
  (942, 21)	3.5526390381258803
  (942, 20)	2.9261285198369196
  (942, 19)	3.084831795045038
  (942, 18)	3.052010781130236
  (942, 17)	3.0104297932724693
  (942, 16)	2.962889752861188
  (942, 15)	3.0072857689750427
  (942, 14)	3.2275979422804406
  (942, 13)	3.2264860030003932
  (942, 12)	3.078915165500369
  (942, 11)	3.6292747272186285
  (942, 10)	3.3741195739324996
  (942, 9)	3.127563717615518
  (942, 8)	3.326298224843688
  (942, 7)	3.4504209161415105
  (942, 6)	3.3959229912829296
  (942, 5)	3.0227695339514846
  (942, 4)	3.0274551413886903
  (942, 3)	3.204910758250941
  (942, 2)	3.004462976912325
  (942, 1)	3.0407679104135226
  (942, 0)	3.4441494633331367
this is the 18 epoch
rmse loss on training set is 0.970724917153518
rmse loss on test set is 0.9708340222479038
for this epoch using 173.6490535736084 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.376287875156609
  (0, 1680)	3.376512346737299
  (0, 1679)	3.376287875156609
  (0, 1678)	3.376287875156609
  (0, 1677)	3.376287875156609
  (0, 1676)	3.376287875156609
  (0, 1675)	3.376287875156609
  (0, 1674)	3.376287875156609
  (0, 1673)	3.376287875156609
  (0, 1672)	3.376287875156609
  (0, 1671)	3.3701995839098657
  (0, 1670)	3.376287875156609
  (0, 1669)	3.376287875156609
  (0, 1668)	3.376287875156609
  (0, 1667)	3.376287875156609
  (0, 1666)	3.376287875156609
  (0, 1665)	3.376287875156609
  (0, 1664)	3.376287875156609
  (0, 1663)	3.382150744729224
  (0, 1662)	3.376287875156609
  (0, 1661)	3.376287875156609
  (0, 1660)	3.3619391905327305
  (0, 1659)	3.3660277773621687
  (0, 1658)	3.376287875156609
  (0, 1657)	3.376287875156609
  :	:
  (942, 24)	3.0360917652731074
  (942, 23)	3.134828851553672
  (942, 22)	3.352350767505085
  (942, 21)	3.5659151052992892
  (942, 20)	2.9212004657503896
  (942, 19)	3.0878374547365754
  (942, 18)	3.0539421249265546
  (942, 17)	3.010808781173352
  (942, 16)	2.9600392336359476
  (942, 15)	3.007177867220157
  (942, 14)	3.2333363099713592
  (942, 13)	3.2345443359226294
  (942, 12)	3.0795043189957365
  (942, 11)	3.6462674129620103
  (942, 10)	3.3832616289703195
  (942, 9)	3.132491182885395
  (942, 8)	3.3355181538512295
  (942, 7)	3.463126743666645
  (942, 6)	3.4044335572842126
  (942, 5)	3.023857026851951
  (942, 4)	3.0275274035930906
  (942, 3)	3.20815625488531
  (942, 2)	3.0035127685964285
  (942, 1)	3.0404813841395995
  (942, 0)	3.453364481886378
this is the 19 epoch
rmse loss on training set is 0.9674728096014621
rmse loss on test set is 0.9678216714486112
for this epoch using 170.0535111427307 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3804876530867616
  (0, 1680)	3.3807392896994024
  (0, 1679)	3.3804876530867616
  (0, 1678)	3.3804876530867616
  (0, 1677)	3.3804876530867616
  (0, 1676)	3.3804876530867616
  (0, 1675)	3.3804876530867616
  (0, 1674)	3.3804876530867616
  (0, 1673)	3.3804876530867616
  (0, 1672)	3.3804876530867616
  (0, 1671)	3.3740921669910935
  (0, 1670)	3.3804876530867616
  (0, 1669)	3.3804876530867616
  (0, 1668)	3.3804876530867616
  (0, 1667)	3.3804876530867616
  (0, 1666)	3.3804876530867616
  (0, 1665)	3.3804876530867616
  (0, 1664)	3.3804876530867616
  (0, 1663)	3.3866422260699975
  (0, 1662)	3.3804876530867616
  (0, 1661)	3.3804876530867616
  (0, 1660)	3.365309589066114
  (0, 1659)	3.369536266901268
  (0, 1658)	3.3804876530867616
  (0, 1657)	3.3804876530867616
  :	:
  (942, 24)	3.0335869944160283
  (942, 23)	3.1374731576060415
  (942, 22)	3.3631051466504354
  (942, 21)	3.5781603080371984
  (942, 20)	2.916284215581461
  (942, 19)	3.090743120904758
  (942, 18)	3.0558223012520096
  (942, 17)	3.0111813193764974
  (942, 16)	2.957190432372814
  (942, 15)	3.007048962532795
  (942, 14)	3.2386837098781425
  (942, 13)	3.2423064707728155
  (942, 12)	3.0799318803496507
  (942, 11)	3.6621225722061
  (942, 10)	3.3917165512202585
  (942, 9)	3.1372912151872603
  (942, 8)	3.344179380889402
  (942, 7)	3.475042500638132
  (942, 6)	3.4121887022171054
  (942, 5)	3.0249375159283
  (942, 4)	3.0275459786428702
  (942, 3)	3.211010505484069
  (942, 2)	3.002532703034462
  (942, 1)	3.0401008870775335
  (942, 0)	3.461726340426163
this is the 20 epoch
rmse loss on training set is 0.9645431507634368
rmse loss on test set is 0.9651223436008618
for this epoch using 175.25444078445435 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3840578698353823
  (0, 1680)	3.3843380958758176
  (0, 1679)	3.3840578698353823
  (0, 1678)	3.3840578698353823
  (0, 1677)	3.3840578698353823
  (0, 1676)	3.3840578698353823
  (0, 1675)	3.3840578698353823
  (0, 1674)	3.3840578698353823
  (0, 1673)	3.3840578698353823
  (0, 1672)	3.3840578698353823
  (0, 1671)	3.3773576759003214
  (0, 1670)	3.3840578698353823
  (0, 1669)	3.3840578698353823
  (0, 1668)	3.3840578698353823
  (0, 1667)	3.3840578698353823
  (0, 1666)	3.3840578698353823
  (0, 1665)	3.3840578698353823
  (0, 1664)	3.3840578698353823
  (0, 1663)	3.390502030448085
  (0, 1662)	3.3840578698353823
  (0, 1661)	3.3840578698353823
  (0, 1660)	3.368048223246372
  (0, 1659)	3.372408858140961
  (0, 1658)	3.3840578698353823
  (0, 1657)	3.3840578698353823
  :	:
  (942, 24)	3.0310016837221214
  (942, 23)	3.1399007099609575
  (942, 22)	3.373380441399632
  (942, 21)	3.5894577605158697
  (942, 20)	2.9113867195180796
  (942, 19)	3.093556592652823
  (942, 18)	3.057655904996243
  (942, 17)	3.0115485877537265
  (942, 16)	2.9543490764016576
  (942, 15)	3.006901917220743
  (942, 14)	3.2436720929144354
  (942, 13)	3.2497910411640976
  (942, 12)	3.080218367322331
  (942, 11)	3.6769221336889752
  (942, 10)	3.3995394947741633
  (942, 9)	3.1419727065346916
  (942, 8)	3.352321956331589
  (942, 7)	3.486223639951192
  (942, 6)	3.41925457017811
  (942, 5)	3.026012065328258
  (942, 4)	3.0275184034301263
  (942, 3)	3.213515785765837
  (942, 2)	3.0015296551182473
  (942, 1)	3.039640471949045
  (942, 0)	3.4693119991018597
this is the 21 epoch
rmse loss on training set is 0.9618917000307093
rmse loss on test set is 0.9626939223167202
for this epoch using 171.55117082595825 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3870724496221687
  (0, 1680)	3.3873826447623707
  (0, 1679)	3.3870724496221687
  (0, 1678)	3.3870724496221687
  (0, 1677)	3.3870724496221687
  (0, 1676)	3.3870724496221687
  (0, 1675)	3.3870724496221687
  (0, 1674)	3.3870724496221687
  (0, 1673)	3.3870724496221687
  (0, 1672)	3.3870724496221687
  (0, 1671)	3.3800700006500355
  (0, 1670)	3.3870724496221687
  (0, 1669)	3.3870724496221687
  (0, 1668)	3.3870724496221687
  (0, 1667)	3.3870724496221687
  (0, 1666)	3.3870724496221687
  (0, 1665)	3.3870724496221687
  (0, 1664)	3.3870724496221687
  (0, 1663)	3.3938041450545415
  (0, 1662)	3.3870724496221687
  (0, 1661)	3.3870724496221687
  (0, 1660)	3.3702293315714336
  (0, 1659)	3.374720250859342
  (0, 1658)	3.3870724496221687
  (0, 1657)	3.3870724496221687
  :	:
  (942, 24)	3.0283606575016737
  (942, 23)	3.142130715881558
  (942, 22)	3.3832060381440883
  (942, 21)	3.599884142026479
  (942, 20)	2.9065140244011416
  (942, 19)	3.0962850086279308
  (942, 18)	3.0594471071032263
  (942, 17)	3.011911621869001
  (942, 16)	2.9515200939273236
  (942, 15)	3.0067393136587346
  (942, 14)	3.2483306556458533
  (942, 13)	3.257015262446888
  (942, 12)	3.0803821907117555
  (942, 11)	3.6907422605766897
  (942, 10)	3.406781284252445
  (942, 9)	3.1465437013292354
  (942, 8)	3.3599829882430936
  (942, 7)	3.4967217584390524
  (942, 6)	3.425691858765894
  (942, 5)	3.027081623382231
  (942, 4)	3.027451301674084
  (942, 3)	3.215710273643579
  (942, 2)	3.0005096005762453
  (942, 1)	3.039112586984653
  (942, 0)	3.4761919867217492
this is the 22 epoch
rmse loss on training set is 0.9594809978702901
rmse loss on test set is 0.9605004968092621
for this epoch using 171.5108470916748 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3895976967194548
  (0, 1680)	3.3899391947337882
  (0, 1679)	3.3895976967194548
  (0, 1678)	3.3895976967194548
  (0, 1677)	3.3895976967194548
  (0, 1676)	3.3895976967194548
  (0, 1675)	3.3895976967194548
  (0, 1674)	3.3895976967194548
  (0, 1673)	3.3895976967194548
  (0, 1672)	3.3895976967194548
  (0, 1671)	3.3822953977818253
  (0, 1670)	3.3895976967194548
  (0, 1669)	3.3895976967194548
  (0, 1668)	3.3895976967194548
  (0, 1667)	3.3895976967194548
  (0, 1666)	3.3895976967194548
  (0, 1665)	3.3895976967194548
  (0, 1664)	3.3895976967194548
  (0, 1663)	3.396614942299397
  (0, 1662)	3.3895976967194548
  (0, 1661)	3.3895976967194548
  (0, 1660)	3.371919489890756
  (0, 1659)	3.376537451967752
  (0, 1658)	3.3895976967194548
  (0, 1657)	3.3895976967194548
  :	:
  (942, 24)	3.0256855246694356
  (942, 23)	3.144180632584504
  (942, 22)	3.392609212678745
  (942, 21)	3.609510096080609
  (942, 20)	2.9016713736505166
  (942, 19)	3.098934893867789
  (942, 18)	3.0611996884866546
  (942, 17)	3.0122713270982553
  (942, 16)	2.9487077060449858
  (942, 15)	3.0065634785473065
  (942, 14)	3.25268605722317
  (942, 13)	3.263995024720951
  (942, 12)	3.0804398405914384
  (942, 11)	3.703653660490963
  (942, 10)	3.4134886945328184
  (942, 9)	3.1510114744455406
  (942, 8)	3.3671968180801755
  (942, 7)	3.5065847993441195
  (942, 6)	3.4315561894539455
  (942, 5)	3.0281470314174945
  (942, 4)	3.027350482901053
  (942, 3)	3.2176283847159297
  (942, 2)	2.9994777170117444
  (942, 1)	3.0385282355624392
  (942, 0)	3.482430834243749
this is the 23 epoch
rmse loss on training set is 0.9572792923343884
rmse loss on test set is 0.9585114290255854
for this epoch using 172.3234453201294 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3916929635863617
  (0, 1680)	3.3920670516794322
  (0, 1679)	3.3916929635863617
  (0, 1678)	3.3916929635863617
  (0, 1677)	3.3916929635863617
  (0, 1676)	3.3916929635863617
  (0, 1675)	3.3916929635863617
  (0, 1674)	3.3916929635863617
  (0, 1673)	3.3916929635863617
  (0, 1672)	3.3916929635863617
  (0, 1671)	3.3840931613618626
  (0, 1670)	3.3916929635863617
  (0, 1669)	3.3916929635863617
  (0, 1668)	3.3916929635863617
  (0, 1667)	3.3916929635863617
  (0, 1666)	3.3916929635863617
  (0, 1665)	3.3916929635863617
  (0, 1664)	3.3916929635863617
  (0, 1663)	3.3989938461612197
  (0, 1662)	3.3916929635863617
  (0, 1661)	3.3916929635863617
  (0, 1660)	3.3731782850286334
  (0, 1659)	3.3779204491075414
  (0, 1658)	3.3916929635863617
  (0, 1657)	3.3916929635863617
  :	:
  (942, 24)	3.0229950050072603
  (942, 23)	3.14606631858676
  (942, 22)	3.4016152712822416
  (942, 21)	3.618400629776563
  (942, 20)	2.8968632974115898
  (942, 19)	3.1015122055905824
  (942, 18)	3.0629170724739025
  (942, 17)	3.0126284919285147
  (942, 16)	2.9459155098625627
  (942, 15)	3.006376505565922
  (942, 14)	3.2567626266401692
  (942, 13)	3.270744985165013
  (942, 12)	3.080406061387732
  (942, 11)	3.715721904285968
  (942, 10)	3.419704728349538
  (942, 9)	3.155382604166457
  (942, 8)	3.3739951975725773
  (942, 7)	3.51585726173995
  (942, 6)	3.436898471455763
  (942, 5)	3.029209032500591
  (942, 4)	3.027221032814609
  (942, 3)	3.2193010929624437
  (942, 2)	2.9984384756485793
  (942, 1)	3.0378971238514727
  (942, 0)	3.4880875025320006
this is the 24 epoch
rmse loss on training set is 0.9552596320571182
rmse loss on test set is 0.9567005557403644
for this epoch using 176.40822577476501 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.393411280069275
  (0, 1680)	3.393819198627406
  (0, 1679)	3.393411280069275
  (0, 1678)	3.393411280069275
  (0, 1677)	3.393411280069275
  (0, 1676)	3.393411280069275
  (0, 1675)	3.393411280069275
  (0, 1674)	3.393411280069275
  (0, 1673)	3.393411280069275
  (0, 1672)	3.393411280069275
  (0, 1671)	3.3855162546370092
  (0, 1670)	3.393411280069275
  (0, 1669)	3.393411280069275
  (0, 1668)	3.393411280069275
  (0, 1667)	3.393411280069275
  (0, 1666)	3.393411280069275
  (0, 1665)	3.393411280069275
  (0, 1664)	3.393411280069275
  (0, 1663)	3.4009939599163523
  (0, 1662)	3.393411280069275
  (0, 1661)	3.393411280069275
  (0, 1660)	3.374058948888598
  (0, 1659)	3.3789228451975246
  (0, 1658)	3.393411280069275
  (0, 1657)	3.393411280069275
  :	:
  (942, 24)	3.020305231255012
  (942, 23)	3.147802175235692
  (942, 22)	3.410247688414831
  (942, 21)	3.6266155062859347
  (942, 20)	2.8920936935693535
  (942, 19)	3.1040223773569635
  (942, 18)	3.0646023555234385
  (942, 17)	3.0129838003441596
  (942, 16)	2.943146553239417
  (942, 15)	3.00618027640745
  (942, 14)	3.2605825587235033
  (942, 13)	3.277278658135962
  (942, 12)	3.0802940151586373
  (942, 11)	3.7270077459971698
  (942, 10)	3.425468887258785
  (942, 9)	3.1596630397250416
  (942, 8)	3.3804074633791377
  (942, 7)	3.5245804116745987
  (942, 6)	3.441765254102696
  (942, 5)	3.0302682799466503
  (942, 4)	3.027067395302162
  (942, 3)	3.220756234071115
  (942, 2)	2.997395724178385
  (942, 1)	3.0372277963960634
  (942, 0)	3.4932157981097944
this is the 25 epoch
rmse loss on training set is 0.9533991022014118
rmse loss on test set is 0.9550455085543913
for this epoch using 175.38929152488708 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3947999417283485
  (0, 1680)	3.39524288442512
  (0, 1679)	3.3947999417283485
  (0, 1678)	3.3947999417283485
  (0, 1677)	3.3947999417283485
  (0, 1676)	3.3947999417283485
  (0, 1675)	3.3947999417283485
  (0, 1674)	3.3947999417283485
  (0, 1673)	3.3947999417283485
  (0, 1672)	3.3947999417283485
  (0, 1671)	3.3866119004545663
  (0, 1670)	3.3947999417283485
  (0, 1669)	3.3947999417283485
  (0, 1668)	3.3947999417283485
  (0, 1667)	3.3947999417283485
  (0, 1666)	3.3947999417283485
  (0, 1665)	3.3947999417283485
  (0, 1664)	3.3947999417283485
  (0, 1663)	3.402662653264456
  (0, 1662)	3.3947999417283485
  (0, 1661)	3.3947999417283485
  (0, 1660)	3.374608951137364
  (0, 1659)	3.3795924519176572
  (0, 1658)	3.3947999417283485
  (0, 1657)	3.3947999417283485
  :	:
  (942, 24)	3.0176300269772067
  (942, 23)	3.1494012781676806
  (942, 22)	3.4185282393720033
  (942, 21)	3.6342096252615748
  (942, 20)	2.887365900323073
  (942, 19)	3.1064703612085838
  (942, 18)	3.066258336063265
  (942, 17)	3.013337843257567
  (942, 16)	2.9404034017154173
  (942, 15)	3.00597648021732
  (942, 14)	3.2641660979350346
  (942, 13)	3.283608501935254
  (942, 12)	3.0801154328708353
  (942, 11)	3.7375674382647426
  (942, 10)	3.4308174327592145
  (942, 9)	3.1638581634181486
  (942, 8)	3.3864607070128936
  (942, 7)	3.5327924910769575
  (942, 6)	3.446199064263749
  (942, 5)	3.031325345481141
  (942, 4)	3.0268934464712887
  (942, 3)	3.2220187898880206
  (942, 2)	2.9963527612211878
  (942, 1)	3.036527759900733
  (942, 0)	3.4978647724620786
this is the 26 epoch
rmse loss on training set is 0.9516781823235865
rmse loss on test set is 0.953527136072983
for this epoch using 172.09623551368713 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.395901056601564
  (0, 1680)	3.3963801707963763
  (0, 1679)	3.395901056601564
  (0, 1678)	3.395901056601564
  (0, 1677)	3.395901056601564
  (0, 1676)	3.395901056601564
  (0, 1675)	3.395901056601564
  (0, 1674)	3.395901056601564
  (0, 1673)	3.395901056601564
  (0, 1672)	3.395901056601564
  (0, 1671)	3.3874221297990577
  (0, 1670)	3.395901056601564
  (0, 1669)	3.395901056601564
  (0, 1668)	3.395901056601564
  (0, 1667)	3.395901056601564
  (0, 1666)	3.395901056601564
  (0, 1665)	3.395901056601564
  (0, 1664)	3.395901056601564
  (0, 1663)	3.404042108123712
  (0, 1662)	3.395901056601564
  (0, 1661)	3.395901056601564
  (0, 1660)	3.3748705498221003
  (0, 1659)	3.3799718413892115
  (0, 1658)	3.395901056601564
  (0, 1657)	3.395901056601564
  :	:
  (942, 24)	3.0149811607149632
  (942, 23)	3.1508754987347403
  (942, 22)	3.4264771267735132
  (942, 21)	3.6412333875242893
  (942, 20)	2.8826827610265378
  (942, 19)	3.1088606675270687
  (942, 18)	3.067887541377479
  (942, 17)	3.013691128977403
  (942, 16)	2.9376881982349814
  (942, 15)	3.0057666314869502
  (942, 14)	3.267531709578542
  (942, 13)	3.28974600149295
  (942, 12)	3.0798807537905026
  (942, 11)	3.747453039055014
  (942, 10)	3.435783635381085
  (942, 9)	3.1679728474031568
  (942, 8)	3.392179938260021
  (942, 7)	3.5405289214989693
  (942, 6)	3.4502387265281445
  (942, 5)	3.032380726976497
  (942, 4)	3.0267025612001968
  (942, 3)	3.2231111532869265
  (942, 2)	2.9953124029790774
  (942, 1)	3.0358035956936495
  (942, 0)	3.5020791018917325
this is the 27 epoch
rmse loss on training set is 0.9500802076449625
rmse loss on test set is 0.9521290140486651
for this epoch using 189.7215895652771 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.396752050677711
  (0, 1680)	3.397268438053753
  (0, 1679)	3.396752050677711
  (0, 1678)	3.396752050677711
  (0, 1677)	3.396752050677711
  (0, 1676)	3.396752050677711
  (0, 1675)	3.396752050677711
  (0, 1674)	3.396752050677711
  (0, 1673)	3.396752050677711
  (0, 1672)	3.396752050677711
  (0, 1671)	3.387984288755373
  (0, 1670)	3.396752050677711
  (0, 1669)	3.396752050677711
  (0, 1668)	3.396752050677711
  (0, 1667)	3.396752050677711
  (0, 1666)	3.396752050677711
  (0, 1665)	3.396752050677711
  (0, 1664)	3.396752050677711
  (0, 1663)	3.405169823332572
  (0, 1662)	3.396752050677711
  (0, 1661)	3.396752050677711
  (0, 1660)	3.374881300234798
  (0, 1659)	3.380098856288532
  (0, 1658)	3.396752050677711
  (0, 1657)	3.396752050677711
  :	:
  (942, 24)	3.0123685773281013
  (942, 23)	3.152235615649434
  (942, 22)	3.4341131001885534
  (942, 21)	3.647733041617007
  (942, 20)	2.878046681988204
  (942, 19)	3.111197402467007
  (942, 18)	3.0694922525277515
  (942, 17)	3.0140440927340313
  (942, 16)	2.935002716276556
  (942, 15)	3.0055520864690437
  (942, 14)	3.2706962383826528
  (942, 13)	3.2957017464965617
  (942, 12)	3.079599253331456
  (942, 11)	3.756712706721349
  (942, 10)	3.440398010359868
  (942, 9)	3.1720115053892006
  (942, 8)	3.397588240894713
  (942, 7)	3.5478225005958044
  (942, 6)	3.453919664800082
  (942, 5)	3.033434855715257
  (942, 4)	3.0264976727362987
  (942, 3)	3.2240533733607597
  (942, 2)	2.9942770426940175
  (942, 1)	3.0350610614866564
  (942, 0)	3.5058994460737343
this is the 28 epoch
rmse loss on training set is 0.9485909176370486
rmse loss on test set is 0.9508370308353566
for this epoch using 173.14112544059753 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3973861330653894
  (0, 1680)	3.397940850460634
  (0, 1679)	3.3973861330653894
  (0, 1678)	3.3973861330653894
  (0, 1677)	3.3973861330653894
  (0, 1676)	3.3973861330653894
  (0, 1675)	3.3973861330653894
  (0, 1674)	3.3973861330653894
  (0, 1673)	3.3973861330653894
  (0, 1672)	3.3973861330653894
  (0, 1671)	3.3883315049209277
  (0, 1670)	3.3973861330653894
  (0, 1669)	3.3973861330653894
  (0, 1668)	3.3973861330653894
  (0, 1667)	3.3973861330653894
  (0, 1666)	3.3973861330653894
  (0, 1665)	3.3973861330653894
  (0, 1664)	3.3973861330653894
  (0, 1663)	3.4060790792154023
  (0, 1662)	3.3973861330653894
  (0, 1661)	3.3973861330653894
  (0, 1660)	3.374674523053584
  (0, 1659)	3.380007079361695
  (0, 1658)	3.3973861330653894
  (0, 1657)	3.3973861330653894
  :	:
  (942, 24)	3.009800607695617
  (942, 23)	3.1534914172439903
  (942, 22)	3.4414535685190577
  (942, 21)	3.6537510107782505
  (942, 20)	2.8734596838985142
  (942, 19)	3.113484302900506
  (942, 18)	3.071074527340663
  (942, 17)	3.0143971052991843
  (942, 16)	2.9323484069858625
  (942, 15)	3.005334058194033
  (942, 14)	3.2736750547085687
  (942, 13)	3.3014855047054303
  (942, 12)	3.079279159860702
  (942, 11)	3.7653909814109605
  (942, 10)	3.4446885391310293
  (942, 9)	3.1759781394986346
  (942, 8)	3.4027069199445106
  (942, 7)	3.5547035899059547
  (942, 6)	3.457274184667408
  (942, 5)	3.0344881031542146
  (942, 4)	3.0262813258968686
  (942, 3)	3.224863381278365
  (942, 2)	2.993248703526153
  (942, 1)	3.0343051831314343
  (942, 0)	3.5093627843350235
this is the 29 epoch
rmse loss on training set is 0.9471980780649921
rmse loss on test set is 0.9496390370310122
for this epoch using 170.7586874961853 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3978327223634257
  (0, 1680)	3.3984267827547026
  (0, 1679)	3.3978327223634257
  (0, 1678)	3.3978327223634257
  (0, 1677)	3.3978327223634257
  (0, 1676)	3.3978327223634257
  (0, 1675)	3.3978327223634257
  (0, 1674)	3.3978327223634257
  (0, 1673)	3.3978327223634257
  (0, 1672)	3.3978327223634257
  (0, 1671)	3.388493114804493
  (0, 1670)	3.3978327223634257
  (0, 1669)	3.3978327223634257
  (0, 1668)	3.3978327223634257
  (0, 1667)	3.3978327223634257
  (0, 1666)	3.3978327223634257
  (0, 1665)	3.3978327223634257
  (0, 1664)	3.3978327223634257
  (0, 1663)	3.4067993634910128
  (0, 1662)	3.3978327223634257
  (0, 1661)	3.3978327223634257
  (0, 1660)	3.374279733307432
  (0, 1659)	3.3797262638366634
  (0, 1658)	3.3978327223634257
  (0, 1657)	3.3978327223634257
  :	:
  (942, 24)	3.0072841581058998
  (942, 23)	3.1546517948343396
  (942, 22)	3.4485147050069536
  (942, 21)	3.659326199628959
  (942, 20)	2.8689234475150074
  (942, 19)	3.115724768874954
  (942, 18)	3.0726362215234078
  (942, 17)	3.0147504807491123
  (942, 16)	2.929726440887254
  (942, 15)	3.0051136301737946
  (942, 14)	3.276482188825442
  (942, 13)	3.3071062903538966
  (942, 12)	3.078927761062518
  (942, 11)	3.773529051580931
  (942, 10)	3.4486808763549908
  (942, 9)	3.179876382612436
  (942, 8)	3.4075556401112435
  (942, 7)	3.561200293013011
  (942, 6)	3.4603317364439614
  (942, 5)	3.035540787181075
  (942, 4)	3.0260557244250847
  (942, 3)	3.225557197462675
  (942, 2)	2.992229085455645
  (942, 1)	3.033540337110512
  (942, 0)	3.512502729361346
this is the 30 epoch
rmse loss on training set is 0.9458911646551926
rmse loss on test set is 0.9485245496281736
for this epoch using 171.61893343925476 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3981178360953326
  (0, 1680)	3.398752209701141
  (0, 1679)	3.3981178360953326
  (0, 1678)	3.3981178360953326
  (0, 1677)	3.3981178360953326
  (0, 1676)	3.3981178360953326
  (0, 1675)	3.3981178360953326
  (0, 1674)	3.3981178360953326
  (0, 1673)	3.3981178360953326
  (0, 1672)	3.3981178360953326
  (0, 1671)	3.3884950541028354
  (0, 1670)	3.3981178360953326
  (0, 1669)	3.3981178360953326
  (0, 1668)	3.3981178360953326
  (0, 1667)	3.3981178360953326
  (0, 1666)	3.3981178360953326
  (0, 1665)	3.3981178360953326
  (0, 1664)	3.3981178360953326
  (0, 1663)	3.407356760363584
  (0, 1662)	3.3981178360953326
  (0, 1661)	3.3981178360953326
  (0, 1660)	3.373723032065829
  (0, 1659)	3.379282726594777
  (0, 1658)	3.3981178360953326
  (0, 1657)	3.3981178360953326
  :	:
  (942, 24)	3.0048248807540485
  (942, 23)	3.1557248277366337
  (942, 22)	3.4553115449110754
  (942, 21)	3.6644942804296305
  (942, 20)	2.8644393541930127
  (942, 19)	3.117921893632596
  (942, 18)	3.0741790079921767
  (942, 17)	3.0151044834272773
  (942, 16)	2.9271377447155573
  (942, 15)	3.0048917688819015
  (942, 14)	3.279130453826928
  (942, 13)	3.3125724276682416
  (942, 12)	3.078551500521715
  (942, 11)	3.7811650049717693
  (942, 10)	3.452398542534563
  (942, 9)	3.183709536531754
  (942, 8)	3.4121525552195546
  (942, 7)	3.5673386235753495
  (942, 6)	3.4631191591822934
  (942, 5)	3.0365931778681983
  (942, 4)	3.0258227730387848
  (942, 3)	3.2261491209593536
  (942, 2)	2.9912196067857373
  (942, 1)	3.032770324510274
  (942, 0)	3.5153498185359173
this is the 31 epoch
rmse loss on training set is 0.9446610983443736
rmse loss on test set is 0.9474845023153636
for this epoch using 168.74931049346924 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.398264445300309
  (0, 1680)	3.398940060773435
  (0, 1679)	3.398264445300309
  (0, 1678)	3.398264445300309
  (0, 1677)	3.398264445300309
  (0, 1676)	3.398264445300309
  (0, 1675)	3.398264445300309
  (0, 1674)	3.398264445300309
  (0, 1673)	3.398264445300309
  (0, 1672)	3.398264445300309
  (0, 1671)	3.3883602129739523
  (0, 1670)	3.398264445300309
  (0, 1669)	3.398264445300309
  (0, 1668)	3.398264445300309
  (0, 1667)	3.398264445300309
  (0, 1666)	3.398264445300309
  (0, 1665)	3.398264445300309
  (0, 1664)	3.398264445300309
  (0, 1663)	3.407774304869025
  (0, 1662)	3.398264445300309
  (0, 1661)	3.398264445300309
  (0, 1660)	3.373027462983091
  (0, 1659)	3.3786997062001505
  (0, 1658)	3.398264445300309
  (0, 1657)	3.398264445300309
  :	:
  (942, 24)	3.002427326792169
  (942, 23)	3.156717860511622
  (942, 22)	3.4618580760300275
  (942, 21)	3.669287959182997
  (942, 20)	2.8600085218042355
  (942, 19)	3.1200784912748527
  (942, 18)	3.0757043945114133
  (942, 17)	3.01545933416638
  (942, 16)	2.924583033874158
  (942, 15)	3.004669335100057
  (942, 14)	3.2816315578438604
  (942, 13)	3.3178916096104443
  (942, 12)	3.0781560652137547
  (942, 11)	3.7883340638334544
  (942, 10)	3.455863102545598
  (942, 9)	3.1874806062915995
  (942, 8)	3.4165144287645437
  (942, 7)	3.5731426630204695
  (942, 6)	3.465660906238655
  (942, 5)	3.037645502737191
  (942, 4)	3.025584114684891
  (942, 3)	3.226651901999557
  (942, 2)	2.9902214407911893
  (942, 1)	3.031998437209869
  (942, 0)	3.5179317834823256
this is the 32 epoch
rmse loss on training set is 0.9435000236322146
rmse loss on test set is 0.9465110347626355
for this epoch using 172.0928337574005 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.398292796503432
  (0, 1680)	3.3990105421885457
  (0, 1679)	3.398292796503432
  (0, 1678)	3.398292796503432
  (0, 1677)	3.398292796503432
  (0, 1676)	3.398292796503432
  (0, 1675)	3.398292796503432
  (0, 1674)	3.398292796503432
  (0, 1673)	3.398292796503432
  (0, 1672)	3.398292796503432
  (0, 1671)	3.388108758552223
  (0, 1670)	3.398292796503432
  (0, 1669)	3.398292796503432
  (0, 1668)	3.398292796503432
  (0, 1667)	3.398292796503432
  (0, 1666)	3.398292796503432
  (0, 1665)	3.398292796503432
  (0, 1664)	3.398292796503432
  (0, 1663)	3.4080723046818813
  (0, 1662)	3.398292796503432
  (0, 1661)	3.398292796503432
  (0, 1660)	3.3722133359534987
  (0, 1659)	3.377997688019741
  (0, 1658)	3.398292796503432
  (0, 1657)	3.398292796503432
  :	:
  (942, 24)	3.000095083365715
  (942, 23)	3.1576375730189237
  (942, 22)	3.468167322338906
  (942, 21)	3.6737372221598004
  (942, 20)	2.8556318365392457
  (942, 19)	3.122197122177266
  (942, 18)	3.0772137397504573
  (942, 17)	3.015815215830438
  (942, 16)	2.922062840986415
  (942, 15)	3.00444709421863
  (942, 14)	3.283996206252438
  (942, 13)	3.3230709520250263
  (942, 12)	3.0777464645943104
  (942, 11)	3.795068804532731
  (942, 10)	3.4590943305840733
  (942, 9)	3.191192330957659
  (942, 8)	3.420656745775958
  (942, 7)	3.5786347079349805
  (942, 6)	3.467979253169817
  (942, 5)	3.0386979515548322
  (942, 4)	3.0253411634809284
  (942, 3)	3.2270768988366334
  (942, 2)	2.989235548018769
  (942, 1)	3.031227516992387
  (942, 0)	3.5202737986435033
this is the 33 epoch
rmse loss on training set is 0.9424011229101067
rmse loss on test set is 0.9455973147786044
for this epoch using 177.43152356147766 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.398220703340376
  (0, 1680)	3.3989814285761923
  (0, 1679)	3.398220703340376
  (0, 1678)	3.398220703340376
  (0, 1677)	3.398220703340376
  (0, 1676)	3.398220703340376
  (0, 1675)	3.398220703340376
  (0, 1674)	3.398220703340376
  (0, 1673)	3.398220703340376
  (0, 1672)	3.398220703340376
  (0, 1671)	3.38775842700112
  (0, 1670)	3.398220703340376
  (0, 1669)	3.398220703340376
  (0, 1668)	3.398220703340376
  (0, 1667)	3.398220703340376
  (0, 1666)	3.398220703340376
  (0, 1665)	3.398220703340376
  (0, 1664)	3.398220703340376
  (0, 1663)	3.4082686316438564
  (0, 1662)	3.398220703340376
  (0, 1661)	3.398220703340376
  (0, 1660)	3.371298520184386
  (0, 1659)	3.377194698722967
  (0, 1658)	3.398220703340376
  (0, 1657)	3.398220703340376
  :	:
  (942, 24)	2.9978308960262328
  (942, 23)	3.158490043854829
  (942, 22)	3.4742514210689204
  (942, 21)	3.67786956363707
  (942, 20)	2.85130998104488
  (942, 19)	3.1242801162763403
  (942, 18)	3.07870826786741
  (942, 17)	3.0161722782368954
  (942, 16)	2.9195775409679943
  (942, 15)	3.0042257255763634
  (942, 14)	3.2862341945934688
  (942, 13)	3.3281170434068734
  (942, 12)	3.0773271019675756
  (942, 11)	3.8013993619151694
  (942, 10)	3.462110362157022
  (942, 9)	3.1948472112241983
  (942, 8)	3.424593816319261
  (942, 7)	3.5838354073545857
  (942, 6)	3.470094488869391
  (942, 5)	3.0397506806851093
  (942, 4)	3.025095133791389
  (942, 3)	3.227434219967601
  (942, 2)	2.9882627047063353
  (942, 1)	3.0304600082473767
  (942, 0)	3.5223987099025416
this is the 34 epoch
rmse loss on training set is 0.941358460794982
rmse loss on test set is 0.9447373881480047
for this epoch using 177.64572525024414 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3980638101064105
  (0, 1680)	3.398868326554976
  (0, 1679)	3.3980638101064105
  (0, 1678)	3.3980638101064105
  (0, 1677)	3.3980638101064105
  (0, 1676)	3.3980638101064105
  (0, 1675)	3.3980638101064105
  (0, 1674)	3.3980638101064105
  (0, 1673)	3.3980638101064105
  (0, 1672)	3.3980638101064105
  (0, 1671)	3.3873247873910532
  (0, 1670)	3.3980638101064105
  (0, 1669)	3.3980638101064105
  (0, 1668)	3.3980638101064105
  (0, 1667)	3.3980638101064105
  (0, 1666)	3.3980638101064105
  (0, 1665)	3.3980638101064105
  (0, 1664)	3.3980638101064105
  (0, 1663)	3.408378985270871
  (0, 1662)	3.3980638101064105
  (0, 1661)	3.3980638101064105
  (0, 1660)	3.3702987089851977
  (0, 1659)	3.3763065724460977
  (0, 1658)	3.3980638101064105
  (0, 1657)	3.3980638101064105
  :	:
  (942, 24)	2.9956367778483113
  (942, 23)	3.1592808077279138
  (942, 22)	3.4801216935967543
  (942, 21)	3.681710195777749
  (942, 20)	2.8470434593037934
  (942, 19)	3.126329594358274
  (942, 18)	3.0801890817305995
  (942, 17)	3.0165306425164355
  (942, 16)	2.9171273730093037
  (942, 15)	3.0040058309201316
  (942, 14)	3.2883544929143125
  (942, 13)	3.333035990534754
  (942, 12)	3.0769018387889253
  (942, 11)	3.8073536189686843
  (942, 10)	3.4649278338224447
  (942, 9)	3.198447534114646
  (942, 8)	3.4283388710238567
  (942, 7)	3.5887638902827983
  (942, 6)	3.4720250909276333
  (942, 5)	3.0408038170246736
  (942, 4)	3.0248470658507625
  (942, 3)	3.227732852849247
  (942, 2)	2.9873035277472764
  (942, 1)	3.0296980048909012
  (942, 0)	3.5243272443600198
this is the 35 epoch
rmse loss on training set is 0.9403668534781138
rmse loss on test set is 0.9439260517574009
for this epoch using 180.68542194366455 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.39783582945073
  (0, 1680)	3.398684912439754
  (0, 1679)	3.39783582945073
  (0, 1678)	3.39783582945073
  (0, 1677)	3.39783582945073
  (0, 1676)	3.39783582945073
  (0, 1675)	3.39783582945073
  (0, 1674)	3.39783582945073
  (0, 1673)	3.39783582945073
  (0, 1672)	3.39783582945073
  (0, 1671)	3.3868214796388623
  (0, 1670)	3.39783582945073
  (0, 1669)	3.39783582945073
  (0, 1668)	3.39783582945073
  (0, 1667)	3.39783582945073
  (0, 1666)	3.39783582945073
  (0, 1665)	3.39783582945073
  (0, 1664)	3.39783582945073
  (0, 1663)	3.4084171304493487
  (0, 1662)	3.39783582945073
  (0, 1661)	3.39783582945073
  (0, 1660)	3.369227658519482
  (0, 1659)	3.3753471908593475
  (0, 1658)	3.39783582945073
  (0, 1657)	3.39783582945073
  :	:
  (942, 24)	2.9935141065027997
  (942, 23)	3.1600149073005563
  (942, 22)	3.4857887105307523
  (942, 21)	3.685282241665179
  (942, 20)	2.8428326186228086
  (942, 19)	3.128347487483187
  (942, 18)	3.0816571748857307
  (942, 17)	3.016890404965496
  (942, 16)	2.914712459819759
  (942, 15)	3.0037879420612206
  (942, 14)	3.2903653222268794
  (942, 13)	3.3378334602295165
  (942, 12)	3.076474052525152
  (942, 11)	3.812957382452909
  (942, 10)	3.4675620114267063
  (942, 9)	3.2019953950668203
  (942, 8)	3.431904149072012
  (942, 7)	3.5934378838532406
  (942, 6)	3.4737878862341525
  (942, 5)	3.0418574615507286
  (942, 4)	3.0245978483099063
  (942, 3)	3.227980780193402
  (942, 2)	2.9863584965875876
  (942, 1)	3.028943292084008
  (942, 0)	3.5260782024397304
this is the 36 epoch
rmse loss on training set is 0.9394217589281694
rmse loss on test set is 0.9431587463028858
for this epoch using 184.2275915145874 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.397548756357784
  (0, 1680)	3.39844314622413
  (0, 1679)	3.397548756357784
  (0, 1678)	3.397548756357784
  (0, 1677)	3.397548756357784
  (0, 1676)	3.397548756357784
  (0, 1675)	3.397548756357784
  (0, 1674)	3.397548756357784
  (0, 1673)	3.397548756357784
  (0, 1672)	3.397548756357784
  (0, 1671)	3.386260428664107
  (0, 1670)	3.397548756357784
  (0, 1669)	3.397548756357784
  (0, 1668)	3.397548756357784
  (0, 1667)	3.397548756357784
  (0, 1666)	3.397548756357784
  (0, 1665)	3.397548756357784
  (0, 1664)	3.397548756357784
  (0, 1663)	3.408395111454105
  (0, 1662)	3.397548756357784
  (0, 1661)	3.397548756357784
  (0, 1660)	3.3680974026847106
  (0, 1659)	3.3743286992952357
  (0, 1658)	3.397548756357784
  (0, 1657)	3.397548756357784
  :	:
  (942, 24)	2.99146371045582
  (942, 23)	3.1606969399938776
  (942, 22)	3.4912623513875087
  (942, 21)	3.6886069125481993
  (942, 20)	2.8386776690585185
  (942, 19)	3.1303355546788096
  (942, 18)	3.083113442373037
  (942, 17)	3.017251640442797
  (942, 16)	2.9123328244509143
  (942, 15)	3.0035725277995042
  (942, 14)	3.2922742237463374
  (942, 13)	3.342514717501221
  (942, 12)	3.0760466886588396
  (942, 11)	3.8182345452329525
  (942, 10)	3.4700269076041574
  (942, 9)	3.2054927176641494
  (942, 8)	3.4353009791059446
  (942, 7)	3.5978738226062066
  (942, 6)	3.475398197848772
  (942, 5)	3.0429116925102746
  (942, 4)	3.0243482380476245
  (942, 3)	3.228185084884851
  (942, 2)	2.9854279724055672
  (942, 1)	3.028197383283793
  (942, 0)	3.5276686335144967
this is the 37 epoch
rmse loss on training set is 0.9385191844835405
rmse loss on test set is 0.9424314654595848
for this epoch using 183.07363867759705 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.397213060455778
  (0, 1680)	3.398153463880706
  (0, 1679)	3.397213060455778
  (0, 1678)	3.397213060455778
  (0, 1677)	3.397213060455778
  (0, 1676)	3.397213060455778
  (0, 1675)	3.397213060455778
  (0, 1674)	3.397213060455778
  (0, 1673)	3.397213060455778
  (0, 1672)	3.397213060455778
  (0, 1671)	3.385652036814097
  (0, 1670)	3.397213060455778
  (0, 1669)	3.397213060455778
  (0, 1668)	3.397213060455778
  (0, 1667)	3.397213060455778
  (0, 1666)	3.397213060455778
  (0, 1665)	3.397213060455778
  (0, 1664)	3.397213060455778
  (0, 1663)	3.408323444320755
  (0, 1662)	3.397213060455778
  (0, 1661)	3.397213060455778
  (0, 1660)	3.3669184461809127
  (0, 1659)	3.373261700996017
  (0, 1658)	3.397213060455778
  (0, 1657)	3.397213060455778
  :	:
  (942, 24)	2.9894859453767113
  (942, 23)	3.1613311002201505
  (942, 22)	3.4965518592498395
  (942, 21)	3.691703670363134
  (942, 20)	2.834578700573685
  (942, 19)	3.1322953990349167
  (942, 18)	3.0845586904936164
  (942, 17)	3.017614405357512
  (942, 16)	2.9099884049824074
  (942, 15)	3.0033600001820444
  (942, 14)	3.29408812154033
  (942, 13)	3.3470846603479494
  (942, 12)	3.075622307383807
  (942, 11)	3.8232072360965472
  (942, 10)	3.4723353893009237
  (942, 9)	3.208941271253367
  (942, 8)	3.438539853519002
  (942, 7)	3.6020869493830046
  (942, 6)	3.476869979149912
  (942, 5)	3.0439665682796617
  (942, 4)	3.024098877556679
  (942, 3)	3.2283520445129
  (942, 2)	2.9845122148887198
  (942, 1)	3.0274615531157347
  (942, 0)	3.5291139962345004
this is the 38 epoch
rmse loss on training set is 0.9376556089524857
rmse loss on test set is 0.9417406788907986
for this epoch using 175.81698179244995 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3968378585788663
  (0, 1680)	3.3978249499072133
  (0, 1679)	3.3968378585788663
  (0, 1678)	3.3968378585788663
  (0, 1677)	3.3968378585788663
  (0, 1676)	3.3968378585788663
  (0, 1675)	3.3968378585788663
  (0, 1674)	3.3968378585788663
  (0, 1673)	3.3968378585788663
  (0, 1672)	3.3968378585788663
  (0, 1671)	3.385005356494064
  (0, 1670)	3.3968378585788663
  (0, 1669)	3.3968378585788663
  (0, 1668)	3.3968378585788663
  (0, 1667)	3.3968378585788663
  (0, 1666)	3.3968378585788663
  (0, 1665)	3.3968378585788663
  (0, 1664)	3.3968378585788663
  (0, 1663)	3.408211289492469
  (0, 1662)	3.3968378585788663
  (0, 1661)	3.3968378585788663
  (0, 1660)	3.365699937713139
  (0, 1659)	3.372155431423423
  (0, 1658)	3.3968378585788663
  (0, 1657)	3.3968378585788663
  :	:
  (942, 24)	2.987580761751934
  (942, 23)	3.1619212174732296
  (942, 22)	3.50166589078651
  (942, 21)	3.6945903765857486
  (942, 20)	2.830535698186008
  (942, 19)	3.1342284823254585
  (942, 18)	3.085993645618569
  (942, 17)	3.0179787402929845
  (942, 16)	2.9076790673246604
  (942, 15)	3.00315072015746
  (942, 14)	3.2958133791797737
  (942, 13)	3.35154785146295
  (942, 12)	3.0752031254983105
  (942, 11)	3.827895957849514
  (942, 10)	3.4744992760674824
  (942, 9)	3.2123426866681233
  (942, 8)	3.4416304965940063
  (942, 7)	3.6060914083561992
  (942, 6)	3.4782159362376555
  (942, 5)	3.045022129922363
  (942, 4)	3.023850310182263
  (942, 3)	3.228487216448972
  (942, 2)	2.9836113968896534
  (942, 1)	3.0267368665117793
  (942, 0)	3.530428304711399
this is the 39 epoch
rmse loss on training set is 0.9368279168257375
rmse loss on test set is 0.941083266895839
for this epoch using 196.72532629966736 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3964310693866735
  (0, 1680)	3.397465491923918
  (0, 1679)	3.3964310693866735
  (0, 1678)	3.3964310693866735
  (0, 1677)	3.3964310693866735
  (0, 1676)	3.3964310693866735
  (0, 1675)	3.3964310693866735
  (0, 1674)	3.3964310693866735
  (0, 1673)	3.3964310693866735
  (0, 1672)	3.3964310693866735
  (0, 1671)	3.3843282448149843
  (0, 1670)	3.3964310693866735
  (0, 1669)	3.3964310693866735
  (0, 1668)	3.3964310693866735
  (0, 1667)	3.3964310693866735
  (0, 1666)	3.3964310693866735
  (0, 1665)	3.3964310693866735
  (0, 1664)	3.3964310693866735
  (0, 1663)	3.408066606539738
  (0, 1662)	3.3964310693866735
  (0, 1661)	3.3964310693866735
  (0, 1660)	3.3644498251477266
  (0, 1659)	3.3710179144506416
  (0, 1658)	3.3964310693866735
  (0, 1657)	3.3964310693866735
  :	:
  (942, 24)	2.9857477646172916
  (942, 23)	3.162470790673109
  (942, 22)	3.5066125619998827
  (942, 21)	3.697283428436688
  (942, 20)	2.826548555341813
  (942, 19)	3.1361361382795008
  (942, 18)	3.087418962128369
  (942, 17)	3.0183446723058696
  (942, 16)	2.905404616364543
  (942, 15)	3.002945002682543
  (942, 14)	3.297455850941417
  (942, 13)	3.3559085470967136
  (942, 12)	3.074791053962556
  (942, 11)	3.8323197144805046
  (942, 10)	3.4765294298372544
  (942, 9)	3.215698470258354
  (942, 8)	3.444581926941435
  (942, 7)	3.6099003307155093
  (942, 6)	3.479447639526794
  (942, 5)	3.04607840347158
  (942, 4)	3.023602993462469
  (942, 3)	3.2285955143400775
  (942, 2)	2.9827256172124965
  (942, 1)	3.026024204516837
  (942, 0)	3.531624261667338
this is the 40 epoch
rmse loss on training set is 0.9360333426113393
rmse loss on test set is 0.9404564648508217
for this epoch using 180.44037079811096 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3959995517199477
  (0, 1680)	3.3970819190022765
  (0, 1679)	3.3959995517199477
  (0, 1678)	3.3959995517199477
  (0, 1677)	3.3959995517199477
  (0, 1676)	3.3959995517199477
  (0, 1675)	3.3959995517199477
  (0, 1674)	3.3959995517199477
  (0, 1673)	3.3959995517199477
  (0, 1672)	3.3959995517199477
  (0, 1671)	3.3836275019450808
  (0, 1670)	3.3959995517199477
  (0, 1669)	3.3959995517199477
  (0, 1668)	3.3959995517199477
  (0, 1667)	3.3959995517199477
  (0, 1666)	3.3959995517199477
  (0, 1665)	3.3959995517199477
  (0, 1664)	3.3959995517199477
  (0, 1663)	3.407896292627231
  (0, 1662)	3.3959995517199477
  (0, 1661)	3.3959995517199477
  (0, 1660)	3.363174994315799
  (0, 1659)	3.3698561021309583
  (0, 1658)	3.3959995517199477
  (0, 1657)	3.3959995517199477
  :	:
  (942, 24)	2.9839862662397394
  (942, 23)	3.1629830191281916
  (942, 22)	3.5113994900486007
  (942, 21)	3.699797883422257
  (942, 20)	2.8226170857211956
  (942, 19)	3.1380195846153853
  (942, 18)	3.0888352295635513
  (942, 17)	3.018712216937257
  (942, 16)	2.9031648056549724
  (942, 15)	3.002743121332951
  (942, 14)	3.2990209280714677
  (942, 13)	3.360170723308877
  (942, 12)	3.07438773154809
  (942, 11)	3.83649612816917
  (942, 10)	3.4784358368748842
  (942, 9)	3.21901001640595
  (942, 8)	3.447402514673042
  (942, 7)	3.6135259135206206
  (942, 6)	3.4805756254155713
  (942, 5)	3.04713540196311
  (942, 4)	3.0233573107935787
  (942, 3)	3.228681276824613
  (942, 2)	2.9818549117538895
  (942, 1)	3.0253242871271118
  (942, 0)	3.5327133796045223
this is the 41 epoch
rmse loss on training set is 0.9352694236383341
rmse loss on test set is 0.9398578158956369
for this epoch using 174.25540781021118 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3955492282454096
  (0, 1680)	3.396680125279145
  (0, 1679)	3.3955492282454096
  (0, 1678)	3.3955492282454096
  (0, 1677)	3.3955492282454096
  (0, 1676)	3.3955492282454096
  (0, 1675)	3.3955492282454096
  (0, 1674)	3.3955492282454096
  (0, 1673)	3.3955492282454096
  (0, 1672)	3.3955492282454096
  (0, 1671)	3.382908994724441
  (0, 1670)	3.3955492282454096
  (0, 1669)	3.3955492282454096
  (0, 1668)	3.3955492282454096
  (0, 1667)	3.3955492282454096
  (0, 1666)	3.3955492282454096
  (0, 1665)	3.3955492282454096
  (0, 1664)	3.3955492282454096
  (0, 1663)	3.4077063062774986
  (0, 1662)	3.3955492282454096
  (0, 1661)	3.3955492282454096
  (0, 1660)	3.3618813930296136
  (0, 1659)	3.3686759996107467
  (0, 1658)	3.3955492282454096
  (0, 1657)	3.3955492282454096
  :	:
  (942, 24)	2.982295332503138
  (942, 23)	3.163460830446947
  (942, 22)	3.516033831473299
  (942, 21)	3.7021475731432383
  (942, 20)	2.8187410336575565
  (942, 19)	3.139879933945688
  (942, 18)	3.0902429790617063
  (942, 17)	3.0190813799683194
  (942, 16)	2.9009593458267475
  (942, 15)	3.002545312465245
  (942, 14)	3.300513580578872
  (942, 13)	3.3643380998312753
  (942, 12)	3.0739945549692838
  (942, 11)	3.8404415468848043
  (942, 10)	3.480227682539345
  (942, 9)	3.2222786186898724
  (942, 8)	3.4501000337265437
  (942, 7)	3.6169794922166862
  (942, 6)	3.481609488862763
  (942, 5)	3.048193127241899
  (942, 4)	3.0231135816190653
  (942, 3)	3.2287483292141155
  (942, 2)	2.980999263197422
  (942, 1)	3.0246376934871826
  (942, 0)	3.5337060909915787
this is the 42 epoch
rmse loss on training set is 0.9345339599548302
rmse loss on test set is 0.9392851305708428
for this epoch using 176.70496582984924 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3950851958207244
  (0, 1680)	3.3962651802882844
  (0, 1679)	3.3950851958207244
  (0, 1678)	3.3950851958207244
  (0, 1677)	3.3950851958207244
  (0, 1676)	3.3950851958207244
  (0, 1675)	3.3950851958207244
  (0, 1674)	3.3950851958207244
  (0, 1673)	3.3950851958207244
  (0, 1672)	3.3950851958207244
  (0, 1671)	3.3821777669790443
  (0, 1670)	3.3950851958207244
  (0, 1669)	3.3950851958207244
  (0, 1668)	3.3950851958207244
  (0, 1667)	3.3950851958207244
  (0, 1666)	3.3950851958207244
  (0, 1665)	3.3950851958207244
  (0, 1664)	3.3950851958207244
  (0, 1663)	3.4075017778593115
  (0, 1662)	3.3950851958207244
  (0, 1661)	3.3950851958207244
  (0, 1660)	3.360574141754052
  (0, 1659)	3.3674827766313093
  (0, 1658)	3.3950851958207244
  (0, 1657)	3.3950851958207244
  :	:
  (942, 24)	2.9806738236803523
  (942, 23)	3.1639069057008684
  (942, 22)	3.5205223171312046
  (942, 21)	3.7043452072505163
  (942, 20)	2.81492008333355
  (942, 19)	3.141718203653099
  (942, 18)	3.091642689149587
  (942, 17)	3.01945215895038
  (942, 16)	2.898787911880324
  (942, 15)	3.0023517789733885
  (942, 14)	3.3019383949878263
  (942, 13)	3.368414161749362
  (942, 12)	3.073612705851973
  (942, 11)	3.8441711432889436
  (942, 10)	3.481913419466981
  (942, 9)	3.225505479847184
  (942, 8)	3.452681709733762
  (942, 7)	3.6202716072877057
  (942, 6)	3.482557967650785
  (942, 5)	3.0492515715644317
  (942, 4)	3.0228720703189422
  (942, 3)	3.2288000388234934
  (942, 2)	2.980158609437876
  (942, 1)	3.0239648797394754
  (942, 0)	3.5346118484003615
this is the 43 epoch
rmse loss on training set is 0.9338249801781547
rmse loss on test set is 0.9387364523184842
for this epoch using 174.6529004573822 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3946118238920246
  (0, 1680)	3.39584142732241
  (0, 1679)	3.3946118238920246
  (0, 1678)	3.3946118238920246
  (0, 1677)	3.3946118238920246
  (0, 1676)	3.3946118238920246
  (0, 1675)	3.3946118238920246
  (0, 1674)	3.3946118238920246
  (0, 1673)	3.3946118238920246
  (0, 1672)	3.3946118238920246
  (0, 1671)	3.381438137851146
  (0, 1670)	3.3946118238920246
  (0, 1669)	3.3946118238920246
  (0, 1668)	3.3946118238920246
  (0, 1667)	3.3946118238920246
  (0, 1666)	3.3946118238920246
  (0, 1665)	3.3946118238920246
  (0, 1664)	3.3946118238920246
  (0, 1663)	3.4072871081105967
  (0, 1662)	3.3946118238920246
  (0, 1661)	3.3946118238920246
  (0, 1660)	3.359257632255263
  (0, 1659)	3.3662808669447926
  (0, 1658)	3.3946118238920246
  (0, 1657)	3.3946118238920246
  :	:
  (942, 24)	2.979120430206922
  (942, 23)	3.164323702112676
  (942, 22)	3.5248712841249756
  (942, 21)	3.7064024683706607
  (942, 20)	2.811153866896727
  (942, 19)	3.1435353248299385
  (942, 18)	3.093034790953292
  (942, 17)	3.0198245445355916
  (942, 16)	2.8966501494968875
  (942, 15)	3.002162693678893
  (942, 14)	3.303299608441847
  (942, 13)	3.372402179194856
  (942, 12)	3.073243174861223
  (942, 11)	3.8476990056178826
  (942, 10)	3.4835008297384062
  (942, 9)	3.228691720661512
  (942, 8)	3.4551542638008033
  (942, 7)	3.6234120654994153
  (942, 6)	3.483429019057182
  (942, 5)	3.05031071901718
  (942, 4)	3.0226329939564938
  (942, 3)	3.2288393645738975
  (942, 2)	2.979332850891202
  (942, 1)	3.0233061947887667
  (942, 0)	3.5354392154629486
this is the 44 epoch
rmse loss on training set is 0.933140712346257
rmse loss on test set is 0.9382100279366565
for this epoch using 181.97421669960022 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3941328421239088
  (0, 1680)	3.39541257102632
  (0, 1679)	3.3941328421239088
  (0, 1678)	3.3941328421239088
  (0, 1677)	3.3941328421239088
  (0, 1676)	3.3941328421239088
  (0, 1675)	3.3941328421239088
  (0, 1674)	3.3941328421239088
  (0, 1673)	3.3941328421239088
  (0, 1672)	3.3941328421239088
  (0, 1671)	3.3806937893496807
  (0, 1670)	3.3941328421239088
  (0, 1669)	3.3941328421239088
  (0, 1668)	3.3941328421239088
  (0, 1667)	3.3941328421239088
  (0, 1666)	3.3941328421239088
  (0, 1665)	3.3941328421239088
  (0, 1664)	3.3941328421239088
  (0, 1663)	3.4070660558941794
  (0, 1662)	3.3941328421239088
  (0, 1661)	3.3941328421239088
  (0, 1660)	3.357935615434931
  (0, 1659)	3.36507405685556
  (0, 1658)	3.3941328421239088
  (0, 1657)	3.3941328421239088
  :	:
  (942, 24)	2.977633704010113
  (942, 23)	3.1647134735179008
  (942, 22)	3.52908670498932
  (942, 21)	3.7083300987672034
  (942, 20)	2.807441971621379
  (942, 19)	3.145332150367237
  (942, 18)	3.0944196728839914
  (942, 17)	3.0201985216321496
  (942, 16)	2.894545680491654
  (942, 15)	3.0019782023902084
  (942, 14)	3.304601139516267
  (942, 13)	3.376305225228114
  (942, 12)	3.072886783279704
  (942, 11)	3.8510382211806458
  (942, 10)	3.484997081552093
  (942, 9)	3.2318383878966523
  (942, 8)	3.457523952543979
  (942, 7)	3.626409996157752
  (942, 6)	3.4842298896029074
  (942, 5)	3.051370546769849
  (942, 4)	3.0223965290214534
  (942, 3)	3.2288689014370338
  (942, 2)	2.9785218568281717
  (942, 1)	3.0226618942168253
  (942, 0)	3.5361959494558284
this is the 45 epoch
rmse loss on training set is 0.932479558979
rmse loss on test set is 0.9377042822244751
for this epoch using 187.59800100326538 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3936514183554607
  (0, 1680)	3.39498175531528
  (0, 1679)	3.3936514183554607
  (0, 1678)	3.3936514183554607
  (0, 1677)	3.3936514183554607
  (0, 1676)	3.3936514183554607
  (0, 1675)	3.3936514183554607
  (0, 1674)	3.3936514183554607
  (0, 1673)	3.3936514183554607
  (0, 1672)	3.3936514183554607
  (0, 1671)	3.3799478442175177
  (0, 1670)	3.3936514183554607
  (0, 1669)	3.3936514183554607
  (0, 1668)	3.3936514183554607
  (0, 1667)	3.3936514183554607
  (0, 1666)	3.3936514183554607
  (0, 1665)	3.3936514183554607
  (0, 1664)	3.3936514183554607
  (0, 1663)	3.4068418162781438
  (0, 1662)	3.3936514183554607
  (0, 1661)	3.3936514183554607
  (0, 1660)	3.3566112794510987
  (0, 1659)	3.363865563991621
  (0, 1658)	3.3936514183554607
  (0, 1657)	3.3936514183554607
  :	:
  (942, 24)	2.97621208589036
  (942, 23)	3.1650782888237026
  (942, 22)	3.533174214378643
  (942, 21)	3.710137979448375
  (942, 20)	2.8037839462285112
  (942, 19)	3.1471094622720335
  (942, 18)	3.0957976848513815
  (942, 17)	3.0205740704050594
  (942, 16)	2.892474107517679
  (942, 15)	3.0017984266635485
  (942, 14)	3.3058466160636106
  (942, 13)	3.380126192074911
  (942, 12)	3.0725442022996385
  (942, 11)	3.854200953067321
  (942, 10)	3.4864087808878783
  (942, 9)	3.234946461380421
  (942, 8)	3.4597966047008213
  (942, 7)	3.629273902782136
  (942, 6)	3.4849671784933163
  (942, 5)	3.0524310261803427
  (942, 4)	3.0221628172924677
  (942, 3)	3.2288909202381917
  (942, 2)	2.9777254708531693
  (942, 1)	3.0220321525565867
  (942, 0)	3.5368890762565335
this is the 46 epoch
rmse loss on training set is 0.9318400756893191
rmse loss on test set is 0.9372177961772997
for this epoch using 190.4186143875122 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3931702278764835
  (0, 1680)	3.3945516326130427
  (0, 1679)	3.3931702278764835
  (0, 1678)	3.3931702278764835
  (0, 1677)	3.3931702278764835
  (0, 1676)	3.3931702278764835
  (0, 1675)	3.3931702278764835
  (0, 1674)	3.3931702278764835
  (0, 1673)	3.3931702278764835
  (0, 1672)	3.3931702278764835
  (0, 1671)	3.379202935112387
  (0, 1670)	3.3931702278764835
  (0, 1669)	3.3931702278764835
  (0, 1668)	3.3931702278764835
  (0, 1667)	3.3931702278764835
  (0, 1666)	3.3931702278764835
  (0, 1665)	3.3931702278764835
  (0, 1664)	3.3931702278764835
  (0, 1663)	3.4066170899338815
  (0, 1662)	3.3931702278764835
  (0, 1661)	3.3931702278764835
  (0, 1660)	3.355287319126064
  (0, 1659)	3.3626581073097124
  (0, 1658)	3.3931702278764835
  (0, 1657)	3.3931702278764835
  :	:
  (942, 24)	2.974853929400584
  (942, 23)	3.165420048667118
  (942, 22)	3.537139133479263
  (942, 21)	3.711835202377163
  (942, 20)	2.8001793064624363
  (942, 19)	3.148867978285241
  (942, 18)	3.097169142052365
  (942, 17)	3.0209511671412708
  (942, 16)	2.8904350181154497
  (942, 15)	3.001623466294305
  (942, 14)	3.307039400385546
  (942, 13)	3.383867805868966
  (942, 12)	3.0722159702657166
  (942, 11)	3.8571985106216498
  (942, 10)	3.487742018605094
  (942, 9)	3.2380168603324693
  (942, 8)	3.461977654611465
  (942, 7)	3.63201171056664
  (942, 6)	3.485646895317916
  (942, 5)	3.0534921237672443
  (942, 4)	3.0219319709277865
  (942, 3)	3.2289074032867457
  (942, 2)	2.976943515635216
  (942, 1)	3.0214170741129203
  (942, 0)	3.537524958358778
this is the 47 epoch
rmse loss on training set is 0.9312209527937484
rmse loss on test set is 0.9367492881943281
for this epoch using 183.15250539779663 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3926915149252785
  (0, 1680)	3.394124425311506
  (0, 1679)	3.3926915149252785
  (0, 1678)	3.3926915149252785
  (0, 1677)	3.3926915149252785
  (0, 1676)	3.3926915149252785
  (0, 1675)	3.3926915149252785
  (0, 1674)	3.3926915149252785
  (0, 1673)	3.3926915149252785
  (0, 1672)	3.3926915149252785
  (0, 1671)	3.3784612660050235
  (0, 1670)	3.3926915149252785
  (0, 1669)	3.3926915149252785
  (0, 1668)	3.3926915149252785
  (0, 1667)	3.3926915149252785
  (0, 1666)	3.3926915149252785
  (0, 1665)	3.3926915149252785
  (0, 1664)	3.3926915149252785
  (0, 1663)	3.40639414475228
  (0, 1662)	3.3926915149252785
  (0, 1661)	3.3926915149252785
  (0, 1660)	3.3539659975482423
  (0, 1659)	3.361453969244564
  (0, 1658)	3.3926915149252785
  (0, 1657)	3.3926915149252785
  :	:
  (942, 24)	2.973557521621937
  (942, 23)	3.165740500454868
  (942, 22)	3.54098649235093
  (942, 21)	3.7134301363877906
  (942, 20)	2.796627540011227
  (942, 19)	3.1506083578661648
  (942, 18)	3.098534328377702
  (942, 17)	3.0213297849958227
  (942, 16)	2.88842798819191
  (942, 15)	3.001453401565413
  (942, 14)	3.3081826119970414
  (942, 13)	3.387532640038659
  (942, 12)	3.0719025080823195
  (942, 11)	3.8600414141916057
  (942, 10)	3.4890024133835236
  (942, 9)	3.241050449019884
  (942, 8)	3.464072172842902
  (942, 7)	3.634630809975165
  (942, 6)	3.486274512527548
  (942, 5)	3.0545538020636904
  (942, 4)	3.021704076879828
  (942, 3)	3.2289200762588055
  (942, 2)	2.9761757969856824
  (942, 1)	3.020816702496016
  (942, 0)	3.538109356576347
this is the 48 epoch
rmse loss on training set is 0.9306209994620117
rmse loss on test set is 0.9362975978468104
for this epoch using 183.99056243896484 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3922171472240197
  (0, 1680)	3.393701980267984
  (0, 1679)	3.3922171472240197
  (0, 1678)	3.3922171472240197
  (0, 1677)	3.3922171472240197
  (0, 1676)	3.3922171472240197
  (0, 1675)	3.3922171472240197
  (0, 1674)	3.3922171472240197
  (0, 1673)	3.3922171472240197
  (0, 1672)	3.3922171472240197
  (0, 1671)	3.3777246666122602
  (0, 1670)	3.3922171472240197
  (0, 1669)	3.3922171472240197
  (0, 1668)	3.3922171472240197
  (0, 1667)	3.3922171472240197
  (0, 1666)	3.3922171472240197
  (0, 1665)	3.3922171472240197
  (0, 1664)	3.3922171472240197
  (0, 1663)	3.4061748704932855
  (0, 1662)	3.3922171472240197
  (0, 1661)	3.3922171472240197
  (0, 1660)	3.3526492006886084
  (0, 1659)	3.3602550508262445
  (0, 1658)	3.3922171472240197
  (0, 1657)	3.3922171472240197
  :	:
  (942, 24)	2.9723211011919877
  (942, 23)	3.166041251948302
  (942, 22)	3.5447210503848523
  (942, 21)	3.714930487363731
  (942, 20)	2.793128110847663
  (942, 19)	3.1523312076038104
  (942, 18)	3.099893499475525
  (942, 17)	3.0217098946339065
  (942, 16)	2.8864525850025298
  (942, 15)	3.0012882952764848
  (942, 14)	3.309279148222716
  (942, 13)	3.391123127464852
  (942, 12)	3.071604132977133
  (942, 11)	3.8627394546333127
  (942, 10)	3.490195150881131
  (942, 9)	3.2440480418147084
  (942, 8)	3.4660848942064164
  (942, 7)	3.637138096791642
  (942, 6)	3.486855013163643
  (942, 5)	3.055616020365615
  (942, 4)	3.0214792007183426
  (942, 3)	3.2289304367152543
  (942, 2)	2.975422107365365
  (942, 1)	3.0202310290153704
  (942, 0)	3.5386474860125134
this is the 49 epoch
rmse loss on training set is 0.9300391300206743
rmse loss on test set is 0.9358616718264522
for this epoch using 179.82340502738953 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.391748664288447
  (0, 1680)	3.393285817077452
  (0, 1679)	3.391748664288447
  (0, 1678)	3.391748664288447
  (0, 1677)	3.391748664288447
  (0, 1676)	3.391748664288447
  (0, 1675)	3.391748664288447
  (0, 1674)	3.391748664288447
  (0, 1673)	3.391748664288447
  (0, 1672)	3.391748664288447
  (0, 1671)	3.3769946406036206
  (0, 1670)	3.391748664288447
  (0, 1669)	3.391748664288447
  (0, 1668)	3.391748664288447
  (0, 1667)	3.391748664288447
  (0, 1666)	3.391748664288447
  (0, 1665)	3.391748664288447
  (0, 1664)	3.391748664288447
  (0, 1663)	3.405960827205214
  (0, 1662)	3.391748664288447
  (0, 1661)	3.391748664288447
  (0, 1660)	3.3513384857727386
  (0, 1659)	3.35906292050982
  (0, 1658)	3.391748664288447
  (0, 1657)	3.391748664288447
  :	:
  (942, 24)	2.9711428739032026
  (942, 23)	3.166323783540825
  (942, 22)	3.5483473150490923
  (942, 21)	3.7163433531853527
  (942, 20)	2.789680463058473
  (942, 19)	3.1540370861099287
  (942, 18)	3.101246885506587
  (942, 17)	3.0220914647817403
  (942, 16)	2.8845083697007614
  (942, 15)	3.001128194575142
  (942, 14)	3.3103317028416286
  (942, 13)	3.3946415715251193
  (942, 12)	3.0713210707933603
  (942, 11)	3.8653017480065266
  (942, 10)	3.4913250194503482
  (942, 9)	3.247010407719707
  (942, 8)	3.468020243398005
  (942, 7)	3.6395400089215095
  (942, 6)	3.4873929342724947
  (942, 5)	3.0566787353858937
  (942, 4)	3.0212573899364377
  (942, 3)	3.2289397796014367
  (942, 2)	2.974682228893892
  (942, 1)	3.019660000065644
  (942, 0)	3.5391440668226144
this is the 50 epoch
rmse loss on training set is 0.9294743520880093
rmse loss on test set is 0.9354405517538016
for this epoch using 177.36532974243164 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.391287320176712
  (0, 1680)	3.392877170784298
  (0, 1679)	3.391287320176712
  (0, 1678)	3.391287320176712
  (0, 1677)	3.391287320176712
  (0, 1676)	3.391287320176712
  (0, 1675)	3.391287320176712
  (0, 1674)	3.391287320176712
  (0, 1673)	3.391287320176712
  (0, 1672)	3.391287320176712
  (0, 1671)	3.3762724082469826
  (0, 1670)	3.391287320176712
  (0, 1669)	3.391287320176712
  (0, 1668)	3.391287320176712
  (0, 1667)	3.391287320176712
  (0, 1666)	3.391287320176712
  (0, 1665)	3.391287320176712
  (0, 1664)	3.391287320176712
  (0, 1663)	3.405753288078173
  (0, 1662)	3.391287320176712
  (0, 1661)	3.391287320176712
  (0, 1660)	3.3500351240764052
  (0, 1659)	3.3578788573884584
  (0, 1658)	3.391287320176712
  (0, 1657)	3.391287320176712
  :	:
  (942, 24)	2.970021026154756
  (942, 23)	3.1665894593600137
  (942, 22)	3.5518695590769203
  (942, 21)	3.7176752739126893
  (942, 20)	2.7862840242215934
  (942, 19)	3.155726508443579
  (942, 18)	3.102594693622818
  (942, 17)	3.022474462697916
  (942, 16)	2.8825948995114796
  (942, 15)	3.0009731326099187
  (942, 14)	3.311342782975579
  (942, 13)	3.398090156129712
  (942, 12)	3.0710534669653238
  (942, 11)	3.8677367858651617
  (942, 10)	3.492396442724715
  (942, 9)	3.2499382744211065
  (942, 8)	3.4698823584719714
  (942, 7)	3.641842560217557
  (942, 6)	3.487892406399657
  (942, 5)	3.0577419018247136
  (942, 4)	3.0210386768050252
  (942, 3)	3.2289492200400383
  (942, 2)	2.973955935925376
  (942, 1)	3.019103523620908
  (942, 0)	3.5396033702510716
this is the 51 epoch
rmse loss on training set is 0.9289257562692363
rmse loss on test set is 0.9350333635762867
for this epoch using 174.7892303466797 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.390834121275523
  (0, 1680)	3.3924770296323397
  (0, 1679)	3.390834121275523
  (0, 1678)	3.390834121275523
  (0, 1677)	3.390834121275523
  (0, 1676)	3.390834121275523
  (0, 1675)	3.390834121275523
  (0, 1674)	3.390834121275523
  (0, 1673)	3.390834121275523
  (0, 1672)	3.390834121275523
  (0, 1671)	3.375558944092811
  (0, 1670)	3.390834121275523
  (0, 1669)	3.390834121275523
  (0, 1668)	3.390834121275523
  (0, 1667)	3.390834121275523
  (0, 1666)	3.390834121275523
  (0, 1665)	3.390834121275523
  (0, 1664)	3.390834121275523
  (0, 1663)	3.4055532773296378
  (0, 1662)	3.390834121275523
  (0, 1661)	3.390834121275523
  (0, 1660)	3.3487401387461073
  (0, 1659)	3.3567038893943972
  (0, 1658)	3.390834121275523
  (0, 1657)	3.390834121275523
  :	:
  (942, 24)	2.9689537365100045
  (942, 23)	3.166839537313042
  (942, 22)	3.5552918362396437
  (942, 21)	3.718932277627968
  (942, 20)	2.7829382083840897
  (942, 19)	3.1573999501124397
  (942, 18)	3.103937110197498
  (942, 17)	3.0228588545753445
  (942, 16)	2.8807117295777487
  (942, 15)	3.000823130022279
  (942, 14)	3.3123147243960886
  (942, 13)	3.4014709548447093
  (942, 12)	3.0708013963159693
  (942, 11)	3.870052481513424
  (942, 10)	3.4934135093599648
  (942, 9)	3.2528323319206423
  (942, 8)	3.4716751123401397
  (942, 7)	3.644051371581042
  (942, 6)	3.488357189523777
  (942, 5)	3.058805472865655
  (942, 4)	3.0208230808332077
  (942, 3)	3.228959713697771
  (942, 2)	2.9732429972463574
  (942, 1)	3.0185614749407526
  (942, 0)	3.540029260381277
this is the 52 epoch
rmse loss on training set is 0.9283925071839716
rmse loss on test set is 0.93463930832764
for this epoch using 177.78298544883728 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3903898596619513
  (0, 1680)	3.3920861683911503
  (0, 1679)	3.3903898596619513
  (0, 1678)	3.3903898596619513
  (0, 1677)	3.3903898596619513
  (0, 1676)	3.3903898596619513
  (0, 1675)	3.3903898596619513
  (0, 1674)	3.3903898596619513
  (0, 1673)	3.3903898596619513
  (0, 1672)	3.3903898596619513
  (0, 1671)	3.3748550102359123
  (0, 1670)	3.3903898596619513
  (0, 1669)	3.3903898596619513
  (0, 1668)	3.3903898596619513
  (0, 1667)	3.3903898596619513
  (0, 1666)	3.3903898596619513
  (0, 1665)	3.3903898596619513
  (0, 1664)	3.3903898596619513
  (0, 1663)	3.405361603660363
  (0, 1662)	3.3903898596619513
  (0, 1661)	3.3903898596619513
  (0, 1660)	3.3474543381851967
  (0, 1659)	3.3555388270310855
  (0, 1658)	3.3903898596619513
  (0, 1657)	3.3903898596619513
  :	:
  (942, 24)	2.9679391855838073
  (942, 23)	3.167075178181957
  (942, 22)	3.558617995832408
  (942, 21)	3.720119922325455
  (942, 20)	2.779642418687132
  (942, 19)	3.1590578506918616
  (942, 18)	3.105274302832532
  (942, 17)	3.023244605882813
  (942, 16)	2.8788584145243306
  (942, 15)	3.0006781962933435
  (942, 14)	3.313249705408067
  (942, 13)	3.404785939189197
  (942, 12)	3.070564871800557
  (942, 11)	3.872256212567632
  (942, 10)	3.494380000188248
  (942, 9)	3.255693235793106
  (942, 8)	3.4734021324718696
  (942, 7)	3.6461716995686735
  (942, 6)	3.488790705756923
  (942, 5)	3.0598694006058147
  (942, 4)	3.0206106108851456
  (942, 3)	3.2289720749784365
  (942, 2)	2.9725431779452043
  (942, 1)	3.018033701579877
  (942, 0)	3.540425231997684
this is the 53 epoch
rmse loss on training set is 0.9278738356341135
rmse loss on test set is 0.934257654055547
for this epoch using 170.46354985237122 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.389955142524071
  (0, 1680)	3.3917051777423604
  (0, 1679)	3.389955142524071
  (0, 1678)	3.389955142524071
  (0, 1677)	3.389955142524071
  (0, 1676)	3.389955142524071
  (0, 1675)	3.389955142524071
  (0, 1674)	3.389955142524071
  (0, 1673)	3.389955142524071
  (0, 1672)	3.389955142524071
  (0, 1671)	3.3741611856384672
  (0, 1670)	3.389955142524071
  (0, 1669)	3.389955142524071
  (0, 1668)	3.389955142524071
  (0, 1667)	3.389955142524071
  (0, 1666)	3.389955142524071
  (0, 1665)	3.389955142524071
  (0, 1664)	3.389955142524071
  (0, 1663)	3.4051788897638318
  (0, 1662)	3.389955142524071
  (0, 1661)	3.389955142524071
  (0, 1660)	3.3461783454909524
  (0, 1659)	3.3543842931247996
  (0, 1658)	3.389955142524071
  (0, 1657)	3.389955142524071
  :	:
  (942, 24)	2.9669755644592173
  (942, 23)	3.1672974538643244
  (942, 22)	3.5618516959898154
  (942, 21)	3.7212433342018074
  (942, 20)	2.776396049679082
  (942, 19)	3.160700617098693
  (942, 18)	3.1066064221657306
  (942, 17)	3.023631681653932
  (942, 16)	2.877034509775655
  (942, 15)	3.0005383309595883
  (942, 14)	3.314149759451655
  (942, 13)	3.408036986185061
  (942, 12)	3.0703438523078286
  (942, 11)	3.874354860134964
  (942, 10)	3.495299413020575
  (942, 9)	3.258521610110738
  (942, 8)	3.4750668189550686
  (942, 7)	3.6482084627165627
  (942, 6)	3.4891960691086017
  (942, 5)	3.060933636427615
  (942, 4)	3.0204012669976814
  (942, 3)	3.228986993268768
  (942, 2)	2.9718562409960496
  (942, 1)	3.01752002778235
  (942, 0)	3.5407944449227675
this is the 54 epoch
rmse loss on training set is 0.9273690317499673
rmse loss on test set is 0.9338877287538409
for this epoch using 177.3206329345703 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.389530418074054
  (0, 1680)	3.3913344901591653
  (0, 1679)	3.389530418074054
  (0, 1678)	3.389530418074054
  (0, 1677)	3.389530418074054
  (0, 1676)	3.389530418074054
  (0, 1675)	3.389530418074054
  (0, 1674)	3.389530418074054
  (0, 1673)	3.389530418074054
  (0, 1672)	3.389530418074054
  (0, 1671)	3.373477891948417
  (0, 1670)	3.389530418074054
  (0, 1669)	3.389530418074054
  (0, 1668)	3.389530418074054
  (0, 1667)	3.389530418074054
  (0, 1666)	3.389530418074054
  (0, 1665)	3.389530418074054
  (0, 1664)	3.389530418074054
  (0, 1663)	3.405005598322802
  (0, 1662)	3.389530418074054
  (0, 1661)	3.389530418074054
  (0, 1660)	3.3449126243778142
  (0, 1659)	3.35324074903325
  (0, 1658)	3.389530418074054
  (0, 1657)	3.389530418074054
  :	:
  (942, 24)	2.9660610818105835
  (942, 23)	3.1675073548447843
  (942, 22)	3.564996415937188
  (942, 21)	3.7223072426685717
  (942, 20)	2.7731984893528097
  (942, 19)	3.162328626553462
  (942, 18)	3.107933603498697
  (942, 17)	3.024020046730541
  (942, 16)	2.875239572661344
  (942, 15)	3.0004035247103014
  (942, 14)	3.3150167865499527
  (942, 13)	3.4112258852307127
  (942, 12)	3.070138249618037
  (942, 11)	3.8763548448944753
  (942, 10)	3.4961749853110233
  (942, 9)	3.2613180500709267
  (942, 8)	3.476672361063769
  (942, 7)	3.650166265774629
  (942, 6)	3.4895761125830465
  (942, 5)	3.0619981313188815
  (942, 4)	3.0201950419376917
  (942, 3)	3.229005047440852
  (942, 2)	2.9711819485949302
  (942, 1)	3.0170202583325185
  (942, 0)	3.541139755158483
this is the 55 epoch
rmse loss on training set is 0.926877438977443
rmse loss on test set is 0.9335289141602561
for this epoch using 174.57260060310364 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.38911599834218
  (0, 1680)	3.3909744026680024
  (0, 1679)	3.38911599834218
  (0, 1678)	3.38911599834218
  (0, 1677)	3.38911599834218
  (0, 1676)	3.38911599834218
  (0, 1675)	3.38911599834218
  (0, 1674)	3.38911599834218
  (0, 1673)	3.38911599834218
  (0, 1672)	3.38911599834218
  (0, 1671)	3.37280541620215
  (0, 1670)	3.38911599834218
  (0, 1669)	3.38911599834218
  (0, 1668)	3.38911599834218
  (0, 1667)	3.38911599834218
  (0, 1666)	3.38911599834218
  (0, 1665)	3.38911599834218
  (0, 1664)	3.38911599834218
  (0, 1663)	3.404842054881769
  (0, 1662)	3.38911599834218
  (0, 1661)	3.38911599834218
  (0, 1660)	3.3436575019770216
  (0, 1659)	3.3521085177039116
  (0, 1658)	3.38911599834218
  (0, 1657)	3.38911599834218
  :	:
  (942, 24)	2.9651939698903513
  (942, 23)	3.167705796974474
  (942, 22)	3.5680554672732585
  (942, 21)	3.7233160123791627
  (942, 20)	2.7700491209390172
  (942, 19)	3.1639422292613006
  (942, 18)	3.109255968263636
  (942, 17)	3.0244096659664894
  (942, 16)	2.8734731633381676
  (942, 15)	3.000273760378265
  (942, 14)	3.3158525637168017
  (942, 13)	3.4143543443631024
  (942, 12)	3.0699479346071157
  (942, 11)	3.8782621603407725
  (942, 10)	3.497009714876896
  (942, 9)	3.2640831243595225
  (942, 8)	3.4782217524648336
  (942, 7)	3.652049422028331
  (942, 6)	3.4899334128549726
  (942, 5)	3.0630628361473895
  (942, 4)	3.0199919225331944
  (942, 3)	3.2290267187937687
  (942, 2)	2.9705200632811786
  (942, 1)	3.0165341819262443
  (942, 0)	3.541463743131385
this is the 56 epoch
rmse loss on training set is 0.9263984487902504
rmse loss on test set is 0.9331806403016364
for this epoch using 173.02334189414978 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.388712079199834
  (0, 1680)	3.390625096840027
  (0, 1679)	3.388712079199834
  (0, 1678)	3.388712079199834
  (0, 1677)	3.388712079199834
  (0, 1676)	3.388712079199834
  (0, 1675)	3.388712079199834
  (0, 1674)	3.388712079199834
  (0, 1673)	3.388712079199834
  (0, 1672)	3.388712079199834
  (0, 1671)	3.3721439307594863
  (0, 1670)	3.388712079199834
  (0, 1669)	3.388712079199834
  (0, 1668)	3.388712079199834
  (0, 1667)	3.388712079199834
  (0, 1666)	3.388712079199834
  (0, 1665)	3.388712079199834
  (0, 1664)	3.388712079199834
  (0, 1663)	3.4046884679431515
  (0, 1662)	3.388712079199834
  (0, 1661)	3.388712079199834
  (0, 1660)	3.342413188861569
  (0, 1659)	3.350987803933016
  (0, 1658)	3.388712079199834
  (0, 1657)	3.388712079199834
  :	:
  (942, 24)	2.9643724895189445
  (942, 23)	3.167893627627
  (942, 22)	3.571032004371521
  (942, 21)	3.724273672536654
  (942, 20)	2.766947324483835
  (942, 19)	3.1655417508388015
  (942, 18)	3.1105736253457414
  (942, 17)	3.0248005043972777
  (942, 16)	2.871734845553536
  (942, 15)	3.0001490138339917
  (942, 14)	3.31665875442735
  (942, 13)	3.417423995966467
  (942, 12)	3.0697727427766375
  (942, 11)	3.880082403428804
  (942, 10)	3.497806378850659
  (942, 9)	3.266817377278698
  (942, 8)	3.4797178051844773
  (942, 7)	3.653861973869523
  (942, 6)	3.490270312745736
  (942, 5)	3.0641277018951865
  (942, 4)	3.019791890808034
  (942, 3)	3.2290524025982776
  (942, 2)	2.969870348872818
  (942, 1)	3.0160615741188224
  (942, 0)	3.5417687393127766
this is the 57 epoch
rmse loss on training set is 0.9259314960283608
rmse loss on test set is 0.9328423806858714
for this epoch using 173.27772688865662 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3883187579223533
  (0, 1680)	3.3902866563237106
  (0, 1679)	3.3883187579223533
  (0, 1678)	3.3883187579223533
  (0, 1677)	3.3883187579223533
  (0, 1676)	3.3883187579223533
  (0, 1675)	3.3883187579223533
  (0, 1674)	3.3883187579223533
  (0, 1673)	3.3883187579223533
  (0, 1672)	3.3883187579223533
  (0, 1671)	3.371493510782337
  (0, 1670)	3.3883187579223533
  (0, 1669)	3.3883187579223533
  (0, 1668)	3.3883187579223533
  (0, 1667)	3.3883187579223533
  (0, 1666)	3.3883187579223533
  (0, 1665)	3.3883187579223533
  (0, 1664)	3.3883187579223533
  (0, 1663)	3.404544946598655
  (0, 1662)	3.3883187579223533
  (0, 1661)	3.3883187579223533
  (0, 1660)	3.3411797966086403
  (0, 1659)	3.349878712139696
  (0, 1658)	3.3883187579223533
  (0, 1657)	3.3883187579223533
  :	:
  (942, 24)	2.963594934201353
  (942, 23)	3.1680716312927566
  (942, 22)	3.573929033978645
  (942, 21)	3.725183943724074
  (942, 20)	2.763892478235467
  (942, 19)	3.167127494511735
  (942, 18)	3.1118866722758725
  (942, 17)	3.0251925273800344
  (942, 16)	2.8700241872725503
  (942, 15)	3.000029254792946
  (942, 14)	3.3174369172438207
  (942, 13)	3.420436401980436
  (942, 12)	3.069612479180746
  (942, 11)	3.8818208028372756
  (942, 10)	3.498567551023451
  (942, 9)	3.2695213306647597
  (942, 8)	3.481163162444136
  (942, 7)	3.655607711763914
  (942, 6)	3.490588941701473
  (942, 5)	3.065192679857459
  (942, 4)	3.019594924946301
  (942, 3)	3.229082418391527
  (942, 2)	2.9692325712412364
  (942, 1)	3.0156021998994103
  (942, 0)	3.542056847459762
this is the 58 epoch
rmse loss on training set is 0.9254760547786206
rmse loss on test set is 0.9325136480547023
for this epoch using 171.24225497245789 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3879360485701278
  (0, 1680)	3.3899590821966368
  (0, 1679)	3.3879360485701278
  (0, 1678)	3.3879360485701278
  (0, 1677)	3.3879360485701278
  (0, 1676)	3.3879360485701278
  (0, 1675)	3.3879360485701278
  (0, 1674)	3.3879360485701278
  (0, 1673)	3.3879360485701278
  (0, 1672)	3.3879360485701278
  (0, 1671)	3.370854149535198
  (0, 1670)	3.3879360485701278
  (0, 1669)	3.3879360485701278
  (0, 1668)	3.3879360485701278
  (0, 1667)	3.3879360485701278
  (0, 1666)	3.3879360485701278
  (0, 1665)	3.3879360485701278
  (0, 1664)	3.3879360485701278
  (0, 1663)	3.4044115159741275
  (0, 1662)	3.3879360485701278
  (0, 1661)	3.3879360485701278
  (0, 1660)	3.3399573531785576
  (0, 1659)	3.34878126193588
  (0, 1658)	3.3879360485701278
  (0, 1657)	3.3879360485701278
  :	:
  (942, 24)	2.9628596334800044
  (942, 23)	3.1682405346669107
  (942, 22)	3.5767494240815485
  (942, 21)	3.7260502624770053
  (942, 20)	2.7608839598618324
  (942, 19)	3.1686997431057846
  (942, 18)	3.113195196306921
  (942, 17)	3.0255857007081457
  (942, 16)	2.868340761187647
  (942, 15)	2.999914447544098
  (942, 14)	3.3181885136788942
  (942, 13)	3.4233930586551713
  (942, 12)	3.069466922813981
  (942, 11)	3.8834822450494233
  (942, 10)	3.499295617725062
  (942, 9)	3.2721954856185014
  (942, 8)	3.4825603104653498
  (942, 7)	3.6572901917502896
  (942, 6)	3.4908912344559453
  (942, 5)	3.0662577218103118
  (942, 4)	3.0194010001092235
  (942, 3)	3.229117019153377
  (942, 2)	2.9686064989470724
  (942, 1)	3.0151558159361675
  (942, 0)	3.542329965700454
this is the 59 epoch
rmse loss on training set is 0.9250316347261984
rmse loss on test set is 0.9321939906239066
for this epoch using 176.38538122177124 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3875638954360636
  (0, 1680)	3.3896423063846988
  (0, 1679)	3.3875638954360636
  (0, 1678)	3.3875638954360636
  (0, 1677)	3.3875638954360636
  (0, 1676)	3.3875638954360636
  (0, 1675)	3.3875638954360636
  (0, 1674)	3.3875638954360636
  (0, 1673)	3.3875638954360636
  (0, 1672)	3.3875638954360636
  (0, 1671)	3.3702257717558752
  (0, 1670)	3.3875638954360636
  (0, 1669)	3.3875638954360636
  (0, 1668)	3.3875638954360636
  (0, 1667)	3.3875638954360636
  (0, 1666)	3.3875638954360636
  (0, 1665)	3.3875638954360636
  (0, 1664)	3.3875638954360636
  (0, 1663)	3.4042881307362824
  (0, 1662)	3.3875638954360636
  (0, 1661)	3.3875638954360636
  (0, 1660)	3.3387458163590695
  (0, 1659)	3.347695401742847
  (0, 1658)	3.3875638954360636
  (0, 1657)	3.3875638954360636
  :	:
  (942, 24)	2.9621649556207625
  (942, 23)	3.168401011280731
  (942, 22)	3.5794959121074394
  (942, 21)	3.7268758037983294
  (942, 20)	2.7579211475185623
  (942, 19)	3.170258760850404
  (942, 18)	3.114499275385541
  (942, 17)	3.025979990703844
  (942, 16)	2.866684145127516
  (942, 15)	2.999804551607393
  (942, 14)	3.3189149153713964
  (942, 13)	3.42629540089649
  (942, 12)	3.069335830516801
  (942, 11)	3.8850712984326687
  (942, 10)	3.499992792371633
  (942, 9)	3.2748403240683444
  (942, 8)	3.4839115893341206
  (942, 7)	3.658912751594444
  (942, 6)	3.491178948043599
  (942, 5)	3.0673227801511587
  (942, 4)	3.019210089124587
  (942, 3)	3.2291563994823815
  (942, 2)	2.9679919037566354
  (942, 1)	3.0147221725310245
  (942, 0)	3.542589805665058
this is the 60 epoch
rmse loss on training set is 0.9245977779153022
rmse loss on test set is 0.9318829887479241
for this epoch using 173.73255062103271 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3872021847811413
  (0, 1680)	3.389336203370517
  (0, 1679)	3.3872021847811413
  (0, 1678)	3.3872021847811413
  (0, 1677)	3.3872021847811413
  (0, 1676)	3.3872021847811413
  (0, 1675)	3.3872021847811413
  (0, 1674)	3.3872021847811413
  (0, 1673)	3.3872021847811413
  (0, 1672)	3.3872021847811413
  (0, 1671)	3.3696082453179725
  (0, 1670)	3.3872021847811413
  (0, 1669)	3.3872021847811413
  (0, 1668)	3.3872021847811413
  (0, 1667)	3.3872021847811413
  (0, 1666)	3.3872021847811413
  (0, 1665)	3.3872021847811413
  (0, 1664)	3.3872021847811413
  (0, 1663)	3.4041746868833482
  (0, 1662)	3.3872021847811413
  (0, 1661)	3.3872021847811413
  (0, 1660)	3.3375450854973114
  (0, 1659)	3.346621020678107
  (0, 1658)	3.3872021847811413
  (0, 1657)	3.3872021847811413
  :	:
  (942, 24)	2.9615093097179095
  (942, 23)	3.168553685720708
  (942, 22)	3.5821711125154407
  (942, 21)	3.727663501796391
  (942, 20)	2.755003420784496
  (942, 19)	3.1718047950140718
  (942, 18)	3.1157989790302048
  (942, 17)	3.0263753642920594
  (942, 16)	2.8650539223797162
  (942, 15)	2.9996995223270164
  (942, 14)	3.3196174106406624
  (942, 13)	3.429144806239898
  (942, 12)	3.069218940449919
  (942, 11)	3.8865922354825386
  (942, 10)	3.5006611288003193
  (942, 9)	3.27745631018394
  (942, 8)	3.4852192030069724
  (942, 7)	3.6604785257101184
  (942, 6)	3.491453677313116
  (942, 5)	3.06838780801517
  (942, 4)	3.0190221630660266
  (942, 3)	3.2292007028771126
  (942, 2)	2.9673885610555244
  (942, 1)	3.014301015318595
  (942, 0)	3.54283790984593
this is the 61 epoch
rmse loss on training set is 0.9241740558669129
rmse loss on test set is 0.9315802519548959
for this epoch using 173.17558598518372 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.386850755055553
  (0, 1680)	3.3890406003884195
  (0, 1679)	3.386850755055553
  (0, 1678)	3.386850755055553
  (0, 1677)	3.386850755055553
  (0, 1676)	3.386850755055553
  (0, 1675)	3.386850755055553
  (0, 1674)	3.386850755055553
  (0, 1673)	3.386850755055553
  (0, 1672)	3.386850755055553
  (0, 1671)	3.369001391382747
  (0, 1670)	3.386850755055553
  (0, 1669)	3.386850755055553
  (0, 1668)	3.386850755055553
  (0, 1667)	3.386850755055553
  (0, 1666)	3.386850755055553
  (0, 1665)	3.386850755055553
  (0, 1664)	3.386850755055553
  (0, 1663)	3.4040710320172254
  (0, 1662)	3.386850755055553
  (0, 1661)	3.386850755055553
  (0, 1660)	3.3363550117172243
  (0, 1659)	3.345557958912093
  (0, 1658)	3.386850755055553
  (0, 1657)	3.386850755055553
  :	:
  (942, 24)	2.96089114729398
  (942, 23)	3.1686991374754374
  (942, 22)	3.584777523832621
  (942, 21)	3.7284160686115566
  (942, 20)	2.7521301614797733
  (942, 19)	3.1733380773870907
  (942, 18)	3.117094369124796
  (942, 17)	3.026771789058125
  (942, 16)	2.8634496819396134
  (942, 15)	2.999599311406565
  (942, 14)	3.320297210479656
  (942, 13)	3.4319425984885115
  (942, 12)	3.0691159751829793
  (942, 11)	3.8880490533824026
  (942, 10)	3.501302533498801
  (942, 9)	3.280043891656192
  (942, 8)	3.486485228533411
  (942, 7)	3.6619904589494996
  (942, 6)	3.491716869077583
  (942, 5)	3.0694527593707903
  (942, 4)	3.018837191737382
  (942, 3)	3.2292500282173613
  (942, 2)	2.9667962501740215
  (942, 1)	3.013892086739796
  (942, 0)	3.5430756673523915
this is the 62 epoch
rmse loss on training set is 0.9237600670086336
rmse loss on test set is 0.9312854163056198
for this epoch using 170.81480288505554 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.386509405781584
  (0, 1680)	3.3887552862821697
  (0, 1679)	3.386509405781584
  (0, 1678)	3.386509405781584
  (0, 1677)	3.386509405781584
  (0, 1676)	3.386509405781584
  (0, 1675)	3.386509405781584
  (0, 1674)	3.386509405781584
  (0, 1673)	3.386509405781584
  (0, 1672)	3.386509405781584
  (0, 1671)	3.36840499321629
  (0, 1670)	3.386509405781584
  (0, 1669)	3.386509405781584
  (0, 1668)	3.386509405781584
  (0, 1667)	3.386509405781584
  (0, 1666)	3.386509405781584
  (0, 1665)	3.386509405781584
  (0, 1664)	3.386509405781584
  (0, 1663)	3.40397697427357
  (0, 1662)	3.386509405781584
  (0, 1661)	3.386509405781584
  (0, 1660)	3.3351754067989736
  (0, 1659)	3.344506016672582
  (0, 1658)	3.386509405781584
  (0, 1657)	3.386509405781584
  :	:
  (942, 24)	2.960308963461356
  (942, 23)	3.16883790444617
  (942, 22)	3.587317535182399
  (942, 21)	3.7291360117807755
  (942, 20)	2.7493007543800014
  (942, 19)	3.1748588256268246
  (942, 18)	3.1183855006365007
  (942, 17)	3.02716923329181
  (942, 16)	2.861871018696488
  (942, 15)	2.999503867391697
  (942, 14)	3.3209554540405484
  (942, 13)	3.4346900510465534
  (942, 12)	3.0690266444382286
  (942, 11)	3.8894454930165585
  (942, 10)	3.5019187768277265
  (942, 9)	3.2826035008576673
  (942, 8)	3.4877116245625337
  (942, 7)	3.6634513193568368
  (942, 6)	3.491969835024484
  (942, 5)	3.070517589096953
  (942, 4)	3.018655144075416
  (942, 3)	3.229304435530051
  (942, 2)	2.966214754637104
  (942, 1)	3.013495127316967
  (942, 0)	3.5433043282102568
this is the 63 epoch
rmse loss on training set is 0.9233554343775491
rmse loss on test set is 0.9309981420363955
for this epoch using 169.83253288269043 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3861779052549075
  (0, 1680)	3.388480019182089
  (0, 1679)	3.3861779052549075
  (0, 1678)	3.3861779052549075
  (0, 1677)	3.3861779052549075
  (0, 1676)	3.3861779052549075
  (0, 1675)	3.3861779052549075
  (0, 1674)	3.3861779052549075
  (0, 1673)	3.3861779052549075
  (0, 1672)	3.3861779052549075
  (0, 1671)	3.3678188038286168
  (0, 1670)	3.3861779052549075
  (0, 1669)	3.3861779052549075
  (0, 1668)	3.3861779052549075
  (0, 1667)	3.3861779052549075
  (0, 1666)	3.3861779052549075
  (0, 1665)	3.3861779052549075
  (0, 1664)	3.3861779052549075
  (0, 1663)	3.4038922900667306
  (0, 1662)	3.3861779052549075
  (0, 1661)	3.3861779052549075
  (0, 1660)	3.334006050877309
  (0, 1659)	3.343464962054867
  (0, 1658)	3.3861779052549075
  (0, 1657)	3.3861779052549075
  :	:
  (942, 24)	2.9597612977050307
  (942, 23)	3.1689704861531207
  (942, 22)	3.5897934323486695
  (942, 21)	3.7298256501764593
  (942, 20)	2.7465145878381594
  (942, 19)	3.1763672444785462
  (942, 18)	3.1196724222655683
  (942, 17)	3.0275676660195776
  (942, 16)	2.8603175335662874
  (942, 15)	2.999413136105315
  (942, 14)	3.3215932136610564
  (942, 13)	3.43738838997703
  (942, 12)	3.0689506475257704
  (942, 11)	3.890785056563155
  (942, 10)	3.502511503324828
  (942, 9)	3.2851355558959576
  (942, 8)	3.4889002391953534
  (942, 7)	3.6648637099703625
  (942, 6)	3.492213763497682
  (942, 5)	3.0715822530442765
  (942, 4)	3.0184759884824106
  (942, 3)	3.229363951115751
  (942, 2)	2.9656438623500074
  (942, 1)	3.0131098767544278
  (942, 0)	3.543525016341898
this is the 64 epoch
rmse loss on training set is 0.9229598035631702
rmse loss on test set is 0.9307181114511743
for this epoch using 176.5005612373352 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3858559972037776
  (0, 1680)	3.3882145331410936
  (0, 1679)	3.3858559972037776
  (0, 1678)	3.3858559972037776
  (0, 1677)	3.3858559972037776
  (0, 1676)	3.3858559972037776
  (0, 1675)	3.3858559972037776
  (0, 1674)	3.3858559972037776
  (0, 1673)	3.3858559972037776
  (0, 1672)	3.3858559972037776
  (0, 1671)	3.3672425525741905
  (0, 1670)	3.3858559972037776
  (0, 1669)	3.3858559972037776
  (0, 1668)	3.3858559972037776
  (0, 1667)	3.3858559972037776
  (0, 1666)	3.3858559972037776
  (0, 1665)	3.3858559972037776
  (0, 1664)	3.3858559972037776
  (0, 1663)	3.4038167307892615
  (0, 1662)	3.3858559972037776
  (0, 1661)	3.3858559972037776
  (0, 1660)	3.3328466990985004
  (0, 1659)	3.3424345377787397
  (0, 1658)	3.3858559972037776
  (0, 1657)	3.3858559972037776
  :	:
  (942, 24)	2.959246734338494
  (942, 23)	3.169097346666549
  (942, 22)	3.592207403415125
  (942, 21)	3.73048712864314
  (942, 20)	2.743771054324935
  (942, 19)	3.177863526883977
  (942, 18)	3.1209551770337667
  (942, 17)	3.027967057027014
  (942, 16)	2.858788833579277
  (942, 15)	2.9993270610397156
  (942, 14)	3.322211499474909
  (942, 13)	3.440038796809208
  (942, 12)	3.068887675502803
  (942, 11)	3.8920710237815723
  (942, 10)	3.5030822411713127
  (942, 9)	3.287640461571107
  (942, 8)	3.490052817238992
  (942, 7)	3.6662300797504863
  (942, 6)	3.492449730252646
  (942, 5)	3.072646708082576
  (942, 4)	3.018299693098657
  (942, 3)	3.229428572103532
  (942, 2)	2.9650833657290336
  (942, 1)	3.0127360748854746
  (942, 0)	3.5437387413500394
this is the 65 epoch
rmse loss on training set is 0.9225728408612576
rmse loss on test set is 0.9304450270329871
for this epoch using 183.66705965995789 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.385543406530099
  (0, 1680)	3.387958543853476
  (0, 1679)	3.385543406530099
  (0, 1678)	3.385543406530099
  (0, 1677)	3.385543406530099
  (0, 1676)	3.385543406530099
  (0, 1675)	3.385543406530099
  (0, 1674)	3.385543406530099
  (0, 1673)	3.385543406530099
  (0, 1672)	3.385543406530099
  (0, 1671)	3.3666759508375437
  (0, 1670)	3.385543406530099
  (0, 1669)	3.385543406530099
  (0, 1668)	3.385543406530099
  (0, 1667)	3.385543406530099
  (0, 1666)	3.385543406530099
  (0, 1665)	3.385543406530099
  (0, 1664)	3.385543406530099
  (0, 1663)	3.4037500285900806
  (0, 1662)	3.385543406530099
  (0, 1661)	3.385543406530099
  (0, 1660)	3.33169708735994
  (0, 1659)	3.341414467017301
  (0, 1658)	3.385543406530099
  (0, 1657)	3.385543406530099
  :	:
  (942, 24)	2.9587639026790553
  (942, 23)	3.1692189172885255
  (942, 22)	3.594561544015185
  (942, 21)	3.7311224314443603
  (942, 20)	2.7410695508966114
  (942, 19)	3.1793478549881242
  (942, 18)	3.122233802817688
  (942, 17)	3.028367376872826
  (942, 16)	2.857284531929565
  (942, 15)	2.999245583709957
  (942, 14)	3.3228112636455305
  (942, 13)	3.4426424111193503
  (942, 12)	3.0688374130861686
  (942, 11)	3.8933064670996886
  (942, 10)	3.503632410893776
  (942, 9)	3.2901186102468993
  (942, 8)	3.491171006913258
  (942, 7)	3.667552733705309
  (942, 6)	3.492678708277053
  (942, 5)	3.073710912136181
  (942, 4)	3.0181262260235924
  (942, 3)	3.2294982704951685
  (942, 2)	2.964533061785984
  (942, 1)	3.0123734624843306
  (942, 0)	3.5439464092164967
this is the 66 epoch
rmse loss on training set is 0.9221942316137414
rmse loss on test set is 0.9301786097488352
for this epoch using 182.58311772346497 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3852398442427107
  (0, 1680)	3.387711753566826
  (0, 1679)	3.3852398442427107
  (0, 1678)	3.3852398442427107
  (0, 1677)	3.3852398442427107
  (0, 1676)	3.3852398442427107
  (0, 1675)	3.3852398442427107
  (0, 1674)	3.3852398442427107
  (0, 1673)	3.3852398442427107
  (0, 1672)	3.3852398442427107
  (0, 1671)	3.3661186969142713
  (0, 1670)	3.3852398442427107
  (0, 1669)	3.3852398442427107
  (0, 1668)	3.3852398442427107
  (0, 1667)	3.3852398442427107
  (0, 1666)	3.3852398442427107
  (0, 1665)	3.3852398442427107
  (0, 1664)	3.3852398442427107
  (0, 1663)	3.4036919013419746
  (0, 1662)	3.3852398442427107
  (0, 1661)	3.3852398442427107
  (0, 1660)	3.330556937242845
  (0, 1659)	3.340404458409019
  (0, 1658)	3.3852398442427107
  (0, 1657)	3.3852398442427107
  :	:
  (942, 24)	2.9583114769829835
  (942, 23)	3.1693355990087837
  (942, 22)	3.5968578622251433
  (942, 21)	3.731733394622228
  (942, 20)	2.738409479598756
  (942, 19)	3.1808204010543832
  (942, 18)	3.1235083328324658
  (942, 17)	3.028768596895915
  (942, 16)	2.855804247992782
  (942, 15)	2.999168643971874
  (942, 14)	3.323393404257913
  (942, 13)	3.445200332905583
  (942, 12)	3.068799540344092
  (942, 11)	3.8944942655969137
  (942, 10)	3.5041633333678206
  (942, 9)	3.2925703826449144
  (942, 8)	3.492256366056212
  (942, 7)	3.6688338422782345
  (942, 6)	3.4929015767602114
  (942, 5)	3.0747748242090656
  (942, 4)	3.0179555554932014
  (942, 3)	3.2295729967529327
  (942, 2)	2.963992752173353
  (942, 1)	3.012021781959568
  (942, 0)	3.544148832016791
this is the 67 epoch
rmse loss on training set is 0.9218236787129368
rmse loss on test set is 0.9299185975253637
for this epoch using 175.78843092918396 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3849450116805397
  (0, 1680)	3.3874738552847266
  (0, 1679)	3.3849450116805397
  (0, 1678)	3.3849450116805397
  (0, 1677)	3.3849450116805397
  (0, 1676)	3.3849450116805397
  (0, 1675)	3.3849450116805397
  (0, 1674)	3.3849450116805397
  (0, 1673)	3.3849450116805397
  (0, 1672)	3.3849450116805397
  (0, 1671)	3.3655704801849766
  (0, 1670)	3.3849450116805397
  (0, 1669)	3.3849450116805397
  (0, 1668)	3.3849450116805397
  (0, 1667)	3.3849450116805397
  (0, 1666)	3.3849450116805397
  (0, 1665)	3.3849450116805397
  (0, 1664)	3.3849450116805397
  (0, 1663)	3.4036420568961616
  (0, 1662)	3.3849450116805397
  (0, 1661)	3.3849450116805397
  (0, 1660)	3.329425960235775
  (0, 1659)	3.3394042103517214
  (0, 1658)	3.3849450116805397
  (0, 1657)	3.3849450116805397
  :	:
  (942, 24)	2.957888176176304
  (942, 23)	3.169447764755635
  (942, 22)	3.599098283129566
  (942, 21)	3.7323217173623084
  (942, 20)	2.73579024781306
  (942, 19)	3.1822813282963938
  (942, 18)	3.1247787960706486
  (942, 17)	3.0291706892164876
  (942, 16)	2.854347607317043
  (942, 15)	2.99909618030838
  (942, 14)	3.323958768900282
  (942, 13)	3.447713624775855
  (942, 12)	3.0687737341905232
  (942, 11)	3.895637117970714
  (942, 10)	3.504676237183802
  (942, 9)	3.294996148569113
  (942, 8)	3.49331036787035
  (942, 7)	3.6700754500570363
  (942, 6)	3.4931191292871193
  (942, 5)	3.0758384044008946
  (942, 4)	3.0177876500201943
  (942, 3)	3.2296526829797205
  (942, 2)	2.9634622431967075
  (942, 1)	3.0116807779433983
  (942, 0)	3.5443467367419994
this is the 68 epoch
rmse loss on training set is 0.9214609012513155
rmse loss on test set is 0.929664743875765
for this epoch using 175.70884537696838 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3846586041124387
  (0, 1680)	3.387244536346978
  (0, 1679)	3.3846586041124387
  (0, 1678)	3.3846586041124387
  (0, 1677)	3.3846586041124387
  (0, 1676)	3.3846586041124387
  (0, 1675)	3.3846586041124387
  (0, 1674)	3.3846586041124387
  (0, 1673)	3.3846586041124387
  (0, 1672)	3.3846586041124387
  (0, 1671)	3.365030984668849
  (0, 1670)	3.3846586041124387
  (0, 1669)	3.3846586041124387
  (0, 1668)	3.3846586041124387
  (0, 1667)	3.3846586041124387
  (0, 1666)	3.3846586041124387
  (0, 1665)	3.3846586041124387
  (0, 1664)	3.3846586041124387
  (0, 1663)	3.403600196711115
  (0, 1662)	3.3846586041124387
  (0, 1661)	3.3846586041124387
  (0, 1660)	3.328303861335817
  (0, 1659)	3.3384134146661477
  (0, 1658)	3.3846586041124387
  (0, 1657)	3.3846586041124387
  :	:
  (942, 24)	2.9574927634125485
  (942, 23)	3.169555761460925
  (942, 22)	3.601284653085829
  (942, 21)	3.7328889724486722
  (942, 20)	2.7332112685537178
  (942, 19)	3.183730791634809
  (942, 18)	3.1260452177008275
  (942, 17)	3.029573626732368
  (942, 16)	2.8529142415918844
  (942, 15)	2.9990281300867823
  (942, 14)	3.3245081579638738
  (942, 13)	3.450183313966161
  (942, 12)	3.068759669702942
  (942, 11)	3.896737554567049
  (942, 10)	3.5051722654294144
  (942, 9)	3.297396267567932
  (942, 8)	3.494334406247918
  (942, 7)	3.671279483858347
  (942, 6)	3.4933320813258524
  (942, 5)	3.07690161391551
  (942, 4)	3.0176224785027244
  (942, 3)	3.2297372457350755
  (942, 2)	2.9629413457996407
  (942, 1)	3.011350197789658
  (942, 0)	3.544540773310523
this is the 69 epoch
rmse loss on training set is 0.9211056333002865
rmse loss on test set is 0.9294168166607518
for this epoch using 172.96832823753357 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.384380313790885
  (0, 1680)	3.387023481464468
  (0, 1679)	3.384380313790885
  (0, 1678)	3.384380313790885
  (0, 1677)	3.384380313790885
  (0, 1676)	3.384380313790885
  (0, 1675)	3.384380313790885
  (0, 1674)	3.384380313790885
  (0, 1673)	3.384380313790885
  (0, 1672)	3.384380313790885
  (0, 1671)	3.364499892033688
  (0, 1670)	3.384380313790885
  (0, 1669)	3.384380313790885
  (0, 1668)	3.384380313790885
  (0, 1667)	3.384380313790885
  (0, 1666)	3.384380313790885
  (0, 1665)	3.384380313790885
  (0, 1664)	3.384380313790885
  (0, 1663)	3.4035660189326804
  (0, 1662)	3.384380313790885
  (0, 1661)	3.384380313790885
  (0, 1660)	3.3271903421044637
  (0, 1659)	3.3374317597069103
  (0, 1658)	3.384380313790885
  (0, 1657)	3.384380313790885
  :	:
  (942, 24)	2.957124045485154
  (942, 23)	3.1696599119559976
  (942, 22)	3.6034187437117344
  (942, 21)	3.7334366158859713
  (942, 20)	2.730671960719048
  (942, 19)	3.1851689383858806
  (942, 18)	3.1273076194298737
  (942, 17)	3.029977383111297
  (942, 16)	2.851503788598975
  (942, 15)	2.9989644297900635
  (942, 14)	3.325042327686489
  (942, 13)	3.4526103942043753
  (942, 12)	3.068757021282222
  (942, 11)	3.897797948547986
  (942, 10)	3.505652481938772
  (942, 9)	3.299771089540087
  (942, 8)	3.495329800709947
  (942, 7)	3.6724477602372017
  (942, 6)	3.49354107707081
  (942, 5)	3.0779644150628065
  (942, 4)	3.017460010306517
  (942, 3)	3.229826588526124
  (942, 2)	2.962429875525929
  (942, 1)	3.0110297919918145
  (942, 0)	3.5447315218446733
this is the 70 epoch
rmse loss on training set is 0.920757622803703
rmse loss on test set is 0.9291745969686026
for this epoch using 173.522465467453 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.384109832527455
  (0, 1680)	3.3868103752767036
  (0, 1679)	3.384109832527455
  (0, 1678)	3.384109832527455
  (0, 1677)	3.384109832527455
  (0, 1676)	3.384109832527455
  (0, 1675)	3.384109832527455
  (0, 1674)	3.384109832527455
  (0, 1673)	3.384109832527455
  (0, 1672)	3.384109832527455
  (0, 1671)	3.36397688413052
  (0, 1670)	3.384109832527455
  (0, 1669)	3.384109832527455
  (0, 1668)	3.384109832527455
  (0, 1667)	3.384109832527455
  (0, 1666)	3.384109832527455
  (0, 1665)	3.384109832527455
  (0, 1664)	3.384109832527455
  (0, 1663)	3.4035392209939723
  (0, 1662)	3.384109832527455
  (0, 1661)	3.384109832527455
  (0, 1660)	3.326085103246361
  (0, 1659)	3.336458932989594
  (0, 1658)	3.384109832527455
  (0, 1657)	3.384109832527455
  :	:
  (942, 24)	2.9567808721186135
  (942, 23)	3.1697605167140206
  (942, 22)	3.605502255618355
  (942, 21)	3.733965995758815
  (942, 20)	2.72817174930356
  (942, 19)	3.186595908888457
  (942, 18)	3.1285660198323417
  (942, 17)	3.030381932779958
  (942, 16)	2.850115892148134
  (942, 15)	2.9989050152244543
  (942, 14)	3.325561992962743
  (942, 13)	3.4549958274337595
  (942, 12)	3.068765463671347
  (942, 11)	3.8988205262637967
  (942, 10)	3.506117877053256
  (942, 9)	3.3021209552896793
  (942, 8)	3.4962978009906776
  (942, 7)	3.673581992466589
  (942, 6)	3.4937466956985013
  (942, 5)	3.0790267712551267
  (942, 4)	3.017300215324753
  (942, 3)	3.229920604008246
  (942, 2)	2.9619276524630793
  (942, 1)	3.0107193145308737
  (942, 0)	3.544919499280019
this is the 71 epoch
rmse loss on training set is 0.9204166305735597
rmse loss on test set is 0.9289378781012787
for this epoch using 172.11670660972595 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3838468538506676
  (0, 1680)	3.386604904492336
  (0, 1679)	3.3838468538506676
  (0, 1678)	3.3838468538506676
  (0, 1677)	3.3838468538506676
  (0, 1676)	3.3838468538506676
  (0, 1675)	3.3838468538506676
  (0, 1674)	3.3838468538506676
  (0, 1673)	3.3838468538506676
  (0, 1672)	3.3838468538506676
  (0, 1671)	3.3634616451129213
  (0, 1670)	3.3838468538506676
  (0, 1669)	3.3838468538506676
  (0, 1668)	3.3838468538506676
  (0, 1667)	3.3838468538506676
  (0, 1666)	3.3838468538506676
  (0, 1665)	3.3838468538506676
  (0, 1664)	3.3838468538506676
  (0, 1663)	3.4035195017954476
  (0, 1662)	3.3838468538506676
  (0, 1661)	3.3838468538506676
  (0, 1660)	3.3249878467710885
  (0, 1659)	3.3354946233950016
  (0, 1658)	3.3838468538506676
  (0, 1657)	3.3838468538506676
  :	:
  (942, 24)	2.9564621351596103
  (942, 23)	3.1698578554525607
  (942, 22)	3.607536821907948
  (942, 21)	3.7344783603920235
  (942, 20)	2.725710065574819
  (942, 19)	3.188011837075061
  (942, 18)	3.1298204346502505
  (942, 17)	3.0307872509104157
  (942, 16)	2.848750202001319
  (942, 15)	2.998849821705515
  (942, 14)	3.3260678299418096
  (942, 13)	3.4573405454086283
  (942, 12)	3.0687846728478134
  (942, 11)	3.8998073768909944
  (942, 10)	3.5065693729352483
  (942, 9)	3.3044461970355314
  (942, 8)	3.4972395912962355
  (942, 7)	3.6746837970286
  (942, 6)	3.4939494570873593
  (942, 5)	3.080088646998845
  (942, 4)	3.017143064019308
  (942, 3)	3.2300191759267856
  (942, 2)	2.961434501170677
  (942, 1)	3.0104185231620635
  (942, 0)	3.545105165368946
this is the 72 epoch
rmse loss on training set is 0.9200824293767476
rmse loss on test set is 0.9287064646549613
for this epoch using 172.62557005882263 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3835910747994187
  (0, 1680)	3.386406759666178
  (0, 1679)	3.3835910747994187
  (0, 1678)	3.3835910747994187
  (0, 1677)	3.3835910747994187
  (0, 1676)	3.3835910747994187
  (0, 1675)	3.3835910747994187
  (0, 1674)	3.3835910747994187
  (0, 1673)	3.3835910747994187
  (0, 1672)	3.3835910747994187
  (0, 1671)	3.3629538631944227
  (0, 1670)	3.3835910747994187
  (0, 1669)	3.3835910747994187
  (0, 1668)	3.3835910747994187
  (0, 1667)	3.3835910747994187
  (0, 1666)	3.3835910747994187
  (0, 1665)	3.3835910747994187
  (0, 1664)	3.3835910747994187
  (0, 1663)	3.4035065635187816
  (0, 1662)	3.3835910747994187
  (0, 1661)	3.3835910747994187
  (0, 1660)	3.3238982777915798
  (0, 1659)	3.334538523004536
  (0, 1658)	3.3835910747994187
  (0, 1657)	3.3835910747994187
  :	:
  (942, 24)	2.956166767686724
  (942, 23)	3.1699521886088657
  (942, 22)	3.6095240114552394
  (942, 21)	3.7349748658703126
  (942, 20)	2.723286347219204
  (942, 19)	3.189416850992344
  (942, 18)	3.1310708770660107
  (942, 17)	3.0311933134044167
  (942, 16)	2.8474063737872584
  (942, 15)	2.998798784224917
  (942, 14)	3.3265604784314067
  (942, 13)	3.459645451173721
  (942, 12)	3.068814326803232
  (942, 11)	3.900760461392733
  (942, 10)	3.5070078284721755
  (942, 9)	3.306747138879105
  (942, 8)	3.498156294263754
  (942, 7)	3.6757546996548034
  (942, 6)	3.4941498270485414
  (942, 5)	3.0811500078821106
  (942, 4)	3.0169885274465833
  (942, 3)	3.2301221808276157
  (942, 2)	2.9609502505965652
  (942, 1)	3.0101271796480074
  (942, 0)	3.5452889281341875
this is the 73 epoch
rmse loss on training set is 0.9197548031033862
rmse loss on test set is 0.9284801716850273
for this epoch using 170.65427041053772 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3833421973993687
  (0, 1680)	3.386215636659752
  (0, 1679)	3.3833421973993687
  (0, 1678)	3.3833421973993687
  (0, 1677)	3.3833421973993687
  (0, 1676)	3.3833421973993687
  (0, 1675)	3.3833421973993687
  (0, 1674)	3.3833421973993687
  (0, 1673)	3.3833421973993687
  (0, 1672)	3.3833421973993687
  (0, 1671)	3.3624532320908798
  (0, 1670)	3.3833421973993687
  (0, 1669)	3.3833421973993687
  (0, 1668)	3.3833421973993687
  (0, 1667)	3.3833421973993687
  (0, 1666)	3.3833421973993687
  (0, 1665)	3.3833421973993687
  (0, 1664)	3.3833421973993687
  (0, 1663)	3.403500113121915
  (0, 1662)	3.3833421973993687
  (0, 1661)	3.3833421973993687
  (0, 1660)	3.3228161060060595
  (0, 1659)	3.3335903286142394
  (0, 1658)	3.3833421973993687
  (0, 1657)	3.3833421973993687
  :	:
  (942, 24)	2.9558937430548213
  (942, 23)	3.170043758699108
  (942, 22)	3.6114653319885233
  (942, 21)	3.7354565829702078
  (942, 20)	2.7209000384601203
  (942, 19)	3.1908110732756403
  (942, 18)	3.132317357951148
  (942, 17)	3.031600096876136
  (942, 16)	2.846084068908709
  (942, 15)	2.9987518375994986
  (942, 14)	3.3270405441248103
  (942, 13)	3.4619114204373695
  (942, 12)	3.0688541062220405
  (942, 11)	3.901681620853231
  (942, 10)	3.507434043804845
  (942, 9)	3.3090240972350964
  (942, 8)	3.4990489746449467
  (942, 7)	3.676796140950605
  (942, 6)	3.4943482221101827
  (942, 5)	3.08221082055926
  (942, 4)	3.0168365772705448
  (942, 3)	3.230229489561687
  (942, 2)	2.960474733983426
  (942, 1)	3.009845049945155
  (942, 0)	3.5454711488227524
this is the 74 epoch
rmse loss on training set is 0.9194335460079857
rmse loss on test set is 0.9282588239465072
for this epoch using 189.00448155403137 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.383099929863804
  (0, 1680)	3.3860312378271025
  (0, 1679)	3.383099929863804
  (0, 1678)	3.383099929863804
  (0, 1677)	3.383099929863804
  (0, 1676)	3.383099929863804
  (0, 1675)	3.383099929863804
  (0, 1674)	3.383099929863804
  (0, 1673)	3.383099929863804
  (0, 1672)	3.383099929863804
  (0, 1671)	3.361959452189689
  (0, 1670)	3.383099929863804
  (0, 1669)	3.383099929863804
  (0, 1668)	3.383099929863804
  (0, 1667)	3.383099929863804
  (0, 1666)	3.383099929863804
  (0, 1665)	3.383099929863804
  (0, 1664)	3.383099929863804
  (0, 1663)	3.40349986355699
  (0, 1662)	3.383099929863804
  (0, 1661)	3.383099929863804
  (0, 1660)	3.3217410469053483
  (0, 1659)	3.3326497429698
  (0, 1658)	3.383099929863804
  (0, 1657)	3.383099929863804
  :	:
  (942, 24)	2.955642073888343
  (942, 23)	3.170132791571745
  (942, 22)	3.613362232985756
  (942, 21)	3.7359245035527064
  (942, 20)	2.7185505901517586
  (942, 19)	3.1921946215818227
  (942, 18)	3.1335598860931237
  (942, 17)	3.032007578633689
  (942, 16)	2.844782954444149
  (942, 15)	2.9987089166044307
  (942, 14)	3.3275086006663237
  (942, 13)	3.4641393028479257
  (942, 12)	3.0689036950700297
  (942, 11)	3.902572584233631
  (942, 10)	3.507848764511152
  (942, 9)	3.3112773812281016
  (942, 8)	3.4999186427358207
  (942, 7)	3.6778094816352245
  (942, 6)	3.494545013893908
  (942, 5)	3.0832710527325378
  (942, 4)	3.0166871857655093
  (942, 3)	3.2303409686057925
  (942, 2)	2.9600077887680234
  (942, 1)	3.0095719043497153
  (942, 0)	3.545652146406225
this is the 75 epoch
rmse loss on training set is 0.9191184620161201
rmse loss on test set is 0.9280422552021532
for this epoch using 182.16578555107117 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3828639875559015
  (0, 1680)	3.3858532729625685
  (0, 1679)	3.3828639875559015
  (0, 1678)	3.3828639875559015
  (0, 1677)	3.3828639875559015
  (0, 1676)	3.3828639875559015
  (0, 1675)	3.3828639875559015
  (0, 1674)	3.3828639875559015
  (0, 1673)	3.3828639875559015
  (0, 1672)	3.3828639875559015
  (0, 1671)	3.36147223148211
  (0, 1670)	3.3828639875559015
  (0, 1669)	3.3828639875559015
  (0, 1668)	3.3828639875559015
  (0, 1667)	3.3828639875559015
  (0, 1666)	3.3828639875559015
  (0, 1665)	3.3828639875559015
  (0, 1664)	3.3828639875559015
  (0, 1663)	3.403505534748175
  (0, 1662)	3.3828639875559015
  (0, 1661)	3.3828639875559015
  (0, 1660)	3.3206728227421047
  (0, 1659)	3.33171647575945
  (0, 1658)	3.3828639875559015
  (0, 1657)	3.3828639875559015
  :	:
  (942, 24)	2.9554108110357196
  (942, 23)	3.170219497564368
  (942, 22)	3.6152161083993204
  (942, 21)	3.736379546460911
  (942, 20)	2.716237459851299
  (942, 19)	3.1935676089843548
  (942, 18)	3.134798468402218
  (942, 17)	3.0324157366597326
  (942, 16)	2.8435027030454747
  (942, 15)	2.9986699560919776
  (942, 14)	3.327965191568794
  (942, 13)	3.466329923181837
  (942, 12)	3.068962781102419
  (942, 11)	3.9034349755926847
  (942, 10)	3.5082526854734546
  (942, 9)	3.313507293058617
  (942, 8)	3.5007662575725833
  (942, 7)	3.678796007426427
  (942, 6)	3.494740533118896
  (942, 5)	3.0843306731316247
  (942, 4)	3.01654032581038
  (942, 3)	3.2304564812196217
  (942, 2)	2.959549256474882
  (942, 1)	3.009307517608055
  (942, 0)	3.5458322016687576
this is the 76 epoch
rmse loss on training set is 0.9188093640898795
rmse loss on test set is 0.9278303075912485
for this epoch using 186.05423283576965 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3826340937446804
  (0, 1680)	3.3856814600429725
  (0, 1679)	3.3826340937446804
  (0, 1678)	3.3826340937446804
  (0, 1677)	3.3826340937446804
  (0, 1676)	3.3826340937446804
  (0, 1675)	3.3826340937446804
  (0, 1674)	3.3826340937446804
  (0, 1673)	3.3826340937446804
  (0, 1672)	3.3826340937446804
  (0, 1671)	3.36099128629131
  (0, 1670)	3.3826340937446804
  (0, 1669)	3.3826340937446804
  (0, 1668)	3.3826340937446804
  (0, 1667)	3.3826340937446804
  (0, 1666)	3.3826340937446804
  (0, 1665)	3.3826340937446804
  (0, 1664)	3.3826340937446804
  (0, 1663)	3.4035168543618717
  (0, 1662)	3.3826340937446804
  (0, 1661)	3.3826340937446804
  (0, 1660)	3.319611163294317
  (0, 1659)	3.330790244397708
  (0, 1658)	3.3826340937446804
  (0, 1657)	3.3826340937446804
  :	:
  (942, 24)	2.9551990424955505
  (942, 23)	3.1703040725720775
  (942, 22)	3.617028299222102
  (942, 21)	3.736822562962866
  (942, 20)	2.713960111871929
  (942, 19)	3.194930144334009
  (942, 18)	3.136033110100443
  (942, 17)	3.032824549591501
  (942, 16)	2.842242992832866
  (942, 15)	2.9986348910971077
  (942, 14)	3.328410831995821
  (942, 13)	3.4684840824509062
  (942, 12)	3.0690310562999428
  (942, 11)	3.904270320812397
  (942, 10)	3.5086464544552984
  (942, 9)	3.3157141283411242
  (942, 8)	3.5015927299118625
  (942, 7)	3.679756933596672
  (942, 6)	3.49493507326548
  (942, 5)	3.0853896514914254
  (942, 4)	3.016395970876366
  (942, 3)	3.2305758884569724
  (942, 2)	2.9590989826061285
  (942, 1)	3.00905166899661
  (942, 0)	3.5460115609205807
this is the 77 epoch
rmse loss on training set is 0.9185060736462357
rmse loss on test set is 0.9276228310529102
for this epoch using 175.4058918952942 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3824099801832204
  (0, 1680)	3.3855155257926643
  (0, 1679)	3.3824099801832204
  (0, 1678)	3.3824099801832204
  (0, 1677)	3.3824099801832204
  (0, 1676)	3.3824099801832204
  (0, 1675)	3.3824099801832204
  (0, 1674)	3.3824099801832204
  (0, 1673)	3.3824099801832204
  (0, 1672)	3.3824099801832204
  (0, 1671)	3.3605163418243995
  (0, 1670)	3.3824099801832204
  (0, 1669)	3.3824099801832204
  (0, 1668)	3.3824099801832204
  (0, 1667)	3.3824099801832204
  (0, 1666)	3.3824099801832204
  (0, 1665)	3.3824099801832204
  (0, 1664)	3.3824099801832204
  (0, 1663)	3.4035335583979136
  (0, 1662)	3.3824099801832204
  (0, 1661)	3.3824099801832204
  (0, 1660)	3.3185558064517116
  (0, 1659)	3.329870774628609
  (0, 1658)	3.3824099801832204
  (0, 1657)	3.3824099801832204
  :	:
  (942, 24)	2.9550058923238693
  (942, 23)	3.170386699035264
  (942, 22)	3.6188000959063618
  (942, 21)	3.737254341776524
  (942, 20)	2.711718017319093
  (942, 19)	3.1962823325883893
  (942, 18)	3.137263814894069
  (942, 17)	3.0332339967004724
  (942, 16)	2.8410035072880406
  (942, 15)	2.9986036569312606
  (942, 14)	3.3288460104198063
  (942, 13)	3.470602558935726
  (942, 12)	3.0691082172408164
  (942, 11)	3.9050800538651615
  (942, 10)	3.509030675411064
  (942, 9)	3.3178981764168998
  (942, 8)	3.502398925011874
  (942, 7)	3.680693409225005
  (942, 6)	3.495128893927585
  (942, 5)	3.0864479585284372
  (942, 4)	3.016254095009341
  (942, 3)	3.2306990500471606
  (942, 2)	2.958656816528754
  (942, 1)	3.0088041423751504
  (942, 0)	3.5461904393710504
this is the 78 epoch
rmse loss on training set is 0.9182084200230733
rmse loss on test set is 0.9274196827985616
for this epoch using 172.71339535713196 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3821913875342675
  (0, 1680)	3.3853552060964645
  (0, 1679)	3.3821913875342675
  (0, 1678)	3.3821913875342675
  (0, 1677)	3.3821913875342675
  (0, 1676)	3.3821913875342675
  (0, 1675)	3.3821913875342675
  (0, 1674)	3.3821913875342675
  (0, 1673)	3.3821913875342675
  (0, 1672)	3.3821913875342675
  (0, 1671)	3.3600471325734134
  (0, 1670)	3.3821913875342675
  (0, 1669)	3.3821913875342675
  (0, 1668)	3.3821913875342675
  (0, 1667)	3.3821913875342675
  (0, 1666)	3.3821913875342675
  (0, 1665)	3.3821913875342675
  (0, 1664)	3.3821913875342675
  (0, 1663)	3.4035553916269725
  (0, 1662)	3.3821913875342675
  (0, 1661)	3.3821913875342675
  (0, 1660)	3.3175064986498364
  (0, 1659)	3.328957800973936
  (0, 1658)	3.3821913875342675
  (0, 1657)	3.3821913875342675
  :	:
  (942, 24)	2.9548305195303097
  (942, 23)	3.1704675468533297
  (942, 22)	3.6205327406458196
  (942, 21)	3.7376756137104827
  (942, 20)	2.709510654111693
  (942, 19)	3.197624275113037
  (942, 18)	3.138490585131376
  (942, 17)	3.033644057871854
  (942, 16)	2.8397839351466634
  (942, 15)	2.9985761892654246
  (942, 14)	3.3292711901661494
  (942, 13)	3.472686109151522
  (942, 12)	3.0691939654153346
  (942, 11)	3.9058655226561716
  (942, 10)	3.509405911550006
  (942, 9)	3.3200597206437754
  (942, 8)	3.5031856652296747
  (942, 7)	3.6816065211674007
  (942, 6)	3.495322223880743
  (942, 5)	3.0875055659161474
  (942, 4)	3.0161146728083126
  (942, 3)	3.2308258251608377
  (942, 2)	2.958222611360519
  (942, 1)	3.0085647262171338
  (942, 0)	3.5463690241924026
this is the 79 epoch
rmse loss on training set is 0.9179162399883997
rmse loss on test set is 0.9272207268286005
for this epoch using 175.40791082382202 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.381978065665265
  (0, 1680)	3.3852002462826887
  (0, 1679)	3.381978065665265
  (0, 1678)	3.381978065665265
  (0, 1677)	3.381978065665265
  (0, 1676)	3.381978065665265
  (0, 1675)	3.381978065665265
  (0, 1674)	3.381978065665265
  (0, 1673)	3.381978065665265
  (0, 1672)	3.381978065665265
  (0, 1671)	3.359583402587329
  (0, 1670)	3.381978065665265
  (0, 1669)	3.381978065665265
  (0, 1668)	3.381978065665265
  (0, 1667)	3.381978065665265
  (0, 1666)	3.381978065665265
  (0, 1665)	3.381978065665265
  (0, 1664)	3.381978065665265
  (0, 1663)	3.403582107896352
  (0, 1662)	3.381978065665265
  (0, 1661)	3.381978065665265
  (0, 1660)	3.3164629951740143
  (0, 1659)	3.328051067048637
  (0, 1658)	3.381978065665265
  (0, 1657)	3.381978065665265
  :	:
  (942, 24)	2.9546721169701655
  (942, 23)	3.1705467742307865
  (942, 22)	3.6222274295306063
  (942, 21)	3.7380870559513792
  (942, 20)	2.707337506990257
  (942, 19)	3.198956069956853
  (942, 18)	3.1397134219468326
  (942, 17)	3.034054713584133
  (942, 16)	2.838583970290755
  (942, 15)	2.9985524242034436
  (942, 14)	3.3296868108528406
  (942, 13)	3.4747354687519274
  (942, 12)	3.069288007489534
  (942, 11)	3.9066279944721494
  (942, 10)	3.5097726881742335
  (942, 9)	3.3221990386649285
  (942, 8)	3.5039537324485166
  (942, 7)	3.6824972977659463
  (942, 6)	3.495515263889643
  (942, 5)	3.088562446259607
  (942, 4)	3.0159776794008555
  (942, 3)	3.2309560730731697
  (942, 2)	2.957796223855419
  (942, 1)	3.0083332136203507
  (942, 0)	3.546547477302187
this is the 80 epoch
rmse loss on training set is 0.9176293772883557
rmse loss on test set is 0.927025833489096
for this epoch using 175.42046523094177 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.381769773832046
  (0, 1680)	3.385050401295368
  (0, 1679)	3.381769773832046
  (0, 1678)	3.381769773832046
  (0, 1677)	3.381769773832046
  (0, 1676)	3.381769773832046
  (0, 1675)	3.381769773832046
  (0, 1674)	3.381769773832046
  (0, 1673)	3.381769773832046
  (0, 1672)	3.381769773832046
  (0, 1671)	3.3591249056342196
  (0, 1670)	3.381769773832046
  (0, 1669)	3.381769773832046
  (0, 1668)	3.381769773832046
  (0, 1667)	3.381769773832046
  (0, 1666)	3.381769773832046
  (0, 1665)	3.381769773832046
  (0, 1664)	3.381769773832046
  (0, 1663)	3.4036134703235628
  (0, 1662)	3.381769773832046
  (0, 1661)	3.381769773832046
  (0, 1660)	3.3154250603523776
  (0, 1659)	3.3271503257630455
  (0, 1658)	3.381769773832046
  (0, 1657)	3.381769773832046
  :	:
  (942, 24)	2.954529910238117
  (942, 23)	3.1706245284611287
  (942, 22)	3.623885314584013
  (942, 21)	3.7384892960260325
  (942, 20)	2.705198067513421
  (942, 19)	3.2002778121039004
  (942, 18)	3.14093232539306
  (942, 17)	3.0344659448886553
  (942, 16)	2.8374033116416335
  (942, 15)	2.9985322983465252
  (942, 14)	3.3300932897338393
  (942, 13)	3.4767513533761005
  (942, 12)	3.0693900555232028
  (942, 11)	3.9073686610649867
  (942, 10)	3.5101314953086313
  (942, 9)	3.3243164026584737
  (942, 8)	3.504703870347909
  (942, 7)	3.6833667123159723
  (942, 6)	3.4957081892777113
  (942, 5)	3.089618573069536
  (942, 4)	3.015843090416494
  (942, 3)	3.2310896537356655
  (942, 2)	2.9573775142894836
  (942, 1)	3.008109402300592
  (942, 0)	3.546725937890029
this is the 81 epoch
rmse loss on training set is 0.9173476822306605
rmse loss on test set is 0.9268348790645325
for this epoch using 175.4662425518036 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3815662807683715
  (0, 1680)	3.3849054357727058
  (0, 1679)	3.3815662807683715
  (0, 1678)	3.3815662807683715
  (0, 1677)	3.3815662807683715
  (0, 1676)	3.3815662807683715
  (0, 1675)	3.3815662807683715
  (0, 1674)	3.3815662807683715
  (0, 1673)	3.3815662807683715
  (0, 1672)	3.3815662807683715
  (0, 1671)	3.3586714052705307
  (0, 1670)	3.3815662807683715
  (0, 1669)	3.3815662807683715
  (0, 1668)	3.3815662807683715
  (0, 1667)	3.3815662807683715
  (0, 1666)	3.3815662807683715
  (0, 1665)	3.3815662807683715
  (0, 1664)	3.3815662807683715
  (0, 1663)	3.4036492513946897
  (0, 1662)	3.3815662807683715
  (0, 1661)	3.3815662807683715
  (0, 1660)	3.3143924676547973
  (0, 1659)	3.3262553394289913
  (0, 1658)	3.3815662807683715
  (0, 1657)	3.3815662807683715
  :	:
  (942, 24)	2.954403156568562
  (942, 23)	3.1707009466538167
  (942, 22)	3.6255075056888404
  (942, 21)	3.7388829154641807
  (942, 20)	2.703091834044293
  (942, 19)	3.2015895937039778
  (942, 18)	3.1421472945616165
  (942, 17)	3.0348777333895978
  (942, 16)	2.8362416630539395
  (942, 15)	2.998515748849825
  (942, 14)	3.3304910229538836
  (942, 13)	3.478734459443466
  (942, 12)	3.0694998271474523
  (942, 11)	3.908088643396533
  (942, 10)	3.510482790139013
  (942, 9)	3.326412079569713
  (942, 8)	3.505436786528121
  (942, 7)	3.6842156863085465
  (942, 6)	3.4959011522786527
  (942, 5)	3.090673920736135
  (942, 4)	3.0157108819587535
  (942, 3)	3.231226428267096
  (942, 2)	2.956966346347671
  (942, 1)	3.0078930945708944
  (942, 0)	3.546904524711842
this is the 82 epoch
rmse loss on training set is 0.9170710112999293
rmse loss on test set is 0.9266477454033272
for this epoch using 174.57968974113464 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.381367364695809
  (0, 1680)	3.3847651240466186
  (0, 1679)	3.381367364695809
  (0, 1678)	3.381367364695809
  (0, 1677)	3.381367364695809
  (0, 1676)	3.381367364695809
  (0, 1675)	3.381367364695809
  (0, 1674)	3.381367364695809
  (0, 1673)	3.381367364695809
  (0, 1672)	3.381367364695809
  (0, 1671)	3.358222674832056
  (0, 1670)	3.381367364695809
  (0, 1669)	3.381367364695809
  (0, 1668)	3.381367364695809
  (0, 1667)	3.381367364695809
  (0, 1666)	3.381367364695809
  (0, 1665)	3.381367364695809
  (0, 1664)	3.381367364695809
  (0, 1663)	3.403689232982465
  (0, 1662)	3.381367364695809
  (0, 1661)	3.381367364695809
  (0, 1660)	3.313364999712642
  (0, 1659)	3.3253658797848633
  (0, 1658)	3.381367364695809
  (0, 1657)	3.381367364695809
  :	:
  (942, 24)	2.9542911437469606
  (942, 23)	3.1707761564088406
  (942, 22)	3.627095072411096
  (942, 21)	3.739268453185418
  (942, 20)	2.7010183117278186
  (942, 19)	3.202891504283618
  (942, 18)	3.143358327693575
  (942, 17)	3.0352900612241625
  (942, 16)	2.8350987332111717
  (942, 15)	2.9985027134717583
  (942, 14)	3.3308803867216623
  (942, 13)	3.4806854649006405
  (942, 12)	3.069617045706179
  (942, 11)	3.9087889960688345
  (942, 10)	3.51082699927358
  (942, 9)	3.3284863313272512
  (942, 8)	3.506153154499763
  (942, 7)	3.6850450924643616
  (942, 6)	3.496094284188554
  (942, 5)	3.091728464502717
  (942, 4)	3.0155810305763957
  (942, 3)	3.2313662593723476
  (942, 2)	2.956562587012275
  (942, 1)	3.0076840973083767
  (942, 0)	3.5470833381725906
this is the 83 epoch
rmse loss on training set is 0.9167992268021757
rmse loss on test set is 0.9264643195729293
for this epoch using 175.47136998176575 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.381172813267243
  (0, 1680)	3.3846292500760926
  (0, 1679)	3.381172813267243
  (0, 1678)	3.381172813267243
  (0, 1677)	3.381172813267243
  (0, 1676)	3.381172813267243
  (0, 1675)	3.381172813267243
  (0, 1674)	3.381172813267243
  (0, 1673)	3.381172813267243
  (0, 1672)	3.381172813267243
  (0, 1671)	3.357778497359632
  (0, 1670)	3.381172813267243
  (0, 1669)	3.381172813267243
  (0, 1668)	3.381172813267243
  (0, 1667)	3.381172813267243
  (0, 1666)	3.381172813267243
  (0, 1665)	3.381172813267243
  (0, 1664)	3.381172813267243
  (0, 1663)	3.403733206297093
  (0, 1662)	3.381172813267243
  (0, 1661)	3.381172813267243
  (0, 1660)	3.312342448272026
  (0, 1659)	3.324481727952573
  (0, 1658)	3.381172813267243
  (0, 1657)	3.381172813267243
  :	:
  (942, 24)	2.9541931890355384
  (942, 23)	3.1708502764431645
  (942, 22)	3.6286490457275495
  (942, 21)	3.7396464086320926
  (942, 20)	2.698977012460276
  (942, 19)	3.2041836309394385
  (942, 18)	3.1445654222808592
  (942, 17)	3.0357029110432645
  (942, 16)	2.833974235522999
  (942, 15)	2.9984931306168434
  (942, 14)	3.3312617384077186
  (942, 13)	3.4826050299241964
  (942, 12)	3.069741440365516
  (942, 11)	3.909470711462258
  (942, 10)	3.5111645208413305
  (942, 9)	3.3305394150446475
  (942, 8)	3.506853615548316
  (942, 7)	3.685855757573831
  (942, 6)	3.4962876973351227
  (942, 5)	3.0927821804394737
  (942, 4)	3.01545351323449
  (942, 3)	3.2315090116977543
  (942, 2)	2.956166106453439
  (942, 1)	3.007482221910747
  (942, 0)	3.547262462216765
this is the 84 epoch
rmse loss on training set is 0.9165321965356041
rmse loss on test set is 0.926284493541841
for this epoch using 174.71799731254578 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3809824234549652
  (0, 1680)	3.3844976073257986
  (0, 1679)	3.3809824234549652
  (0, 1678)	3.3809824234549652
  (0, 1677)	3.3809824234549652
  (0, 1676)	3.3809824234549652
  (0, 1675)	3.3809824234549652
  (0, 1674)	3.3809824234549652
  (0, 1673)	3.3809824234549652
  (0, 1672)	3.3809824234549652
  (0, 1671)	3.357338665470661
  (0, 1670)	3.3809824234549652
  (0, 1669)	3.3809824234549652
  (0, 1668)	3.3809824234549652
  (0, 1667)	3.3809824234549652
  (0, 1666)	3.3809824234549652
  (0, 1665)	3.3809824234549652
  (0, 1664)	3.3809824234549652
  (0, 1663)	3.4037809717810625
  (0, 1662)	3.3809824234549652
  (0, 1661)	3.3809824234549652
  (0, 1660)	3.3113246140920034
  (0, 1659)	3.323602674338061
  (0, 1658)	3.3809824234549652
  (0, 1657)	3.3809824234549652
  :	:
  (942, 24)	2.9541086381164856
  (942, 23)	3.1709234171728493
  (942, 22)	3.630170419663671
  (942, 21)	3.740017244667858
  (942, 20)	2.696967454851979
  (942, 19)	3.2054660585152095
  (942, 18)	3.1457685751590696
  (942, 17)	3.036116265992635
  (942, 16)	2.8328678880246145
  (942, 15)	2.9984869393726283
  (942, 14)	3.33163541757273
  (942, 13)	3.4844937975827333
  (942, 12)	3.0698727461948367
  (942, 11)	3.91013472360191
  (942, 10)	3.5114957264400997
  (942, 9)	3.3325715832085883
  (942, 8)	3.5075387804825104
  (942, 7)	3.6866484651571
  (942, 6)	3.496481486879793
  (942, 5)	3.0938350454173364
  (942, 4)	3.0153283072856154
  (942, 3)	3.231654552129919
  (942, 2)	2.955776777921931
  (942, 1)	3.007287284243977
  (942, 0)	3.5474419660438463
this is the 85 epoch
rmse loss on training set is 0.9162697934856563
rmse loss on test set is 0.9261081638860877
for this epoch using 172.21151518821716 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.380796001393405
  (0, 1680)	3.384369998599745
  (0, 1679)	3.380796001393405
  (0, 1678)	3.380796001393405
  (0, 1677)	3.380796001393405
  (0, 1676)	3.380796001393405
  (0, 1675)	3.380796001393405
  (0, 1674)	3.380796001393405
  (0, 1673)	3.380796001393405
  (0, 1672)	3.380796001393405
  (0, 1671)	3.3569029811862445
  (0, 1670)	3.380796001393405
  (0, 1669)	3.380796001393405
  (0, 1668)	3.380796001393405
  (0, 1667)	3.380796001393405
  (0, 1666)	3.380796001393405
  (0, 1665)	3.380796001393405
  (0, 1664)	3.380796001393405
  (0, 1663)	3.403832338958
  (0, 1662)	3.380796001393405
  (0, 1661)	3.380796001393405
  (0, 1660)	3.310311306797355
  (0, 1659)	3.3227285184850466
  (0, 1658)	3.380796001393405
  (0, 1657)	3.380796001393405
  :	:
  (942, 24)	2.954036864054939
  (942, 23)	3.170995681254467
  (942, 22)	3.6316601528475494
  (942, 21)	3.740381390260201
  (942, 20)	2.6949891641839
  (942, 19)	3.206738869764259
  (942, 18)	3.1469677825925952
  (942, 17)	3.0365301096945148
  (942, 16)	2.831779413278384
  (942, 15)	2.9984840795412695
  (942, 14)	3.3320017469315055
  (942, 13)	3.486352394461513
  (942, 12)	3.0700107042224745
  (942, 11)	3.9107819117716995
  (942, 10)	3.511820962945616
  (942, 9)	3.334583083854776
  (942, 8)	3.508209231274972
  (942, 7)	3.6874239579563644
  (942, 6)	3.4966757324663207
  (942, 5)	3.0948870370821155
  (942, 4)	3.0152053904415275
  (942, 3)	3.2318027500446824
  (942, 2)	2.9553944776447
  (942, 1)	3.0070991045826707
  (942, 0)	3.5476219056647045
this is the 86 epoch
rmse loss on training set is 0.9160118955418973
rmse loss on test set is 0.9259352315179366
for this epoch using 172.2922167778015 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3806133621849748
  (0, 1680)	3.3842462358383334
  (0, 1679)	3.3806133621849748
  (0, 1678)	3.3806133621849748
  (0, 1677)	3.3806133621849748
  (0, 1676)	3.3806133621849748
  (0, 1675)	3.3806133621849748
  (0, 1674)	3.3806133621849748
  (0, 1673)	3.3806133621849748
  (0, 1672)	3.3806133621849748
  (0, 1671)	3.35647125572236
  (0, 1670)	3.3806133621849748
  (0, 1669)	3.3806133621849748
  (0, 1668)	3.3806133621849748
  (0, 1667)	3.3806133621849748
  (0, 1666)	3.3806133621849748
  (0, 1665)	3.3806133621849748
  (0, 1664)	3.3806133621849748
  (0, 1663)	3.4038871262439545
  (0, 1662)	3.3806133621849748
  (0, 1661)	3.3806133621849748
  (0, 1660)	3.3093023446944874
  (0, 1659)	3.321859068890885
  (0, 1658)	3.3806133621849748
  (0, 1657)	3.3806133621849748
  :	:
  (942, 24)	2.9539772662839763
  (942, 23)	3.171067164088809
  (942, 22)	3.633119169985168
  (942, 21)	3.740739242963702
  (942, 20)	2.6930416723591453
  (942, 19)	3.208002145498369
  (942, 18)	3.1481630403526135
  (942, 17)	3.0369444262297987
  (942, 16)	2.8307085382778547
  (942, 15)	2.998484491666375
  (942, 14)	3.3323610332574187
  (942, 13)	3.488181431252508
  (942, 12)	3.0701550614691318
  (942, 11)	3.91141310389338
  (942, 10)	3.512140554192265
  (942, 9)	3.3365741607325634
  (942, 8)	3.508865522602611
  (942, 7)	3.6881829402722683
  (942, 6)	3.4968704997290208
  (942, 5)	3.095938133829044
  (942, 4)	3.0150847407456176
  (942, 3)	3.231953477512082
  (942, 2)	2.955019084723184
  (942, 1)	3.0069175075443826
  (942, 0)	3.5478023253130924
this is the 87 epoch
rmse loss on training set is 0.9157583852349841
rmse loss on test set is 0.9257656014348375
for this epoch using 170.14480876922607 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.38043432967628
  (0, 1680)	3.3841261398863893
  (0, 1679)	3.38043432967628
  (0, 1678)	3.38043432967628
  (0, 1677)	3.38043432967628
  (0, 1676)	3.38043432967628
  (0, 1675)	3.38043432967628
  (0, 1674)	3.38043432967628
  (0, 1673)	3.38043432967628
  (0, 1672)	3.38043432967628
  (0, 1671)	3.3560433092524784
  (0, 1670)	3.38043432967628
  (0, 1669)	3.38043432967628
  (0, 1668)	3.38043432967628
  (0, 1667)	3.38043432967628
  (0, 1666)	3.38043432967628
  (0, 1665)	3.38043432967628
  (0, 1664)	3.38043432967628
  (0, 1663)	3.40394516072871
  (0, 1662)	3.38043432967628
  (0, 1661)	3.38043432967628
  (0, 1660)	3.3082975545577646
  (0, 1659)	3.320994142791827
  (0, 1658)	3.38043432967628
  (0, 1657)	3.38043432967628
  :	:
  (942, 24)	2.953929269612954
  (942, 23)	3.1711379542900198
  (942, 22)	3.634548363262063
  (942, 21)	3.741091171219275
  (942, 20)	2.691124517849868
  (942, 19)	3.2092559647243433
  (942, 18)	3.1493543437886533
  (942, 17)	3.0373592001208314
  (942, 16)	2.829654994354274
  (942, 15)	2.9984881170554107
  (942, 14)	3.332713568231666
  (942, 13)	3.4899815033124324
  (942, 12)	3.0703055709616023
  (942, 11)	3.912029079687045
  (942, 10)	3.5124548025352422
  (942, 9)	3.3385450534591903
  (942, 8)	3.509508183293792
  (942, 7)	3.688926080155069
  (942, 6)	3.4970658416722027
  (942, 5)	3.096988314777721
  (942, 4)	3.014966336546364
  (942, 3)	3.23210660946247
  (942, 2)	2.954650481034759
  (942, 1)	3.006742322019031
  (942, 0)	3.547983258725586
this is the 88 epoch
rmse loss on training set is 0.9155091494920653
rmse loss on test set is 0.9255991824869068
for this epoch using 172.21562027931213 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.380258736211283
  (0, 1680)	3.3840095402383037
  (0, 1679)	3.380258736211283
  (0, 1678)	3.380258736211283
  (0, 1677)	3.380258736211283
  (0, 1676)	3.380258736211283
  (0, 1675)	3.380258736211283
  (0, 1674)	3.380258736211283
  (0, 1673)	3.380258736211283
  (0, 1672)	3.380258736211283
  (0, 1671)	3.3556189706478006
  (0, 1670)	3.380258736211283
  (0, 1669)	3.380258736211283
  (0, 1668)	3.380258736211283
  (0, 1667)	3.380258736211283
  (0, 1666)	3.380258736211283
  (0, 1665)	3.380258736211283
  (0, 1664)	3.380258736211283
  (0, 1663)	3.404006277933396
  (0, 1662)	3.380258736211283
  (0, 1661)	3.380258736211283
  (0, 1660)	3.3072967713926484
  (0, 1659)	3.3201335659242592
  (0, 1658)	3.380258736211283
  (0, 1657)	3.380258736211283
  :	:
  (942, 24)	2.95389232326065
  (942, 23)	3.171208134122623
  (942, 22)	3.6359485936756433
  (942, 21)	3.7414375164835203
  (942, 20)	2.6892372456403417
  (942, 19)	3.210500404769341
  (942, 18)	3.1505416878942163
  (942, 17)	3.0377744163147407
  (942, 16)	2.828618517085652
  (942, 15)	2.998494897798272
  (942, 14)	3.333059629241358
  (942, 13)	3.4917531911912385
  (942, 12)	3.0704619917290064
  (942, 11)	3.912630573628002
  (942, 10)	3.5127639903029633
  (942, 9)	3.3404959976644673
  (942, 8)	3.5101377176888
  (942, 7)	3.689654011460347
  (942, 6)	3.4972617999315743
  (942, 5)	3.0980375597476018
  (942, 4)	3.0148501564718253
  (942, 3)	3.2322620238184396
  (942, 2)	2.9542885511371892
  (942, 1)	3.006573381094291
  (942, 0)	3.548164730301529
this is the 89 epoch
rmse loss on training set is 0.9152640794088306
rmse loss on test set is 0.9254358871612283
for this epoch using 170.68400931358337 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3800864223666456
  (0, 1680)	3.3838962747659833
  (0, 1679)	3.3800864223666456
  (0, 1678)	3.3800864223666456
  (0, 1677)	3.3800864223666456
  (0, 1676)	3.3800864223666456
  (0, 1675)	3.3800864223666456
  (0, 1674)	3.3800864223666456
  (0, 1673)	3.3800864223666456
  (0, 1672)	3.3800864223666456
  (0, 1671)	3.35519807720066
  (0, 1670)	3.3800864223666456
  (0, 1669)	3.3800864223666456
  (0, 1668)	3.3800864223666456
  (0, 1667)	3.3800864223666456
  (0, 1666)	3.3800864223666456
  (0, 1665)	3.3800864223666456
  (0, 1664)	3.3800864223666456
  (0, 1663)	3.4040703215500283
  (0, 1662)	3.3800864223666456
  (0, 1661)	3.3800864223666456
  (0, 1660)	3.3062998381811086
  (0, 1659)	3.3192771722674315
  (0, 1658)	3.3800864223666456
  (0, 1657)	3.3800864223666456
  :	:
  (942, 24)	2.9538658999141334
  (942, 23)	3.1712777799090706
  (942, 22)	3.6373206923027426
  (942, 21)	3.7417785952012834
  (942, 20)	2.6873794071666266
  (942, 19)	3.2117355413959925
  (942, 18)	3.1517250673668933
  (942, 17)	3.0381900601673677
  (942, 16)	2.827598846208431
  (942, 15)	2.9985047767822754
  (942, 14)	3.3333994801300064
  (942, 13)	3.4934970611331324
  (942, 12)	3.0706240887837337
  (942, 11)	3.9132182777140256
  (942, 10)	3.513068381147933
  (942, 9)	3.34242722512667
  (942, 8)	3.5107546069194027
  (942, 7)	3.690367335778604
  (942, 6)	3.4974584059274387
  (942, 5)	3.099085849233975
  (942, 4)	3.014736179405471
  (942, 3)	3.232419601596731
  (942, 2)	2.95393318217642
  (942, 1)	3.0064105219778607
  (942, 0)	3.5483467561539435
this is the 90 epoch
rmse loss on training set is 0.9150230700371287
rmse loss on test set is 0.9252756313816153
for this epoch using 177.75850439071655 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3799172366742853
  (0, 1680)	3.383786189434092
  (0, 1679)	3.3799172366742853
  (0, 1678)	3.3799172366742853
  (0, 1677)	3.3799172366742853
  (0, 1676)	3.3799172366742853
  (0, 1675)	3.3799172366742853
  (0, 1674)	3.3799172366742853
  (0, 1673)	3.3799172366742853
  (0, 1672)	3.3799172366742853
  (0, 1671)	3.3547804743357297
  (0, 1670)	3.3799172366742853
  (0, 1669)	3.3799172366742853
  (0, 1668)	3.3799172366742853
  (0, 1667)	3.3799172366742853
  (0, 1666)	3.3799172366742853
  (0, 1665)	3.3799172366742853
  (0, 1664)	3.3799172366742853
  (0, 1663)	3.404137143167762
  (0, 1662)	3.3799172366742853
  (0, 1661)	3.3799172366742853
  (0, 1660)	3.3053066056139393
  (0, 1659)	3.318424803772542
  (0, 1658)	3.3799172366742853
  (0, 1657)	3.3799172366742853
  :	:
  (942, 24)	2.9538494948139356
  (942, 23)	3.171346962409794
  (942, 22)	3.6386654615058798
  (942, 21)	3.742114700633149
  (942, 20)	2.6855505602534118
  (942, 19)	3.212961448907971
  (942, 18)	3.1529044766635583
  (942, 17)	3.038606117427833
  (942, 16)	2.826595725531767
  (942, 15)	2.998517697704028
  (942, 14)	3.3337333719039237
  (942, 13)	3.4952136655522277
  (942, 12)	3.0707916330889358
  (942, 11)	3.9137928440558474
  (942, 10)	3.5133682213036352
  (942, 9)	3.3443389639002303
  (942, 8)	3.511359310113151
  (942, 7)	3.691066624247092
  (942, 6)	3.4976556819186415
  (942, 5)	3.100133164384598
  (942, 4)	3.014624384463293
  (942, 3)	3.232579226983752
  (942, 2)	2.9535842637975422
  (942, 1)	3.006253585917367
  (942, 0)	3.5485293450612914
this is the 91 epoch
rmse loss on training set is 0.9147860201865807
rmse loss on test set is 0.9251183343224832
for this epoch using 169.85469150543213 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.379751035334898
  (0, 1680)	3.3836791380068183
  (0, 1679)	3.379751035334898
  (0, 1678)	3.379751035334898
  (0, 1677)	3.379751035334898
  (0, 1676)	3.379751035334898
  (0, 1675)	3.379751035334898
  (0, 1674)	3.379751035334898
  (0, 1673)	3.379751035334898
  (0, 1672)	3.379751035334898
  (0, 1671)	3.35436601531302
  (0, 1670)	3.379751035334898
  (0, 1669)	3.379751035334898
  (0, 1668)	3.379751035334898
  (0, 1667)	3.379751035334898
  (0, 1666)	3.379751035334898
  (0, 1665)	3.379751035334898
  (0, 1664)	3.379751035334898
  (0, 1663)	3.4042066019897828
  (0, 1662)	3.379751035334898
  (0, 1661)	3.379751035334898
  (0, 1660)	3.30431693181405
  (0, 1659)	3.317576310082198
  (0, 1658)	3.379751035334898
  (0, 1657)	3.379751035334898
  :	:
  (942, 24)	2.9538426248661747
  (942, 23)	3.171415747178095
  (942, 22)	3.6399836760821196
  (942, 21)	3.7424461045489856
  (942, 20)	2.683750269048443
  (942, 19)	3.2141782002471353
  (942, 18)	3.1540799100509833
  (942, 17)	3.0390225742236083
  (942, 16)	2.8256089028543547
  (942, 15)	2.9985336050783853
  (942, 14)	3.3340615433973944
  (942, 13)	3.4969035434845357
  (942, 12)	3.0709644015142357
  (942, 11)	3.914354887302897
  (942, 10)	3.513663740754352
  (942, 9)	3.3462314384360874
  (942, 8)	3.5119522655273676
  (942, 7)	3.6917524192517495
  (942, 6)	3.497853641965531
  (942, 5)	3.10117948697688
  (942, 4)	3.014514750972252
  (942, 3)	3.232740787388157
  (942, 2)	2.953241688059022
  (942, 1)	3.006102418118434
  (942, 0)	3.5487124993288814
this is the 92 epoch
rmse loss on training set is 0.9145528322392725
rmse loss on test set is 0.9249639182356401
for this epoch using 170.74661135673523 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.379587681925966
  (0, 1680)	3.3835749817493426
  (0, 1679)	3.379587681925966
  (0, 1678)	3.379587681925966
  (0, 1677)	3.379587681925966
  (0, 1676)	3.379587681925966
  (0, 1675)	3.379587681925966
  (0, 1674)	3.379587681925966
  (0, 1673)	3.379587681925966
  (0, 1672)	3.379587681925966
  (0, 1671)	3.353954560925954
  (0, 1670)	3.379587681925966
  (0, 1669)	3.379587681925966
  (0, 1668)	3.379587681925966
  (0, 1667)	3.379587681925966
  (0, 1666)	3.379587681925966
  (0, 1665)	3.379587681925966
  (0, 1664)	3.379587681925966
  (0, 1663)	3.4042785645444167
  (0, 1662)	3.379587681925966
  (0, 1661)	3.379587681925966
  (0, 1660)	3.3033306820540838
  (0, 1659)	3.316731548243701
  (0, 1658)	3.379587681925966
  (0, 1657)	3.379587681925966
  :	:
  (942, 24)	2.9538448277817837
  (942, 23)	3.171484194891445
  (942, 22)	3.64127608435787
  (942, 21)	3.7427730587975545
  (942, 20)	2.6819781039549184
  (942, 19)	3.2153858670826096
  (942, 18)	3.155251361652178
  (942, 17)	3.0394394170462538
  (942, 16)	2.824638129883874
  (942, 15)	2.9985524442449325
  (942, 14)	3.3343842218996462
  (942, 13)	3.4985672210180687
  (942, 12)	3.0711421767811937
  (942, 11)	3.9149049869152854
  (942, 10)	3.5139551543243335
  (942, 9)	3.348104869694885
  (942, 8)	3.512533891617475
  (942, 7)	3.6924252360265366
  (942, 6)	3.4980522928094677
  (942, 5)	3.1022247993957923
  (942, 4)	3.0144072584502353
  (942, 3)	3.232904173473223
  (942, 2)	2.9529053493501984
  (942, 1)	3.005956867661606
  (942, 0)	3.548896215568108
this is the 93 epoch
rmse loss on training set is 0.914323411976368
rmse loss on test set is 0.9248123082889849
for this epoch using 172.45929384231567 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.379427047107291
  (0, 1680)	3.383473589127119
  (0, 1679)	3.379427047107291
  (0, 1678)	3.379427047107291
  (0, 1677)	3.379427047107291
  (0, 1676)	3.379427047107291
  (0, 1675)	3.379427047107291
  (0, 1674)	3.379427047107291
  (0, 1673)	3.379427047107291
  (0, 1672)	3.379427047107291
  (0, 1671)	3.353545979197614
  (0, 1670)	3.379427047107291
  (0, 1669)	3.379427047107291
  (0, 1668)	3.379427047107291
  (0, 1667)	3.379427047107291
  (0, 1666)	3.379427047107291
  (0, 1665)	3.379427047107291
  (0, 1664)	3.379427047107291
  (0, 1663)	3.4043529043934266
  (0, 1662)	3.379427047107291
  (0, 1661)	3.379427047107291
  (0, 1660)	3.302347728471328
  (0, 1659)	3.315890382419351
  (0, 1658)	3.379427047107291
  (0, 1657)	3.379427047107291
  :	:
  (942, 24)	2.9538556612430207
  (942, 23)	3.1715523616612002
  (942, 22)	3.6425434092324465
  (942, 21)	3.7430957967616028
  (942, 20)	2.680233641562172
  (942, 19)	3.2165845198927943
  (942, 18)	3.156418825488894
  (942, 17)	3.039856632737709
  (942, 16)	2.823683162158928
  (942, 15)	2.998574161372059
  (942, 14)	3.3347016237460063
  (942, 13)	3.5002052117024234
  (942, 12)	3.0713247473998226
  (942, 11)	3.9154436892924016
  (942, 10)	3.5142426626920527
  (942, 9)	3.349959475253917
  (942, 8)	3.513104588044102
  (942, 7)	3.693085564156878
  (942, 6)	3.4982516346757415
  (942, 5)	3.103269084612335
  (942, 4)	3.0143018865873343
  (942, 3)	3.2330692791717945
  (942, 2)	2.9525751443119526
  (942, 1)	3.005816787418446
  (942, 0)	3.549080485401011
this is the 94 epoch
rmse loss on training set is 0.9140976684157506
rmse loss on test set is 0.9246634324160512
for this epoch using 171.5431125164032 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.379269008326236
  (0, 1680)	3.383374835505282
  (0, 1679)	3.379269008326236
  (0, 1678)	3.379269008326236
  (0, 1677)	3.379269008326236
  (0, 1676)	3.379269008326236
  (0, 1675)	3.379269008326236
  (0, 1674)	3.379269008326236
  (0, 1673)	3.379269008326236
  (0, 1672)	3.379269008326236
  (0, 1671)	3.353140145077243
  (0, 1670)	3.379269008326236
  (0, 1669)	3.379269008326236
  (0, 1668)	3.379269008326236
  (0, 1667)	3.379269008326236
  (0, 1666)	3.379269008326236
  (0, 1665)	3.379269008326236
  (0, 1664)	3.379269008326236
  (0, 1663)	3.4044295018397457
  (0, 1662)	3.379269008326236
  (0, 1661)	3.379269008326236
  (0, 1660)	3.301367949782213
  (0, 1659)	3.315052683595911
  (0, 1658)	3.379269008326236
  (0, 1657)	3.379269008326236
  :	:
  (942, 24)	2.953874702097115
  (942, 23)	3.1716202993220084
  (942, 22)	3.643786349173667
  (942, 21)	3.7434145347068566
  (942, 20)	2.678516464575021
  (942, 19)	3.2177742280406427
  (942, 18)	3.1575822955205664
  (942, 17)	3.040274208477094
  (942, 16)	2.822743758973408
  (942, 15)	2.998598703459104
  (942, 14)	3.3350139548757647
  (942, 13)	3.501818016939357
  (942, 12)	3.0715119075974253
  (942, 11)	3.91597150976768
  (942, 10)	3.514526453335165
  (942, 9)	3.3517954694080205
  (942, 8)	3.5136647366228395
  (942, 7)	3.6937338689934713
  (942, 6)	3.498451662006197
  (942, 5)	3.104312326162728
  (942, 4)	3.0141986152285876
  (942, 3)	3.233236001686052
  (942, 2)	2.9522509717605723
  (942, 1)	3.0056820339673602
  (942, 0)	3.5492652960967814
this is the 95 epoch
rmse loss on training set is 0.913875513659781
rmse loss on test set is 0.9245172211756001
for this epoch using 171.63254165649414 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.379113449525
  (0, 1680)	3.3832786028502086
  (0, 1679)	3.379113449525
  (0, 1678)	3.379113449525
  (0, 1677)	3.379113449525
  (0, 1676)	3.379113449525
  (0, 1675)	3.379113449525
  (0, 1674)	3.379113449525
  (0, 1673)	3.379113449525
  (0, 1672)	3.379113449525
  (0, 1671)	3.35273694013934
  (0, 1670)	3.379113449525
  (0, 1669)	3.379113449525
  (0, 1668)	3.379113449525
  (0, 1667)	3.379113449525
  (0, 1666)	3.379113449525
  (0, 1665)	3.379113449525
  (0, 1664)	3.379113449525
  (0, 1663)	3.4045082436370504
  (0, 1662)	3.379113449525
  (0, 1661)	3.379113449525
  (0, 1660)	3.30039123099861
  (0, 1659)	3.3142183292956595
  (0, 1658)	3.379113449525
  (0, 1657)	3.379113449525
  :	:
  (942, 24)	2.953901545577087
  (942, 23)	3.1716880557026106
  (942, 22)	3.6450055791678877
  (942, 21)	3.743729473032914
  (942, 20)	2.6768261617419857
  (942, 19)	3.2189550598429606
  (942, 18)	3.158741765679938
  (942, 17)	3.0406921317681395
  (942, 16)	2.821819683303365
  (942, 15)	2.9986260183365436
  (942, 14)	3.335321411358888
  (942, 13)	3.503406126355581
  (942, 12)	3.0717034572407926
  (942, 11)	3.916488934478229
  (942, 10)	3.5148067014109934
  (942, 9)	3.35361306326498
  (942, 8)	3.5142147022204138
  (942, 7)	3.694370592982305
  (942, 6)	3.49865236412758
  (942, 5)	3.1053545081282774
  (942, 4)	3.014097424358097
  (942, 3)	3.233404241474201
  (942, 2)	2.951932732614693
  (942, 1)	3.0055524675093817
  (942, 0)	3.5494506311463954
this is the 96 epoch
rmse loss on training set is 0.9136568627524869
rmse loss on test set is 0.9243736076203942
for this epoch using 167.42304587364197 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.378960260851433
  (0, 1680)	3.383184779435016
  (0, 1679)	3.378960260851433
  (0, 1678)	3.378960260851433
  (0, 1677)	3.378960260851433
  (0, 1676)	3.378960260851433
  (0, 1675)	3.378960260851433
  (0, 1674)	3.378960260851433
  (0, 1673)	3.378960260851433
  (0, 1672)	3.378960260851433
  (0, 1671)	3.352336252286819
  (0, 1670)	3.378960260851433
  (0, 1669)	3.378960260851433
  (0, 1668)	3.378960260851433
  (0, 1667)	3.378960260851433
  (0, 1666)	3.378960260851433
  (0, 1665)	3.378960260851433
  (0, 1664)	3.378960260851433
  (0, 1663)	3.404589022702647
  (0, 1662)	3.378960260851433
  (0, 1661)	3.378960260851433
  (0, 1660)	3.2994174631474964
  (0, 1659)	3.313387203290569
  (0, 1658)	3.378960260851433
  (0, 1657)	3.378960260851433
  :	:
  (942, 24)	2.9539358045492574
  (942, 23)	3.171755674879238
  (942, 22)	3.6462017516270593
  (942, 21)	3.7440407974333136
  (942, 20)	2.675162327782663
  (942, 19)	3.2201270826340544
  (942, 18)	3.1598972299056634
  (942, 17)	3.041110390427093
  (942, 16)	2.8209107017360964
  (942, 15)	2.998656054664656
  (942, 14)	3.335624179893621
  (942, 13)	3.5049700181589487
  (942, 12)	3.071899201752733
  (942, 11)	3.9169964221178017
  (942, 10)	3.5150835705772594
  (942, 9)	3.3554124648357937
  (942, 8)	3.514754833600702
  (942, 7)	3.6949961569162357
  (942, 6)	3.4988537258605796
  (942, 5)	3.106395615115855
  (942, 4)	3.013998294084485
  (942, 3)	3.233573902225915
  (942, 2)	2.951620329825279
  (942, 1)	3.0054279517842892
  (942, 0)	3.5496364707810146
this is the 97 epoch
rmse loss on training set is 0.9134416335453903
rmse loss on test set is 0.9242325271744901
for this epoch using 175.3448395729065 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.378809338374846
  (0, 1680)	3.383093259550258
  (0, 1679)	3.378809338374846
  (0, 1678)	3.378809338374846
  (0, 1677)	3.378809338374846
  (0, 1676)	3.378809338374846
  (0, 1675)	3.378809338374846
  (0, 1674)	3.378809338374846
  (0, 1673)	3.378809338374846
  (0, 1672)	3.378809338374846
  (0, 1671)	3.351937975459583
  (0, 1670)	3.378809338374846
  (0, 1669)	3.378809338374846
  (0, 1668)	3.378809338374846
  (0, 1667)	3.378809338374846
  (0, 1666)	3.378809338374846
  (0, 1665)	3.378809338374846
  (0, 1664)	3.378809338374846
  (0, 1663)	3.404671737835139
  (0, 1662)	3.378809338374846
  (0, 1661)	3.378809338374846
  (0, 1660)	3.2984465429953578
  (0, 1659)	3.312559195321076
  (0, 1658)	3.378809338374846
  (0, 1657)	3.378809338374846
  :	:
  (942, 24)	2.9539771087872717
  (942, 23)	3.1718231974127815
  (942, 22)	3.6473754972552173
  (942, 21)	3.74434867997151
  (942, 20)	2.6735245633144156
  (942, 19)	3.2212903628243033
  (942, 18)	3.161048682172167
  (942, 17)	3.0415289725711743
  (942, 16)	2.820016584401606
  (942, 15)	2.9986887619306275
  (942, 14)	3.3359224382767834
  (942, 13)	3.5065101594790424
  (942, 12)	3.0720989520238935
  (942, 11)	3.9174944055805305
  (942, 10)	3.5153572137572584
  (942, 9)	3.35719387912019
  (942, 8)	3.515285464223688
  (942, 7)	3.695610961113038
  (942, 6)	3.499055728074762
  (942, 5)	3.107435632239099
  (942, 4)	3.013901204627702
  (942, 3)	3.2337448908281563
  (942, 2)	2.9513136683085355
  (942, 1)	3.005308353987253
  (942, 0)	3.5498227924391452
this is the 98 epoch
rmse loss on training set is 0.9132297465713252
rmse loss on test set is 0.9240939175183533
for this epoch using 178.13354992866516 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3786605838079744
  (0, 1680)	3.383003943221021
  (0, 1679)	3.3786605838079744
  (0, 1678)	3.3786605838079744
  (0, 1677)	3.3786605838079744
  (0, 1676)	3.3786605838079744
  (0, 1675)	3.3786605838079744
  (0, 1674)	3.3786605838079744
  (0, 1673)	3.3786605838079744
  (0, 1672)	3.3786605838079744
  (0, 1671)	3.3515420093497124
  (0, 1670)	3.3786605838079744
  (0, 1669)	3.3786605838079744
  (0, 1668)	3.3786605838079744
  (0, 1667)	3.3786605838079744
  (0, 1666)	3.3786605838079744
  (0, 1665)	3.3786605838079744
  (0, 1664)	3.3786605838079744
  (0, 1663)	3.4047562934380764
  (0, 1662)	3.3786605838079744
  (0, 1661)	3.3786605838079744
  (0, 1660)	3.29747837277854
  (0, 1659)	3.3117342008207
  (0, 1658)	3.3786605838079744
  (0, 1657)	3.3786605838079744
  :	:
  (942, 24)	2.9540251042721106
  (942, 23)	3.1718906605710573
  (942, 22)	3.64852742587647
  (942, 21)	3.744653280078869
  (942, 20)	2.67191247477867
  (942, 19)	3.222444965954075
  (942, 18)	3.1621961165168018
  (942, 17)	3.0419478666075137
  (942, 16)	2.8191371049061535
  (942, 15)	2.998724090444439
  (942, 14)	3.3362163558485762
  (942, 13)	3.508027006693239
  (942, 12)	3.072302524320468
  (942, 11)	3.9179832935027474
  (942, 10)	3.515627773853413
  (942, 9)	3.3589575081876717
  (942, 8)	3.5158069130004796
  (942, 7)	3.6962153865248646
  (942, 6)	3.4992583481936905
  (942, 5)	3.1084745451002216
  (942, 4)	3.0138061363070845
  (942, 3)	3.2339171173228443
  (942, 2)	2.9510126548816626
  (942, 1)	3.0051935446862927
  (942, 0)	3.550009571187323
this is the 99 epoch
rmse loss on training set is 0.9130211249257296
rmse loss on test set is 0.9239577184811592
for this epoch using 176.28196811676025 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.378513904235956
  (0, 1680)	3.382916735931318
  (0, 1679)	3.378513904235956
  (0, 1678)	3.378513904235956
  (0, 1677)	3.378513904235956
  (0, 1676)	3.378513904235956
  (0, 1675)	3.378513904235956
  (0, 1674)	3.378513904235956
  (0, 1673)	3.378513904235956
  (0, 1672)	3.378513904235956
  (0, 1671)	3.3511482591241655
  (0, 1670)	3.378513904235956
  (0, 1669)	3.378513904235956
  (0, 1668)	3.378513904235956
  (0, 1667)	3.378513904235956
  (0, 1666)	3.378513904235956
  (0, 1665)	3.378513904235956
  (0, 1664)	3.378513904235956
  (0, 1663)	3.404842599250513
  (0, 1662)	3.378513904235956
  (0, 1661)	3.378513904235956
  (0, 1660)	3.2965128599404143
  (0, 1659)	3.310912120647314
  (0, 1658)	3.378513904235956
  (0, 1657)	3.378513904235956
  :	:
  (942, 24)	2.9540794525176053
  (942, 23)	3.1719580985369356
  (942, 22)	3.6496581272266018
  (942, 21)	3.7449547454805376
  (942, 20)	2.6703256743668686
  (942, 19)	3.223590956743243
  (942, 18)	3.1633395270647737
  (942, 17)	3.042367061222556
  (942, 16)	2.8182720402680044
  (942, 15)	2.9987619913336
  (942, 14)	3.3365060939134277
  (942, 13)	3.5095210057391575
  (942, 12)	3.0725097401886723
  (942, 11)	3.918463471709348
  (942, 10)	3.5158953844128753
  (942, 9)	3.3607035512544785
  (942, 8)	3.516319485006864
  (942, 7)	3.6968097957831065
  (942, 6)	3.4994615606544204
  (942, 5)	3.1095123397725026
  (942, 4)	3.0137130695306142
  (942, 3)	3.2340904948576097
  (942, 2)	2.95071719820143
  (942, 1)	3.005083397740653
  (942, 0)	3.550196780098382
this is the 100 epoch
rmse loss on training set is 0.9128156941548161
rmse loss on test set is 0.9238238719398147
for this epoch using 173.83550310134888 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3783692118530766
  (0, 1680)	3.3828315483563625
  (0, 1679)	3.3783692118530766
  (0, 1678)	3.3783692118530766
  (0, 1677)	3.3783692118530766
  (0, 1676)	3.3783692118530766
  (0, 1675)	3.3783692118530766
  (0, 1674)	3.3783692118530766
  (0, 1673)	3.3783692118530766
  (0, 1672)	3.3783692118530766
  (0, 1671)	3.35075663515545
  (0, 1670)	3.3783692118530766
  (0, 1669)	3.3783692118530766
  (0, 1668)	3.3783692118530766
  (0, 1667)	3.3783692118530766
  (0, 1666)	3.3783692118530766
  (0, 1665)	3.3783692118530766
  (0, 1664)	3.3783692118530766
  (0, 1663)	3.404930570085107
  (0, 1662)	3.3783692118530766
  (0, 1661)	3.3783692118530766
  (0, 1660)	3.295549916875979
  (0, 1659)	3.3100928608218876
  (0, 1658)	3.3783692118530766
  (0, 1657)	3.3783692118530766
  :	:
  (942, 24)	2.9541398299210524
  (942, 23)	3.172025542603542
  (942, 22)	3.650768171710134
  (942, 21)	3.745253213054416
  (942, 20)	2.668763779946308
  (942, 19)	3.2247283991368056
  (942, 18)	3.164478908051736
  (942, 17)	3.0427865453719787
  (942, 16)	2.8174211708551438
  (942, 15)	2.998802416536828
  (942, 14)	3.3367918061383555
  (942, 13)	3.5109925924141256
  (942, 12)	3.072720426356534
  (942, 11)	3.9189353045709643
  (942, 10)	3.5161601702484706
  (942, 9)	3.362432204756622
  (942, 8)	3.5168234721582907
  (942, 7)	3.6973945341829624
  (942, 6)	3.499665337325092
  (942, 5)	3.110549002783401
  (942, 4)	3.0136219847853782
  (942, 3)	3.2342649396308363
  (942, 2)	2.9504272087053547
  (942, 1)	3.0049777902202717
  (942, 0)	3.5503843905913497
this is the 101 epoch
rmse loss on training set is 0.9126133821500777
rmse loss on test set is 0.9236923217240997
for this epoch using 170.21034979820251 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.378226423707775
  (0, 1680)	3.3827482961034545
  (0, 1679)	3.378226423707775
  (0, 1678)	3.378226423707775
  (0, 1677)	3.378226423707775
  (0, 1676)	3.378226423707775
  (0, 1675)	3.378226423707775
  (0, 1674)	3.378226423707775
  (0, 1673)	3.378226423707775
  (0, 1672)	3.378226423707775
  (0, 1671)	3.35036705276111
  (0, 1670)	3.378226423707775
  (0, 1669)	3.378226423707775
  (0, 1668)	3.378226423707775
  (0, 1667)	3.378226423707775
  (0, 1666)	3.378226423707775
  (0, 1665)	3.378226423707775
  (0, 1664)	3.378226423707775
  (0, 1663)	3.4050201255744046
  (0, 1662)	3.378226423707775
  (0, 1661)	3.378226423707775
  (0, 1660)	3.2945894606845956
  (0, 1659)	3.3092763322752616
  (0, 1658)	3.378226423707775
  (0, 1657)	3.378226423707775
  :	:
  (942, 24)	2.9542059271381156
  (942, 23)	3.172093021357281
  (942, 22)	3.651858111124668
  (942, 21)	3.7455488096280805
  (942, 20)	2.667226414985977
  (942, 19)	3.225857356346839
  (942, 18)	3.165614253844407
  (942, 17)	3.043206308271024
  (942, 16)	2.816584280324961
  (942, 15)	2.9988453187969037
  (942, 14)	3.337073638930261
  (942, 13)	3.5124421926627964
  (942, 12)	3.0729344146334716
  (942, 11)	3.91939913627759
  (942, 10)	3.516422248018203
  (942, 9)	3.364143662419439
  (942, 8)	3.517319153848248
  (942, 7)	3.697969930611294
  (942, 6)	3.4998696478841187
  (942, 5)	3.111584521098271
  (942, 4)	3.0135328626290927
  (942, 3)	3.2344403708319587
  (942, 2)	2.9501425985555123
  (942, 1)	3.004876602326532
  (942, 0)	3.5505723727362875
this is the 102 epoch
rmse loss on training set is 0.9124141190488458
rmse loss on test set is 0.9235630135275686
for this epoch using 174.69070410728455 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.378085461456299
  (0, 1680)	3.3826668994616114
  (0, 1679)	3.378085461456299
  (0, 1678)	3.378085461456299
  (0, 1677)	3.378085461456299
  (0, 1676)	3.378085461456299
  (0, 1675)	3.378085461456299
  (0, 1674)	3.378085461456299
  (0, 1673)	3.378085461456299
  (0, 1672)	3.378085461456299
  (0, 1671)	3.3499794319520775
  (0, 1670)	3.378085461456299
  (0, 1669)	3.378085461456299
  (0, 1668)	3.378085461456299
  (0, 1667)	3.378085461456299
  (0, 1666)	3.378085461456299
  (0, 1665)	3.378085461456299
  (0, 1664)	3.378085461456299
  (0, 1663)	3.4051111899256563
  (0, 1662)	3.378085461456299
  (0, 1661)	3.378085461456299
  (0, 1660)	3.2936314129310484
  (0, 1659)	3.3084624506033067
  (0, 1658)	3.378085461456299
  (0, 1657)	3.378085461456299
  :	:
  (942, 24)	2.95427744848169
  (942, 23)	3.1721605608494796
  (942, 22)	3.65292847935419
  (942, 21)	3.745841652718296
  (942, 20)	2.6657132084824866
  (942, 19)	3.2269778908910975
  (942, 18)	3.1667455589593207
  (942, 17)	3.043626339385241
  (942, 16)	2.8157611555658084
  (942, 15)	2.998890651652701
  (942, 14)	3.337351731793368
  (942, 13)	3.513870222853187
  (942, 12)	3.073151541808332
  (942, 11)	3.919855292034197
  (942, 10)	3.5166817267660746
  (942, 9)	3.365838115323711
  (942, 8)	3.5178067975526033
  (942, 7)	3.6985362984213856
  (942, 6)	3.500074460164155
  (942, 5)	3.112618882104744
  (942, 4)	3.0134456836827153
  (942, 3)	3.2346167105778774
  (942, 2)	2.9498632815847676
  (942, 1)	3.0047797173142525
  (942, 0)	3.5507606955274214
this is the 103 epoch
rmse loss on training set is 0.9122178371402216
rmse loss on test set is 0.9234358948237065
for this epoch using 171.49596786499023 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3779462511253127
  (0, 1680)	3.382587283160448
  (0, 1679)	3.3779462511253127
  (0, 1678)	3.3779462511253127
  (0, 1677)	3.3779462511253127
  (0, 1676)	3.3779462511253127
  (0, 1675)	3.3779462511253127
  (0, 1674)	3.3779462511253127
  (0, 1673)	3.3779462511253127
  (0, 1672)	3.3779462511253127
  (0, 1671)	3.3495936971903513
  (0, 1670)	3.3779462511253127
  (0, 1669)	3.3779462511253127
  (0, 1668)	3.3779462511253127
  (0, 1667)	3.3779462511253127
  (0, 1666)	3.3779462511253127
  (0, 1665)	3.3779462511253127
  (0, 1664)	3.3779462511253127
  (0, 1663)	3.405203691684461
  (0, 1662)	3.3779462511253127
  (0, 1661)	3.3779462511253127
  (0, 1660)	3.292675699415381
  (0, 1659)	3.307651135830868
  (0, 1658)	3.3779462511253127
  (0, 1657)	3.3779462511253127
  :	:
  (942, 24)	2.954354111343815
  (942, 23)	3.17222818475753
  (942, 22)	3.6539797930329034
  (942, 21)	3.7461318512171276
  (942, 20)	2.664223794886247
  (942, 19)	3.228090064628513
  (942, 18)	3.167872818079733
  (942, 17)	3.044046628421666
  (942, 16)	2.8149515866403414
  (942, 15)	2.998938369430593
  (942, 14)	3.3376262176679767
  (942, 13)	3.515277090042184
  (942, 12)	3.0733716495461545
  (942, 11)	3.920304079183047
  (942, 10)	3.516938708426947
  (942, 9)	3.367515751968648
  (942, 8)	3.518286659401764
  (942, 7)	3.6990939362578295
  (942, 6)	3.5002797404637414
  (942, 5)	3.113652073597634
  (942, 4)	3.013360428623996
  (942, 3)	3.2347938838463266
  (942, 2)	2.9495891732454145
  (942, 1)	3.004687021415158
  (942, 0)	3.550949327127379
this is the 104 epoch
rmse loss on training set is 0.9120244707763007
rmse loss on test set is 0.9233109147870053
for this epoch using 173.41258263587952 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3778087228836444
  (0, 1680)	3.3825093761382368
  (0, 1679)	3.3778087228836444
  (0, 1678)	3.3778087228836444
  (0, 1677)	3.3778087228836444
  (0, 1676)	3.3778087228836444
  (0, 1675)	3.3778087228836444
  (0, 1674)	3.3778087228836444
  (0, 1673)	3.3778087228836444
  (0, 1672)	3.3778087228836444
  (0, 1671)	3.3492097771560863
  (0, 1670)	3.3778087228836444
  (0, 1669)	3.3778087228836444
  (0, 1668)	3.3778087228836444
  (0, 1667)	3.3778087228836444
  (0, 1666)	3.3778087228836444
  (0, 1665)	3.3778087228836444
  (0, 1664)	3.3778087228836444
  (0, 1663)	3.4052975635074687
  (0, 1662)	3.3778087228836444
  (0, 1661)	3.3778087228836444
  (0, 1660)	3.2917222499515346
  (0, 1659)	3.306842312184501
  (0, 1658)	3.3778087228836444
  (0, 1657)	3.3778087228836444
  :	:
  (942, 24)	2.9544356456402467
  (942, 23)	3.172295914536096
  (942, 22)	3.6550125521809753
  (942, 21)	3.74641950602872
  (942, 20)	2.6627578140279002
  (942, 19)	3.2291939387918793
  (942, 18)	3.1689960260710737
  (942, 17)	3.0444671653204085
  (942, 16)	2.814155366730597
  (942, 15)	2.9989884272352647
  (942, 14)	3.337897223251767
  (942, 13)	3.5166631922308684
  (942, 12)	3.0735945842841947
  (942, 11)	3.920745788257678
  (942, 10)	3.517193288297898
  (942, 9)	3.3691767583320136
  (942, 8)	3.5187589847224916
  (942, 7)	3.6996431288345346
  (942, 6)	3.5004854538293553
  (942, 5)	3.1146840837644585
  (942, 4)	3.013277078181977
  (942, 3)	3.234971818406801
  (942, 2)	2.949320190560119
  (942, 1)	3.004598403762764
  (942, 0)	3.55113823508524
this is the 105 epoch
rmse loss on training set is 0.9118339562880493
rmse loss on test set is 0.9231880242186001
for this epoch using 170.42492628097534 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3776728108231286
  (0, 1680)	3.3824331113194113
  (0, 1679)	3.3776728108231286
  (0, 1678)	3.3776728108231286
  (0, 1677)	3.3776728108231286
  (0, 1676)	3.3776728108231286
  (0, 1675)	3.3776728108231286
  (0, 1674)	3.3776728108231286
  (0, 1673)	3.3776728108231286
  (0, 1672)	3.3776728108231286
  (0, 1671)	3.348827604524069
  (0, 1670)	3.3776728108231286
  (0, 1669)	3.3776728108231286
  (0, 1668)	3.3776728108231286
  (0, 1667)	3.3776728108231286
  (0, 1666)	3.3776728108231286
  (0, 1665)	3.3776728108231286
  (0, 1664)	3.3776728108231286
  (0, 1663)	3.4053927419441137
  (0, 1662)	3.3776728108231286
  (0, 1661)	3.3776728108231286
  (0, 1660)	3.290770998154995
  (0, 1659)	3.3060359078743478
  (0, 1658)	3.3776728108231286
  (0, 1657)	3.3776728108231286
  :	:
  (942, 24)	2.9545217932768417
  (942, 23)	3.172363769559137
  (942, 22)	3.6560272408137355
  (942, 21)	3.7467047106600977
  (942, 20)	2.661314911045156
  (942, 19)	3.2302895740179043
  (942, 18)	3.170115177994704
  (942, 17)	3.044887940246561
  (942, 16)	2.813372292084656
  (942, 15)	2.9990407809399615
  (942, 14)	3.338164869304427
  (942, 13)	3.5180289186102818
  (942, 12)	3.0738201971273864
  (942, 11)	3.9211806939725373
  (942, 10)	3.517445555478482
  (942, 9)	3.3708213179274145
  (942, 8)	3.519224008551463
  (942, 7)	3.700184147668861
  (942, 6)	3.500691564310238
  (942, 5)	3.1157149011715295
  (942, 4)	3.0131956131323636
  (942, 3)	3.235150444749796
  (942, 2)	2.949056252074999
  (942, 1)	3.0045137563188122
  (942, 0)	3.551327386530794
this is the 106 epoch
rmse loss on training set is 0.9116462319057672
rmse loss on test set is 0.923067175476129
for this epoch using 171.20062923431396 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.377538452748669
  (0, 1680)	3.3823584254013555
  (0, 1679)	3.377538452748669
  (0, 1678)	3.377538452748669
  (0, 1677)	3.377538452748669
  (0, 1676)	3.377538452748669
  (0, 1675)	3.377538452748669
  (0, 1674)	3.377538452748669
  (0, 1673)	3.377538452748669
  (0, 1672)	3.377538452748669
  (0, 1671)	3.3484471157497073
  (0, 1670)	3.377538452748669
  (0, 1669)	3.377538452748669
  (0, 1668)	3.377538452748669
  (0, 1667)	3.377538452748669
  (0, 1666)	3.377538452748669
  (0, 1665)	3.377538452748669
  (0, 1664)	3.377538452748669
  (0, 1663)	3.405489167227465
  (0, 1662)	3.377538452748669
  (0, 1661)	3.377538452748669
  (0, 1660)	3.2898218812392304
  (0, 1659)	3.3052318548848287
  (0, 1658)	3.377538452748669
  (0, 1657)	3.377538452748669
  :	:
  (942, 24)	2.954612307637167
  (942, 23)	3.172431767253242
  (942, 22)	3.657024327525455
  (942, 21)	3.746987551769497
  (942, 20)	2.659894736310112
  (942, 19)	3.231377030374882
  (942, 18)	3.1712302691204797
  (942, 17)	3.045308943582524
  (942, 16)	2.8126021619649353
  (942, 15)	2.999095387176442
  (942, 14)	3.3384292709368086
  (942, 13)	3.519374649798213
  (942, 12)	3.074048343743814
  (942, 11)	3.9216090561526653
  (942, 10)	3.5176955932817386
  (942, 9)	3.372449611859119
  (942, 8)	3.5196819561218673
  (942, 7)	3.700717251774304
  (942, 6)	3.5008980351884045
  (942, 5)	3.1167445147505473
  (942, 4)	3.013116014293667
  (942, 3)	3.2353296960146567
  (942, 2)	2.9487972778148057
  (942, 1)	3.004432973801248
  (942, 0)	3.5515167483472116
this is the 107 epoch
rmse loss on training set is 0.9114612376836706
rmse loss on test set is 0.922948322407534
for this epoch using 170.9876139163971 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.377405589977434
  (0, 1680)	3.382285258650451
  (0, 1679)	3.377405589977434
  (0, 1678)	3.377405589977434
  (0, 1677)	3.377405589977434
  (0, 1676)	3.377405589977434
  (0, 1675)	3.377405589977434
  (0, 1674)	3.377405589977434
  (0, 1673)	3.377405589977434
  (0, 1672)	3.377405589977434
  (0, 1671)	3.3480682508642716
  (0, 1670)	3.377405589977434
  (0, 1669)	3.377405589977434
  (0, 1668)	3.377405589977434
  (0, 1667)	3.377405589977434
  (0, 1666)	3.377405589977434
  (0, 1665)	3.377405589977434
  (0, 1664)	3.377405589977434
  (0, 1663)	3.4055867830740976
  (0, 1662)	3.377405589977434
  (0, 1661)	3.377405589977434
  (0, 1660)	3.288874839821186
  (0, 1659)	3.304430088774502
  (0, 1658)	3.377405589977434
  (0, 1657)	3.377405589977434
  :	:
  (942, 24)	2.9547069530906818
  (942, 23)	3.1724999232229862
  (942, 22)	3.6580042660490975
  (942, 21)	3.747268109675161
  (942, 20)	2.658496945357001
  (942, 19)	3.232456367388072
  (942, 18)	3.172341294937884
  (942, 17)	3.045730165920617
  (942, 16)	2.8118447785979277
  (942, 15)	2.9991522033244506
  (942, 14)	3.3386905378852854
  (942, 13)	3.520700758067428
  (942, 12)	3.074278884260149
  (942, 11)	3.92203112060696
  (942, 10)	3.5179434796182467
  (942, 9)	3.374061818874379
  (942, 8)	3.5201330433248743
  (942, 7)	3.7012426883144656
  (942, 6)	3.501104829185791
  (942, 5)	3.117772913785745
  (942, 4)	3.0130382625241476
  (942, 3)	3.2355095079167353
  (942, 2)	2.9485431892401177
  (942, 1)	3.004355953613746
  (942, 0)	3.55170628732413
this is the 108 epoch
rmse loss on training set is 0.9112789154283639
rmse loss on test set is 0.9228314202885176
for this epoch using 168.7702522277832 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3772741671469473
  (0, 1680)	3.382213554707298
  (0, 1679)	3.3772741671469473
  (0, 1678)	3.3772741671469473
  (0, 1677)	3.3772741671469473
  (0, 1676)	3.3772741671469473
  (0, 1675)	3.3772741671469473
  (0, 1674)	3.3772741671469473
  (0, 1673)	3.3772741671469473
  (0, 1672)	3.3772741671469473
  (0, 1671)	3.347690953279475
  (0, 1670)	3.3772741671469473
  (0, 1669)	3.3772741671469473
  (0, 1668)	3.3772741671469473
  (0, 1667)	3.3772741671469473
  (0, 1666)	3.3772741671469473
  (0, 1665)	3.3772741671469473
  (0, 1664)	3.3772741671469473
  (0, 1663)	3.40568553649294
  (0, 1662)	3.3772741671469473
  (0, 1661)	3.3772741671469473
  (0, 1660)	3.287929817735351
  (0, 1659)	3.303630548484576
  (0, 1658)	3.3772741671469473
  (0, 1657)	3.3772741671469473
  :	:
  (942, 24)	2.9548055045207704
  (942, 23)	3.172568251368608
  (942, 22)	3.6589674957930858
  (942, 21)	3.747546458827528
  (942, 20)	2.6571211988106
  (942, 19)	3.2335276440631446
  (942, 18)	3.1734482511660107
  (942, 17)	3.046151598056079
  (942, 16)	2.8110999471253835
  (942, 15)	2.9992111875009724
  (942, 14)	3.3389487747723194
  (942, 13)	3.5220076075657354
  (942, 12)	3.074511683157533
  (942, 11)	3.9224471199486453
  (942, 10)	3.5181892873548386
  (942, 9)	3.3756581154135317
  (942, 8)	3.520577477147263
  (942, 7)	3.7017606932204115
  (942, 6)	3.5013119086505506
  (942, 5)	3.118800087901559
  (942, 4)	3.012962338719388
  (942, 3)	3.235689818674083
  (942, 2)	2.9482939092064564
  (942, 1)	3.0042825957768584
  (942, 0)	3.5518959702930446
this is the 109 epoch
rmse loss on training set is 0.9110992086309463
rmse loss on test set is 0.9227164257634314
for this epoch using 172.36861872673035 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3771441320320887
  (0, 1680)	3.382143260400918
  (0, 1679)	3.3771441320320887
  (0, 1678)	3.3771441320320887
  (0, 1677)	3.3771441320320887
  (0, 1676)	3.3771441320320887
  (0, 1675)	3.3771441320320887
  (0, 1674)	3.3771441320320887
  (0, 1673)	3.3771441320320887
  (0, 1672)	3.3771441320320887
  (0, 1671)	3.347315169600979
  (0, 1670)	3.3771441320320887
  (0, 1669)	3.3771441320320887
  (0, 1668)	3.3771441320320887
  (0, 1667)	3.3771441320320887
  (0, 1666)	3.3771441320320887
  (0, 1665)	3.3771441320320887
  (0, 1664)	3.3771441320320887
  (0, 1663)	3.405785377602831
  (0, 1662)	3.3771441320320887
  (0, 1661)	3.3771441320320887
  (0, 1660)	3.2869867618565487
  (0, 1659)	3.3028331761562506
  (0, 1658)	3.3771441320320887
  (0, 1657)	3.3771441320320887
  :	:
  (942, 24)	2.9549077468719713
  (942, 23)	3.172636763996779
  (942, 22)	3.6599144423561767
  (942, 21)	3.747822668247336
  (942, 20)	2.6557671623151697
  (942, 19)	3.2345909189076263
  (942, 18)	3.1745511337624976
  (942, 17)	3.046573230980322
  (942, 16)	2.8103674755568293
  (942, 15)	2.999272298549231
  (942, 14)	3.3392040813538575
  (942, 13)	3.5232955545284663
  (942, 12)	3.0747466091680664
  (942, 11)	3.9228572743662755
  (942, 10)	3.518433084649721
  (942, 9)	3.3772386756580057
  (942, 8)	3.521015456086674
  (942, 7)	3.7022714917737507
  (942, 6)	3.501519235724214
  (942, 5)	3.1198260270507494
  (942, 4)	3.0128882238105694
  (942, 3)	3.2358705689341276
  (942, 2)	2.9480493619251367
  (942, 1)	3.004212802860763
  (942, 0)	3.5520857642465504
this is the 110 epoch
rmse loss on training set is 0.9109220624026124
rmse loss on test set is 0.9226032967893268
for this epoch using 171.61599969863892 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3770154353707023
  (0, 1680)	3.3820743255716708
  (0, 1679)	3.3770154353707023
  (0, 1678)	3.3770154353707023
  (0, 1677)	3.3770154353707023
  (0, 1676)	3.3770154353707023
  (0, 1675)	3.3770154353707023
  (0, 1674)	3.3770154353707023
  (0, 1673)	3.3770154353707023
  (0, 1672)	3.3770154353707023
  (0, 1671)	3.346940849450795
  (0, 1670)	3.3770154353707023
  (0, 1669)	3.3770154353707023
  (0, 1668)	3.3770154353707023
  (0, 1667)	3.3770154353707023
  (0, 1666)	3.3770154353707023
  (0, 1665)	3.3770154353707023
  (0, 1664)	3.3770154353707023
  (0, 1663)	3.405886259458702
  (0, 1662)	3.3770154353707023
  (0, 1661)	3.3770154353707023
  (0, 1660)	3.286045621931089
  (0, 1659)	3.3020379169565333
  (0, 1658)	3.3770154353707023
  (0, 1657)	3.3770154353707023
  :	:
  (942, 24)	2.9550134747157846
  (942, 23)	3.1727054719245644
  (942, 22)	3.6608455180215222
  (942, 21)	3.748096801932205
  (942, 20)	2.6544345064640766
  (942, 19)	3.235646249950696
  (942, 18)	3.17564993893132
  (942, 17)	3.0469950558745293
  (942, 16)	2.809647174723435
  (942, 15)	2.999335496027466
  (942, 14)	3.3394565527543842
  (942, 13)	3.5245649474835665
  (942, 12)	3.0749835351719987
  (942, 11)	3.923261792348236
  (942, 10)	3.518674935265669
  (942, 9)	3.378803671576325
  (942, 8)	3.5214471705456947
  (942, 7)	3.7027752991573624
  (942, 6)	3.501726772491298
  (942, 5)	3.1208507215030155
  (942, 4)	3.0128158987632987
  (942, 3)	3.2360517017005592
  (942, 2)	2.94780947292595
  (942, 1)	3.004146479919578
  (942, 0)	3.5522756364430936
this is the 111 epoch
rmse loss on training set is 0.9107474234133571
rmse loss on test set is 0.9224919925829852
for this epoch using 170.37626934051514 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3768880306976063
  (0, 1680)	3.3820067029027463
  (0, 1679)	3.3768880306976063
  (0, 1678)	3.3768880306976063
  (0, 1677)	3.3768880306976063
  (0, 1676)	3.3768880306976063
  (0, 1675)	3.3768880306976063
  (0, 1674)	3.3768880306976063
  (0, 1673)	3.3768880306976063
  (0, 1672)	3.3768880306976063
  (0, 1671)	3.3465679452982684
  (0, 1670)	3.3768880306976063
  (0, 1669)	3.3768880306976063
  (0, 1668)	3.3768880306976063
  (0, 1667)	3.3768880306976063
  (0, 1666)	3.3768880306976063
  (0, 1665)	3.3768880306976063
  (0, 1664)	3.3768880306976063
  (0, 1663)	3.405988137886108
  (0, 1662)	3.3768880306976063
  (0, 1661)	3.3768880306976063
  (0, 1660)	3.2851063504160765
  (0, 1659)	3.3012447189123324
  (0, 1658)	3.3768880306976063
  (0, 1657)	3.3768880306976063
  :	:
  (942, 24)	2.955122491834376
  (942, 23)	3.172774384577302
  (942, 22)	3.661761122230867
  (942, 21)	3.7483689192338523
  (942, 20)	2.653122906730077
  (942, 19)	3.236693694761337
  (942, 18)	3.176744663129762
  (942, 17)	3.047417064103473
  (942, 16)	2.808938858233049
  (942, 15)	2.9994007401976224
  (942, 14)	3.339706279690275
  (942, 13)	3.5258161274497772
  (942, 12)	3.075222338095896
  (942, 11)	3.9236608713637944
  (942, 10)	3.518914898862618
  (942, 9)	3.3803532729681898
  (942, 8)	3.521872803205927
  (942, 7)	3.703272320975738
  (942, 6)	3.501934481112961
  (942, 5)	3.1218741618340653
  (942, 4)	3.012745344576945
  (942, 3)	3.236233162260784
  (942, 2)	2.947574169021444
  (942, 1)	3.0040835344272705
  (942, 0)	3.5524655544985055
this is the 112 epoch
rmse loss on training set is 0.9105752398337521
rmse loss on test set is 0.9223824735707299
for this epoch using 169.08154702186584 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.376761874186764
  (0, 1680)	3.3819403477600023
  (0, 1679)	3.376761874186764
  (0, 1678)	3.376761874186764
  (0, 1677)	3.376761874186764
  (0, 1676)	3.376761874186764
  (0, 1675)	3.376761874186764
  (0, 1674)	3.376761874186764
  (0, 1673)	3.376761874186764
  (0, 1672)	3.376761874186764
  (0, 1671)	3.3461964122994576
  (0, 1670)	3.376761874186764
  (0, 1669)	3.376761874186764
  (0, 1668)	3.376761874186764
  (0, 1667)	3.376761874186764
  (0, 1666)	3.376761874186764
  (0, 1665)	3.376761874186764
  (0, 1664)	3.376761874186764
  (0, 1663)	3.4060909713238954
  (0, 1662)	3.376761874186764
  (0, 1661)	3.376761874186764
  (0, 1660)	3.284168902326723
  (0, 1659)	3.3004535327527074
  (0, 1658)	3.376761874186764
  (0, 1657)	3.376761874186764
  :	:
  (942, 24)	2.9552346108215004
  (942, 23)	3.1728435100805963
  (942, 22)	3.6626616420397826
  (942, 21)	3.74863907520811
  (942, 20)	2.6518320433963187
  (942, 19)	3.2377333104650123
  (942, 18)	3.1778353030743816
  (942, 17)	3.047839247209676
  (942, 16)	2.8082423424264404
  (942, 15)	2.999467992013894
  (942, 14)	3.3399533486820245
  (942, 13)	3.5270494281281977
  (942, 12)	3.0754628988118644
  (942, 11)	3.924054698503188
  (942, 10)	3.519153031271166
  (942, 9)	3.381887647506848
  (942, 8)	3.5222925293833147
  (942, 7)	3.7037627537467075
  (942, 6)	3.5021423239459284
  (942, 5)	3.122896338915117
  (942, 4)	3.0126765422845487
  (942, 3)	3.2364148981140657
  (942, 2)	2.9473433782727536
  (942, 1)	3.0040238762151654
  (942, 0)	3.552655486465644
this is the 113 epoch
rmse loss on training set is 0.9104054612794577
rmse loss on test set is 0.9222747013408187
for this epoch using 171.72525191307068 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3766369245013856
  (0, 1680)	3.3818752180397
  (0, 1679)	3.3766369245013856
  (0, 1678)	3.3766369245013856
  (0, 1677)	3.3766369245013856
  (0, 1676)	3.3766369245013856
  (0, 1675)	3.3766369245013856
  (0, 1674)	3.3766369245013856
  (0, 1673)	3.3766369245013856
  (0, 1672)	3.3766369245013856
  (0, 1671)	3.345826208144474
  (0, 1670)	3.3766369245013856
  (0, 1669)	3.3766369245013856
  (0, 1668)	3.3766369245013856
  (0, 1667)	3.3766369245013856
  (0, 1666)	3.3766369245013856
  (0, 1665)	3.3766369245013856
  (0, 1664)	3.3766369245013856
  (0, 1663)	3.406194720674736
  (0, 1662)	3.3766369245013856
  (0, 1661)	3.3766369245013856
  (0, 1660)	3.2832332350913496
  (0, 1659)	3.2996643117588698
  (0, 1658)	3.3766369245013856
  (0, 1657)	3.3766369245013856
  :	:
  (942, 24)	2.955349652700103
  (942, 23)	3.172912855346888
  (942, 22)	3.663547452554749
  (942, 21)	3.748907320939621
  (942, 20)	2.650561601488074
  (942, 19)	3.2387651537589885
  (942, 18)	3.178921855746219
  (942, 17)	3.048261596907771
  (942, 16)	2.8075574463346724
  (942, 15)	2.999537213111199
  (942, 14)	3.3401978422560545
  (942, 13)	3.5282651760875323
  (942, 12)	3.075705102037957
  (942, 11)	3.924443451079497
  (942, 10)	3.519389384748145
  (942, 9)	3.383406960779834
  (942, 8)	3.522706517365554
  (942, 7)	3.704246785366118
  (942, 6)	3.5023502636480965
  (942, 5)	3.1239172439028557
  (942, 4)	3.0126094729531
  (942, 3)	3.236596858900565
  (942, 2)	2.9471170299569787
  (942, 1)	3.0039674174109794
  (942, 0)	3.552845400903325
this is the 114 epoch
rmse loss on training set is 0.9102380387585006
rmse loss on test set is 0.9221686385982697
for this epoch using 169.31966829299927 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.37651314265164
  (0, 1680)	3.3818112740241717
  (0, 1679)	3.37651314265164
  (0, 1678)	3.37651314265164
  (0, 1677)	3.37651314265164
  (0, 1676)	3.37651314265164
  (0, 1675)	3.37651314265164
  (0, 1674)	3.37651314265164
  (0, 1673)	3.37651314265164
  (0, 1672)	3.37651314265164
  (0, 1671)	3.3454572929127284
  (0, 1670)	3.37651314265164
  (0, 1669)	3.37651314265164
  (0, 1668)	3.37651314265164
  (0, 1667)	3.37651314265164
  (0, 1666)	3.37651314265164
  (0, 1665)	3.37651314265164
  (0, 1664)	3.37651314265164
  (0, 1663)	3.4062993491632714
  (0, 1662)	3.37651314265164
  (0, 1661)	3.37651314265164
  (0, 1660)	3.2822993084138097
  (0, 1659)	3.2988770116217276
  (0, 1658)	3.37651314265164
  (0, 1657)	3.37651314265164
  :	:
  (942, 24)	2.9554674465559043
  (942, 23)	3.172982426156866
  (942, 22)	3.6644189173530957
  (942, 21)	3.7491737038430957
  (942, 20)	2.649311270705208
  (942, 19)	3.2397892809264097
  (942, 18)	3.180004318395268
  (942, 17)	3.0486841050791464
  (942, 16)	2.8068839916375095
  (942, 15)	2.9996083657936494
  (942, 14)	3.3404398391365837
  (942, 13)	3.529463690943418
  (942, 12)	3.0759488362399394
  (942, 11)	3.9248272971944607
  (942, 10)	3.51962400821551
  (942, 9)	3.3849113763280654
  (942, 8)	3.523114928732768
  (942, 7)	3.7047245955472925
  (942, 6)	3.502558263271855
  (942, 5)	3.1249368682297054
  (942, 4)	3.0125441176842576
  (942, 3)	3.2367789963315072
  (942, 2)	2.946895054535916
  (942, 1)	3.0039140723794326
  (942, 0)	3.5530352669354444
this is the 115 epoch
rmse loss on training set is 0.9100729246209046
rmse loss on test set is 0.9220642491219704
for this epoch using 172.1406557559967 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3763904918597616
  (0, 1680)	3.3817484782447567
  (0, 1679)	3.3763904918597616
  (0, 1678)	3.3763904918597616
  (0, 1677)	3.3763904918597616
  (0, 1676)	3.3763904918597616
  (0, 1675)	3.3763904918597616
  (0, 1674)	3.3763904918597616
  (0, 1673)	3.3763904918597616
  (0, 1672)	3.3763904918597616
  (0, 1671)	3.345089628935622
  (0, 1670)	3.3763904918597616
  (0, 1669)	3.3763904918597616
  (0, 1668)	3.3763904918597616
  (0, 1667)	3.3763904918597616
  (0, 1666)	3.3763904918597616
  (0, 1665)	3.3763904918597616
  (0, 1664)	3.3763904918597616
  (0, 1663)	3.4064048222015813
  (0, 1662)	3.3763904918597616
  (0, 1661)	3.3763904918597616
  (0, 1660)	3.281367084143011
  (0, 1659)	3.298091590306834
  (0, 1658)	3.3763904918597616
  (0, 1657)	3.3763904918597616
  :	:
  (942, 24)	2.9555878291863844
  (942, 23)	3.173052227236028
  (942, 22)	3.6652763888863125
  (942, 21)	3.749438267942717
  (942, 20)	2.6480807453554283
  (942, 19)	3.2408057478491887
  (942, 18)	3.1810826885441785
  (942, 17)	3.049106763766753
  (942, 16)	2.8062218026228876
  (942, 15)	2.9996814130229796
  (942, 14)	3.340679414428089
  (942, 13)	3.530645285531841
  (942, 12)	3.076193993534419
  (942, 11)	3.9252063962705637
  (942, 10)	3.5198569474836012
  (942, 9)	3.386401055683536
  (942, 8)	3.5235179186622054
  (942, 7)	3.7051963562363617
  (942, 6)	3.5027662863462257
  (942, 5)	3.125955203594623
  (942, 4)	3.012480457615418
  (942, 3)	3.236961264120521
  (942, 2)	2.9466773836262155
  (942, 1)	3.003863757664342
  (942, 0)	3.5532250543014214
this is the 116 epoch
rmse loss on training set is 0.9099100725107501
rmse loss on test set is 0.9219614977239063
for this epoch using 172.9103126525879 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3762689374321644
  (0, 1680)	3.3816867953520506
  (0, 1679)	3.3762689374321644
  (0, 1678)	3.3762689374321644
  (0, 1677)	3.3762689374321644
  (0, 1676)	3.3762689374321644
  (0, 1675)	3.3762689374321644
  (0, 1674)	3.3762689374321644
  (0, 1673)	3.3762689374321644
  (0, 1672)	3.3762689374321644
  (0, 1671)	3.3447231806664597
  (0, 1670)	3.3762689374321644
  (0, 1669)	3.3762689374321644
  (0, 1668)	3.3762689374321644
  (0, 1667)	3.3762689374321644
  (0, 1666)	3.3762689374321644
  (0, 1665)	3.3762689374321644
  (0, 1664)	3.3762689374321644
  (0, 1663)	3.406511107261718
  (0, 1662)	3.3762689374321644
  (0, 1661)	3.3762689374321644
  (0, 1660)	3.280436526149428
  (0, 1659)	3.297308007926179
  (0, 1658)	3.3762689374321644
  (0, 1657)	3.3762689374321644
  :	:
  (942, 24)	2.9557106447646087
  (942, 23)	3.1731222623267996
  (942, 22)	3.6661202088676794
  (942, 21)	3.749701054131278
  (942, 20)	2.646869724288299
  (942, 19)	3.2418146100198215
  (942, 18)	3.1821569639913343
  (942, 17)	3.049529565170245
  (942, 16)	2.805570706147293
  (942, 15)	2.9997563184070093
  (942, 14)	3.3409166397888654
  (942, 13)	3.5318102660772714
  (942, 12)	3.0764404695934053
  (942, 11)	3.9255808995513957
  (942, 10)	3.5200882454598608
  (942, 9)	3.387876158405618
  (942, 8)	3.5239156362179274
  (942, 7)	3.705662232005214
  (942, 6)	3.5029742969488735
  (942, 5)	3.126972241954151
  (942, 4)	3.0124184739211097
  (942, 3)	3.2371436179163107
  (942, 2)	2.9464639499707066
  (942, 1)	3.003816391932212
  (942, 0)	3.553414733398717
this is the 117 epoch
rmse loss on training set is 0.9097494373204363
rmse loss on test set is 0.9218603502103824
for this epoch using 170.79044437408447 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3761484466383767
  (0, 1680)	3.38162619199298
  (0, 1679)	3.3761484466383767
  (0, 1678)	3.3761484466383767
  (0, 1677)	3.3761484466383767
  (0, 1676)	3.3761484466383767
  (0, 1675)	3.3761484466383767
  (0, 1674)	3.3761484466383767
  (0, 1673)	3.3761484466383767
  (0, 1672)	3.3761484466383767
  (0, 1671)	3.344357914557274
  (0, 1670)	3.3761484466383767
  (0, 1669)	3.3761484466383767
  (0, 1668)	3.3761484466383767
  (0, 1667)	3.3761484466383767
  (0, 1666)	3.3761484466383767
  (0, 1665)	3.3761484466383767
  (0, 1664)	3.3761484466383767
  (0, 1663)	3.4066181737549446
  (0, 1662)	3.3761484466383767
  (0, 1661)	3.3761484466383767
  (0, 1660)	3.2795076002081207
  (0, 1659)	3.2965262266168303
  (0, 1658)	3.3761484466383767
  (0, 1657)	3.3761484466383767
  :	:
  (942, 24)	2.955835744517314
  (942, 23)	3.173192534256341
  (942, 22)	3.666950708644818
  (942, 21)	3.7499621004105426
  (942, 20)	2.645677910830072
  (942, 19)	3.2428159225522886
  (942, 18)	3.183227142813359
  (942, 17)	3.049952501641201
  (942, 16)	2.804930531597124
  (942, 15)	2.99983304618816
  (942, 14)	3.341151583596142
  (942, 13)	3.5329589323554287
  (942, 12)	3.0766881635505112
  (942, 11)	3.9259509505723114
  (942, 10)	3.520317942343911
  (942, 9)	3.3893368421160126
  (942, 8)	3.5243082246263104
  (942, 7)	3.706122380423111
  (942, 6)	3.503182259768716
  (942, 5)	3.127987975513864
  (942, 4)	3.012358147814707
  (942, 3)	3.2373260152367194
  (942, 2)	2.946254687411056
  (942, 1)	3.0037718959173327
  (942, 0)	3.5536042753182624
this is the 118 epoch
rmse loss on training set is 0.9095909751469423
rmse loss on test set is 0.9217607733451484
for this epoch using 171.7864682674408 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3760289885965085
  (0, 1680)	3.381566636694489
  (0, 1679)	3.3760289885965085
  (0, 1678)	3.3760289885965085
  (0, 1677)	3.3760289885965085
  (0, 1676)	3.3760289885965085
  (0, 1675)	3.3760289885965085
  (0, 1674)	3.3760289885965085
  (0, 1673)	3.3760289885965085
  (0, 1672)	3.3760289885965085
  (0, 1671)	3.3439937989422814
  (0, 1670)	3.3760289885965085
  (0, 1669)	3.3760289885965085
  (0, 1668)	3.3760289885965085
  (0, 1667)	3.3760289885965085
  (0, 1666)	3.3760289885965085
  (0, 1665)	3.3760289885965085
  (0, 1664)	3.3760289885965085
  (0, 1663)	3.4067259929175537
  (0, 1662)	3.3760289885965085
  (0, 1661)	3.3760289885965085
  (0, 1660)	3.2785802738881054
  (0, 1659)	3.295746210426025
  (0, 1658)	3.3760289885965085
  (0, 1657)	3.3760289885965085
  :	:
  (942, 24)	2.955962986416634
  (942, 23)	3.1732630450003625
  (942, 22)	3.6677682095577855
  (942, 21)	3.7502214421141042
  (942, 20)	2.644505012719259
  (942, 19)	3.243809740191954
  (942, 18)	3.184293223366959
  (942, 17)	3.0503755656786407
  (942, 16)	2.8043011108509037
  (942, 15)	2.999911561232006
  (942, 14)	3.3413843111032
  (942, 13)	3.534091577851089
  (942, 12)	3.0769369779086895
  (942, 11)	3.926316685603065
  (942, 10)	3.5205460758099165
  (942, 9)	3.3907832625324836
  (942, 8)	3.5246958215379824
  (942, 7)	3.7065769524082404
  (942, 6)	3.50339014016021
  (942, 5)	3.129002396720206
  (942, 4)	3.0122994605503255
  (942, 3)	3.2375084154043106
  (942, 2)	2.946049530861506
  (942, 1)	3.0037301923682374
  (942, 0)	3.5537936518735216
this is the 119 epoch
rmse loss on training set is 0.9094346432501498
rmse loss on test set is 0.9216627348142463
for this epoch using 167.48257303237915 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3759105341649036
  (0, 1680)	3.3815080997535443
  (0, 1679)	3.3759105341649036
  (0, 1678)	3.3759105341649036
  (0, 1677)	3.3759105341649036
  (0, 1676)	3.3759105341649036
  (0, 1675)	3.3759105341649036
  (0, 1674)	3.3759105341649036
  (0, 1673)	3.3759105341649036
  (0, 1672)	3.3759105341649036
  (0, 1671)	3.343630803927657
  (0, 1670)	3.3759105341649036
  (0, 1669)	3.3759105341649036
  (0, 1668)	3.3759105341649036
  (0, 1667)	3.3759105341649036
  (0, 1666)	3.3759105341649036
  (0, 1665)	3.3759105341649036
  (0, 1664)	3.3759105341649036
  (0, 1663)	3.4068345377027636
  (0, 1662)	3.3759105341649036
  (0, 1661)	3.3759105341649036
  (0, 1660)	3.277654516447768
  (0, 1659)	3.2949679252023256
  (0, 1658)	3.3759105341649036
  (0, 1657)	3.3759105341649036
  :	:
  (942, 24)	2.9560922348850642
  (942, 23)	3.1733337957432046
  (942, 22)	3.668573023283478
  (942, 21)	3.750479112113968
  (942, 20)	2.6433507420430717
  (942, 19)	3.2447961173246664
  (942, 18)	3.185355204290397
  (942, 17)	3.050798749924681
  (942, 16)	2.8036822782423094
  (942, 15)	2.9999918290159373
  (942, 14)	3.341614884588862
  (942, 13)	3.5352084899110663
  (942, 12)	3.077186818449597
  (942, 11)	3.926678234064229
  (942, 10)	3.520772681177011
  (942, 9)	3.3922155735014954
  (942, 8)	3.525078559277082
  (942, 7)	3.707026092560444
  (942, 6)	3.503597904189754
  (942, 5)	3.1300154982525874
  (942, 4)	3.012242393425035
  (942, 3)	3.237690779483437
  (942, 2)	2.9458484162836998
  (942, 1)	3.0036912059956604
  (942, 0)	3.5539828356237972
this is the 120 epoch
rmse loss on training set is 0.9092804000129358
rmse loss on test set is 0.9215662031925549
for this epoch using 167.56464004516602 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3757930558396594
  (0, 1680)	3.3814505531330856
  (0, 1679)	3.3757930558396594
  (0, 1678)	3.3757930558396594
  (0, 1677)	3.3757930558396594
  (0, 1676)	3.3757930558396594
  (0, 1675)	3.3757930558396594
  (0, 1674)	3.3757930558396594
  (0, 1673)	3.3757930558396594
  (0, 1672)	3.3757930558396594
  (0, 1671)	3.34326890128735
  (0, 1670)	3.3757930558396594
  (0, 1669)	3.3757930558396594
  (0, 1668)	3.3757930558396594
  (0, 1667)	3.3757930558396594
  (0, 1666)	3.3757930558396594
  (0, 1665)	3.3757930558396594
  (0, 1664)	3.3757930558396594
  (0, 1663)	3.406943782678657
  (0, 1662)	3.3757930558396594
  (0, 1661)	3.3757930558396594
  (0, 1660)	3.2767302987359876
  (0, 1659)	3.294191338492809
  (0, 1658)	3.3757930558396594
  (0, 1657)	3.3757930558396594
  :	:
  (942, 24)	2.9562233605129333
  (942, 23)	3.1734047869343525
  (942, 22)	3.6693654521668067
  (942, 21)	3.7507351410120497
  (942, 20)	2.642214815174621
  (942, 19)	3.2457751079851165
  (942, 18)	3.186413084504314
  (942, 17)	3.0512220471603944
  (942, 16)	2.8030738705240816
  (942, 15)	3.0000738156178857
  (942, 14)	3.3418433634998315
  (942, 13)	3.5363099498926247
  (942, 12)	3.077437594144701
  (942, 11)	3.927035718918946
  (942, 10)	3.5209977915686697
  (942, 9)	3.39363392702961
  (942, 8)	3.5254565650783936
  (942, 7)	3.7074699394760398
  (942, 6)	3.503805518675263
  (942, 5)	3.131027273015846
  (942, 4)	3.0121869277812006
  (942, 3)	3.2378730702189222
  (942, 2)	2.9456512806625983
  (942, 1)	3.003654863421758
  (942, 0)	3.554171799892409
this is the 121 epoch
rmse loss on training set is 0.9091282049030347
rmse loss on test set is 0.9214711479118789
for this epoch using 170.9788315296173 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3756765276579332
  (0, 1680)	3.381393970363828
  (0, 1679)	3.3756765276579332
  (0, 1678)	3.3756765276579332
  (0, 1677)	3.3756765276579332
  (0, 1676)	3.3756765276579332
  (0, 1675)	3.3756765276579332
  (0, 1674)	3.3756765276579332
  (0, 1673)	3.3756765276579332
  (0, 1672)	3.3756765276579332
  (0, 1671)	3.3429080643646576
  (0, 1670)	3.3756765276579332
  (0, 1669)	3.3756765276579332
  (0, 1668)	3.3756765276579332
  (0, 1667)	3.3756765276579332
  (0, 1666)	3.3756765276579332
  (0, 1665)	3.3756765276579332
  (0, 1664)	3.3756765276579332
  (0, 1663)	3.4070537039316604
  (0, 1662)	3.3756765276579332
  (0, 1661)	3.3756765276579332
  (0, 1660)	3.275807593098867
  (0, 1659)	3.29341641944576
  (0, 1658)	3.3756765276579332
  (0, 1657)	3.3756765276579332
  :	:
  (942, 24)	2.9563562397881586
  (942, 23)	3.1734760183416433
  (942, 22)	3.670145789539213
  (942, 21)	3.750989557317724
  (942, 20)	2.641096952710931
  (942, 19)	3.246746765864428
  (942, 18)	3.187466863212251
  (942, 17)	3.051645450301826
  (942, 16)	2.802475726832609
  (942, 15)	3.000157487705168
  (942, 14)	3.34206980458611
  (942, 13)	3.53739623330745
  (942, 12)	3.0776892170680363
  (942, 11)	3.927389257041508
  (942, 10)	3.5212214380615743
  (942, 9)	3.3950384733139556
  (942, 8)	3.5258299613131263
  (942, 7)	3.707908626045842
  (942, 6)	3.5040129512192206
  (942, 5)	3.1320377141329754
  (942, 4)	3.0121330450090165
  (942, 3)	3.2380552519763364
  (942, 2)	2.9454580619833175
  (942, 1)	3.003621093130809
  (942, 0)	3.5543605187803515
this is the 122 epoch
rmse loss on training set is 0.9089780184365823
rmse loss on test set is 0.9213775392304927
for this epoch using 178.2750678062439 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3755609251065737
  (0, 1680)	3.3813383264514445
  (0, 1679)	3.3755609251065737
  (0, 1678)	3.3755609251065737
  (0, 1677)	3.3755609251065737
  (0, 1676)	3.3755609251065737
  (0, 1675)	3.3755609251065737
  (0, 1674)	3.3755609251065737
  (0, 1673)	3.3755609251065737
  (0, 1672)	3.3755609251065737
  (0, 1671)	3.3425482679793346
  (0, 1670)	3.3755609251065737
  (0, 1669)	3.3755609251065737
  (0, 1668)	3.3755609251065737
  (0, 1667)	3.3755609251065737
  (0, 1666)	3.3755609251065737
  (0, 1665)	3.3755609251065737
  (0, 1664)	3.3755609251065737
  (0, 1663)	3.4071642789754732
  (0, 1662)	3.3755609251065737
  (0, 1661)	3.3755609251065737
  (0, 1660)	3.2748863732915803
  (0, 1659)	3.2926431387188035
  (0, 1658)	3.3755609251065737
  (0, 1657)	3.3755609251065737
  :	:
  (942, 24)	2.9564907548374526
  (942, 23)	3.1735474891013475
  (942, 22)	3.670914320025181
  (942, 21)	3.7512423876122805
  (942, 20)	2.6399968794117674
  (942, 19)	3.247711144317122
  (942, 18)	3.1885165399006437
  (942, 17)	3.052068952396175
  (942, 16)	2.8018876886532893
  (942, 15)	3.0002428125234886
  (942, 14)	3.3422942620299483
  (942, 13)	3.5384676099613914
  (942, 12)	3.0779416023106965
  (942, 11)	3.9277389595642416
  (942, 10)	3.521443649824894
  (942, 9)	3.3964293607716676
  (942, 8)	3.526198865703713
  (942, 7)	3.7083422797373315
  (942, 6)	3.5042201702360547
  (942, 5)	3.1330468149381843
  (942, 4)	3.012080726549173
  (942, 3)	3.2382372906839043
  (942, 2)	2.9452686992089245
  (942, 1)	3.0035898254210767
  (942, 0)	3.5545489671757506
this is the 123 epoch
rmse loss on training set is 0.9088298021431831
rmse loss on test set is 0.9212853482040932
for this epoch using 170.3828194141388 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3754462250358492
  (0, 1680)	3.3812835977889995
  (0, 1679)	3.3754462250358492
  (0, 1678)	3.3754462250358492
  (0, 1677)	3.3754462250358492
  (0, 1676)	3.3754462250358492
  (0, 1675)	3.3754462250358492
  (0, 1674)	3.3754462250358492
  (0, 1673)	3.3754462250358492
  (0, 1672)	3.3754462250358492
  (0, 1671)	3.3421894883398577
  (0, 1670)	3.3754462250358492
  (0, 1669)	3.3754462250358492
  (0, 1668)	3.3754462250358492
  (0, 1667)	3.3754462250358492
  (0, 1666)	3.3754462250358492
  (0, 1665)	3.3754462250358492
  (0, 1664)	3.3754462250358492
  (0, 1663)	3.4072754866651054
  (0, 1662)	3.3754462250358492
  (0, 1661)	3.3754462250358492
  (0, 1660)	3.27396661439525
  (0, 1659)	3.291871468392122
  (0, 1658)	3.3754462250358492
  (0, 1657)	3.3754462250358492
  :	:
  (942, 24)	2.9566267931788457
  (942, 23)	3.1736191977652584
  (942, 22)	3.6716713198371616
  (942, 21)	3.7514936567012653
  (942, 20)	2.6389143241392765
  (942, 19)	3.248668296367468
  (942, 18)	3.189562114338534
  (942, 17)	3.05249254661813
  (942, 16)	2.801309599786617
  (942, 15)	3.0003297578860164
  (942, 14)	3.342516787568652
  (942, 13)	3.5395243440901063
  (942, 12)	3.0781946678971157
  (942, 11)	3.9280849322037623
  (942, 10)	3.5216644542503124
  (942, 9)	3.3978067360683744
  (942, 8)	3.5265633915284584
  (942, 7)	3.708771022861777
  (942, 6)	3.5044271449742532
  (942, 5)	3.134054568970196
  (942, 4)	3.0120299538956736
  (942, 3)	3.2384191537760274
  (942, 2)	2.9450831322591413
  (942, 1)	3.0035609923580946
  (942, 0)	3.5547371207597496
this is the 124 epoch
rmse loss on training set is 0.9086835185324346
rmse loss on test set is 0.9211945466580435
for this epoch using 168.13721346855164 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.375332405578129
  (0, 1680)	3.3812297620743097
  (0, 1679)	3.375332405578129
  (0, 1678)	3.375332405578129
  (0, 1677)	3.375332405578129
  (0, 1676)	3.375332405578129
  (0, 1675)	3.375332405578129
  (0, 1674)	3.375332405578129
  (0, 1673)	3.375332405578129
  (0, 1672)	3.375332405578129
  (0, 1671)	3.3418317029606497
  (0, 1670)	3.375332405578129
  (0, 1669)	3.375332405578129
  (0, 1668)	3.375332405578129
  (0, 1667)	3.375332405578129
  (0, 1666)	3.375332405578129
  (0, 1665)	3.375332405578129
  (0, 1664)	3.375332405578129
  (0, 1663)	3.4073873071157372
  (0, 1662)	3.375332405578129
  (0, 1661)	3.375332405578129
  (0, 1660)	3.2730482927385567
  (0, 1659)	3.2911013818865076
  (0, 1658)	3.375332405578129
  (0, 1657)	3.375332405578129
  :	:
  (942, 24)	2.9567642474848106
  (942, 23)	3.173691142345025
  (942, 22)	3.6724170570593677
  (942, 21)	3.7517433877556527
  (942, 20)	2.6378490197984195
  (942, 19)	3.2496182747152984
  (942, 18)	3.190603586576835
  (942, 17)	3.052916226266371
  (942, 16)	2.8007413063148707
  (942, 15)	3.0004182921626503
  (942, 14)	3.342737430611458
  (942, 13)	3.540566694490893
  (942, 12)	3.078448334703053
  (942, 11)	3.928427275568197
  (942, 10)	3.5218838770737064
  (942, 9)	3.399170744145841
  (942, 8)	3.5269236478163473
  (942, 7)	3.709194972827245
  (942, 6)	3.504633845533744
  (942, 5)	3.1350609699658287
  (942, 4)	3.011980708598692
  (942, 3)	3.2386008101384904
  (942, 2)	2.9449013019898187
  (942, 1)	3.0035345277290957
  (942, 0)	3.5549249560091107
this is the 125 epoch
rmse loss on training set is 0.9085391310619418
rmse loss on test set is 0.9211051071608597
for this epoch using 172.22005701065063 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3752194460711697
  (0, 1680)	3.381176798232
  (0, 1679)	3.3752194460711697
  (0, 1678)	3.3752194460711697
  (0, 1677)	3.3752194460711697
  (0, 1676)	3.3752194460711697
  (0, 1675)	3.3752194460711697
  (0, 1674)	3.3752194460711697
  (0, 1673)	3.3752194460711697
  (0, 1672)	3.3752194460711697
  (0, 1671)	3.341474890584116
  (0, 1670)	3.3752194460711697
  (0, 1669)	3.3752194460711697
  (0, 1668)	3.3752194460711697
  (0, 1667)	3.3752194460711697
  (0, 1666)	3.3752194460711697
  (0, 1665)	3.3752194460711697
  (0, 1664)	3.3752194460711697
  (0, 1663)	3.4074997216262837
  (0, 1662)	3.3752194460711697
  (0, 1661)	3.3752194460711697
  (0, 1660)	3.272131385823872
  (0, 1659)	3.290332853886047
  (0, 1658)	3.3752194460711697
  (0, 1657)	3.3752194460711697
  :	:
  (942, 24)	2.95690301535567
  (942, 23)	3.173763320353928
  (942, 22)	3.6731517919210463
  (942, 21)	3.751991602442489
  (942, 20)	2.6368007032781837
  (942, 19)	3.250561131741276
  (942, 18)	3.1916409569473556
  (942, 17)	3.0533399847601546
  (942, 16)	2.800182656569509
  (942, 15)	3.0005083842694122
  (942, 14)	3.342956238350834
  (942, 13)	3.5415949146506036
  (942, 12)	3.0787025263753502
  (942, 11)	3.928766085446212
  (942, 10)	3.5221019424886975
  (942, 9)	3.4005215282487504
  (942, 8)	3.527279739532664
  (942, 7)	3.7096142423782346
  (942, 6)	3.504840242878959
  (942, 5)	3.1360660118538277
  (942, 4)	3.011932972267541
  (942, 3)	3.2387822300552545
  (942, 2)	2.9447231501732825
  (942, 1)	3.0035103669987224
  (942, 0)	3.5551124501960025
this is the 126 epoch
rmse loss on training set is 0.908396604106523
rmse loss on test set is 0.9210170029988446
for this epoch using 175.46521067619324 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3751073269857375
  (0, 1680)	3.3811246863400584
  (0, 1679)	3.3751073269857375
  (0, 1678)	3.3751073269857375
  (0, 1677)	3.3751073269857375
  (0, 1676)	3.3751073269857375
  (0, 1675)	3.3751073269857375
  (0, 1674)	3.3751073269857375
  (0, 1673)	3.3751073269857375
  (0, 1672)	3.3751073269857375
  (0, 1671)	3.3411190311070267
  (0, 1670)	3.3751073269857375
  (0, 1669)	3.3751073269857375
  (0, 1668)	3.3751073269857375
  (0, 1667)	3.3751073269857375
  (0, 1666)	3.3751073269857375
  (0, 1665)	3.3751073269857375
  (0, 1664)	3.3751073269857375
  (0, 1663)	3.4076127126072935
  (0, 1662)	3.3751073269857375
  (0, 1661)	3.3751073269857375
  (0, 1660)	3.271215872257523
  (0, 1659)	3.289565860265185
  (0, 1658)	3.3751073269857375
  (0, 1657)	3.3751073269857375
  :	:
  (942, 24)	2.9570429991028364
  (942, 23)	3.1738357288460692
  (942, 22)	3.673875777059448
  (942, 21)	3.752238321045947
  (942, 20)	2.635769115393635
  (942, 19)	3.2514969195117356
  (942, 18)	3.1926742260614644
  (942, 17)	3.0537638156361107
  (942, 16)	2.7996335010991307
  (942, 15)	3.000600003657977
  (942, 14)	3.343173255868526
  (942, 13)	3.542609252870104
  (942, 12)	3.0789571692534756
  (942, 11)	3.929101453079114
  (942, 10)	3.5223186732528995
  (942, 9)	3.401859229950664
  (942, 8)	3.5276317677558393
  (942, 7)	3.7100289398226804
  (942, 6)	3.505046308848087
  (942, 5)	3.137069688748961
  (942, 4)	3.0118867265737386
  (942, 3)	3.23896338515693
  (942, 2)	2.9445486194793276
  (942, 1)	3.0034884472658803
  (942, 0)	3.5552995813851567
this is the 127 epoch
rmse loss on training set is 0.9082559029288311
rmse loss on test set is 0.9209302081518289
for this epoch using 176.4487099647522 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3749960298574906
  (0, 1680)	3.3810734075605247
  (0, 1679)	3.3749960298574906
  (0, 1678)	3.3749960298574906
  (0, 1677)	3.3749960298574906
  (0, 1676)	3.3749960298574906
  (0, 1675)	3.3749960298574906
  (0, 1674)	3.3749960298574906
  (0, 1673)	3.3749960298574906
  (0, 1672)	3.3749960298574906
  (0, 1671)	3.3407641055111896
  (0, 1670)	3.3749960298574906
  (0, 1669)	3.3749960298574906
  (0, 1668)	3.3749960298574906
  (0, 1667)	3.3749960298574906
  (0, 1666)	3.3749960298574906
  (0, 1665)	3.3749960298574906
  (0, 1664)	3.3749960298574906
  (0, 1663)	3.4077262635129717
  (0, 1662)	3.3749960298574906
  (0, 1661)	3.3749960298574906
  (0, 1660)	3.2703017316842606
  (0, 1659)	3.288800378019883
  (0, 1658)	3.3749960298574906
  (0, 1657)	3.3749960298574906
  :	:
  (942, 24)	2.957184105541481
  (942, 23)	3.173908364453333
  (942, 22)	3.674589257773181
  (942, 21)	3.752483562579239
  (942, 20)	2.634754000828753
  (942, 19)	3.2524256897830104
  (942, 18)	3.1937033948084896
  (942, 17)	3.0541877125451036
  (942, 16)	2.7990936926380665
  (942, 15)	3.000693120305414
  (942, 14)	3.34338852623653
  (942, 13)	3.543609952385101
  (942, 12)	3.0792121922927236
  (942, 11)	3.9294334654169374
  (942, 10)	3.5225340907871323
  (942, 9)	3.403183989179264
  (942, 8)	3.5279798298459015
  (942, 7)	3.7104391692470027
  (942, 6)	3.505252016158839
  (942, 5)	3.1380719949463067
  (942, 4)	3.011841953254028
  (942, 3)	3.239144248370795
  (942, 2)	2.9443776534570527
  (942, 1)	3.00346870722179
  (942, 0)	3.5554863284288527
this is the 128 epoch
rmse loss on training set is 0.9081169936509987
rmse loss on test set is 0.9208446972699836
for this epoch using 178.69458651542664 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3748855372227444
  (0, 1680)	3.3810229440742914
  (0, 1679)	3.3748855372227444
  (0, 1678)	3.3748855372227444
  (0, 1677)	3.3748855372227444
  (0, 1676)	3.3748855372227444
  (0, 1675)	3.3748855372227444
  (0, 1674)	3.3748855372227444
  (0, 1673)	3.3748855372227444
  (0, 1672)	3.3748855372227444
  (0, 1671)	3.340410095798158
  (0, 1670)	3.3748855372227444
  (0, 1669)	3.3748855372227444
  (0, 1668)	3.3748855372227444
  (0, 1667)	3.3748855372227444
  (0, 1666)	3.3748855372227444
  (0, 1665)	3.3748855372227444
  (0, 1664)	3.3748855372227444
  (0, 1663)	3.407840358777243
  (0, 1662)	3.3748855372227444
  (0, 1661)	3.3748855372227444
  (0, 1660)	3.2693889447253994
  (0, 1659)	3.28803638520281
  (0, 1658)	3.3748855372227444
  (0, 1657)	3.3748855372227444
  :	:
  (942, 24)	2.9573262457922116
  (942, 23)	3.173981223420121
  (942, 22)	3.675292472266102
  (942, 21)	3.7527273448882235
  (942, 20)	2.6337551080799875
  (942, 19)	3.2533474940054767
  (942, 18)	3.1947284643539073
  (942, 17)	3.0546116692492467
  (942, 16)	2.7985630860755055
  (942, 15)	3.000787704704046
  (942, 14)	3.3436020906132398
  (942, 13)	3.5445972514837334
  (942, 12)	3.079467526989303
  (942, 11)	3.9297622053595664
  (942, 10)	3.522748215268107
  (942, 9)	3.404495944240861
  (942, 8)	3.528324019605105
  (942, 7)	3.7108450307199394
  (942, 6)	3.5054573384110994
  (942, 5)	3.1390729249157965
  (942, 4)	3.011798634113472
  (942, 3)	3.239324793872427
  (942, 2)	2.9442101965172345
  (942, 1)	3.003451087109095
  (942, 0)	3.5556726709599324
this is the 129 epoch
rmse loss on training set is 0.9079798432275662
rmse loss on test set is 0.9207604456515545
for this epoch using 183.3434100151062 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.374775832558024
  (0, 1680)	3.3809732790196296
  (0, 1679)	3.374775832558024
  (0, 1678)	3.374775832558024
  (0, 1677)	3.374775832558024
  (0, 1676)	3.374775832558024
  (0, 1675)	3.374775832558024
  (0, 1674)	3.374775832558024
  (0, 1673)	3.374775832558024
  (0, 1672)	3.374775832558024
  (0, 1671)	3.3400569849277035
  (0, 1670)	3.374775832558024
  (0, 1669)	3.374775832558024
  (0, 1668)	3.374775832558024
  (0, 1667)	3.374775832558024
  (0, 1666)	3.374775832558024
  (0, 1665)	3.374775832558024
  (0, 1664)	3.374775832558024
  (0, 1663)	3.407954983753501
  (0, 1662)	3.374775832558024
  (0, 1661)	3.374775832558024
  (0, 1660)	3.2684774929206974
  (0, 1659)	3.287273860862206
  (0, 1658)	3.374775832558024
  (0, 1657)	3.374775832558024
  :	:
  (942, 24)	2.9574693350914
  (942, 23)	3.1740543016360148
  (942, 22)	3.6759856518822693
  (942, 21)	3.7529696847472747
  (942, 20)	2.6327721894006806
  (942, 19)	3.254262383327155
  (942, 18)	3.195749436137229
  (942, 17)	3.055035679619002
  (942, 16)	2.798041538425163
  (942, 15)	3.0008837278515226
  (942, 14)	3.3438139883350466
  (942, 13)	3.545571383620843
  (942, 12)	3.079723107307027
  (942, 11)	3.9300877519837174
  (942, 10)	3.5229610657150583
  (942, 9)	3.40579523184425
  (942, 8)	3.5286644274309995
  (942, 7)	3.7112466204856918
  (942, 6)	3.505662250086707
  (942, 5)	3.140072473296951
  (942, 4)	3.0117567510286043
  (942, 3)	3.2395049970389316
  (942, 2)	2.944046193915441
  (942, 1)	3.003435528682163
  (942, 0)	3.5558585893831225
this is the 130 epoch
rmse loss on training set is 0.9078444194193904
rmse loss on test set is 0.9206774292215966
for this epoch using 179.25432872772217 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.374666900223055
  (0, 1680)	3.380924396434322
  (0, 1679)	3.374666900223055
  (0, 1678)	3.374666900223055
  (0, 1677)	3.374666900223055
  (0, 1676)	3.374666900223055
  (0, 1675)	3.374666900223055
  (0, 1674)	3.374666900223055
  (0, 1673)	3.374666900223055
  (0, 1672)	3.374666900223055
  (0, 1671)	3.339704756759893
  (0, 1670)	3.374666900223055
  (0, 1669)	3.374666900223055
  (0, 1668)	3.374666900223055
  (0, 1667)	3.374666900223055
  (0, 1666)	3.374666900223055
  (0, 1665)	3.374666900223055
  (0, 1664)	3.374666900223055
  (0, 1663)	3.408070124657809
  (0, 1662)	3.374666900223055
  (0, 1661)	3.374666900223055
  (0, 1660)	3.2675673586735563
  (0, 1659)	3.28651278498424
  (0, 1658)	3.374666900223055
  (0, 1657)	3.374666900223055
  :	:
  (942, 24)	2.9576132926097882
  (942, 23)	3.1741275946664813
  (942, 22)	3.676669021332319
  (942, 21)	3.753210597947866
  (942, 20)	2.6318050007462173
  (942, 19)	3.255170408596952
  (942, 18)	3.196766311869742
  (942, 17)	3.0554597376304393
  (942, 16)	2.797528908795515
  (942, 15)	3.0009811612409956
  (942, 14)	3.3440242570035985
  (942, 13)	3.5465325775291494
  (942, 12)	3.0799788696058266
  (942, 11)	3.930410180756599
  (942, 10)	3.523172660070604
  (942, 9)	3.4070819871238274
  (942, 8)	3.5290011404623733
  (942, 7)	3.7116440311469936
  (942, 6)	3.505866726546875
  (942, 5)	3.1410706348938455
  (942, 4)	3.0117162859504707
  (942, 3)	3.239684834403645
  (942, 2)	2.9438855917356914
  (942, 1)	3.003421975168335
  (942, 0)	3.5560440648648055
this is the 131 epoch
rmse loss on training set is 0.90771069076863
rmse loss on test set is 0.9205956245115345
for this epoch using 172.73756074905396 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3745587254072444
  (0, 1680)	3.3808762812011777
  (0, 1679)	3.3745587254072444
  (0, 1678)	3.3745587254072444
  (0, 1677)	3.3745587254072444
  (0, 1676)	3.3745587254072444
  (0, 1675)	3.3745587254072444
  (0, 1674)	3.3745587254072444
  (0, 1673)	3.3745587254072444
  (0, 1672)	3.3745587254072444
  (0, 1671)	3.339353396000571
  (0, 1670)	3.3745587254072444
  (0, 1669)	3.3745587254072444
  (0, 1668)	3.3745587254072444
  (0, 1667)	3.3745587254072444
  (0, 1666)	3.3745587254072444
  (0, 1665)	3.3745587254072444
  (0, 1664)	3.3745587254072444
  (0, 1663)	3.40818576851561
  (0, 1662)	3.3745587254072444
  (0, 1661)	3.3745587254072444
  (0, 1660)	3.266658525199511
  (0, 1659)	3.2857531384387504
  (0, 1658)	3.3745587254072444
  (0, 1657)	3.3745587254072444
  :	:
  (942, 24)	2.9577580412790088
  (942, 23)	3.174201097781772
  (942, 22)	3.6773427989115377
  (942, 21)	3.7534500993804847
  (942, 20)	2.6308533017199247
  (942, 19)	3.2560716203676883
  (942, 18)	3.1977790935320054
  (942, 17)	3.055883837362526
  (942, 16)	2.79702505836046
  (942, 15)	3.0010799768515524
  (942, 14)	3.3442329325689575
  (942, 13)	3.547481057327428
  (942, 12)	3.080234752571849
  (942, 11)	3.930729563737167
  (942, 10)	3.523383015276303
  (942, 9)	3.408356343662213
  (942, 8)	3.529334242718483
  (942, 7)	3.7120373518386973
  (942, 6)	3.5060707440272436
  (942, 5)	3.142067404670247
  (942, 4)	3.01167722090776
  (942, 3)	3.239864283612442
  (942, 2)	2.943728336874714
  (942, 1)	3.0034103712303013
  (942, 0)	3.556229079321539
this is the 132 epoch
rmse loss on training set is 0.9075786265746626
rmse loss on test set is 0.9205150086396037
for this epoch using 171.99231362342834 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.374451294079222
  (0, 1680)	3.380828918996743
  (0, 1679)	3.374451294079222
  (0, 1678)	3.374451294079222
  (0, 1677)	3.374451294079222
  (0, 1676)	3.374451294079222
  (0, 1675)	3.374451294079222
  (0, 1674)	3.374451294079222
  (0, 1673)	3.374451294079222
  (0, 1672)	3.374451294079222
  (0, 1671)	3.339002888150054
  (0, 1670)	3.374451294079222
  (0, 1669)	3.374451294079222
  (0, 1668)	3.374451294079222
  (0, 1667)	3.374451294079222
  (0, 1666)	3.374451294079222
  (0, 1665)	3.374451294079222
  (0, 1664)	3.374451294079222
  (0, 1663)	3.4083019031114485
  (0, 1662)	3.374451294079222
  (0, 1661)	3.374451294079222
  (0, 1660)	3.265750976477764
  (0, 1659)	3.284994902928168
  (0, 1658)	3.374451294079222
  (0, 1657)	3.374451294079222
  :	:
  (942, 24)	2.9579035076257325
  (942, 23)	3.174274805984074
  (942, 22)	3.67800719671003
  (942, 21)	3.7536882031102996
  (942, 20)	2.629916855519764
  (942, 19)	3.2569660688987536
  (942, 18)	3.1987877833711926
  (942, 17)	3.056307972994586
  (942, 16)	2.79652985033055
  (942, 15)	3.0011801471387782
  (942, 14)	3.3444400494087017
  (942, 13)	3.5484170426257395
  (942, 12)	3.0804906971493806
  (942, 11)	3.9310459697655458
  (942, 10)	3.5235921473432334
  (942, 9)	3.4096184335121977
  (942, 8)	3.5296638152317157
  (942, 7)	3.712426668392309
  (942, 6)	3.506274279630994
  (942, 5)	3.143062777744937
  (942, 4)	3.0116395380098475
  (942, 3)	3.2400433233813692
  (942, 2)	2.943574377026727
  (942, 1)	3.0034006629294345
  (942, 0)	3.5564136154075494
this is the 133 epoch
rmse loss on training set is 0.9074481968709446
rmse loss on test set is 0.9204355592920699
for this epoch using 171.03552436828613 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3743445929393263
  (0, 1680)	3.380782296243103
  (0, 1679)	3.3743445929393263
  (0, 1678)	3.3743445929393263
  (0, 1677)	3.3743445929393263
  (0, 1676)	3.3743445929393263
  (0, 1675)	3.3743445929393263
  (0, 1674)	3.3743445929393263
  (0, 1673)	3.3743445929393263
  (0, 1672)	3.3743445929393263
  (0, 1671)	3.3386532194548364
  (0, 1670)	3.3743445929393263
  (0, 1669)	3.3743445929393263
  (0, 1668)	3.3743445929393263
  (0, 1667)	3.3743445929393263
  (0, 1666)	3.3743445929393263
  (0, 1665)	3.3743445929393263
  (0, 1664)	3.3743445929393263
  (0, 1663)	3.4084185169416896
  (0, 1662)	3.3743445929393263
  (0, 1661)	3.3743445929393263
  (0, 1660)	3.264844697205575
  (0, 1659)	3.2842380609393214
  (0, 1658)	3.3743445929393263
  (0, 1657)	3.3743445929393263
  :	:
  (942, 24)	2.9580496216130063
  (942, 23)	3.174348714032986
  (942, 22)	3.678662420815271
  (942, 21)	3.753924922447034
  (942, 20)	2.62899542888575
  (942, 19)	3.257853804158578
  (942, 18)	3.1997923838982536
  (942, 17)	3.056732138803814
  (942, 16)	2.796043149924612
  (942, 15)	3.001281645025489
  (942, 14)	3.344645640403422
  (942, 13)	3.5493407486279
  (942, 12)	3.0807466464743065
  (942, 11)	3.931359464641509
  (942, 10)	3.523800071417837
  (942, 9)	3.410868387218156
  (942, 8)	3.529989936174282
  (942, 7)	3.712812063492033
  (942, 6)	3.506477311320299
  (942, 5)	3.14405674938722
  (942, 4)	3.011603219449845
  (942, 3)	3.2402219334558775
  (942, 2)	2.9434236606687594
  (942, 1)	3.0033927976901285
  (942, 0)	3.556597656501143
this is the 134 epoch
rmse loss on training set is 0.9073193724028056
rmse loss on test set is 0.9203572547052008
for this epoch using 178.0432105064392 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3742386093750674
  (0, 1680)	3.380736400062461
  (0, 1679)	3.3742386093750674
  (0, 1678)	3.3742386093750674
  (0, 1677)	3.3742386093750674
  (0, 1676)	3.3742386093750674
  (0, 1675)	3.3742386093750674
  (0, 1674)	3.3742386093750674
  (0, 1673)	3.3742386093750674
  (0, 1672)	3.3742386093750674
  (0, 1671)	3.3383043768622382
  (0, 1670)	3.3742386093750674
  (0, 1669)	3.3742386093750674
  (0, 1668)	3.3742386093750674
  (0, 1667)	3.3742386093750674
  (0, 1666)	3.3742386093750674
  (0, 1665)	3.3742386093750674
  (0, 1664)	3.3742386093750674
  (0, 1663)	3.4085355991701767
  (0, 1662)	3.3742386093750674
  (0, 1661)	3.3742386093750674
  (0, 1660)	3.2639396727554066
  (0, 1659)	3.2834825956981883
  (0, 1658)	3.3742386093750674
  (0, 1657)	3.3742386093750674
  :	:
  (942, 24)	2.958196316488608
  (942, 23)	3.1744228164694843
  (942, 22)	3.67930867150737
  (942, 21)	3.754160270009548
  (942, 20)	2.6280887920481244
  (942, 19)	3.258734875826798
  (942, 18)	3.2007928978849747
  (942, 17)	3.057156329162895
  (942, 16)	2.7955648243418874
  (942, 15)	3.0013844438926625
  (942, 14)	3.344849737008572
  (942, 13)	3.5502523862312105
  (942, 12)	3.0810025458092816
  (942, 11)	3.9316701112924335
  (942, 10)	3.524006801843415
  (942, 9)	3.4121063338369133
  (942, 8)	3.5303126809789807
  (942, 7)	3.713193616822831
  (942, 6)	3.506679817906084
  (942, 5)	3.145049315012621
  (942, 4)	3.0115682475075842
  (942, 3)	3.2404000945713833
  (942, 2)	2.9432761370464298
  (942, 1)	3.0033867242650487
  (942, 0)	3.5567811866904946
this is the 135 epoch
rmse loss on training set is 0.9071921246059755
rmse loss on test set is 0.9202800736479603
for this epoch using 188.67622065544128 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3741333314190776
  (0, 1680)	3.380691218234439
  (0, 1679)	3.3741333314190776
  (0, 1678)	3.3741333314190776
  (0, 1677)	3.3741333314190776
  (0, 1676)	3.3741333314190776
  (0, 1675)	3.3741333314190776
  (0, 1674)	3.3741333314190776
  (0, 1673)	3.3741333314190776
  (0, 1672)	3.3741333314190776
  (0, 1671)	3.3379563479776
  (0, 1670)	3.3741333314190776
  (0, 1669)	3.3741333314190776
  (0, 1668)	3.3741333314190776
  (0, 1667)	3.3741333314190776
  (0, 1666)	3.3741333314190776
  (0, 1665)	3.3741333314190776
  (0, 1664)	3.3741333314190776
  (0, 1663)	3.4086531395863835
  (0, 1662)	3.3741333314190776
  (0, 1661)	3.3741333314190776
  (0, 1660)	3.263035889134635
  (0, 1659)	3.282728491127162
  (0, 1658)	3.3741333314190776
  (0, 1657)	3.3741333314190776
  :	:
  (942, 24)	2.9583435286400177
  (942, 23)	3.1744971076384463
  (942, 22)	3.679946143447267
  (942, 21)	3.7543942577853664
  (942, 20)	2.6271967186762413
  (942, 19)	3.259609333296276
  (942, 18)	3.2017893283608396
  (942, 17)	3.057580538537685
  (942, 16)	2.7950947427345323
  (942, 15)	3.0014885175705386
  (942, 14)	3.3450523693229033
  (942, 13)	3.551152162123517
  (942, 12)	3.0812583424805267
  (942, 11)	3.931977969931632
  (942, 10)	3.5242123522175133
  (942, 9)	3.4133324009581805
  (942, 8)	3.530632122454475
  (942, 7)	3.7135714052107307
  (942, 6)	3.506881779036532
  (942, 5)	3.1460404701787015
  (942, 4)	3.0115346045525255
  (942, 3)	3.2405777884151994
  (942, 2)	2.9431317561602053
  (942, 1)	3.0033823927013463
  (942, 0)	3.5569641907586584
this is the 136 epoch
rmse loss on training set is 0.9070664255860138
rmse loss on test set is 0.9202039954053856
for this epoch using 183.49047708511353 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3740287477096724
  (0, 1680)	3.3806467391559885
  (0, 1679)	3.3740287477096724
  (0, 1678)	3.3740287477096724
  (0, 1677)	3.3740287477096724
  (0, 1676)	3.3740287477096724
  (0, 1675)	3.3740287477096724
  (0, 1674)	3.3740287477096724
  (0, 1673)	3.3740287477096724
  (0, 1672)	3.3740287477096724
  (0, 1671)	3.3376091210242103
  (0, 1670)	3.3740287477096724
  (0, 1669)	3.3740287477096724
  (0, 1668)	3.3740287477096724
  (0, 1667)	3.3740287477096724
  (0, 1666)	3.3740287477096724
  (0, 1665)	3.3740287477096724
  (0, 1664)	3.3740287477096724
  (0, 1663)	3.4087711285661744
  (0, 1662)	3.3740287477096724
  (0, 1661)	3.3740287477096724
  (0, 1660)	3.2621333329476028
  (0, 1659)	3.281975731804947
  (0, 1658)	3.3740287477096724
  (0, 1657)	3.3740287477096724
  :	:
  (942, 24)	2.9584911974557855
  (942, 23)	3.1745715817097713
  (942, 22)	3.6805750258582366
  (942, 21)	3.754626897185592
  (942, 20)	2.6263189858281932
  (942, 19)	3.260477225674847
  (942, 18)	3.2027816786098273
  (942, 17)	3.058004761485017
  (942, 16)	2.7946327761806384
  (942, 15)	3.0015938403298987
  (942, 14)	3.3452535661537177
  (942, 13)	3.5520402788778487
  (942, 12)	3.081513985816175
  (942, 11)	3.932283098207323
  (942, 10)	3.5244167354454796
  (942, 9)	3.414546714724348
  (942, 8)	3.530948330895311
  (942, 7)	3.7139455027560166
  (942, 6)	3.507083175184378
  (942, 5)	3.1470302105810863
  (942, 4)	3.0115022730467014
  (942, 3)	3.2407549975898227
  (942, 2)	2.942990468752099
  (942, 1)	3.0033797543077414
  (942, 0)	3.5571466541681134
this is the 137 epoch
rmse loss on training set is 0.9069422480984354
rmse loss on test set is 0.9201289997626173
for this epoch using 176.0882830619812 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.373924847453759
  (0, 1680)	3.3806029518035956
  (0, 1679)	3.373924847453759
  (0, 1678)	3.373924847453759
  (0, 1677)	3.373924847453759
  (0, 1676)	3.373924847453759
  (0, 1675)	3.373924847453759
  (0, 1674)	3.373924847453759
  (0, 1673)	3.373924847453759
  (0, 1672)	3.373924847453759
  (0, 1671)	3.337262684805525
  (0, 1670)	3.373924847453759
  (0, 1669)	3.373924847453759
  (0, 1668)	3.373924847453759
  (0, 1667)	3.373924847453759
  (0, 1666)	3.373924847453759
  (0, 1665)	3.373924847453759
  (0, 1664)	3.373924847453759
  (0, 1663)	3.4088895570349105
  (0, 1662)	3.373924847453759
  (0, 1661)	3.373924847453759
  (0, 1660)	3.261231991360082
  (0, 1659)	3.281224302928771
  (0, 1658)	3.373924847453759
  (0, 1657)	3.373924847453759
  :	:
  (942, 24)	2.9586392651929154
  (942, 23)	3.1746462326981635
  (942, 22)	3.6811955027009122
  (942, 21)	3.754858199095534
  (942, 20)	2.6254553739011537
  (942, 19)	3.2613386017869948
  (942, 18)	3.203769952167044
  (942, 17)	3.0584289926505566
  (942, 16)	2.7941787976575543
  (942, 15)	3.001700386873529
  (942, 14)	3.345453355078987
  (942, 13)	3.5529169350444483
  (942, 12)	3.081769427086206
  (942, 11)	3.9325855513430765
  (942, 10)	3.5246199637904376
  (942, 9)	3.4157493998499873
  (942, 8)	3.531261374186895
  (942, 7)	3.714315980959658
  (942, 6)	3.5072839876331567
  (942, 5)	3.1480185320495773
  (942, 4)	3.0114712355474786
  (942, 3)	3.240931705577527
  (942, 2)	2.9428522262927586
  (942, 1)	3.0033787616225256
  (942, 0)	3.557328563044913
this is the 138 epoch
rmse loss on training set is 0.9068195655296313
rmse loss on test set is 0.9200550669895239
for this epoch using 174.22646379470825 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.37382162039191
  (0, 1680)	3.380559845697812
  (0, 1679)	3.37382162039191
  (0, 1678)	3.37382162039191
  (0, 1677)	3.37382162039191
  (0, 1676)	3.37382162039191
  (0, 1675)	3.37382162039191
  (0, 1674)	3.37382162039191
  (0, 1673)	3.37382162039191
  (0, 1672)	3.37382162039191
  (0, 1671)	3.336917028669644
  (0, 1670)	3.37382162039191
  (0, 1669)	3.37382162039191
  (0, 1668)	3.37382162039191
  (0, 1667)	3.37382162039191
  (0, 1666)	3.37382162039191
  (0, 1665)	3.37382162039191
  (0, 1664)	3.37382162039191
  (0, 1663)	3.409008416432709
  (0, 1662)	3.37382162039191
  (0, 1661)	3.37382162039191
  (0, 1660)	3.260331852065762
  (0, 1659)	3.280474190278808
  (0, 1658)	3.37382162039191
  (0, 1657)	3.37382162039191
  :	:
  (942, 24)	2.9587876768501773
  (942, 23)	3.174721054481776
  (942, 22)	3.681807752842032
  (942, 21)	3.7550881739214064
  (942, 20)	2.6246056665824007
  (942, 19)	3.262193510175247
  (942, 18)	3.204754152815337
  (942, 17)	3.0588532267666957
  (942, 16)	2.7937326820156834
  (942, 15)	3.0018081323278007
  (942, 14)	3.3456517625065576
  (942, 13)	3.553782325240579
  (942, 12)	3.0820246194439567
  (942, 11)	3.9328853822700576
  (942, 10)	3.5248220489198783
  (942, 9)	3.4169405796407752
  (942, 8)	3.531571317905762
  (942, 7)	3.7146829088430917
  (942, 6)	3.507484198462631
  (942, 5)	3.149005430544462
  (942, 4)	3.011441474710332
  (942, 3)	3.2411078967062172
  (942, 2)	2.942716980968996
  (942, 1)	3.003379368382309
  (942, 0)	3.55750990416241
this is the 139 epoch
rmse loss on training set is 0.906698351878428
rmse loss on test set is 0.9199821778259527
for this epoch using 172.18846988677979 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.373719056765672
  (0, 1680)	3.3805174108699747
  (0, 1679)	3.373719056765672
  (0, 1678)	3.373719056765672
  (0, 1677)	3.373719056765672
  (0, 1676)	3.373719056765672
  (0, 1675)	3.373719056765672
  (0, 1674)	3.373719056765672
  (0, 1673)	3.373719056765672
  (0, 1672)	3.373719056765672
  (0, 1671)	3.336572142476007
  (0, 1670)	3.373719056765672
  (0, 1669)	3.373719056765672
  (0, 1668)	3.373719056765672
  (0, 1667)	3.373719056765672
  (0, 1666)	3.373719056765672
  (0, 1665)	3.373719056765672
  (0, 1664)	3.373719056765672
  (0, 1663)	3.40912769868198
  (0, 1662)	3.373719056765672
  (0, 1661)	3.373719056765672
  (0, 1660)	3.2594329032548557
  (0, 1659)	3.279725380184744
  (0, 1658)	3.373719056765672
  (0, 1657)	3.373719056765672
  :	:
  (942, 24)	2.9589363800468877
  (942, 23)	3.1747960408196256
  (942, 22)	3.6824119502173
  (942, 21)	3.755316831633265
  (942, 20)	2.6237696508010746
  (942, 19)	3.263041999101502
  (942, 18)	3.205734284581767
  (942, 17)	3.0592774586506275
  (942, 16)	2.793294305952632
  (942, 15)	3.001917052234543
  (942, 14)	3.3458488137305404
  (942, 13)	3.5546366402379164
  (942, 12)	3.082279517869078
  (942, 11)	3.9331826417516034
  (942, 10)	3.5250230019490796
  (942, 9)	3.418120376012096
  (942, 8)	3.531878225415235
  (942, 7)	3.7150463530621236
  (942, 6)	3.5076837905334317
  (942, 5)	3.1499909021529566
  (942, 4)	3.0114129732915424
  (942, 3)	3.2412835561164823
  (942, 2)	2.9425846856716324
  (942, 1)	3.0033815294917345
  (942, 0)	3.5576906649248845
this is the 140 epoch
rmse loss on training set is 0.9065785817383288
rmse loss on test set is 0.9199103134675122
for this epoch using 172.3795177936554 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.373617147286724
  (0, 1680)	3.380475637830777
  (0, 1679)	3.373617147286724
  (0, 1678)	3.373617147286724
  (0, 1677)	3.373617147286724
  (0, 1676)	3.373617147286724
  (0, 1675)	3.373617147286724
  (0, 1674)	3.373617147286724
  (0, 1673)	3.373617147286724
  (0, 1672)	3.373617147286724
  (0, 1671)	3.3362280165640574
  (0, 1670)	3.373617147286724
  (0, 1669)	3.373617147286724
  (0, 1668)	3.373617147286724
  (0, 1667)	3.373617147286724
  (0, 1666)	3.373617147286724
  (0, 1665)	3.373617147286724
  (0, 1664)	3.373617147286724
  (0, 1663)	3.4092473961567333
  (0, 1662)	3.373617147286724
  (0, 1661)	3.373617147286724
  (0, 1660)	3.2585351335845547
  (0, 1659)	3.27897785949433
  (0, 1658)	3.373617147286724
  (0, 1657)	3.373617147286724
  :	:
  (942, 24)	2.9590853249070954
  (942, 23)	3.1748711853679237
  (942, 22)	3.68300826398842
  (942, 21)	3.755544181804555
  (942, 20)	2.6229471166806095
  (942, 19)	3.263884116548231
  (942, 18)	3.2067103517339874
  (942, 17)	3.0597016832023534
  (942, 16)	2.792863547987718
  (942, 15)	3.0020271225429536
  (942, 14)	3.3460445329850392
  (942, 13)	3.555480067047728
  (942, 12)	3.082534079112052
  (942, 11)	3.9334773785006094
  (942, 10)	3.5252228334817057
  (942, 9)	3.4192889095071406
  (942, 8)	3.5321821579568553
  (942, 7)	3.7154063780148894
  (942, 6)	3.507882747471047
  (942, 5)	3.1509749430857226
  (942, 4)	3.01138571415074
  (942, 3)	3.241458669729897
  (942, 2)	2.9424552939837216
  (942, 1)	3.003385200993864
  (942, 0)	3.5578708333509086
this is the 141 epoch
rmse loss on training set is 0.9064602302803791
rmse loss on test set is 0.9198394555518831
for this epoch using 169.76943969726562 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.373515883107941
  (0, 1680)	3.380434517540893
  (0, 1679)	3.373515883107941
  (0, 1678)	3.373515883107941
  (0, 1677)	3.373515883107941
  (0, 1676)	3.373515883107941
  (0, 1675)	3.373515883107941
  (0, 1674)	3.373515883107941
  (0, 1673)	3.373515883107941
  (0, 1672)	3.373515883107941
  (0, 1671)	3.335884641723725
  (0, 1670)	3.373515883107941
  (0, 1669)	3.373515883107941
  (0, 1668)	3.373515883107941
  (0, 1667)	3.373515883107941
  (0, 1666)	3.373515883107941
  (0, 1665)	3.373515883107941
  (0, 1664)	3.373515883107941
  (0, 1663)	3.409367501653859
  (0, 1662)	3.373515883107941
  (0, 1661)	3.373515883107941
  (0, 1660)	3.2576385321512418
  (0, 1659)	3.2782316155437257
  (0, 1658)	3.373515883107941
  (0, 1657)	3.373515883107941
  :	:
  (942, 24)	2.959234463948814
  (942, 23)	3.1749464816954216
  (942, 22)	3.683596858694632
  (942, 21)	3.7557702336484806
  (942, 20)	2.6221378574918286
  (942, 19)	3.2647199102194837
  (942, 18)	3.2076823587766254
  (942, 17)	3.0601258954028525
  (942, 16)	2.792440288436882
  (942, 15)	3.002138319601759
  (942, 14)	3.3462389434953703
  (942, 13)	3.5563127890039685
  (942, 12)	3.082788261640107
  (942, 11)	3.933769639290113
  (942, 10)	3.5254215536474582
  (942, 9)	3.4204462993147278
  (942, 8)	3.5324831747376275
  (942, 7)	3.715763045944411
  (942, 6)	3.5080810536493683
  (942, 5)	3.1519575496735825
  (942, 4)	3.0113596802535
  (942, 3)	3.2416332242184054
  (942, 2)	2.94232876016917
  (942, 1)	3.0033903400414212
  (942, 0)	3.5580503980566784
this is the 142 epoch
rmse loss on training set is 0.9063432732367249
rmse loss on test set is 0.9197695861456732
for this epoch using 172.63919854164124 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3734152557962576
  (0, 1680)	3.3803940413833042
  (0, 1679)	3.3734152557962576
  (0, 1678)	3.3734152557962576
  (0, 1677)	3.3734152557962576
  (0, 1676)	3.3734152557962576
  (0, 1675)	3.3734152557962576
  (0, 1674)	3.3734152557962576
  (0, 1673)	3.3734152557962576
  (0, 1672)	3.3734152557962576
  (0, 1671)	3.335542009167875
  (0, 1670)	3.3734152557962576
  (0, 1669)	3.3734152557962576
  (0, 1668)	3.3734152557962576
  (0, 1667)	3.3734152557962576
  (0, 1666)	3.3734152557962576
  (0, 1665)	3.3734152557962576
  (0, 1664)	3.3734152557962576
  (0, 1663)	3.409488008366181
  (0, 1662)	3.3734152557962576
  (0, 1661)	3.3734152557962576
  (0, 1660)	3.2567430884645465
  (0, 1659)	3.2774866361297454
  (0, 1658)	3.3734152557962576
  (0, 1657)	3.3734152557962576
  :	:
  (942, 24)	2.9593837519781525
  (942, 23)	3.1750219232976824
  (942, 22)	3.6841778943989048
  (942, 21)	3.755994996051421
  (942, 20)	2.6213416696067227
  (942, 19)	3.2655494275418904
  (942, 18)	3.2086503104475472
  (942, 17)	3.0605500903122738
  (942, 16)	2.792024409387913
  (942, 15)	3.0022506201515347
  (942, 14)	3.3464320675267394
  (942, 13)	3.557134985844207
  (942, 12)	3.0830420255846422
  (942, 11)	3.9340594690574924
  (942, 10)	3.525619172137356
  (942, 9)	3.421592663286634
  (942, 8)	3.5327813330134012
  (942, 7)	3.7161164170359364
  (942, 6)	3.5082786941737605
  (942, 5)	3.152938718364284
  (942, 4)	3.0113348546737084
  (942, 3)	3.2418072069748725
  (942, 2)	2.942205039161538
  (942, 1)	3.0033969048687488
  (942, 0)	3.5582293482392613
this is the 143 epoch
rmse loss on training set is 0.9062276868845994
rmse loss on test set is 0.9197006877317289
for this epoch using 173.76132893562317 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3733152573071084
  (0, 1680)	3.3803542011372762
  (0, 1679)	3.3733152573071084
  (0, 1678)	3.3733152573071084
  (0, 1677)	3.3733152573071084
  (0, 1676)	3.3733152573071084
  (0, 1675)	3.3733152573071084
  (0, 1674)	3.3733152573071084
  (0, 1673)	3.3733152573071084
  (0, 1672)	3.3733152573071084
  (0, 1671)	3.3352001105062086
  (0, 1670)	3.3733152573071084
  (0, 1669)	3.3733152573071084
  (0, 1668)	3.3733152573071084
  (0, 1667)	3.3733152573071084
  (0, 1666)	3.3733152573071084
  (0, 1665)	3.3733152573071084
  (0, 1664)	3.3733152573071084
  (0, 1663)	3.4096089098571074
  (0, 1662)	3.3733152573071084
  (0, 1661)	3.3733152573071084
  (0, 1660)	3.2558487924227557
  (0, 1659)	3.276742909483587
  (0, 1658)	3.3733152573071084
  (0, 1657)	3.3733152573071084
  :	:
  (942, 24)	2.9595331459880985
  (942, 23)	3.1750975036105524
  (942, 22)	3.684751526829106
  (942, 21)	3.7562184776036784
  (942, 20)	2.6205583524528935
  (942, 19)	3.266372715665462
  (942, 18)	3.2096142117140904
  (942, 17)	3.0609742630681964
  (942, 16)	2.7916157946760394
  (942, 15)	3.0023640013171553
  (942, 14)	3.346623926430793
  (942, 13)	3.557946833788544
  (942, 12)	3.083295332689946
  (942, 11)	3.93434691100263
  (942, 10)	3.5258156982364004
  (942, 9)	3.4227281179546782
  (942, 8)	3.533076688168491
  (942, 7)	3.7164665495094105
  (942, 6)	3.5084756548638056
  (942, 5)	3.153918445719468
  (942, 4)	3.0113112205959527
  (942, 3)	3.241980606084693
  (942, 2)	2.9420840865533
  (942, 1)	3.003404854764537
  (942, 0)	3.5584076736599752
this is the 144 epoch
rmse loss on training set is 0.9061134480310161
rmse loss on test set is 0.9196327431969092
for this epoch using 172.5364546775818 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.373215879960511
  (0, 1680)	3.3803149889540367
  (0, 1679)	3.373215879960511
  (0, 1678)	3.373215879960511
  (0, 1677)	3.373215879960511
  (0, 1676)	3.373215879960511
  (0, 1675)	3.373215879960511
  (0, 1674)	3.373215879960511
  (0, 1673)	3.373215879960511
  (0, 1672)	3.373215879960511
  (0, 1671)	3.334858937720963
  (0, 1670)	3.373215879960511
  (0, 1669)	3.373215879960511
  (0, 1668)	3.373215879960511
  (0, 1667)	3.373215879960511
  (0, 1666)	3.373215879960511
  (0, 1665)	3.373215879960511
  (0, 1664)	3.373215879960511
  (0, 1663)	3.4097302000368153
  (0, 1662)	3.373215879960511
  (0, 1661)	3.373215879960511
  (0, 1660)	3.2549556342899626
  (0, 1659)	3.2760004242462744
  (0, 1658)	3.373215879960511
  (0, 1657)	3.373215879960511
  :	:
  (942, 24)	2.9596826050617433
  (942, 23)	3.175173216022652
  (942, 22)	3.6853179075141242
  (942, 21)	3.7564406866275726
  (942, 20)	2.61978770846866
  (942, 19)	3.2671898214644317
  (942, 18)	3.2105740677692767
  (942, 17)	3.0613984088839543
  (942, 16)	2.7912143298598475
  (942, 15)	3.002478440600464
  (942, 14)	3.346814540689796
  (942, 13)	3.5587485056165504
  (942, 12)	3.0835481462633987
  (942, 11)	3.934632006680516
  (942, 10)	3.526011140854181
  (942, 9)	3.4238527785473822
  (942, 8)	3.533369293791782
  (942, 7)	3.716813499707228
  (942, 6)	3.508671922235807
  (942, 5)	3.154896728411651
  (942, 4)	3.0112887613177692
  (942, 3)	3.2421534102984766
  (942, 2)	2.941965858585299
  (942, 1)	3.0034141500452356
  (942, 0)	3.5585853646277372
this is the 145 epoch
rmse loss on training set is 0.9060005339978824
rmse loss on test set is 0.9195657358203281
for this epoch using 172.02260613441467 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3731171164184843
  (0, 1680)	3.3802763973337653
  (0, 1679)	3.3731171164184843
  (0, 1678)	3.3731171164184843
  (0, 1677)	3.3731171164184843
  (0, 1676)	3.3731171164184843
  (0, 1675)	3.3731171164184843
  (0, 1674)	3.3731171164184843
  (0, 1673)	3.3731171164184843
  (0, 1672)	3.3731171164184843
  (0, 1671)	3.334518483143916
  (0, 1670)	3.3731171164184843
  (0, 1669)	3.3731171164184843
  (0, 1668)	3.3731171164184843
  (0, 1667)	3.3731171164184843
  (0, 1666)	3.3731171164184843
  (0, 1665)	3.3731171164184843
  (0, 1664)	3.3731171164184843
  (0, 1663)	3.40985187314
  (0, 1662)	3.3731171164184843
  (0, 1661)	3.3731171164184843
  (0, 1660)	3.254063604674375
  (0, 1659)	3.275259169445482
  (0, 1658)	3.3731171164184843
  (0, 1657)	3.3731171164184843
  :	:
  (942, 24)	2.9598320902797908
  (942, 23)	3.1752490538871148
  (942, 22)	3.685877183915374
  (942, 21)	3.756661631203363
  (942, 20)	2.6190295430587773
  (942, 19)	3.2680007915378555
  (942, 18)	3.211529884027932
  (942, 17)	3.061822523046981
  (942, 16)	2.790819902197515
  (942, 15)	3.0025939158730144
  (942, 14)	3.347003929958793
  (942, 13)	3.559540170742338
  (942, 12)	3.0838004311269542
  (942, 11)	3.934914796088361
  (942, 10)	3.526205508553226
  (942, 9)	3.424966759006348
  (942, 8)	3.5336592017494346
  (942, 7)	3.7171573221776937
  (942, 6)	3.508867483485156
  (942, 5)	3.155873563221363
  (942, 4)	3.0112674602518137
  (942, 3)	3.2423256090056967
  (942, 2)	2.941850312136472
  (942, 1)	3.003424752029155
  (942, 0)	3.55876241198258
this is the 146 epoch
rmse loss on training set is 0.9058889226077249
rmse loss on test set is 0.9194996492619841
for this epoch using 173.50698471069336 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3730189596639986
  (0, 1680)	3.3802384191041472
  (0, 1679)	3.3730189596639986
  (0, 1678)	3.3730189596639986
  (0, 1677)	3.3730189596639986
  (0, 1676)	3.3730189596639986
  (0, 1675)	3.3730189596639986
  (0, 1674)	3.3730189596639986
  (0, 1673)	3.3730189596639986
  (0, 1672)	3.3730189596639986
  (0, 1671)	3.3341787394349116
  (0, 1670)	3.3730189596639986
  (0, 1669)	3.3730189596639986
  (0, 1668)	3.3730189596639986
  (0, 1667)	3.3730189596639986
  (0, 1666)	3.3730189596639986
  (0, 1665)	3.3730189596639986
  (0, 1664)	3.3730189596639986
  (0, 1663)	3.409973923704856
  (0, 1662)	3.3730189596639986
  (0, 1661)	3.3730189596639986
  (0, 1660)	3.2531726945081827
  (0, 1659)	3.2745191344737408
  (0, 1658)	3.3730189596639986
  (0, 1657)	3.3730189596639986
  :	:
  (942, 24)	2.959981564632124
  (942, 23)	3.1753250105325326
  (942, 22)	3.6864294995536837
  (942, 21)	3.756881319192851
  (942, 20)	2.61828366455082
  (942, 19)	3.268805672210322
  (942, 18)	3.212481666122875
  (942, 17)	3.062246600917244
  (942, 16)	2.7904324006233976
  (942, 15)	3.002710405369082
  (942, 14)	3.3471921131057685
  (942, 13)	3.560321995287747
  (942, 12)	3.084052153569951
  (942, 11)	3.935195317747819
  (942, 10)	3.526398809575394
  (942, 9)	3.4260701720022935
  (942, 8)	3.5339464622543333
  (942, 7)	3.717498069754161
  (942, 6)	3.5090623264684866
  (942, 5)	3.1568489470343906
  (942, 4)	3.0112473009279452
  (942, 3)	3.24249719220937
  (942, 2)	2.9417374047139053
  (942, 1)	3.003436623011286
  (942, 0)	3.558938807079331
this is the 147 epoch
rmse loss on training set is 0.9057785921697805
rmse loss on test set is 0.9194344675518394
for this epoch using 174.51182913780212 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.372921402981088
  (0, 1680)	3.380201047400117
  (0, 1679)	3.372921402981088
  (0, 1678)	3.372921402981088
  (0, 1677)	3.372921402981088
  (0, 1676)	3.372921402981088
  (0, 1675)	3.372921402981088
  (0, 1674)	3.372921402981088
  (0, 1673)	3.372921402981088
  (0, 1672)	3.372921402981088
  (0, 1671)	3.3338396995616675
  (0, 1670)	3.372921402981088
  (0, 1669)	3.372921402981088
  (0, 1668)	3.372921402981088
  (0, 1667)	3.372921402981088
  (0, 1666)	3.372921402981088
  (0, 1665)	3.372921402981088
  (0, 1664)	3.372921402981088
  (0, 1663)	3.410096346553498
  (0, 1662)	3.372921402981088
  (0, 1661)	3.372921402981088
  (0, 1660)	3.2522828950284746
  (0, 1659)	3.27378030906802
  (0, 1658)	3.372921402981088
  (0, 1657)	3.372921402981088
  :	:
  (942, 24)	2.9601309929332627
  (942, 23)	3.175401079273137
  (942, 22)	3.6869749941318433
  (942, 21)	3.757099758261068
  (942, 20)	2.617549884152177
  (942, 19)	3.2696045095324697
  (942, 18)	3.2134294199009723
  (942, 17)	3.0626706379257143
  (942, 16)	2.7900517157248985
  (942, 15)	3.0028278876787327
  (942, 14)	3.3473791082498865
  (942, 13)	3.5610941421537086
  (942, 12)	3.084303281303245
  (942, 11)	3.9354736087824627
  (942, 10)	3.526591051866547
  (942, 9)	3.4271631289508093
  (942, 8)	3.5342311239325412
  (942, 7)	3.7178357936303694
  (942, 6)	3.5092564396859145
  (942, 5)	3.15782287683908
  (942, 4)	3.0112282669952193
  (942, 3)	3.2426681505016246
  (942, 2)	2.9416270944430796
  (942, 1)	3.003449726238718
  (942, 0)	3.5591145417714514
this is the 148 epoch
rmse loss on training set is 0.9056695214666842
rmse loss on test set is 0.9193701750792429
for this epoch using 173.9052300453186 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3728244399362333
  (0, 1680)	3.3801642756449164
  (0, 1679)	3.3728244399362333
  (0, 1678)	3.3728244399362333
  (0, 1677)	3.3728244399362333
  (0, 1676)	3.3728244399362333
  (0, 1675)	3.3728244399362333
  (0, 1674)	3.3728244399362333
  (0, 1673)	3.3728244399362333
  (0, 1672)	3.3728244399362333
  (0, 1671)	3.3335013567807454
  (0, 1670)	3.3728244399362333
  (0, 1669)	3.3728244399362333
  (0, 1668)	3.3728244399362333
  (0, 1667)	3.3728244399362333
  (0, 1666)	3.3728244399362333
  (0, 1665)	3.3728244399362333
  (0, 1664)	3.3728244399362333
  (0, 1663)	3.4102191367734775
  (0, 1662)	3.3728244399362333
  (0, 1661)	3.3728244399362333
  (0, 1660)	3.2513941977593954
  (0, 1659)	3.273042683290428
  (0, 1658)	3.3728244399362333
  (0, 1657)	3.3728244399362333
  :	:
  (942, 24)	2.960280341741545
  (942, 23)	3.1754772534183124
  (942, 22)	3.6875138036529513
  (942, 21)	3.7573169558961004
  (942, 20)	2.616828015907671
  (942, 19)	3.2703973492815415
  (942, 18)	3.214373151419259
  (942, 17)	3.063094629572905
  (942, 16)	2.7896777397196475
  (942, 15)	3.00294634174109
  (942, 14)	3.3475649327978845
  (942, 13)	3.5618567710899494
  (942, 12)	3.0845537834145396
  (942, 11)	3.935749704990799
  (942, 10)	3.5267822430992863
  (942, 9)	3.4282457400278017
  (942, 8)	3.5345132338867606
  (942, 7)	3.7181705434319516
  (942, 6)	3.5094498122631497
  (942, 5)	3.158795349723787
  (942, 4)	3.011210342223765
  (942, 3)	3.2428384750402324
  (942, 2)	2.9415193400583797
  (942, 1)	3.0034640258867435
  (942, 0)	3.5592896083951535
this is the 149 epoch
rmse loss on training set is 0.9055616897415268
rmse loss on test set is 0.9193067565827551
for this epoch using 169.6390779018402 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.372728064360929
  (0, 1680)	3.3801280975322916
  (0, 1679)	3.372728064360929
  (0, 1678)	3.372728064360929
  (0, 1677)	3.372728064360929
  (0, 1676)	3.372728064360929
  (0, 1675)	3.372728064360929
  (0, 1674)	3.372728064360929
  (0, 1673)	3.372728064360929
  (0, 1672)	3.372728064360929
  (0, 1671)	3.3331637046198512
  (0, 1670)	3.372728064360929
  (0, 1669)	3.372728064360929
  (0, 1668)	3.372728064360929
  (0, 1667)	3.372728064360929
  (0, 1666)	3.372728064360929
  (0, 1665)	3.372728064360929
  (0, 1664)	3.372728064360929
  (0, 1663)	3.410342289700495
  (0, 1662)	3.372728064360929
  (0, 1661)	3.372728064360929
  (0, 1660)	3.2505065944954614
  (0, 1659)	3.272306247510154
  (0, 1658)	3.372728064360929
  (0, 1657)	3.372728064360929
  :	:
  (942, 24)	2.9604295792818873
  (942, 23)	3.1755535262814933
  (942, 22)	3.6880460605345946
  (942, 21)	3.757532919427153
  (942, 20)	2.616117876657786
  (942, 19)	3.2711842369618234
  (942, 18)	3.21531286694101
  (942, 17)	3.063518571427398
  (942, 16)	2.789310366432995
  (942, 15)	3.0030657468377506
  (942, 14)	3.347749603478773
  (942, 13)	3.562610038762883
  (942, 12)	3.084803630325019
  (942, 11)	3.9360236409150584
  (942, 10)	3.5269723906942825
  (942, 9)	3.4293181141846745
  (942, 8)	3.5347928377570232
  (942, 7)	3.718502367284347
  (942, 6)	3.509642433933752
  (942, 5)	3.1597663628743455
  (942, 4)	3.011193510506621
  (942, 3)	3.2430081575259857
  (942, 2)	2.9414141008938115
  (942, 1)	3.003479487035545
  (942, 0)	3.5594639997536475
this is the 150 epoch
rmse loss on training set is 0.9054550766853587
rmse loss on test set is 0.9192441971402988
for this epoch using 174.86516880989075 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.372632270335219
  (0, 1680)	3.3800925070097296
  (0, 1679)	3.372632270335219
  (0, 1678)	3.372632270335219
  (0, 1677)	3.372632270335219
  (0, 1676)	3.372632270335219
  (0, 1675)	3.372632270335219
  (0, 1674)	3.372632270335219
  (0, 1673)	3.372632270335219
  (0, 1672)	3.372632270335219
  (0, 1671)	3.3328267368610325
  (0, 1670)	3.372632270335219
  (0, 1669)	3.372632270335219
  (0, 1668)	3.372632270335219
  (0, 1667)	3.372632270335219
  (0, 1666)	3.372632270335219
  (0, 1665)	3.372632270335219
  (0, 1664)	3.372632270335219
  (0, 1663)	3.4104658009022066
  (0, 1662)	3.372632270335219
  (0, 1661)	3.372632270335219
  (0, 1660)	3.24962007728577
  (0, 1659)	3.2715709923864256
  (0, 1658)	3.372632270335219
  (0, 1657)	3.372632270335219
  :	:
  (942, 24)	2.960578675371895
  (942, 23)	3.175629891188358
  (942, 22)	3.688571893719312
  (942, 21)	3.7577476560410665
  (942, 20)	2.615419285997491
  (942, 19)	3.2719652178051057
  (942, 18)	3.2162485729318124
  (942, 17)	3.0639424591244757
  (942, 16)	2.7889494912757713
  (942, 15)	3.003186082586338
  (942, 14)	3.3479331363769056
  (942, 13)	3.56335409882198
  (942, 12)	3.085052793747151
  (942, 11)	3.93629544990617
  (942, 10)	3.5271615018399167
  (942, 9)	3.430380359163227
  (942, 8)	3.5350699797787426
  (942, 7)	3.718831311877491
  (942, 6)	3.509834295021457
  (942, 5)	3.160735913571695
  (942, 4)	3.0111777558614143
  (942, 3)	3.243177190180951
  (942, 2)	2.9413113368739414
  (942, 1)	3.0034960756475164
  (942, 0)	3.5596377091017657
this is the 151 epoch
rmse loss on training set is 0.9053496624251253
rmse loss on test set is 0.9191824821596891
for this epoch using 171.75566148757935 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.372537052172359
  (0, 1680)	3.3800574982628504
  (0, 1679)	3.372537052172359
  (0, 1678)	3.372537052172359
  (0, 1677)	3.372537052172359
  (0, 1676)	3.372537052172359
  (0, 1675)	3.372537052172359
  (0, 1674)	3.372537052172359
  (0, 1673)	3.372537052172359
  (0, 1672)	3.372537052172359
  (0, 1671)	3.332490447525032
  (0, 1670)	3.372537052172359
  (0, 1669)	3.372537052172359
  (0, 1668)	3.372537052172359
  (0, 1667)	3.372537052172359
  (0, 1666)	3.372537052172359
  (0, 1665)	3.372537052172359
  (0, 1664)	3.372537052172359
  (0, 1663)	3.410589666162988
  (0, 1662)	3.372537052172359
  (0, 1661)	3.372537052172359
  (0, 1660)	3.248734638419282
  (0, 1659)	3.2708369088525475
  (0, 1658)	3.372537052172359
  (0, 1657)	3.372537052172359
  :	:
  (942, 24)	2.9607276013512878
  (942, 23)	3.1757063414845192
  (942, 22)	3.689091428781094
  (942, 21)	3.7579611727973585
  (942, 20)	2.6147320662356743
  (942, 19)	3.2727403367710535
  (942, 18)	3.217180276055665
  (942, 17)	3.064366288364772
  (942, 16)	2.7885950112223705
  (942, 15)	3.0033073289341887
  (942, 14)	3.3481155469633324
  (942, 13)	3.564089101964418
  (942, 12)	3.085301246643633
  (942, 11)	3.9365651641848753
  (942, 10)	3.5273495835106687
  (942, 9)	3.431432581510285
  (942, 8)	3.535344702838155
  (942, 7)	3.719157422527202
  (942, 6)	3.510025386422593
  (942, 5)	3.1617039991895286
  (942, 4)	3.011163062431988
  (942, 3)	3.2433455657275125
  (942, 2)	2.9412110085050776
  (942, 1)	3.003513758545135
  (942, 0)	3.5598107301308075
this is the 152 epoch
rmse loss on training set is 0.9052454275119673
rmse loss on test set is 0.9191215973694444
for this epoch using 172.96519541740417 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3724424044043517
  (0, 1680)	3.380023065700615
  (0, 1679)	3.3724424044043517
  (0, 1678)	3.3724424044043517
  (0, 1677)	3.3724424044043517
  (0, 1676)	3.3724424044043517
  (0, 1675)	3.3724424044043517
  (0, 1674)	3.3724424044043517
  (0, 1673)	3.3724424044043517
  (0, 1672)	3.3724424044043517
  (0, 1671)	3.3321548308565823
  (0, 1670)	3.3724424044043517
  (0, 1669)	3.3724424044043517
  (0, 1668)	3.3724424044043517
  (0, 1667)	3.3724424044043517
  (0, 1666)	3.3724424044043517
  (0, 1665)	3.3724424044043517
  (0, 1664)	3.3724424044043517
  (0, 1663)	3.41071388146968
  (0, 1662)	3.3724424044043517
  (0, 1661)	3.3724424044043517
  (0, 1660)	3.247850270410985
  (0, 1659)	3.2701039881008147
  (0, 1658)	3.3724424044043517
  (0, 1657)	3.3724424044043517
  :	:
  (942, 24)	2.960876330014383
  (942, 23)	3.175782870542625
  (942, 22)	3.689604788028445
  (942, 21)	3.75817347664189
  (942, 20)	2.614056042355118
  (942, 19)	3.27350963854765
  (942, 18)	3.2181079831710213
  (942, 17)	3.0647900549129363
  (942, 16)	2.7882468247890793
  (942, 15)	3.0034294661521983
  (942, 14)	3.3482968501258807
  (942, 13)	3.564815195998274
  (942, 12)	3.085548963187535
  (942, 11)	3.9368328148994447
  (942, 10)	3.5275366424840624
  (942, 9)	3.432474886592106
  (942, 8)	3.5356170485254523
  (942, 7)	3.7194807432335613
  (942, 6)	3.510215699588675
  (942, 5)	3.1626706171920222
  (942, 4)	3.0111494144899513
  (942, 3)	3.2435132773682094
  (942, 2)	2.941113076866573
  (942, 1)	3.003532503389448
  (942, 0)	3.55998305695367
this is the 153 epoch
rmse loss on training set is 0.9051423529099574
rmse loss on test set is 0.9190615288099448
for this epoch using 173.5566794872284 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.372348321768383
  (0, 1680)	3.3799892039415362
  (0, 1679)	3.372348321768383
  (0, 1678)	3.372348321768383
  (0, 1677)	3.372348321768383
  (0, 1676)	3.372348321768383
  (0, 1675)	3.372348321768383
  (0, 1674)	3.372348321768383
  (0, 1673)	3.372348321768383
  (0, 1672)	3.372348321768383
  (0, 1671)	3.3318198813106
  (0, 1670)	3.372348321768383
  (0, 1669)	3.372348321768383
  (0, 1668)	3.372348321768383
  (0, 1667)	3.372348321768383
  (0, 1666)	3.372348321768383
  (0, 1665)	3.372348321768383
  (0, 1664)	3.372348321768383
  (0, 1663)	3.4108384429982337
  (0, 1662)	3.372348321768383
  (0, 1661)	3.372348321768383
  (0, 1660)	3.246966965988874
  (0, 1659)	3.2693722215684247
  (0, 1658)	3.372348321768383
  (0, 1657)	3.372348321768383
  :	:
  (942, 24)	2.96102483554556
  (942, 23)	3.1758594717689212
  (942, 22)	3.690112090603816
  (942, 21)	3.7583845744193263
  (942, 20)	2.613391041973112
  (942, 19)	3.274273167551473
  (942, 18)	3.2190317013269065
  (942, 17)	3.065213754596408
  (942, 16)	2.7879048320127016
  (942, 15)	3.0035524748288185
  (942, 14)	3.348477060197568
  (942, 13)	3.5655325259041852
  (942, 12)	3.0857959187235826
  (942, 11)	3.937098432180113
  (942, 10)	3.5277226853564154
  (942, 9)	3.433507378608504
  (942, 8)	3.5358870571855268
  (942, 7)	3.7198013167364583
  (942, 6)	3.5104052265092727
  (942, 5)	3.163635765131728
  (942, 4)	3.0111367964360922
  (942, 3)	3.243680318766384
  (942, 2)	2.9410175036024038
  (942, 1)	3.0035522786590496
  (942, 0)	3.5601546840903437
this is the 154 epoch
rmse loss on training set is 0.9050404199851279
rmse loss on test set is 0.9190022628248634
for this epoch using 173.5019166469574 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3722547991941414
  (0, 1680)	3.3799559078007295
  (0, 1679)	3.3722547991941414
  (0, 1678)	3.3722547991941414
  (0, 1677)	3.3722547991941414
  (0, 1676)	3.3722547991941414
  (0, 1675)	3.3722547991941414
  (0, 1674)	3.3722547991941414
  (0, 1673)	3.3722547991941414
  (0, 1672)	3.3722547991941414
  (0, 1671)	3.331485593539198
  (0, 1670)	3.3722547991941414
  (0, 1669)	3.3722547991941414
  (0, 1668)	3.3722547991941414
  (0, 1667)	3.3722547991941414
  (0, 1666)	3.3722547991941414
  (0, 1665)	3.3722547991941414
  (0, 1664)	3.3722547991941414
  (0, 1663)	3.410963347101143
  (0, 1662)	3.3722547991941414
  (0, 1661)	3.3722547991941414
  (0, 1660)	3.246084718081788
  (0, 1659)	3.2686416009241555
  (0, 1658)	3.3722547991941414
  (0, 1657)	3.3722547991941414
  :	:
  (942, 24)	2.9611730934575813
  (942, 23)	3.1759361386093827
  (942, 22)	3.6906134525797722
  (942, 21)	3.7585944728843805
  (942, 20)	2.612736895302584
  (942, 19)	3.275030967928089
  (942, 18)	3.2199514377589717
  (942, 17)	3.0656373833041424
  (942, 16)	2.7875689344294856
  (942, 15)	3.0036763358641134
  (942, 14)	3.3486561909838115
  (942, 13)	3.566241233895457
  (942, 12)	3.086042089730445
  (942, 11)	3.937362045190346
  (942, 10)	3.527907718557493
  (942, 9)	3.434530160606798
  (942, 8)	3.5361547679665133
  (942, 7)	3.720119184568404
  (942, 6)	3.5105939596949747
  (942, 5)	3.1645994406473923
  (942, 4)	3.0111251928017264
  (942, 3)	3.243846684027483
  (942, 2)	2.9409242509128513
  (942, 1)	3.0035730536296827
  (942, 0)	3.5603256064536235
this is the 155 epoch
rmse loss on training set is 0.9049396104949213
rmse loss on test set is 0.9189437860529112
for this epoch using 174.44197297096252 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3721618317918707
  (0, 1680)	3.3799231722777106
  (0, 1679)	3.3721618317918707
  (0, 1678)	3.3721618317918707
  (0, 1677)	3.3721618317918707
  (0, 1676)	3.3721618317918707
  (0, 1675)	3.3721618317918707
  (0, 1674)	3.3721618317918707
  (0, 1673)	3.3721618317918707
  (0, 1672)	3.3721618317918707
  (0, 1671)	3.3311519623795633
  (0, 1670)	3.3721618317918707
  (0, 1669)	3.3721618317918707
  (0, 1668)	3.3721618317918707
  (0, 1667)	3.3721618317918707
  (0, 1666)	3.3721618317918707
  (0, 1665)	3.3721618317918707
  (0, 1664)	3.3721618317918707
  (0, 1663)	3.411088590295725
  (0, 1662)	3.3721618317918707
  (0, 1661)	3.3721618317918707
  (0, 1660)	3.2452035198079505
  (0, 1659)	3.2679121180558806
  (0, 1658)	3.3721618317918707
  (0, 1657)	3.3721618317918707
  :	:
  (942, 24)	2.9613210805326267
  (942, 23)	3.1760128645553487
  (942, 22)	3.691108987051867
  (942, 21)	3.758803178712065
  (942, 20)	2.6120934351138017
  (942, 19)	3.2757830835523576
  (942, 18)	3.220867199885651
  (942, 17)	3.066060936985421
  (942, 16)	2.787239035054239
  (942, 15)	3.003801030464047
  (942, 14)	3.348834255788245
  (942, 13)	3.5669414594768916
  (942, 12)	3.0862874537841813
  (942, 11)	3.9376236821752117
  (942, 10)	3.5280917483639977
  (942, 9)	3.435543334495445
  (942, 8)	3.536420218866259
  (942, 7)	3.720434387104787
  (942, 6)	3.5107818921606953
  (942, 5)	3.1655616414619505
  (942, 4)	3.0111145882499617
  (942, 3)	3.2440123676811314
  (942, 2)	2.940833281546403
  (942, 1)	3.003594798354283
  (942, 0)	3.560495819335247
this is the 156 epoch
rmse loss on training set is 0.9048399065779259
rmse loss on test set is 0.9188860854198326
for this epoch using 176.0940260887146 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.372069414841185
  (0, 1680)	3.379890992545054
  (0, 1679)	3.372069414841185
  (0, 1678)	3.372069414841185
  (0, 1677)	3.372069414841185
  (0, 1676)	3.372069414841185
  (0, 1675)	3.372069414841185
  (0, 1674)	3.372069414841185
  (0, 1673)	3.372069414841185
  (0, 1672)	3.372069414841185
  (0, 1671)	3.3308189828425334
  (0, 1670)	3.372069414841185
  (0, 1669)	3.372069414841185
  (0, 1668)	3.372069414841185
  (0, 1667)	3.372069414841185
  (0, 1666)	3.372069414841185
  (0, 1665)	3.372069414841185
  (0, 1664)	3.372069414841185
  (0, 1663)	3.4112141692530966
  (0, 1662)	3.372069414841185
  (0, 1661)	3.372069414841185
  (0, 1660)	3.2443233644642575
  (0, 1659)	3.2671837650588067
  (0, 1658)	3.372069414841185
  (0, 1657)	3.372069414841185
  :	:
  (942, 24)	2.961468774765887
  (942, 23)	3.1760896431486825
  (942, 22)	3.691598804228429
  (942, 21)	3.7590106985068608
  (942, 20)	2.611460496696656
  (942, 19)	3.2765295580287566
  (942, 18)	3.2217789953042626
  (942, 17)	3.066484411648696
  (942, 16)	2.7869150383597794
  (942, 15)	3.0039265401348376
  (942, 14)	3.349011267437339
  (942, 13)	3.5676333395021023
  (942, 12)	3.0865319895226677
  (942, 11)	3.937883370507117
  (942, 10)	3.528274780912111
  (942, 9)	3.4365470010575345
  (942, 8)	3.5366834467767987
  (942, 7)	3.7207469636116257
  (942, 6)	3.510969017409165
  (942, 5)	3.1665223653805596
  (942, 4)	3.011104967576862
  (942, 3)	3.24417736466389
  (942, 2)	2.940744558791823
  (942, 1)	3.003617483643572
  (942, 0)	3.5606653183923247
this is the 157 epoch
rmse loss on training set is 0.9047412907439913
rmse loss on test set is 0.9188291481306649
for this epoch using 173.14134883880615 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3719775437806025
  (0, 1680)	3.37985936393761
  (0, 1679)	3.3719775437806025
  (0, 1678)	3.3719775437806025
  (0, 1677)	3.3719775437806025
  (0, 1676)	3.3719775437806025
  (0, 1675)	3.3719775437806025
  (0, 1674)	3.3719775437806025
  (0, 1673)	3.3719775437806025
  (0, 1672)	3.3719775437806025
  (0, 1671)	3.3304866501019177
  (0, 1670)	3.3719775437806025
  (0, 1669)	3.3719775437806025
  (0, 1668)	3.3719775437806025
  (0, 1667)	3.3719775437806025
  (0, 1666)	3.3719775437806025
  (0, 1665)	3.3719775437806025
  (0, 1664)	3.3719775437806025
  (0, 1663)	3.4113400807878724
  (0, 1662)	3.3719775437806025
  (0, 1661)	3.3719775437806025
  (0, 1660)	3.243444245516171
  (0, 1659)	3.2664565342244396
  (0, 1658)	3.3719775437806025
  (0, 1657)	3.3719775437806025
  :	:
  (942, 24)	2.9616161553116744
  (942, 23)	3.176166467986597
  (942, 22)	3.6920830115173717
  (942, 21)	3.75921703881112
  (942, 20)	2.610837917823439
  (942, 19)	3.277270434691705
  (942, 18)	3.222686831787147
  (942, 17)	3.066907803360458
  (942, 16)	2.786596850256632
  (942, 15)	3.004052846677456
  (942, 14)	3.3491872383038253
  (942, 13)	3.5683170082295472
  (942, 12)	3.086775676611107
  (942, 11)	3.9381411367287673
  (942, 10)	3.528456822209064
  (942, 9)	3.4375412599640547
  (942, 8)	3.5369444875268816
  (942, 7)	3.721056952291097
  (942, 6)	3.5111553294147706
  (942, 5)	3.167481610288696
  (942, 4)	3.011096315712554
  (942, 3)	3.2443416703025645
  (942, 2)	2.940658046470309
  (942, 1)	3.0036410810471366
  (942, 0)	3.5608340996340586
this is the 158 epoch
rmse loss on training set is 0.904643745864585
rmse loss on test set is 0.918772961662295
for this epoch using 169.59114813804626 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3718862141976618
  (0, 1680)	3.379828281942519
  (0, 1679)	3.3718862141976618
  (0, 1678)	3.3718862141976618
  (0, 1677)	3.3718862141976618
  (0, 1676)	3.3718862141976618
  (0, 1675)	3.3718862141976618
  (0, 1674)	3.3718862141976618
  (0, 1673)	3.3718862141976618
  (0, 1672)	3.3718862141976618
  (0, 1671)	3.330154959484439
  (0, 1670)	3.3718862141976618
  (0, 1669)	3.3718862141976618
  (0, 1668)	3.3718862141976618
  (0, 1667)	3.3718862141976618
  (0, 1666)	3.3718862141976618
  (0, 1665)	3.3718862141976618
  (0, 1664)	3.3718862141976618
  (0, 1663)	3.4114663218484713
  (0, 1662)	3.3718862141976618
  (0, 1661)	3.3718862141976618
  (0, 1660)	3.242566156588306
  (0, 1659)	3.265730418030201
  (0, 1658)	3.3718862141976618
  (0, 1657)	3.3718862141976618
  :	:
  (942, 24)	2.9617632024318667
  (942, 23)	3.176243332726057
  (942, 22)	3.692561713610005
  (942, 21)	3.759422206112474
  (942, 20)	2.610225538712198
  (942, 19)	3.278005756605855
  (942, 18)	3.223590717277869
  (942, 17)	3.0673311082441317
  (942, 16)	2.7862843780729487
  (942, 15)	3.004179932182233
  (942, 14)	3.349362180328997
  (942, 13)	3.568992597377196
  (942, 12)	3.0870184957084215
  (942, 11)	3.9383970065938203
  (942, 10)	3.5286378781438805
  (942, 9)	3.438526209786907
  (942, 8)	3.537203375922688
  (942, 7)	3.7213643903247555
  (942, 6)	3.5113408226076466
  (942, 5)	3.168439374150271
  (942, 4)	3.011088617722191
  (942, 3)	3.244505280298322
  (942, 2)	2.940573708927929
  (942, 1)	3.0036655628350077
  (942, 0)	3.561002159408861
this is the 159 epoch
rmse loss on training set is 0.9045472551635245
rmse loss on test set is 0.9187175137561819
for this epoch using 171.12041592597961 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3717954218197566
  (0, 1680)	3.379797742189788
  (0, 1679)	3.3717954218197566
  (0, 1678)	3.3717954218197566
  (0, 1677)	3.3717954218197566
  (0, 1676)	3.3717954218197566
  (0, 1675)	3.3717954218197566
  (0, 1674)	3.3717954218197566
  (0, 1673)	3.3717954218197566
  (0, 1672)	3.3717954218197566
  (0, 1671)	3.3298239064603736
  (0, 1670)	3.3717954218197566
  (0, 1669)	3.3717954218197566
  (0, 1668)	3.3717954218197566
  (0, 1667)	3.3717954218197566
  (0, 1666)	3.3717954218197566
  (0, 1665)	3.3717954218197566
  (0, 1664)	3.3717954218197566
  (0, 1663)	3.411592889508099
  (0, 1662)	3.3717954218197566
  (0, 1661)	3.3717954218197566
  (0, 1660)	3.2416890914555467
  (0, 1659)	3.2650054091296674
  (0, 1658)	3.3717954218197566
  (0, 1657)	3.3717954218197566
  :	:
  (942, 24)	2.9619098974466698
  (942, 23)	3.1763202310877574
  (942, 22)	3.6930350125622007
  (942, 21)	3.759626206850636
  (942, 20)	2.609623201990607
  (942, 19)	3.2787355665663993
  (942, 18)	3.2244906598873895
  (942, 17)	3.0677543224790034
  (942, 16)	2.7859775305347174
  (942, 15)	3.0043077790236223
  (942, 14)	3.3495361050438928
  (942, 13)	3.569660236175993
  (942, 12)	3.0872604284347456
  (942, 11)	3.9386510051052652
  (942, 10)	3.528817954497215
  (942, 9)	3.4395019480117646
  (942, 8)	3.537460145786799
  (942, 7)	3.7216693139147776
  (942, 6)	3.5115254918581122
  (942, 5)	3.1693956550058693
  (942, 4)	3.0110818588068904
  (942, 3)	3.2446681907112596
  (942, 2)	2.9404915110280645
  (942, 1)	3.0036909019796947
  (942, 0)	3.5611694943917755
this is the 160 epoch
rmse loss on training set is 0.904451802207938
rmse loss on test set is 0.9186627924113882
for this epoch using 171.27075362205505 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.371705162505424
  (0, 1680)	3.3797677404434396
  (0, 1679)	3.371705162505424
  (0, 1678)	3.371705162505424
  (0, 1677)	3.371705162505424
  (0, 1676)	3.371705162505424
  (0, 1675)	3.371705162505424
  (0, 1674)	3.371705162505424
  (0, 1673)	3.371705162505424
  (0, 1672)	3.371705162505424
  (0, 1671)	3.3294934866346733
  (0, 1670)	3.371705162505424
  (0, 1669)	3.371705162505424
  (0, 1668)	3.371705162505424
  (0, 1667)	3.371705162505424
  (0, 1666)	3.371705162505424
  (0, 1665)	3.371705162505424
  (0, 1664)	3.371705162505424
  (0, 1663)	3.411719780956261
  (0, 1662)	3.371705162505424
  (0, 1661)	3.371705162505424
  (0, 1660)	3.240813044034741
  (0, 1659)	3.2642815003433636
  (0, 1658)	3.371705162505424
  (0, 1657)	3.371705162505424
  :	:
  (942, 24)	2.962056222687483
  (942, 23)	3.1763971568598826
  (942, 22)	3.693503007872773
  (942, 21)	3.759829047423331
  (942, 20)	2.6090307526603396
  (942, 19)	3.279459907099434
  (942, 18)	3.2253866678902745
  (942, 17)	3.0681774422991697
  (942, 16)	2.785676217746206
  (942, 15)	3.004436369855014
  (942, 14)	3.3497090235895106
  (942, 13)	3.570320051421994
  (942, 12)	3.087501457339736
  (942, 11)	3.9389031565515
  (942, 10)	3.5289970569505553
  (942, 9)	3.440468571050736
  (942, 8)	3.5377148299955246
  (942, 7)	3.7219717583231597
  (942, 6)	3.5117093324613164
  (942, 5)	3.1703504509710263
  (942, 4)	3.011076024304556
  (942, 3)	3.244830397945646
  (942, 2)	2.9404114181440972
  (942, 1)	3.0037170721386617
  (942, 0)	3.5613361015722385
this is the 161 epoch
rmse loss on training set is 0.9043573708995523
rmse loss on test set is 0.9186087858778118
for this epoch using 171.01700735092163 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3716154322362897
  (0, 1680)	3.379738272593264
  (0, 1679)	3.3716154322362897
  (0, 1678)	3.3716154322362897
  (0, 1677)	3.3716154322362897
  (0, 1676)	3.3716154322362897
  (0, 1675)	3.3716154322362897
  (0, 1674)	3.3716154322362897
  (0, 1673)	3.3716154322362897
  (0, 1672)	3.3716154322362897
  (0, 1671)	3.3291636957387305
  (0, 1670)	3.3716154322362897
  (0, 1669)	3.3716154322362897
  (0, 1668)	3.3716154322362897
  (0, 1667)	3.3716154322362897
  (0, 1666)	3.3716154322362897
  (0, 1665)	3.3716154322362897
  (0, 1664)	3.3716154322362897
  (0, 1663)	3.411846993490776
  (0, 1662)	3.3716154322362897
  (0, 1661)	3.3716154322362897
  (0, 1660)	3.2399380083768765
  (0, 1659)	3.263558684650153
  (0, 1658)	3.3716154322362897
  (0, 1657)	3.3716154322362897
  :	:
  (942, 24)	2.9622021614518728
  (942, 23)	3.176474103901422
  (942, 22)	3.693965796559275
  (942, 21)	3.7600307341917554
  (942, 20)	2.608448038061995
  (942, 19)	3.2801788204622078
  (942, 18)	3.2262787497210117
  (942, 17)	3.0686004639925764
  (942, 16)	2.7853803511706205
  (942, 15)	3.004565687603766
  (942, 14)	3.3498809467360218
  (942, 13)	3.570972167527358
  (942, 12)	3.0877415658718816
  (942, 11)	3.939153484540546
  (942, 10)	3.5291751910945752
  (942, 9)	3.441426174254824
  (942, 8)	3.5379674605146
  (942, 7)	3.72227175790904
  (942, 6)	3.5118923401223863
  (942, 5)	3.1713037602345113
  (942, 4)	3.011071099690656
  (942, 3)	3.2449918987356625
  (942, 2)	2.9403333961521856
  (942, 1)	3.003744047637265
  (942, 0)	3.56150197824223
this is the 162 epoch
rmse loss on training set is 0.904263945466215
rmse loss on test set is 0.9185554826495912
for this epoch using 170.58498334884644 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3715262271093955
  (0, 1680)	3.3797093346470404
  (0, 1679)	3.3715262271093955
  (0, 1678)	3.3715262271093955
  (0, 1677)	3.3715262271093955
  (0, 1676)	3.3715262271093955
  (0, 1675)	3.3715262271093955
  (0, 1674)	3.3715262271093955
  (0, 1673)	3.3715262271093955
  (0, 1672)	3.3715262271093955
  (0, 1671)	3.3288345296226036
  (0, 1670)	3.3715262271093955
  (0, 1669)	3.3715262271093955
  (0, 1668)	3.3715262271093955
  (0, 1667)	3.3715262271093955
  (0, 1666)	3.3715262271093955
  (0, 1665)	3.3715262271093955
  (0, 1664)	3.3715262271093955
  (0, 1663)	3.411974524510413
  (0, 1662)	3.3715262271093955
  (0, 1661)	3.3715262271093955
  (0, 1660)	3.2390639786597855
  (0, 1659)	3.26283695517911
  (0, 1658)	3.3715262271093955
  (0, 1657)	3.3715262271093955
  :	:
  (942, 24)	2.962347697960504
  (942, 23)	3.1765510661452496
  (942, 22)	3.6944234732313395
  (942, 21)	3.7602312734852985
  (942, 20)	2.607874907840505
  (942, 19)	3.2808923486435217
  (942, 18)	3.227166913970205
  (942, 17)	3.069023383899959
  (942, 16)	2.7850898436110776
  (942, 15)	3.0046957154662195
  (942, 14)	3.350051884901006
  (942, 13)	3.571616706570119
  (942, 12)	3.087980738348668
  (942, 11)	3.939402012032201
  (942, 10)	3.5293523624369434
  (942, 9)	3.442374851926201
  (942, 8)	3.5382180684333804
  (942, 7)	3.722569346164266
  (942, 6)	3.5120745109417557
  (942, 5)	3.172255581056714
  (942, 4)	3.011067070578875
  (942, 3)	3.2451526901318086
  (942, 2)	2.940257411424169
  (942, 1)	3.0037718034521483
  (942, 0)	3.561667121984629
this is the 163 epoch
rmse loss on training set is 0.904171510453715
rmse loss on test set is 0.9185028714587918
for this epoch using 167.97351026535034 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3714375433301806
  (0, 1680)	3.37968092272325
  (0, 1679)	3.3714375433301806
  (0, 1678)	3.3714375433301806
  (0, 1677)	3.3714375433301806
  (0, 1676)	3.3714375433301806
  (0, 1675)	3.3714375433301806
  (0, 1674)	3.3714375433301806
  (0, 1673)	3.3714375433301806
  (0, 1672)	3.3714375433301806
  (0, 1671)	3.3285059842477587
  (0, 1670)	3.3714375433301806
  (0, 1669)	3.3714375433301806
  (0, 1668)	3.3714375433301806
  (0, 1667)	3.3714375433301806
  (0, 1666)	3.3714375433301806
  (0, 1665)	3.3714375433301806
  (0, 1664)	3.3714375433301806
  (0, 1663)	3.412102371507891
  (0, 1662)	3.3714375433301806
  (0, 1661)	3.3714375433301806
  (0, 1660)	3.238190949181268
  (0, 1659)	3.2621163052019213
  (0, 1658)	3.3714375433301806
  (0, 1657)	3.3714375433301806
  :	:
  (942, 24)	2.962492817315969
  (942, 23)	3.176628037600859
  (942, 22)	3.694876130161546
  (942, 21)	3.760430671605764
  (942, 20)	2.6073112139110215
  (942, 19)	3.281600533364032
  (942, 18)	3.2280511693809837
  (942, 17)	3.069446198413939
  (942, 16)	2.7848046091917342
  (942, 15)	3.004826436902934
  (942, 14)	3.3502218481668895
  (942, 13)	3.5722537883428287
  (942, 12)	3.088218959927637
  (942, 11)	3.939648761368518
  (942, 10)	3.5295285764094
  (942, 9)	3.4433146973303304
  (942, 8)	3.538466683997645
  (942, 7)	3.7228645557472904
  (942, 6)	3.512255841400908
  (942, 5)	3.173205911768064
  (942, 4)	3.0110639227217013
  (942, 3)	3.2453127694876533
  (942, 2)	2.940183430820609
  (942, 1)	3.0038003151949972
  (942, 0)	3.56183153066209
this is the 164 epoch
rmse loss on training set is 0.904080050717773
rmse loss on test set is 0.918450941269246
for this epoch using 168.37349462509155 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3713493772056897
  (0, 1680)	3.3796530330442778
  (0, 1679)	3.3713493772056897
  (0, 1678)	3.3713493772056897
  (0, 1677)	3.3713493772056897
  (0, 1676)	3.3713493772056897
  (0, 1675)	3.3713493772056897
  (0, 1674)	3.3713493772056897
  (0, 1673)	3.3713493772056897
  (0, 1672)	3.3713493772056897
  (0, 1671)	3.328178055680242
  (0, 1670)	3.3713493772056897
  (0, 1669)	3.3713493772056897
  (0, 1668)	3.3713493772056897
  (0, 1667)	3.3713493772056897
  (0, 1666)	3.3713493772056897
  (0, 1665)	3.3713493772056897
  (0, 1664)	3.3713493772056897
  (0, 1663)	3.4122305320633655
  (0, 1662)	3.3713493772056897
  (0, 1661)	3.3713493772056897
  (0, 1660)	3.2373189143526315
  (0, 1659)	3.2613967281256375
  (0, 1658)	3.3713493772056897
  (0, 1657)	3.3713493772056897
  :	:
  (942, 24)	2.9626375054634226
  (942, 23)	3.1767050123568956
  (942, 22)	3.695323857354055
  (942, 21)	3.7606289348311357
  (942, 20)	2.606756810425346
  (942, 19)	3.2823034160765987
  (942, 18)	3.2289315248452755
  (942, 17)	3.069868903978083
  (942, 16)	2.784524563339203
  (942, 15)	3.0049578356339697
  (942, 14)	3.3503908462974685
  (942, 13)	3.5728835304000843
  (942, 12)	3.0884562165782485
  (942, 11)	3.9398937543024433
  (942, 10)	3.529703838374367
  (942, 9)	3.444245802707881
  (942, 8)	3.5387133366409067
  (942, 7)	3.7231574185153837
  (942, 6)	3.5124363283483944
  (942, 5)	3.17415475076752
  (942, 4)	3.0110616420109944
  (942, 3)	3.2454721344472635
  (942, 2)	2.940111421683957
  (942, 1)	3.003829559096764
  (942, 0)	3.561995202406048
this is the 165 epoch
rmse loss on training set is 0.9039895514163643
rmse loss on test set is 0.9183996812705932
for this epoch using 167.48384428024292 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3712617251383743
  (0, 1680)	3.379625661929981
  (0, 1679)	3.3712617251383743
  (0, 1678)	3.3712617251383743
  (0, 1677)	3.3712617251383743
  (0, 1676)	3.3712617251383743
  (0, 1675)	3.3712617251383743
  (0, 1674)	3.3712617251383743
  (0, 1673)	3.3712617251383743
  (0, 1672)	3.3712617251383743
  (0, 1671)	3.327850740084304
  (0, 1670)	3.3712617251383743
  (0, 1669)	3.3712617251383743
  (0, 1668)	3.3712617251383743
  (0, 1667)	3.3712617251383743
  (0, 1666)	3.3712617251383743
  (0, 1665)	3.3712617251383743
  (0, 1664)	3.3712617251383743
  (0, 1663)	3.4123590038383393
  (0, 1662)	3.3712617251383743
  (0, 1661)	3.3712617251383743
  (0, 1660)	3.236447868692675
  (0, 1659)	3.26067821748599
  (0, 1658)	3.3712617251383743
  (0, 1657)	3.3712617251383743
  :	:
  (942, 24)	2.962781749152958
  (942, 23)	3.1767819845833785
  (942, 22)	3.695766742610918
  (942, 21)	3.7608260694188376
  (942, 20)	2.606211553738799
  (942, 19)	3.2830010379666756
  (942, 18)	3.229807989400274
  (942, 17)	3.0702914970859534
  (942, 16)	2.7842496227641793
  (942, 15)	3.00508989563429
  (942, 14)	3.3505588887536124
  (942, 13)	3.5735060481049525
  (942, 12)	3.088692495054613
  (942, 11)	3.940137012025002
  (942, 10)	3.5298781536309716
  (942, 9)	3.4451682592865125
  (942, 8)	3.5389580550144757
  (942, 7)	3.7234479655553927
  (942, 6)	3.512615968986282
  (942, 5)	3.1751020965210093
  (942, 4)	3.0110602144784115
  (942, 3)	3.2456307829329627
  (942, 2)	2.9400413518318183
  (942, 1)	3.0038595119922458
  (942, 0)	3.562158135606208
this is the 166 epoch
rmse loss on training set is 0.9038999980022465
rmse loss on test set is 0.9183490808725028
for this epoch using 167.2536916732788 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3711745836202116
  (0, 1680)	3.3795988057917485
  (0, 1679)	3.3711745836202116
  (0, 1678)	3.3711745836202116
  (0, 1677)	3.3711745836202116
  (0, 1676)	3.3711745836202116
  (0, 1675)	3.3711745836202116
  (0, 1674)	3.3711745836202116
  (0, 1673)	3.3711745836202116
  (0, 1672)	3.3711745836202116
  (0, 1671)	3.327524033716391
  (0, 1670)	3.3711745836202116
  (0, 1669)	3.3711745836202116
  (0, 1668)	3.3711745836202116
  (0, 1667)	3.3711745836202116
  (0, 1666)	3.3711745836202116
  (0, 1665)	3.3711745836202116
  (0, 1664)	3.3711745836202116
  (0, 1663)	3.4124877845699526
  (0, 1662)	3.3711745836202116
  (0, 1661)	3.3711745836202116
  (0, 1660)	3.2355778068219974
  (0, 1659)	3.25996076694101
  (0, 1658)	3.3711745836202116
  (0, 1657)	3.3711745836202116
  :	:
  (942, 24)	2.9629255359035804
  (942, 23)	3.1768589485337024
  (942, 22)	3.696204871596253
  (942, 21)	3.7610220816085573
  (942, 20)	2.6056753023776063
  (942, 19)	3.283693439952671
  (942, 18)	3.2306805722247995
  (942, 17)	3.0707139742802867
  (942, 16)	2.7839797054433144
  (942, 15)	3.0052226011292755
  (942, 14)	3.350725984708247
  (942, 13)	3.5741214546743296
  (942, 12)	3.0889277828690274
  (942, 11)	3.9403785551908252
  (942, 10)	3.530051527420535
  (942, 9)	3.446082157292452
  (942, 8)	3.5392008670162887
  (942, 7)	3.7237362272130485
  (942, 6)	3.5127947608568695
  (942, 5)	3.1760479475600776
  (942, 4)	3.0110596262957774
  (942, 3)	3.245788713133702
  (942, 2)	2.939973189550343
  (942, 1)	3.0038901513050904
  (942, 0)	3.562320328900292
this is the 167 epoch
rmse loss on training set is 0.9038113762156709
rmse loss on test set is 0.9182991296990987
for this epoch using 171.35517930984497 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.371087949227187
  (0, 1680)	3.3795724611268065
  (0, 1679)	3.371087949227187
  (0, 1678)	3.371087949227187
  (0, 1677)	3.371087949227187
  (0, 1676)	3.371087949227187
  (0, 1675)	3.371087949227187
  (0, 1674)	3.371087949227187
  (0, 1673)	3.371087949227187
  (0, 1672)	3.371087949227187
  (0, 1671)	3.327197932919555
  (0, 1670)	3.371087949227187
  (0, 1669)	3.371087949227187
  (0, 1668)	3.371087949227187
  (0, 1667)	3.371087949227187
  (0, 1666)	3.371087949227187
  (0, 1665)	3.371087949227187
  (0, 1664)	3.371087949227187
  (0, 1663)	3.4126168720656596
  (0, 1662)	3.371087949227187
  (0, 1661)	3.371087949227187
  (0, 1660)	3.2347087234576803
  (0, 1659)	3.2592443702650358
  (0, 1658)	3.371087949227187
  (0, 1657)	3.371087949227187
  :	:
  (942, 24)	2.9630688539688204
  (942, 23)	3.1769358985464113
  (942, 22)	3.696638327898333
  (942, 21)	3.7612169776247426
  (942, 20)	2.605147917006707
  (942, 19)	3.2843806626863463
  (942, 18)	3.23154928263581
  (942, 17)	3.071136332152073
  (942, 16)	2.7837147306012993
  (942, 15)	3.0053559365902833
  (942, 14)	3.3508921430605847
  (942, 13)	3.5747298612233154
  (942, 12)	3.0891620682662584
  (942, 11)	3.9406184039423806
  (942, 10)	3.5302239649316562
  (942, 9)	3.44698758596196
  (942, 8)	3.5394417998184053
  (942, 7)	3.7240222331208885
  (942, 6)	3.51297270182982
  (942, 5)	3.17699230248041
  (942, 4)	3.011059863775428
  (942, 3)	3.245945923493763
  (942, 2)	2.9399069035877194
  (942, 1)	3.0039214550331708
  (942, 0)	3.5624817811640668
this is the 168 epoch
rmse loss on training set is 0.9037236720773212
rmse loss on test set is 0.9182498175835301
for this epoch using 170.2727460861206 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3710018186142126
  (0, 1680)	3.3795466245130505
  (0, 1679)	3.3710018186142126
  (0, 1678)	3.3710018186142126
  (0, 1677)	3.3710018186142126
  (0, 1676)	3.3710018186142126
  (0, 1675)	3.3710018186142126
  (0, 1674)	3.3710018186142126
  (0, 1673)	3.3710018186142126
  (0, 1672)	3.3710018186142126
  (0, 1671)	3.3268724341181772
  (0, 1670)	3.3710018186142126
  (0, 1669)	3.3710018186142126
  (0, 1668)	3.3710018186142126
  (0, 1667)	3.3710018186142126
  (0, 1666)	3.3710018186142126
  (0, 1665)	3.3710018186142126
  (0, 1664)	3.3710018186142126
  (0, 1663)	3.4127462641982285
  (0, 1662)	3.3710018186142126
  (0, 1661)	3.3710018186142126
  (0, 1660)	3.2338406134083297
  (0, 1659)	3.258529021343166
  (0, 1658)	3.3710018186142126
  (0, 1657)	3.3710018186142126
  :	:
  (942, 24)	2.9632116923038314
  (942, 23)	3.1770128290467436
  (942, 22)	3.6970671930897265
  (942, 21)	3.761410763678684
  (942, 20)	2.604629260398084
  (942, 19)	3.2850627465532414
  (942, 18)	3.232414130084888
  (942, 17)	3.0715585673397388
  (942, 16)	2.783454618693166
  (942, 15)	3.00548988673041
  (942, 14)	3.351057372449627
  (942, 13)	3.5753313768085433
  (942, 12)	3.0893953401986014
  (942, 11)	3.940856577932816
  (942, 10)	3.530395471304843
  (942, 9)	3.447884633552612
  (942, 8)	3.5396808798935147
  (942, 7)	3.7243060122248424
  (942, 6)	3.5131497900895186
  (942, 5)	3.1779351599405214
  (942, 4)	3.0110609133704225
  (942, 3)	3.246102412701934
  (942, 2)	2.939842463147787
  (942, 1)	3.0039534017342704
  (942, 0)	3.5626424915017325
this is the 169 epoch
rmse loss on training set is 0.9036368718815323
rmse loss on test set is 0.9182011345627095
for this epoch using 174.4623510837555 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3709161885102272
  (0, 1680)	3.379521292604038
  (0, 1679)	3.3709161885102272
  (0, 1678)	3.3709161885102272
  (0, 1677)	3.3709161885102272
  (0, 1676)	3.3709161885102272
  (0, 1675)	3.3709161885102272
  (0, 1674)	3.3709161885102272
  (0, 1673)	3.3709161885102272
  (0, 1672)	3.3709161885102272
  (0, 1671)	3.326547533813073
  (0, 1670)	3.3709161885102272
  (0, 1669)	3.3709161885102272
  (0, 1668)	3.3709161885102272
  (0, 1667)	3.3709161885102272
  (0, 1666)	3.3709161885102272
  (0, 1665)	3.3709161885102272
  (0, 1664)	3.3709161885102272
  (0, 1663)	3.412875958901091
  (0, 1662)	3.3709161885102272
  (0, 1661)	3.3709161885102272
  (0, 1660)	3.2329734715693617
  (0, 1659)	3.257814714165914
  (0, 1658)	3.3709161885102272
  (0, 1657)	3.3709161885102272
  :	:
  (942, 24)	2.9633540405339094
  (942, 23)	3.1770897345480233
  (942, 22)	3.697491546785342
  (942, 21)	3.7616034459703673
  (942, 20)	2.604119197399511
  (942, 19)	3.2857397316731003
  (942, 18)	3.2332751241548046
  (942, 17)	3.071980676528339
  (942, 16)	2.7831992913868544
  (942, 15)	3.0056244365002107
  (942, 14)	3.3512216812670417
  (942, 13)	3.5759261084704783
  (942, 12)	3.0896275883017075
  (942, 11)	3.9410930963474926
  (942, 10)	3.530566051636728
  (942, 9)	3.448773387354415
  (942, 8)	3.5399181330402003
  (942, 7)	3.7245875928096517
  (942, 6)	3.513326024122892
  (942, 5)	3.1788765186604007
  (942, 4)	3.0110627616747547
  (942, 3)	3.2462581796811323
  (942, 2)	2.9397798378837305
  (942, 1)	3.0039859705122187
  (942, 0)	3.562802459236631
this is the 170 epoch
rmse loss on training set is 0.9035509621895953
rmse loss on test set is 0.9181530708722269
for this epoch using 170.71249556541443 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.370831055713695
  (0, 1680)	3.3794964621243935
  (0, 1679)	3.370831055713695
  (0, 1678)	3.370831055713695
  (0, 1677)	3.370831055713695
  (0, 1676)	3.370831055713695
  (0, 1675)	3.370831055713695
  (0, 1674)	3.370831055713695
  (0, 1673)	3.370831055713695
  (0, 1672)	3.370831055713695
  (0, 1671)	3.326223228576813
  (0, 1670)	3.370831055713695
  (0, 1669)	3.370831055713695
  (0, 1668)	3.370831055713695
  (0, 1667)	3.370831055713695
  (0, 1666)	3.370831055713695
  (0, 1665)	3.370831055713695
  (0, 1664)	3.370831055713695
  (0, 1663)	3.4130059541639404
  (0, 1662)	3.370831055713695
  (0, 1661)	3.370831055713695
  (0, 1660)	3.232107292918583
  (0, 1659)	3.2571014428242338
  (0, 1658)	3.370831055713695
  (0, 1657)	3.370831055713695
  :	:
  (942, 24)	2.9634958889243928
  (942, 23)	3.1771666096527986
  (942, 22)	3.6979114666988004
  (942, 21)	3.7617950306899623
  (942, 20)	2.6036175949037577
  (942, 19)	3.2864116579003326
  (942, 18)	3.2341322745560834
  (942, 17)	3.0724026564487246
  (942, 16)	2.7829486715459226
  (942, 15)	3.005759571083651
  (942, 14)	3.351385077669367
  (942, 13)	3.576514161274886
  (942, 12)	3.089858802871093
  (942, 11)	3.9413279779244355
  (942, 10)	3.530735710983923
  (942, 9)	3.4496539337008243
  (942, 8)	3.5401535844072414
  (942, 7)	3.724867002523079
  (942, 6)	3.5135014027075635
  (942, 5)	3.179816377420226
  (942, 4)	3.011065395423455
  (942, 3)	3.246413223578364
  (942, 2)	2.939718997891865
  (942, 1)	3.004019141003324
  (942, 0)	3.562961683902179
this is the 171 epoch
rmse loss on training set is 0.9034659298233639
rmse loss on test set is 0.9181056169414022
for this epoch using 167.13494348526 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3707464170884043
  (0, 1680)	3.3794721298655133
  (0, 1679)	3.3707464170884043
  (0, 1678)	3.3707464170884043
  (0, 1677)	3.3707464170884043
  (0, 1676)	3.3707464170884043
  (0, 1675)	3.3707464170884043
  (0, 1674)	3.3707464170884043
  (0, 1673)	3.3707464170884043
  (0, 1672)	3.3707464170884043
  (0, 1671)	3.325899515049511
  (0, 1670)	3.3707464170884043
  (0, 1669)	3.3707464170884043
  (0, 1668)	3.3707464170884043
  (0, 1667)	3.3707464170884043
  (0, 1666)	3.3707464170884043
  (0, 1665)	3.3707464170884043
  (0, 1664)	3.3707464170884043
  (0, 1663)	3.4131362480287315
  (0, 1662)	3.3707464170884043
  (0, 1661)	3.3707464170884043
  (0, 1660)	3.231242072512153
  (0, 1659)	3.2563892015049003
  (0, 1658)	3.3707464170884043
  (0, 1657)	3.3707464170884043
  :	:
  (942, 24)	2.9636372283519123
  (942, 23)	3.1772434490538637
  (942, 22)	3.6983270286968146
  (942, 21)	3.7619855240190456
  (942, 20)	2.60312432181827
  (942, 19)	3.287078564824442
  (942, 18)	3.234985591123667
  (942, 17)	3.0728245038767965
  (942, 16)	2.7827026832125616
  (942, 15)	3.005895275894027
  (942, 14)	3.3515475695896475
  (942, 13)	3.5770956383532613
  (942, 12)	3.090088974839371
  (942, 11)	3.9415612409735523
  (942, 10)	3.530904454366503
  (942, 9)	3.450526357979555
  (942, 8)	3.54038725851684
  (942, 7)	3.7251442683989433
  (942, 6)	3.5136759249001996
  (942, 5)	3.1807547350591436
  (942, 4)	3.0110688014926428
  (942, 3)	3.2465675437551256
  (942, 2)	2.9396599137055652
  (942, 1)	3.0040528933631467
  (942, 0)	3.5631201652332085
this is the 172 epoch
rmse loss on training set is 0.9033817618589556
rmse loss on test set is 0.918058763388506
for this epoch using 168.13723635673523 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3706622695594817
  (0, 1680)	3.3794482926814577
  (0, 1679)	3.3706622695594817
  (0, 1678)	3.3706622695594817
  (0, 1677)	3.3706622695594817
  (0, 1676)	3.3706622695594817
  (0, 1675)	3.3706622695594817
  (0, 1674)	3.3706622695594817
  (0, 1673)	3.3706622695594817
  (0, 1672)	3.3706622695594817
  (0, 1671)	3.3255763899346467
  (0, 1670)	3.3706622695594817
  (0, 1669)	3.3706622695594817
  (0, 1668)	3.3706622695594817
  (0, 1667)	3.3706622695594817
  (0, 1666)	3.3706622695594817
  (0, 1665)	3.3706622695594817
  (0, 1664)	3.3706622695594817
  (0, 1663)	3.4132668385858027
  (0, 1662)	3.3706622695594817
  (0, 1661)	3.3706622695594817
  (0, 1660)	3.230377805480662
  (0, 1659)	3.25567798448605
  (0, 1658)	3.3706622695594817
  (0, 1657)	3.3706622695594817
  :	:
  (942, 24)	2.963778050276879
  (942, 23)	3.177320247535091
  (942, 22)	3.698738306851969
  (942, 21)	3.762174932131628
  (942, 20)	2.6026392490352523
  (942, 19)	3.287740491770587
  (942, 18)	3.23583508381357
  (942, 17)	3.0732462156327136
  (942, 16)	2.7824612515907416
  (942, 15)	3.0060315365700423
  (942, 14)	3.3517091647484683
  (942, 13)	3.5776706409423933
  (942, 12)	3.0903180957541503
  (942, 11)	3.9417929033948904
  (942, 10)	3.531072286771232
  (942, 9)	3.451390744643314
  (942, 8)	3.5406191792869617
  (942, 7)	3.725419416879244
  (942, 6)	3.513849590025391
  (942, 5)	3.1816915904740175
  (942, 4)	3.0110729668995457
  (942, 3)	3.246721139778146
  (942, 2)	2.9396025562892296
  (942, 1)	3.0040872082536194
  (942, 0)	3.563277903157426
this is the 173 epoch
rmse loss on training set is 0.9032984456206955
rmse loss on test set is 0.9180125010160962
for this epoch using 166.28459477424622 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3705786101096975
  (0, 1680)	3.3794249474851976
  (0, 1679)	3.3705786101096975
  (0, 1678)	3.3705786101096975
  (0, 1677)	3.3705786101096975
  (0, 1676)	3.3705786101096975
  (0, 1675)	3.3705786101096975
  (0, 1674)	3.3705786101096975
  (0, 1673)	3.3705786101096975
  (0, 1672)	3.3705786101096975
  (0, 1671)	3.3252538499953816
  (0, 1670)	3.3705786101096975
  (0, 1669)	3.3705786101096975
  (0, 1668)	3.3705786101096975
  (0, 1667)	3.3705786101096975
  (0, 1666)	3.3705786101096975
  (0, 1665)	3.3705786101096975
  (0, 1664)	3.3705786101096975
  (0, 1663)	3.4133977239703412
  (0, 1662)	3.3705786101096975
  (0, 1661)	3.3705786101096975
  (0, 1660)	3.2295144870255363
  (0, 1659)	3.2549677861330992
  (0, 1658)	3.3705786101096975
  (0, 1657)	3.3705786101096975
  :	:
  (942, 24)	2.963918346717157
  (942, 23)	3.17739699997206
  (942, 22)	3.699145373493718
  (942, 21)	3.762363261194968
  (942, 20)	2.602162249402189
  (942, 19)	3.2883974778000367
  (942, 18)	3.2366807626996046
  (942, 17)	3.0736677885801753
  (942, 16)	2.782224303029642
  (942, 15)	3.0061683389719653
  (942, 14)	3.3518698706643986
  (942, 13)	3.5782392684230504
  (942, 12)	3.0905461577566147
  (942, 11)	3.942022982695836
  (942, 10)	3.5312392131544135
  (942, 9)	3.4522471772203516
  (942, 8)	3.5408493700527175
  (942, 7)	3.7256924738350783
  (942, 6)	3.514022397664713
  (942, 5)	3.182626942618281
  (942, 4)	3.0110778788024155
  (942, 3)	3.2468740114104557
  (942, 2)	2.9395468970323817
  (942, 1)	3.0041220668304667
  (942, 0)	3.563434897787343
this is the 174 epoch
rmse loss on training set is 0.9032159686752076
rmse loss on test set is 0.9179668208065059
for this epoch using 167.4417383670807 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.370495435775967
  (0, 1680)	3.3794020912450335
  (0, 1679)	3.370495435775967
  (0, 1678)	3.370495435775967
  (0, 1677)	3.370495435775967
  (0, 1676)	3.370495435775967
  (0, 1675)	3.370495435775967
  (0, 1674)	3.370495435775967
  (0, 1673)	3.370495435775967
  (0, 1672)	3.370495435775967
  (0, 1671)	3.324931892050958
  (0, 1670)	3.370495435775967
  (0, 1669)	3.370495435775967
  (0, 1668)	3.370495435775967
  (0, 1667)	3.370495435775967
  (0, 1666)	3.370495435775967
  (0, 1665)	3.370495435775967
  (0, 1664)	3.370495435775967
  (0, 1663)	3.4135289023590816
  (0, 1662)	3.370495435775967
  (0, 1661)	3.370495435775967
  (0, 1660)	3.2286521124155882
  (0, 1659)	3.2542586008947714
  (0, 1658)	3.370495435775967
  (0, 1657)	3.370495435775967
  :	:
  (942, 24)	2.9640581102228833
  (942, 23)	3.1774737013326626
  (942, 22)	3.6995482992578093
  (942, 21)	3.762550517370134
  (942, 20)	2.601693197692827
  (942, 19)	3.289049561710738
  (942, 18)	3.2375226379701467
  (942, 17)	3.07408921962567
  (942, 16)	2.7819917650072266
  (942, 15)	3.0063056691778316
  (942, 14)	3.352029694664032
  (942, 13)	3.5788016183577755
  (942, 12)	3.090773153560772
  (942, 11)	3.942251496007426
  (942, 10)	3.53140523844449
  (942, 9)	3.4530957383248833
  (942, 8)	3.5410778535868324
  (942, 7)	3.725963464586828
  (942, 6)	3.514194347646151
  (942, 5)	3.183560790500749
  (942, 4)	3.0110835245004504
  (942, 3)	3.247026158602861
  (942, 2)	2.939492907743816
  (942, 1)	3.0041574507309723
  (942, 0)	3.563591149412337
this is the 175 epoch
rmse loss on training set is 0.9031343188257152
rmse loss on test set is 0.9179217139174782
for this epoch using 168.13797211647034 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3704127436461335
  (0, 1680)	3.3793797209813174
  (0, 1679)	3.3704127436461335
  (0, 1678)	3.3704127436461335
  (0, 1677)	3.3704127436461335
  (0, 1676)	3.3704127436461335
  (0, 1675)	3.3704127436461335
  (0, 1674)	3.3704127436461335
  (0, 1673)	3.3704127436461335
  (0, 1672)	3.3704127436461335
  (0, 1671)	3.324610512973368
  (0, 1670)	3.3704127436461335
  (0, 1669)	3.3704127436461335
  (0, 1668)	3.3704127436461335
  (0, 1667)	3.3704127436461335
  (0, 1666)	3.3704127436461335
  (0, 1665)	3.3704127436461335
  (0, 1664)	3.3704127436461335
  (0, 1663)	3.413660371967169
  (0, 1662)	3.3704127436461335
  (0, 1661)	3.3704127436461335
  (0, 1660)	3.2277906769838887
  (0, 1659)	3.253550423299518
  (0, 1658)	3.3704127436461335
  (0, 1657)	3.3704127436461335
  :	:
  (942, 24)	2.9641973338524537
  (942, 23)	3.1775503466774397
  (942, 22)	3.6999471531341324
  (942, 21)	3.7627367068124364
  (942, 20)	2.6012319705785307
  (942, 19)	3.2896967820378373
  (942, 18)	3.238360719924938
  (942, 17)	3.0745105057178033
  (942, 16)	2.78176356611408
  (942, 15)	3.0064435134797614
  (942, 14)	3.3521886438913735
  (942, 13)	3.579357786527853
  (942, 12)	3.0909990764332425
  (942, 11)	3.942478460099741
  (942, 10)	3.5315703675444126
  (942, 9)	3.453936509667383
  (942, 8)	3.5413046521193317
  (942, 7)	3.7262324139232077
  (942, 6)	3.5143654400339237
  (942, 5)	3.1844931331845387
  (942, 4)	3.0110898914335733
  (942, 3)	3.2471775814857162
  (942, 2)	2.9394405606458545
  (942, 1)	3.0041933420620333
  (942, 0)	3.563746658491041
this is the 176 epoch
rmse loss on training set is 0.9030534841063993
rmse loss on test set is 0.9178771716779038
for this epoch using 167.76701545715332 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.370330530855892
  (0, 1680)	3.3793578337632684
  (0, 1679)	3.370330530855892
  (0, 1678)	3.370330530855892
  (0, 1677)	3.370330530855892
  (0, 1676)	3.370330530855892
  (0, 1675)	3.370330530855892
  (0, 1674)	3.370330530855892
  (0, 1673)	3.370330530855892
  (0, 1672)	3.370330530855892
  (0, 1671)	3.324289709684286
  (0, 1670)	3.370330530855892
  (0, 1669)	3.370330530855892
  (0, 1668)	3.370330530855892
  (0, 1667)	3.370330530855892
  (0, 1666)	3.370330530855892
  (0, 1665)	3.370330530855892
  (0, 1664)	3.370330530855892
  (0, 1663)	3.413792131045306
  (0, 1662)	3.370330530855892
  (0, 1661)	3.370330530855892
  (0, 1660)	3.226930176124741
  (0, 1659)	3.252843247952008
  (0, 1658)	3.370330530855892
  (0, 1657)	3.370330530855892
  :	:
  (942, 24)	2.9643360111494714
  (942, 23)	3.177626931159882
  (942, 22)	3.7003420025130347
  (942, 21)	3.7629218356716856
  (942, 20)	2.600778446600074
  (942, 19)	3.290339177054302
  (942, 18)	3.2391950189719614
  (942, 17)	3.0749316438465564
  (942, 16)	2.781539636037402
  (942, 15)	3.0065818583803487
  (942, 14)	3.3523467253169015
  (942, 13)	3.5799078669694686
  (942, 12)	3.091223920173751
  (942, 11)	3.9427038913964543
  (942, 10)	3.5317346053337366
  (942, 9)	3.454769572064769
  (942, 8)	3.541529787356403
  (942, 7)	3.7264993461196547
  (942, 6)	3.51453567511848
  (942, 5)	3.1854239697859605
  (942, 4)	3.0110969671822767
  (942, 3)	3.247328280360984
  (942, 2)	2.939389828368705
  (942, 1)	3.004229723388496
  (942, 0)	3.563901425643999
this is the 177 epoch
rmse loss on training set is 0.9029734527770565
rmse loss on test set is 0.9178331855837005
for this epoch using 168.16222524642944 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3702487945859776
  (0, 1680)	3.3793364267061348
  (0, 1679)	3.3702487945859776
  (0, 1678)	3.3702487945859776
  (0, 1677)	3.3702487945859776
  (0, 1676)	3.3702487945859776
  (0, 1675)	3.3702487945859776
  (0, 1674)	3.3702487945859776
  (0, 1673)	3.3702487945859776
  (0, 1672)	3.3702487945859776
  (0, 1671)	3.323969479152129
  (0, 1670)	3.3702487945859776
  (0, 1669)	3.3702487945859776
  (0, 1668)	3.3702487945859776
  (0, 1667)	3.3702487945859776
  (0, 1666)	3.3702487945859776
  (0, 1665)	3.3702487945859776
  (0, 1664)	3.3702487945859776
  (0, 1663)	3.413924177877024
  (0, 1662)	3.3702487945859776
  (0, 1661)	3.3702487945859776
  (0, 1660)	3.226070605290861
  (0, 1659)	3.2521370695298923
  (0, 1658)	3.3702487945859776
  (0, 1657)	3.3702487945859776
  :	:
  (942, 24)	2.964474136120752
  (942, 23)	3.177703450026542
  (942, 22)	3.7007329132301865
  (942, 21)	3.7631059100923476
  (942, 20)	2.6003325061398694
  (942, 19)	3.290976784771477
  (942, 18)	3.2400255456242877
  (942, 17)	3.07535263104266
  (942, 16)	2.781319905545265
  (942, 15)	3.0067206905891317
  (942, 14)	3.3525039457460375
  (942, 13)	3.5804519520090614
  (942, 12)	3.091447679096164
  (942, 11)	3.9429278059886594
  (942, 10)	3.531897956670527
  (942, 9)	3.4555950054504456
  (942, 8)	3.5417532804984613
  (942, 7)	3.7267642849557094
  (942, 6)	3.514705053406913
  (942, 5)	3.186353299473461
  (942, 4)	3.011104739467309
  (942, 3)	3.2474782556946487
  (942, 2)	2.9393406839448577
  (942, 1)	3.004266577721815
  (942, 0)	3.5640554516465244
this is the 178 epoch
rmse loss on training set is 0.902894213317806
rmse loss on test set is 0.9177897472938117
for this epoch using 167.44181728363037 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3701675320594777
  (0, 1680)	3.379315496968417
  (0, 1679)	3.3701675320594777
  (0, 1678)	3.3701675320594777
  (0, 1677)	3.3701675320594777
  (0, 1676)	3.3701675320594777
  (0, 1675)	3.3701675320594777
  (0, 1674)	3.3701675320594777
  (0, 1673)	3.3701675320594777
  (0, 1672)	3.3701675320594777
  (0, 1671)	3.323649818389372
  (0, 1670)	3.3701675320594777
  (0, 1669)	3.3701675320594777
  (0, 1668)	3.3701675320594777
  (0, 1667)	3.3701675320594777
  (0, 1666)	3.3701675320594777
  (0, 1665)	3.3701675320594777
  (0, 1664)	3.3701675320594777
  (0, 1663)	3.414056510776196
  (0, 1662)	3.3701675320594777
  (0, 1661)	3.3701675320594777
  (0, 1660)	3.2252119599908164
  (0, 1659)	3.2514318827807798
  (0, 1658)	3.3701675320594777
  (0, 1657)	3.3701675320594777
  :	:
  (942, 24)	2.9646117032152546
  (942, 23)	3.1777798986171164
  (942, 22)	3.7011199496100375
  (942, 21)	3.763288936213499
  (942, 20)	2.5998940313945345
  (942, 19)	3.2916096429397306
  (942, 18)	3.240852310497089
  (942, 17)	3.0757734643769004
  (942, 16)	2.7811043064709904
  (942, 15)	3.006859997019101
  (942, 14)	3.3526603118272824
  (942, 13)	3.580990132297862
  (942, 12)	3.0916703480101377
  (942, 11)	3.9431502196479067
  (942, 10)	3.532060426393026
  (942, 9)	3.456412888884181
  (942, 8)	3.541975152257531
  (942, 7)	3.72702725373184
  (942, 6)	3.5148735756136213
  (942, 5)	3.1872811214666013
  (942, 4)	3.011113196149375
  (942, 3)	3.2476275081093906
  (942, 2)	2.9392931008035856
  (942, 1)	3.004303888508987
  (942, 0)	3.564208737421864
this is the 179 epoch
rmse loss on training set is 0.9028157544239669
rmse loss on test set is 0.9177468486263097
for this epoch using 166.5542242527008 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3700867405393735
  (0, 1680)	3.379295041749348
  (0, 1679)	3.3700867405393735
  (0, 1678)	3.3700867405393735
  (0, 1677)	3.3700867405393735
  (0, 1676)	3.3700867405393735
  (0, 1675)	3.3700867405393735
  (0, 1674)	3.3700867405393735
  (0, 1673)	3.3700867405393735
  (0, 1672)	3.3700867405393735
  (0, 1671)	3.323330724449923
  (0, 1670)	3.3700867405393735
  (0, 1669)	3.3700867405393735
  (0, 1668)	3.3700867405393735
  (0, 1667)	3.3700867405393735
  (0, 1666)	3.3700867405393735
  (0, 1665)	3.3700867405393735
  (0, 1664)	3.3700867405393735
  (0, 1663)	3.414189128084651
  (0, 1662)	3.3700867405393735
  (0, 1661)	3.3700867405393735
  (0, 1660)	3.2243542357864636
  (0, 1659)	3.2507276825193
  (0, 1658)	3.3700867405393735
  (0, 1657)	3.3700867405393735
  :	:
  (942, 24)	2.964748707303995
  (942, 23)	3.177856272364349
  (942, 22)	3.7015031745079012
  (942, 21)	3.76347092016871
  (942, 20)	2.5994629063479153
  (942, 19)	3.292237789049102
  (942, 18)	3.2416753243045733
  (942, 17)	3.076194140959478
  (942, 16)	2.7808927716978187
  (942, 15)	3.0069997647833353
  (942, 14)	3.3528158300599236
  (942, 13)	3.581522496845729
  (942, 12)	3.0918919222032715
  (942, 11)	3.943371147838581
  (942, 10)	3.532222019321172
  (942, 9)	3.457223300561951
  (942, 8)	3.5421954228738612
  (942, 7)	3.727288275285258
  (942, 6)	3.5150412426513564
  (942, 5)	3.1882074350350305
  (942, 4)	3.0111223252287838
  (942, 3)	3.2477760383775536
  (942, 2)	2.9392470527655203
  (942, 1)	3.0043416396217344
  (942, 0)	3.5643612840345837
this is the 180 epoch
rmse loss on training set is 0.9027380650011252
rmse loss on test set is 0.9177044815546206
for this epoch using 168.64299654960632 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3700064173261652
  (0, 1680)	3.379275058286502
  (0, 1679)	3.3700064173261652
  (0, 1678)	3.3700064173261652
  (0, 1677)	3.3700064173261652
  (0, 1676)	3.3700064173261652
  (0, 1675)	3.3700064173261652
  (0, 1674)	3.3700064173261652
  (0, 1673)	3.3700064173261652
  (0, 1672)	3.3700064173261652
  (0, 1671)	3.323012194426835
  (0, 1670)	3.3700064173261652
  (0, 1669)	3.3700064173261652
  (0, 1668)	3.3700064173261652
  (0, 1667)	3.3700064173261652
  (0, 1666)	3.3700064173261652
  (0, 1665)	3.3700064173261652
  (0, 1664)	3.3700064173261652
  (0, 1663)	3.4143220281700466
  (0, 1662)	3.3700064173261652
  (0, 1661)	3.3700064173261652
  (0, 1660)	3.223497428290674
  (0, 1659)	3.2500244636244515
  (0, 1658)	3.3700064173261652
  (0, 1657)	3.3700064173261652
  :	:
  (942, 24)	2.964885143660741
  (942, 23)	3.177932566793884
  (942, 22)	3.701882649350735
  (942, 21)	3.763651868085843
  (942, 20)	2.5990390167444777
  (942, 19)	3.292861260329949
  (942, 18)	3.2424945978570436
  (942, 17)	3.076614657939418
  (942, 16)	2.7806852351436824
  (942, 15)	3.0071399811916715
  (942, 14)	3.3529705068012845
  (942, 13)	3.582049133054198
  (942, 12)	3.0921123974238847
  (942, 11)	3.943590605729551
  (942, 10)	3.532382740257887
  (942, 9)	3.4580263178255892
  (942, 8)	3.542414112131947
  (942, 7)	3.7275473720052865
  (942, 6)	3.5152080556223813
  (942, 5)	3.189132239497534
  (942, 4)	3.0111321148450294
  (942, 3)	3.2479238474143686
  (942, 2)	2.9392025140373037
  (942, 1)	3.004379815345988
  (942, 0)	3.564513092684152
this is the 181 epoch
rmse loss on training set is 0.9026611341602265
rmse loss on test set is 0.9176626382038561
for this epoch using 166.60965704917908 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.369926559755742
  (0, 1680)	3.379255543853559
  (0, 1679)	3.369926559755742
  (0, 1678)	3.369926559755742
  (0, 1677)	3.369926559755742
  (0, 1676)	3.369926559755742
  (0, 1675)	3.369926559755742
  (0, 1674)	3.369926559755742
  (0, 1673)	3.369926559755742
  (0, 1672)	3.369926559755742
  (0, 1671)	3.32269422545004
  (0, 1670)	3.369926559755742
  (0, 1669)	3.369926559755742
  (0, 1668)	3.369926559755742
  (0, 1667)	3.369926559755742
  (0, 1666)	3.369926559755742
  (0, 1665)	3.369926559755742
  (0, 1664)	3.369926559755742
  (0, 1663)	3.414455209423763
  (0, 1662)	3.369926559755742
  (0, 1661)	3.369926559755742
  (0, 1660)	3.222641533165189
  (0, 1659)	3.2493222210370156
  (0, 1658)	3.369926559755742
  (0, 1657)	3.369926559755742
  :	:
  (942, 24)	2.9650210079436263
  (942, 23)	3.178008777524009
  (942, 22)	3.7022584341766147
  (942, 21)	3.763831786086723
  (942, 20)	2.598622250063094
  (942, 19)	3.2934800937536375
  (942, 18)	3.243310142057971
  (942, 17)	3.077035012503872
  (942, 16)	2.780481631746245
  (942, 15)	3.007280633747461
  (942, 14)	3.353124348273708
  (942, 13)	3.5825701267488137
  (942, 12)	3.09233176986423
  (942, 11)	3.9438086082052948
  (942, 10)	3.5325425939902937
  (942, 9)	3.45882201717233
  (942, 8)	3.5426312393758432
  (942, 7)	3.727804565847848
  (942, 6)	3.51537401581013
  (942, 5)	3.1900555342210546
  (942, 4)	3.0111425532763634
  (942, 3)	3.248070936271465
  (942, 2)	2.939159459206307
  (942, 1)	3.004418400371624
  (942, 0)	3.5646641646988058
this is the 182 epoch
rmse loss on training set is 0.9025849512129858
rmse loss on test set is 0.9176213108472436
for this epoch using 174.5405662059784 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.36984716519731
  (0, 1680)	3.379236495758204
  (0, 1679)	3.36984716519731
  (0, 1678)	3.36984716519731
  (0, 1677)	3.36984716519731
  (0, 1676)	3.36984716519731
  (0, 1675)	3.36984716519731
  (0, 1674)	3.36984716519731
  (0, 1673)	3.36984716519731
  (0, 1672)	3.36984716519731
  (0, 1671)	3.322376814684236
  (0, 1670)	3.36984716519731
  (0, 1669)	3.36984716519731
  (0, 1668)	3.36984716519731
  (0, 1667)	3.36984716519731
  (0, 1666)	3.36984716519731
  (0, 1665)	3.36984716519731
  (0, 1664)	3.36984716519731
  (0, 1663)	3.4145886702590715
  (0, 1662)	3.36984716519731
  (0, 1661)	3.36984716519731
  (0, 1660)	3.2217865461185267
  (0, 1659)	3.2486209497571514
  (0, 1658)	3.36984716519731
  (0, 1657)	3.36984716519731
  :	:
  (942, 24)	2.965156296177544
  (942, 23)	3.1780849002653047
  (942, 22)	3.7026305876730397
  (942, 21)	3.7640106802867948
  (942, 20)	2.5982124954911767
  (942, 19)	3.2940943260332705
  (942, 18)	3.24412196790112
  (942, 17)	3.07745520187761
  (942, 16)	2.780281897448094
  (942, 15)	3.007421710144365
  (942, 14)	3.3532773605710995
  (942, 13)	3.5830855622107878
  (942, 12)	3.092550036144298
  (942, 11)	3.944025169876419
  (942, 10)	3.532701585290693
  (942, 9)	3.4596104742642853
  (942, 8)	3.54284682352388
  (942, 7)	3.7280598783494816
  (942, 6)	3.5155391246709966
  (942, 5)	3.1909773186197867
  (942, 4)	3.0111536289392733
  (942, 3)	3.24821730613063
  (942, 2)	2.9391178632354187
  (942, 1)	3.004457379782449
  (942, 0)	3.5648145015295833
this is the 183 epoch
rmse loss on training set is 0.9025095056671931
rmse loss on test set is 0.9175804919026713
for this epoch using 177.0224142074585 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.369768231051535
  (0, 1680)	3.3792179113402425
  (0, 1679)	3.369768231051535
  (0, 1678)	3.369768231051535
  (0, 1677)	3.369768231051535
  (0, 1676)	3.369768231051535
  (0, 1675)	3.369768231051535
  (0, 1674)	3.369768231051535
  (0, 1673)	3.369768231051535
  (0, 1672)	3.369768231051535
  (0, 1671)	3.3220599593269964
  (0, 1670)	3.369768231051535
  (0, 1669)	3.369768231051535
  (0, 1668)	3.369768231051535
  (0, 1667)	3.369768231051535
  (0, 1666)	3.369768231051535
  (0, 1665)	3.369768231051535
  (0, 1664)	3.369768231051535
  (0, 1663)	3.4147224091093227
  (0, 1662)	3.369768231051535
  (0, 1661)	3.369768231051535
  (0, 1660)	3.2209324629040914
  (0, 1659)	3.2479206448421447
  (0, 1658)	3.369768231051535
  (0, 1657)	3.369768231051535
  :	:
  (942, 24)	2.96529100473726
  (942, 23)	3.1781609308202614
  (942, 22)	3.702999167213973
  (942, 21)	3.7641885567946116
  (942, 20)	2.597809643899249
  (942, 19)	3.2947039936243994
  (942, 18)	3.244930086467729
  (942, 17)	3.0778752233223465
  (942, 16)	2.7800859691821493
  (942, 15)	3.007563198263275
  (942, 14)	3.3534295496651607
  (942, 13)	3.5835955222078844
  (942, 12)	3.0927671932961047
  (942, 11)	3.944240305089547
  (942, 10)	3.532859718917486
  (942, 9)	3.4603917639377553
  (942, 8)	3.5430608830827777
  (942, 7)	3.728313330640648
  (942, 6)	3.51570338382643
  (942, 5)	3.191897592154243
  (942, 4)	3.0111653303880046
  (942, 3)	3.248362958297735
  (942, 2)	2.939077701457937
  (942, 1)	3.004496739046429
  (942, 0)	3.5649641047445995
this is the 184 epoch
rmse loss on training set is 0.9024347872223545
rmse loss on test set is 0.9175401739293068
for this epoch using 171.56190252304077 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3696897547487374
  (0, 1680)	3.379199787969724
  (0, 1679)	3.3696897547487374
  (0, 1678)	3.3696897547487374
  (0, 1677)	3.3696897547487374
  (0, 1676)	3.3696897547487374
  (0, 1675)	3.3696897547487374
  (0, 1674)	3.3696897547487374
  (0, 1673)	3.3696897547487374
  (0, 1672)	3.3696897547487374
  (0, 1671)	3.321743656606935
  (0, 1670)	3.3696897547487374
  (0, 1669)	3.3696897547487374
  (0, 1668)	3.3696897547487374
  (0, 1667)	3.3696897547487374
  (0, 1666)	3.3696897547487374
  (0, 1665)	3.3696897547487374
  (0, 1664)	3.3696897547487374
  (0, 1663)	3.414856424426376
  (0, 1662)	3.3696897547487374
  (0, 1661)	3.3696897547487374
  (0, 1660)	3.2200792793184063
  (0, 1659)	3.247221301404291
  (0, 1658)	3.3696897547487374
  (0, 1657)	3.3696897547487374
  :	:
  (942, 24)	2.9654251303313712
  (942, 23)	3.1782368650827673
  (942, 22)	3.70336422889581
  (942, 21)	3.7643654217113705
  (942, 20)	2.59741358781583
  (942, 19)	3.2953091327257935
  (942, 18)	3.245734508923708
  (942, 17)	3.0782950741362374
  (942, 16)	2.7798937848572285
  (942, 15)	3.007705086169226
  (942, 14)	3.3535809214113312
  (942, 13)	3.584100088024728
  (942, 12)	3.092983238748441
  (942, 11)	3.944454027936796
  (942, 10)	3.533016999615879
  (942, 9)	3.461165960212447
  (942, 8)	3.5432734361612535
  (942, 7)	3.728564943458477
  (942, 6)	3.515866795055351
  (942, 5)	3.192816354330413
  (942, 4)	3.0111776463139557
  (942, 3)	3.2485078941970387
  (942, 2)	2.9390389495724594
  (942, 1)	3.0045364640061814
  (942, 0)	3.5651129760235496
this is the 185 epoch
rmse loss on training set is 0.9023607857653347
rmse loss on test set is 0.9175003496243364
for this epoch using 171.56303310394287 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.369611733747218
  (0, 1680)	3.379182123045266
  (0, 1679)	3.369611733747218
  (0, 1678)	3.369611733747218
  (0, 1677)	3.369611733747218
  (0, 1676)	3.369611733747218
  (0, 1675)	3.369611733747218
  (0, 1674)	3.369611733747218
  (0, 1673)	3.369611733747218
  (0, 1672)	3.369611733747218
  (0, 1671)	3.3214279037819985
  (0, 1670)	3.369611733747218
  (0, 1669)	3.369611733747218
  (0, 1668)	3.369611733747218
  (0, 1667)	3.369611733747218
  (0, 1666)	3.369611733747218
  (0, 1665)	3.369611733747218
  (0, 1664)	3.369611733747218
  (0, 1663)	3.4149907146789844
  (0, 1662)	3.369611733747218
  (0, 1661)	3.369611733747218
  (0, 1660)	3.219226991199402
  (0, 1659)	3.2465229146088497
  (0, 1658)	3.369611733747218
  (0, 1657)	3.369611733747218
  :	:
  (942, 24)	2.965558669986808
  (942, 23)	3.178312699037567
  (942, 22)	3.703725827572167
  (942, 21)	3.7645412811303305
  (942, 20)	2.5970242214027106
  (942, 19)	3.295909779280188
  (942, 18)	3.2465352465169173
  (942, 17)	3.078714751653244
  (942, 16)	2.7797052833438425
  (942, 15)	3.0078473621084107
  (942, 14)	3.35373148155435
  (942, 13)	3.5845993394924003
  (942, 12)	3.093198170312084
  (942, 11)	3.9446663522647407
  (942, 10)	3.533173432118562
  (942, 9)	3.461933136300572
  (942, 8)	3.5434845004830247
  (942, 7)	3.7288147371590084
  (942, 6)	3.516029360286743
  (942, 5)	3.1937336046988407
  (942, 4)	3.011190565545106
  (942, 3)	3.2486521153655525
  (942, 2)	2.9390015836379364
  (942, 1)	3.0045765408697025
  (942, 0)	3.565261117152361
this is the 186 epoch
rmse loss on training set is 0.9022874913661215
rmse loss on test set is 0.9174610118197717
for this epoch using 177.40567827224731 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.369534165531762
  (0, 1680)	3.3791649139924544
  (0, 1679)	3.369534165531762
  (0, 1678)	3.369534165531762
  (0, 1677)	3.369534165531762
  (0, 1676)	3.369534165531762
  (0, 1675)	3.369534165531762
  (0, 1674)	3.369534165531762
  (0, 1673)	3.369534165531762
  (0, 1672)	3.369534165531762
  (0, 1671)	3.3211126981378687
  (0, 1670)	3.369534165531762
  (0, 1669)	3.369534165531762
  (0, 1668)	3.369534165531762
  (0, 1667)	3.369534165531762
  (0, 1666)	3.369534165531762
  (0, 1665)	3.369534165531762
  (0, 1664)	3.369534165531762
  (0, 1663)	3.4151252783514594
  (0, 1662)	3.369534165531762
  (0, 1661)	3.369534165531762
  (0, 1660)	3.2183755944248165
  (0, 1659)	3.2458254796721535
  (0, 1658)	3.369534165531762
  (0, 1657)	3.369534165531762
  :	:
  (942, 24)	2.9656916210341726
  (942, 23)	3.1783884287596447
  (942, 22)	3.7040840168876437
  (942, 21)	3.7647161411361876
  (942, 20)	2.596641440430585
  (942, 19)	3.296505968975122
  (942, 18)	3.2473323105744583
  (942, 17)	3.0791342532426453
  (942, 16)	2.7795204044601376
  (942, 15)	3.0079900145052614
  (942, 14)	3.3538812357336183
  (942, 13)	3.5850933550173942
  (942, 12)	3.0934119861655573
  (942, 11)	3.9448772916828423
  (942, 10)	3.5333290211462427
  (942, 9)	3.462693364615886
  (942, 8)	3.543694093399296
  (942, 7)	3.7290627317289062
  (942, 6)	3.5161910815925626
  (942, 5)	3.1946493428538507
  (942, 4)	3.0112040770453614
  (942, 3)	3.248795623447733
  (942, 2)	2.9389655800687033
  (942, 1)	3.0046169562012874
  (942, 0)	3.5654085300180753
this is the 187 epoch
rmse loss on training set is 0.902214894273791
rmse loss on test set is 0.9174221534793732
for this epoch using 177.47426056861877 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.369457047612157
  (0, 1680)	3.379148158262389
  (0, 1679)	3.369457047612157
  (0, 1678)	3.369457047612157
  (0, 1677)	3.369457047612157
  (0, 1676)	3.369457047612157
  (0, 1675)	3.369457047612157
  (0, 1674)	3.369457047612157
  (0, 1673)	3.369457047612157
  (0, 1672)	3.369457047612157
  (0, 1671)	3.320798036986548
  (0, 1670)	3.369457047612157
  (0, 1669)	3.369457047612157
  (0, 1668)	3.369457047612157
  (0, 1667)	3.369457047612157
  (0, 1666)	3.369457047612157
  (0, 1665)	3.369457047612157
  (0, 1664)	3.369457047612157
  (0, 1663)	3.415260113942331
  (0, 1662)	3.369457047612157
  (0, 1661)	3.369457047612157
  (0, 1660)	3.217525084910793
  (0, 1659)	3.2451289918598705
  (0, 1658)	3.369457047612157
  (0, 1657)	3.369457047612157
  :	:
  (942, 24)	2.965823981093589
  (942, 23)	3.17846405041356
  (942, 22)	3.7044388493105767
  (942, 21)	3.764890007804468
  (942, 20)	2.5962651422550365
  (942, 19)	3.2970977372436994
  (942, 18)	3.2481257125000544
  (942, 17)	3.0795535763084687
  (942, 16)	2.7793390889580234
  (942, 15)	3.0081330319595714
  (942, 14)	3.3540301894882276
  (942, 13)	3.5855822116099616
  (942, 12)	3.0936246848412163
  (942, 11)	3.9450868595715343
  (942, 10)	3.5334837714080742
  (942, 9)	3.4634467167825207
  (942, 8)	3.543902231900819
  (942, 7)	3.7293089467965888
  (942, 6)	3.5163519611808796
  (942, 5)	3.1955635684326706
  (942, 4)	3.0112181699139224
  (942, 3)	3.248938420190362
  (942, 2)	2.9389309156296233
  (942, 1)	3.00465769691271
  (942, 0)	3.5655552166039124
this is the 188 epoch
rmse loss on training set is 0.9021429849124456
rmse loss on test set is 0.9173837676956246
for this epoch using 169.46375703811646 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3693803775218583
  (0, 1680)	3.3791318533302745
  (0, 1679)	3.3693803775218583
  (0, 1678)	3.3693803775218583
  (0, 1677)	3.3693803775218583
  (0, 1676)	3.3693803775218583
  (0, 1675)	3.3693803775218583
  (0, 1674)	3.3693803775218583
  (0, 1673)	3.3693803775218583
  (0, 1672)	3.3693803775218583
  (0, 1671)	3.3204839176648853
  (0, 1670)	3.3693803775218583
  (0, 1669)	3.3693803775218583
  (0, 1668)	3.3693803775218583
  (0, 1667)	3.3693803775218583
  (0, 1666)	3.3693803775218583
  (0, 1665)	3.3693803775218583
  (0, 1664)	3.3693803775218583
  (0, 1663)	3.415395219963125
  (0, 1662)	3.3693803775218583
  (0, 1661)	3.3693803775218583
  (0, 1660)	3.2166754586103794
  (0, 1659)	3.2444334464852824
  (0, 1658)	3.3693803775218583
  (0, 1657)	3.3693803775218583
  :	:
  (942, 24)	2.965955748061229
  (942, 23)	3.178539560252712
  (942, 22)	3.704790376164707
  (942, 21)	3.7650628872008443
  (942, 20)	2.5958952257928676
  (942, 19)	3.2976851192654926
  (942, 18)	3.248915463771396
  (942, 17)	3.0799727182889423
  (942, 16)	2.7791612785095237
  (942, 15)	3.0082764032436886
  (942, 14)	3.3541783482616987
  (942, 13)	3.586065984911846
  (942, 12)	3.093836265211825
  (942, 11)	3.9452950690898936
  (942, 10)	3.5336376876020252
  (942, 9)	3.4641932636438604
  (942, 8)	3.5441089326293977
  (942, 7)	3.729553401642999
  (942, 6)	3.5165120013892097
  (942, 5)	3.196476281114678
  (942, 4)	3.0112328333845566
  (942, 3)	3.2490805074375535
  (942, 2)	2.9388975674312885
  (942, 1)	3.0046987502546254
  (942, 0)	3.5657011789845368
this is the 189 epoch
rmse loss on training set is 0.9020717538773927
rmse loss on test set is 0.9173458476868201
for this epoch using 174.43593549728394 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3693041528167096
  (0, 1680)	3.3791159966941393
  (0, 1679)	3.3693041528167096
  (0, 1678)	3.3693041528167096
  (0, 1677)	3.3693041528167096
  (0, 1676)	3.3693041528167096
  (0, 1675)	3.3693041528167096
  (0, 1674)	3.3693041528167096
  (0, 1673)	3.3693041528167096
  (0, 1672)	3.3693041528167096
  (0, 1671)	3.3201703375333635
  (0, 1670)	3.3693041528167096
  (0, 1669)	3.3693041528167096
  (0, 1668)	3.3693041528167096
  (0, 1667)	3.3693041528167096
  (0, 1666)	3.3693041528167096
  (0, 1665)	3.3693041528167096
  (0, 1664)	3.3693041528167096
  (0, 1663)	3.4155305949372265
  (0, 1662)	3.3693041528167096
  (0, 1661)	3.3693041528167096
  (0, 1660)	3.2158267115123245
  (0, 1659)	3.2437388389076727
  (0, 1658)	3.3693041528167096
  (0, 1657)	3.3693041528167096
  :	:
  (942, 24)	2.9660869200964317
  (942, 23)	3.1786149546185594
  (942, 22)	3.7051386476599286
  (942, 21)	3.7652347853804056
  (942, 20)	2.5955315914988053
  (942, 19)	3.298268149967341
  (942, 18)	3.24970157593763
  (942, 17)	3.0803916766560135
  (942, 16)	2.7789869156932485
  (942, 15)	3.008420117299743
  (942, 14)	3.354325717406568
  (942, 13)	3.5865447492233966
  (942, 12)	3.0940467264775946
  (942, 11)	3.945501933182839
  (942, 10)	3.5337907744151633
  (942, 9)	3.464933075271139
  (942, 8)	3.5443142118890103
  (942, 7)	3.7297961152118915
  (942, 6)	3.5166712046781616
  (942, 5)	3.197387480620557
  (942, 4)	3.0112480568248685
  (942, 3)	3.249221887126063
  (942, 2)	2.9388655129252874
  (942, 1)	3.0047401038081727
  (942, 0)	3.565846419321426
this is the 190 epoch
rmse loss on training set is 0.9020011919313375
rmse loss on test set is 0.9173083867942136
for this epoch using 176.9316771030426 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.369228371073823
  (0, 1680)	3.379100585873674
  (0, 1679)	3.369228371073823
  (0, 1678)	3.369228371073823
  (0, 1677)	3.369228371073823
  (0, 1676)	3.369228371073823
  (0, 1675)	3.369228371073823
  (0, 1674)	3.369228371073823
  (0, 1673)	3.369228371073823
  (0, 1672)	3.369228371073823
  (0, 1671)	3.319857293974882
  (0, 1670)	3.369228371073823
  (0, 1669)	3.369228371073823
  (0, 1668)	3.369228371073823
  (0, 1667)	3.369228371073823
  (0, 1666)	3.369228371073823
  (0, 1665)	3.369228371073823
  (0, 1664)	3.369228371073823
  (0, 1663)	3.415666237398884
  (0, 1662)	3.369228371073823
  (0, 1661)	3.369228371073823
  (0, 1660)	3.214978839639793
  (0, 1659)	3.243045164530913
  (0, 1658)	3.369228371073823
  (0, 1657)	3.369228371073823
  :	:
  (942, 24)	2.9662174956093175
  (942, 23)	3.178690229939862
  (942, 22)	3.705483712922125
  (942, 21)	3.7654057083869943
  (942, 20)	2.5951741413424734
  (942, 19)	3.298846864024241
  (942, 18)	3.2504840606168113
  (942, 17)	3.080810448914824
  (942, 16)	2.7788159439810896
  (942, 15)	3.0085641632369593
  (942, 14)	3.3544723021886154
  (942, 13)	3.587018577530116
  (942, 12)	3.0942560681535243
  (942, 11)	3.945707464588088
  (942, 10)	3.5339430365238296
  (942, 9)	3.465666220972125
  (942, 8)	3.5445180856564336
  (942, 7)	3.7300371061196604
  (942, 6)	3.516829573625252
  (942, 5)	3.198297166711628
  (942, 4)	3.0112638297356016
  (942, 3)	3.2493625612806776
  (942, 2)	2.9388347298995106
  (942, 1)	3.0047817454767594
  (942, 0)	3.5659909398585006
this is the 191 epoch
rmse loss on training set is 0.9019312900006977
rmse loss on test set is 0.9172713784792481
for this epoch using 173.4835124015808 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.36915302989041
  (0, 1680)	3.3790856184090283
  (0, 1679)	3.36915302989041
  (0, 1678)	3.36915302989041
  (0, 1677)	3.36915302989041
  (0, 1676)	3.36915302989041
  (0, 1675)	3.36915302989041
  (0, 1674)	3.36915302989041
  (0, 1673)	3.36915302989041
  (0, 1672)	3.36915302989041
  (0, 1671)	3.3195447843936003
  (0, 1670)	3.36915302989041
  (0, 1669)	3.36915302989041
  (0, 1668)	3.36915302989041
  (0, 1667)	3.36915302989041
  (0, 1666)	3.36915302989041
  (0, 1665)	3.36915302989041
  (0, 1664)	3.36915302989041
  (0, 1663)	3.4158021458921666
  (0, 1662)	3.36915302989041
  (0, 1661)	3.36915302989041
  (0, 1660)	3.2141318390492444
  (0, 1659)	3.2423524188019734
  (0, 1658)	3.36915302989041
  (0, 1657)	3.36915302989041
  :	:
  (942, 24)	2.9663474732490367
  (942, 23)	3.1787653827317355
  (942, 22)	3.7058256200220847
  (942, 21)	3.765575662252442
  (942, 20)	2.5948227787857996
  (942, 19)	3.2994212958602875
  (942, 18)	3.2512629294934485
  (942, 17)	3.0812290326032183
  (942, 16)	2.778648307725067
  (942, 15)	3.0087085303289958
  (942, 14)	3.3546181077909694
  (942, 13)	3.587487541528645
  (942, 12)	3.0944642900572696
  (942, 11)	3.945911675842639
  (942, 10)	3.5340944785937696
  (942, 9)	3.4663927692995204
  (942, 8)	3.5447205695914974
  (942, 7)	3.730276392664784
  (942, 6)	3.516987110918968
  (942, 5)	3.1992053391890027
  (942, 4)	3.0112801417497908
  (942, 3)	3.249502532009857
  (942, 2)	2.938805196473552
  (942, 1)	3.0048236634781165
  (942, 0)	3.5661347429179147
this is the 192 epoch
rmse loss on training set is 0.9018620391720529
rmse loss on test set is 0.9172348163208722
for this epoch using 173.39581871032715 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.369078126882869
  (0, 1680)	3.3790710918598483
  (0, 1679)	3.369078126882869
  (0, 1678)	3.369078126882869
  (0, 1677)	3.369078126882869
  (0, 1676)	3.369078126882869
  (0, 1675)	3.369078126882869
  (0, 1674)	3.369078126882869
  (0, 1673)	3.369078126882869
  (0, 1672)	3.369078126882869
  (0, 1671)	3.319232806213934
  (0, 1670)	3.369078126882869
  (0, 1669)	3.369078126882869
  (0, 1668)	3.369078126882869
  (0, 1667)	3.369078126882869
  (0, 1666)	3.369078126882869
  (0, 1665)	3.369078126882869
  (0, 1664)	3.369078126882869
  (0, 1663)	3.4159383189701575
  (0, 1662)	3.369078126882869
  (0, 1661)	3.369078126882869
  (0, 1660)	3.2132857058293496
  (0, 1659)	3.2416605972096275
  (0, 1658)	3.369078126882869
  (0, 1657)	3.369078126882869
  :	:
  (942, 24)	2.966476851892447
  (942, 23)	3.178840409594824
  (942, 22)	3.7061644160034715
  (942, 21)	3.7657446529958394
  (942, 20)	2.5944774087606643
  (942, 19)	3.2999914796495053
  (942, 18)	3.2520381943160532
  (942, 17)	3.081647425291251
  (942, 16)	2.778483952144351
  (942, 15)	3.008853208011362
  (942, 14)	3.354763139317929
  (942, 13)	3.5879517116521815
  (942, 12)	3.0946713922972653
  (942, 11)	3.946114579289063
  (942, 10)	3.5342451052802812
  (942, 9)	3.467112788059425
  (942, 8)	3.54492167904694
  (942, 7)	3.7305139928368645
  (942, 6)	3.517143819353013
  (942, 5)	3.200111997892918
  (942, 4)	3.0112969826320044
  (942, 3)	3.2496418015014923
  (942, 2)	2.938776891094125
  (942, 1)	3.0048658463364726
  (942, 0)	3.566277830895887
this is the 193 epoch
rmse loss on training set is 0.9017934306886126
rmse loss on test set is 0.9171986940129018
for this epoch using 179.46120929718018 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3690036596857103
  (0, 1680)	3.379057003804258
  (0, 1679)	3.3690036596857103
  (0, 1678)	3.3690036596857103
  (0, 1677)	3.3690036596857103
  (0, 1676)	3.3690036596857103
  (0, 1675)	3.3690036596857103
  (0, 1674)	3.3690036596857103
  (0, 1673)	3.3690036596857103
  (0, 1672)	3.3690036596857103
  (0, 1671)	3.3189213568795677
  (0, 1670)	3.3690036596857103
  (0, 1669)	3.3690036596857103
  (0, 1668)	3.3690036596857103
  (0, 1667)	3.3690036596857103
  (0, 1666)	3.3690036596857103
  (0, 1665)	3.3690036596857103
  (0, 1664)	3.3690036596857103
  (0, 1663)	3.4160747551940536
  (0, 1662)	3.3690036596857103
  (0, 1661)	3.3690036596857103
  (0, 1660)	3.212440436099967
  (0, 1659)	3.240969695283187
  (0, 1658)	3.3690036596857103
  (0, 1657)	3.3690036596857103
  :	:
  (942, 24)	2.9666056306333193
  (942, 23)	3.178915307214354
  (942, 22)	3.706500146910098
  (942, 21)	3.765912686622785
  (942, 20)	2.59413793764692
  (942, 19)	3.300557449316875
  (942, 18)	3.252809866894774
  (942, 17)	3.0820656245807103
  (942, 16)	2.7783228233124797
  (942, 15)	3.008998185878859
  (942, 14)	3.3549074017985854
  (942, 13)	3.588411157095338
  (942, 12)	3.0948773752613135
  (942, 11)	3.94631618708141
  (942, 10)	3.5343949212281283
  (942, 9)	3.467826344319596
  (942, 8)	3.5451214290778403
  (942, 7)	3.730749924325377
  (942, 6)	3.517299701820798
  (942, 5)	3.2010171427020073
  (942, 4)	3.011314342277483
  (942, 3)	3.24978037201889
  (942, 2)	2.9387497925306
  (942, 1)	3.0049082828749833
  (942, 0)	3.566420206258853
this is the 194 epoch
rmse loss on training set is 0.9017254559468586
rmse loss on test set is 0.9171630053614962
for this epoch using 175.8864827156067 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.36892962595081
  (0, 1680)	3.379043351837986
  (0, 1679)	3.36892962595081
  (0, 1678)	3.36892962595081
  (0, 1677)	3.36892962595081
  (0, 1676)	3.36892962595081
  (0, 1675)	3.36892962595081
  (0, 1674)	3.36892962595081
  (0, 1673)	3.36892962595081
  (0, 1672)	3.36892962595081
  (0, 1671)	3.318610433852576
  (0, 1670)	3.36892962595081
  (0, 1669)	3.36892962595081
  (0, 1668)	3.36892962595081
  (0, 1667)	3.36892962595081
  (0, 1666)	3.36892962595081
  (0, 1665)	3.36892962595081
  (0, 1664)	3.36892962595081
  (0, 1663)	3.4162114531324668
  (0, 1662)	3.36892962595081
  (0, 1661)	3.36892962595081
  (0, 1660)	3.2115960260112364
  (0, 1659)	3.2402797085913537
  (0, 1658)	3.36892962595081
  (0, 1657)	3.36892962595081
  :	:
  (942, 24)	2.9667338087720148
  (942, 23)	3.178990072359178
  (942, 22)	3.706832857812209
  (942, 21)	3.766079769124646
  (942, 20)	2.5938042732507465
  (942, 19)	3.301119238539198
  (942, 18)	3.2535779590990392
  (942, 17)	3.08248362810466
  (942, 16)	2.7781648681447053
  (942, 15)	3.0091434536831057
  (942, 14)	3.35505090019032
  (942, 13)	3.588865945838499
  (942, 12)	3.095082239605522
  (942, 11)	3.946516511190802
  (942, 10)	3.534543931071594
  (942, 9)	3.4685335044176484
  (942, 8)	3.5453198344507504
  (942, 7)	3.730984204527909
  (942, 6)	3.5174547613101406
  (942, 5)	3.201920773532614
  (942, 4)	3.0113322107113265
  (942, 3)	3.249918245896816
  (942, 2)	2.938723879870545
  (942, 1)	3.004950962208312
  (942, 0)	3.5665618715396525
this is the 195 epoch
rmse loss on training set is 0.9016581064931992
rmse loss on test set is 0.9171277442826508
for this epoch using 114.85414147377014 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.368856023346472
  (0, 1680)	3.3790301335735036
  (0, 1679)	3.368856023346472
  (0, 1678)	3.368856023346472
  (0, 1677)	3.368856023346472
  (0, 1676)	3.368856023346472
  (0, 1675)	3.368856023346472
  (0, 1674)	3.368856023346472
  (0, 1673)	3.368856023346472
  (0, 1672)	3.368856023346472
  (0, 1671)	3.318300034612552
  (0, 1670)	3.368856023346472
  (0, 1669)	3.368856023346472
  (0, 1668)	3.368856023346472
  (0, 1667)	3.368856023346472
  (0, 1666)	3.368856023346472
  (0, 1665)	3.368856023346472
  (0, 1664)	3.368856023346472
  (0, 1663)	3.416348411360692
  (0, 1662)	3.368856023346472
  (0, 1661)	3.368856023346472
  (0, 1660)	3.210752471742628
  (0, 1659)	3.2395906327410406
  (0, 1658)	3.368856023346472
  (0, 1657)	3.368856023346472
  :	:
  (942, 24)	2.966861385805576
  (942, 23)	3.1790647018807694
  (942, 22)	3.7071625928320984
  (942, 21)	3.7662459064778213
  (942, 20)	2.593476324783255
  (942, 19)	3.301676880746147
  (942, 18)	3.254342482855255
  (942, 17)	3.082901433526979
  (942, 16)	2.778010034385538
  (942, 15)	3.0092890013300626
  (942, 14)	3.3551936393819757
  (942, 13)	3.5893161446716664
  (942, 12)	3.0952859862435274
  (942, 11)	3.946715563410881
  (942, 10)	3.5346921394343824
  (942, 9)	3.4692343339691782
  (942, 8)	3.5455169096524295
  (942, 7)	3.7312168505582446
  (942, 6)	3.517609000898119
  (942, 5)	3.202822890338093
  (942, 4)	3.01135057808759
  (942, 3)	3.2500554255378016
  (942, 2)	2.9386991325153193
  (942, 1)	3.004993873735407
  (942, 0)	3.5667028293339125
this is the 196 epoch
rmse loss on training set is 0.9015913740207807
rmse loss on test set is 0.917092904799794
for this epoch using 88.09104061126709 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3687828495567302
  (0, 1680)	3.37901734663923
  (0, 1679)	3.3687828495567302
  (0, 1678)	3.3687828495567302
  (0, 1677)	3.3687828495567302
  (0, 1676)	3.3687828495567302
  (0, 1675)	3.3687828495567302
  (0, 1674)	3.3687828495567302
  (0, 1673)	3.3687828495567302
  (0, 1672)	3.3687828495567302
  (0, 1671)	3.3179901566557977
  (0, 1670)	3.3687828495567302
  (0, 1669)	3.3687828495567302
  (0, 1668)	3.3687828495567302
  (0, 1667)	3.3687828495567302
  (0, 1666)	3.3687828495567302
  (0, 1665)	3.3687828495567302
  (0, 1664)	3.3687828495567302
  (0, 1663)	3.416485628460047
  (0, 1662)	3.3687828495567302
  (0, 1661)	3.3687828495567302
  (0, 1660)	3.209909769502144
  (0, 1659)	3.2389024633763412
  (0, 1658)	3.3687828495567302
  (0, 1657)	3.3687828495567302
  :	:
  (942, 24)	2.966988361418312
  (942, 23)	3.1791391927122645
  (942, 22)	3.7074893951689396
  (942, 21)	3.766411104642948
  (942, 20)	2.593154002839502
  (942, 19)	3.302230409121187
  (942, 18)	3.255103450144553
  (942, 17)	3.0833190385419025
  (942, 16)	2.777858270596482
  (942, 15)	3.009434818877654
  (942, 14)	3.3553356241970516
  (942, 13)	3.5897618192177503
  (942, 12)	3.0954886163361564
  (942, 11)	3.946913355362813
  (942, 10)	3.534839550929541
  (942, 9)	3.46992889787578
  (942, 8)	3.5457126688982266
  (942, 7)	3.731447879254014
  (942, 6)	3.5177624237461083
  (942, 5)	3.2037234931081637
  (942, 4)	3.011369434688403
  (942, 3)	3.250191913408538
  (942, 2)	2.9386755301757868
  (942, 1)	3.005037007132461
  (942, 0)	3.5668430822965385
this is the 197 epoch
rmse loss on training set is 0.9015252503663047
rmse loss on test set is 0.9170584810414284
for this epoch using 82.72473645210266 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.368710102280637
  (0, 1680)	3.3790049886788296
  (0, 1679)	3.368710102280637
  (0, 1678)	3.368710102280637
  (0, 1677)	3.368710102280637
  (0, 1676)	3.368710102280637
  (0, 1675)	3.368710102280637
  (0, 1674)	3.368710102280637
  (0, 1673)	3.368710102280637
  (0, 1672)	3.368710102280637
  (0, 1671)	3.3176807974946816
  (0, 1670)	3.368710102280637
  (0, 1669)	3.368710102280637
  (0, 1668)	3.368710102280637
  (0, 1667)	3.368710102280637
  (0, 1666)	3.368710102280637
  (0, 1665)	3.368710102280637
  (0, 1664)	3.368710102280637
  (0, 1663)	3.416623103017336
  (0, 1662)	3.368710102280637
  (0, 1661)	3.368710102280637
  (0, 1660)	3.2090679155255315
  (0, 1659)	3.2382151961775505
  (0, 1658)	3.368710102280637
  (0, 1657)	3.368710102280637
  :	:
  (942, 24)	2.9671147354727307
  (942, 23)	3.1792135418673646
  (942, 22)	3.7078133071228248
  (942, 21)	3.7665753695642175
  (942, 20)	2.592837219377709
  (942, 19)	3.3027798566026094
  (942, 18)	3.2558608730005605
  (942, 17)	3.0837364408735923
  (942, 16)	2.777709526143845
  (942, 15)	3.0095808965333966
  (942, 14)	3.3554768593965063
  (942, 13)	3.590203033955386
  (942, 12)	3.0956901312813865
  (942, 11)	3.9471098985002455
  (942, 10)	3.534986170159232
  (942, 9)	3.4706172603329515
  (942, 8)	3.5459071261402304
  (942, 7)	3.7316773071840625
  (942, 6)	3.5179150330950932
  (942, 5)	3.2046225818682506
  (942, 4)	3.0113887709230545
  (942, 3)	3.250327712036372
  (942, 2)	2.938653052868017
  (942, 1)	3.005080352346034
  (942, 0)	3.566982633138373
this is the 198 epoch
rmse loss on training set is 0.9014597275069985
rmse loss on test set is 0.9170244672388461
for this epoch using 83.09249782562256 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.368637779231593
  (0, 1680)	3.3789930573505593
  (0, 1679)	3.368637779231593
  (0, 1678)	3.368637779231593
  (0, 1677)	3.368637779231593
  (0, 1676)	3.368637779231593
  (0, 1675)	3.368637779231593
  (0, 1674)	3.368637779231593
  (0, 1673)	3.368637779231593
  (0, 1672)	3.368637779231593
  (0, 1671)	3.3173719546568887
  (0, 1670)	3.368637779231593
  (0, 1669)	3.368637779231593
  (0, 1668)	3.368637779231593
  (0, 1667)	3.368637779231593
  (0, 1666)	3.368637779231593
  (0, 1665)	3.368637779231593
  (0, 1664)	3.368637779231593
  (0, 1663)	3.416760833624261
  (0, 1662)	3.368637779231593
  (0, 1661)	3.368637779231593
  (0, 1660)	3.2082269060755553
  (0, 1659)	3.237528826860214
  (0, 1658)	3.368637779231593
  (0, 1657)	3.368637779231593
  :	:
  (942, 24)	2.9672405080008795
  (942, 23)	3.179287746439341
  (942, 22)	3.708134370118138
  (942, 21)	3.766738707168615
  (942, 20)	2.5925258876988777
  (942, 19)	3.303325255884543
  (942, 18)	3.256614763507221
  (942, 17)	3.084153638275722
  (942, 16)	2.7775637511868294
  (942, 15)	3.0097272246520994
  (942, 14)	3.3556173496815926
  (942, 13)	3.590639852241327
  (942, 12)	3.0958905327045576
  (942, 11)	3.947305204113906
  (942, 10)	3.535132001714652
  (942, 9)	3.471299484837948
  (942, 8)	3.5461002950750227
  (942, 7)	3.7319051506555363
  (942, 6)	3.518066832261057
  (942, 5)	3.2055201566788543
  (942, 4)	3.01140857732707
  (942, 3)	3.250462824006034
  (942, 2)	2.9386316809090727
  (942, 1)	3.0051238995863443
  (942, 0)	3.5671214846229464
this is the 199 epoch
rmse loss on training set is 0.9013947975576262
rmse loss on test set is 0.9169908577238969
for this epoch using 80.66234588623047 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.368565878136725
  (0, 1680)	3.378981550326581
  (0, 1679)	3.368565878136725
  (0, 1678)	3.368565878136725
  (0, 1677)	3.368565878136725
  (0, 1676)	3.368565878136725
  (0, 1675)	3.368565878136725
  (0, 1674)	3.368565878136725
  (0, 1673)	3.368565878136725
  (0, 1672)	3.368565878136725
  (0, 1671)	3.3170636256848254
  (0, 1670)	3.368565878136725
  (0, 1669)	3.368565878136725
  (0, 1668)	3.368565878136725
  (0, 1667)	3.368565878136725
  (0, 1666)	3.368565878136725
  (0, 1665)	3.368565878136725
  (0, 1664)	3.368565878136725
  (0, 1663)	3.416898818876966
  (0, 1662)	3.368565878136725
  (0, 1661)	3.368565878136725
  (0, 1660)	3.2073867374412752
  (0, 1659)	3.2368433511742287
  (0, 1658)	3.368565878136725
  (0, 1657)	3.368565878136725
  :	:
  (942, 24)	2.967365679196095
  (942, 23)	3.1793618035999454
  (942, 22)	3.708452624726187
  (942, 21)	3.7669011233652014
  (942, 20)	2.5922199224266214
  (942, 19)	3.3038666394179956
  (942, 18)	3.2573651337966574
  (942, 17)	3.0845706285310195
  (942, 16)	2.777420896665705
  (942, 15)	3.009873793733625
  (942, 14)	3.3557570996963992
  (942, 13)	3.591072336332248
  (942, 12)	3.0960898224490054
  (942, 11)	3.9474992833360187
  (942, 10)	3.535277050175784
  (942, 9)	3.4719756341975376
  (942, 8)	3.5462921891511505
  (942, 7)	3.732131425720747
  (942, 6)	3.5182178246305744
  (942, 5)	3.2064162176349327
  (942, 4)	3.0114288445612774
  (942, 3)	3.2505972519564224
  (942, 2)	2.938611394912855
  (942, 1)	3.00516763932075
  (942, 0)	3.567259639563391
this is the 200 epoch
rmse loss on training set is 0.901330452767547
rmse loss on test set is 0.9169576469268141
for this epoch using 82.75273704528809 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.368494396736344
  (0, 1680)	3.378970465292413
  (0, 1679)	3.368494396736344
  (0, 1678)	3.368494396736344
  (0, 1677)	3.368494396736344
  (0, 1676)	3.368494396736344
  (0, 1675)	3.368494396736344
  (0, 1674)	3.368494396736344
  (0, 1673)	3.368494396736344
  (0, 1672)	3.368494396736344
  (0, 1671)	3.3167558081350244
  (0, 1670)	3.368494396736344
  (0, 1669)	3.368494396736344
  (0, 1668)	3.368494396736344
  (0, 1667)	3.368494396736344
  (0, 1666)	3.368494396736344
  (0, 1665)	3.368494396736344
  (0, 1664)	3.368494396736344
  (0, 1663)	3.4170370573755062
  (0, 1662)	3.368494396736344
  (0, 1661)	3.368494396736344
  (0, 1660)	3.206547405937423
  (0, 1659)	3.236158764903002
  (0, 1658)	3.368494396736344
  (0, 1657)	3.368494396736344
  :	:
  (942, 24)	2.9674902494050786
  (942, 23)	3.1794357105983324
  (942, 22)	3.708768110687237
  (942, 21)	3.7670626240444216
  (942, 20)	2.5919192394873614
  (942, 19)	3.304404039411903
  (942, 18)	3.2581119960470692
  (942, 17)	3.0849874094508682
  (942, 16)	2.7772809142901402
  (942, 15)	3.010020594420609
  (942, 14)	3.3558961140303927
  (942, 13)	3.591500547406224
  (942, 12)	3.0962880025669435
  (942, 11)	3.947692147144517
  (942, 10)	3.53542132011117
  (942, 9)	3.4726457705356157
  (942, 8)	3.546482821576393
  (942, 7)	3.732356148183635
  (942, 6)	3.5183680136566147
  (942, 5)	3.2073107648652743
  (942, 4)	3.011449563410817
  (942, 3)	3.2507309985775272
  (942, 2)	2.9385921757859665
  (942, 1)	3.0052115622673545
  (942, 0)	3.56739710081946
this is the 201 epoch
rmse loss on training set is 0.9012666855179284
rmse loss on test set is 0.9169248293740964
for this epoch using 81.706538438797 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.368423332783415
  (0, 1680)	3.378959799946419
  (0, 1679)	3.368423332783415
  (0, 1678)	3.368423332783415
  (0, 1677)	3.368423332783415
  (0, 1676)	3.368423332783415
  (0, 1675)	3.368423332783415
  (0, 1674)	3.368423332783415
  (0, 1673)	3.368423332783415
  (0, 1672)	3.368423332783415
  (0, 1671)	3.3164484995776182
  (0, 1670)	3.368423332783415
  (0, 1669)	3.368423332783415
  (0, 1668)	3.368423332783415
  (0, 1667)	3.368423332783415
  (0, 1666)	3.368423332783415
  (0, 1665)	3.368423332783415
  (0, 1664)	3.368423332783415
  (0, 1663)	3.417175547723556
  (0, 1662)	3.368423332783415
  (0, 1661)	3.368423332783415
  (0, 1660)	3.205708907903794
  (0, 1659)	3.235475063862665
  (0, 1658)	3.368423332783415
  (0, 1657)	3.368423332783415
  :	:
  (942, 24)	2.967614219120301
  (942, 23)	3.17950946475995
  (942, 22)	3.709080866931847
  (942, 21)	3.767223215077366
  (942, 20)	2.591623756090764
  (942, 19)	3.304937487834188
  (942, 18)	3.2588553624806953
  (942, 17)	3.085403978874919
  (942, 16)	2.777143756527749
  (942, 15)	3.010167617496329
  (942, 14)	3.356034397220648
  (942, 13)	3.5919245455836193
  (942, 12)	3.0964850753106394
  (942, 11)	3.9478838063671238
  (942, 10)	3.5355648160776627
  (942, 9)	3.473309955300861
  (942, 8)	3.5466722053246476
  (942, 7)	3.732579333606161
  (942, 6)	3.5185174028544504
  (942, 5)	3.2082037985319434
  (942, 4)	3.0114707247841803
  (942, 3)	3.2508640666074835
  (942, 2)	2.9385740047236815
  (942, 1)	3.0052556593887894
  (942, 0)	3.5675338712946716
this is the 202 epoch
rmse loss on training set is 0.9012034883189676
rmse loss on test set is 0.916892399686453
for this epoch using 84.45831108093262 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3683526840430473
  (0, 1680)	3.378949551999249
  (0, 1679)	3.3683526840430473
  (0, 1678)	3.3683526840430473
  (0, 1677)	3.3683526840430473
  (0, 1676)	3.3683526840430473
  (0, 1675)	3.3683526840430473
  (0, 1674)	3.3683526840430473
  (0, 1673)	3.3683526840430473
  (0, 1672)	3.3683526840430473
  (0, 1671)	3.316141697595822
  (0, 1670)	3.3683526840430473
  (0, 1669)	3.3683526840430473
  (0, 1668)	3.3683526840430473
  (0, 1667)	3.3683526840430473
  (0, 1666)	3.3683526840430473
  (0, 1665)	3.3683526840430473
  (0, 1664)	3.3683526840430473
  (0, 1663)	3.4173142885279177
  (0, 1662)	3.3683526840430473
  (0, 1661)	3.3683526840430473
  (0, 1660)	3.2048712397046546
  (0, 1659)	3.234792243901328
  (0, 1658)	3.3683526840430473
  (0, 1657)	3.3683526840430473
  :	:
  (942, 24)	2.967737588972798
  (942, 23)	3.179583063485454
  (942, 22)	3.709390931601559
  (942, 21)	3.767382902315154
  (942, 20)	2.591333390710491
  (942, 19)	3.305467016412849
  (942, 18)	3.259595245361748
  (942, 17)	3.085820334670664
  (942, 16)	2.7770093765927473
  (942, 15)	3.010314853882551
  (942, 14)	3.3561719537541217
  (942, 13)	3.5923443899476495
  (942, 12)	3.0966810431238616
  (942, 11)	3.948074271685127
  (942, 10)	3.535707542620186
  (942, 9)	3.473968249274123
  (942, 8)	3.5468603531426206
  (942, 7)	3.7328009973143175
  (942, 6)	3.5186659957977704
  (942, 5)	3.209095318829641
  (942, 4)	3.011492319712222
  (942, 3)	3.2509964588297575
  (942, 2)	2.938556863205905
  (942, 1)	3.005299921886184
  (942, 0)	3.567669953933539
this is the 203 epoch
rmse loss on training set is 0.9011408538071518
rmse loss on test set is 0.9168603525767878
for this epoch using 81.18876791000366 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3682824482920752
  (0, 1680)	3.3789397191734256
  (0, 1679)	3.3682824482920752
  (0, 1678)	3.3682824482920752
  (0, 1677)	3.3682824482920752
  (0, 1676)	3.3682824482920752
  (0, 1675)	3.3682824482920752
  (0, 1674)	3.3682824482920752
  (0, 1673)	3.3682824482920752
  (0, 1672)	3.3682824482920752
  (0, 1671)	3.315835399785488
  (0, 1670)	3.3682824482920752
  (0, 1669)	3.3682824482920752
  (0, 1668)	3.3682824482920752
  (0, 1667)	3.3682824482920752
  (0, 1666)	3.3682824482920752
  (0, 1665)	3.3682824482920752
  (0, 1664)	3.3682824482920752
  (0, 1663)	3.4174532783982574
  (0, 1662)	3.3682824482920752
  (0, 1661)	3.3682824482920752
  (0, 1660)	3.2040343977282126
  (0, 1659)	3.2341103008983234
  (0, 1658)	3.3682824482920752
  (0, 1657)	3.3682824482920752
  :	:
  (942, 24)	2.9678603597252273
  (942, 23)	3.1796565042495857
  (942, 22)	3.709698342069007
  (942, 21)	3.7675416915882107
  (942, 20)	2.591048063065227
  (942, 19)	3.305992656637025
  (942, 18)	3.260331656994485
  (942, 17)	3.0862364747330577
  (942, 16)	2.7768777284347643
  (942, 15)	3.0104622946374175
  (942, 14)	3.3563087880696734
  (942, 13)	3.5927601385644485
  (942, 12)	3.096875908633678
  (942, 11)	3.94826355363711
  (942, 10)	3.5358495042714373
  (942, 9)	3.4746207125759137
  (942, 8)	3.5470472775562807
  (942, 7)	3.733021154403947
  (942, 6)	3.5188137961148707
  (942, 5)	3.209985325985193
  (942, 4)	3.011514339347166
  (942, 3)	3.2511281780703993
  (942, 2)	2.938540732993259
  (942, 1)	3.005344341193194
  (942, 0)	3.5678053517189396
this is the 204 epoch
rmse loss on training set is 0.9010787747427038
rmse loss on test set is 0.9168286828482491
for this epoch using 82.9750645160675 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.368212623318632
  (0, 1680)	3.3789302992029087
  (0, 1679)	3.368212623318632
  (0, 1678)	3.368212623318632
  (0, 1677)	3.368212623318632
  (0, 1676)	3.368212623318632
  (0, 1675)	3.368212623318632
  (0, 1674)	3.368212623318632
  (0, 1673)	3.368212623318632
  (0, 1672)	3.368212623318632
  (0, 1671)	3.3155296037546673
  (0, 1670)	3.368212623318632
  (0, 1669)	3.368212623318632
  (0, 1668)	3.368212623318632
  (0, 1667)	3.368212623318632
  (0, 1666)	3.368212623318632
  (0, 1665)	3.368212623318632
  (0, 1664)	3.368212623318632
  (0, 1663)	3.417592515946754
  (0, 1662)	3.368212623318632
  (0, 1661)	3.368212623318632
  (0, 1660)	3.2031983783861353
  (0, 1659)	3.2334292307635963
  (0, 1658)	3.368212623318632
  (0, 1657)	3.368212623318632
  :	:
  (942, 24)	2.9679825322652174
  (942, 23)	3.1797297846000547
  (942, 22)	3.71000313495749
  (942, 21)	3.767699588705624
  (942, 20)	2.590767694099984
  (942, 19)	3.3065144397581574
  (942, 18)	3.2610646097211986
  (942, 17)	3.086652396984137
  (942, 16)	2.7767487667278434
  (942, 15)	3.010609930953406
  (942, 14)	3.356444904560058
  (942, 13)	3.5931718485027404
  (942, 12)	3.0970696746424258
  (942, 11)	3.9484516626224333
  (942, 10)	3.5359907055515665
  (942, 9)	3.475267404673677
  (942, 8)	3.547232990877047
  (942, 7)	3.733239819746404
  (942, 6)	3.5189608074851004
  (942, 5)	3.210873820256954
  (942, 4)	3.0115367749615833
  (942, 3)	3.2512592271954306
  (942, 2)	2.938525596123124
  (942, 1)	3.00538890897028
  (942, 0)	3.567940067669579
this is the 205 epoch
rmse loss on training set is 0.9010172440069675
rmse loss on test set is 0.9167973853923176
for this epoch using 81.81616735458374 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.368143206921759
  (0, 1680)	3.3789212898326766
  (0, 1679)	3.368143206921759
  (0, 1678)	3.368143206921759
  (0, 1677)	3.368143206921759
  (0, 1676)	3.368143206921759
  (0, 1675)	3.368143206921759
  (0, 1674)	3.368143206921759
  (0, 1673)	3.368143206921759
  (0, 1672)	3.368143206921759
  (0, 1671)	3.315224307123204
  (0, 1670)	3.368143206921759
  (0, 1669)	3.368143206921759
  (0, 1668)	3.368143206921759
  (0, 1667)	3.368143206921759
  (0, 1666)	3.368143206921759
  (0, 1665)	3.368143206921759
  (0, 1664)	3.368143206921759
  (0, 1663)	3.4177319997878546
  (0, 1662)	3.368143206921759
  (0, 1661)	3.368143206921759
  (0, 1660)	3.202363178113028
  (0, 1659)	3.2327490294370413
  (0, 1658)	3.368143206921759
  (0, 1657)	3.368143206921759
  :	:
  (942, 24)	2.968104107599062
  (942, 23)	3.1798029021563963
  (942, 22)	3.7103053461598576
  (942, 21)	3.7678565994545723
  (942, 20)	2.5904922059676765
  (942, 19)	3.3070323967910635
  (942, 18)	3.2617941159203747
  (942, 17)	3.0870680993726407
  (942, 16)	2.7766224468595424
  (942, 15)	3.0107577541552906
  (942, 14)	3.356580307573733
  (942, 13)	3.5935795758530693
  (942, 12)	3.0972623441199993
  (942, 11)	3.9486386089046204
  (942, 10)	3.5361311509679187
  (942, 9)	3.475908384389071
  (942, 8)	3.5474175052077297
  (942, 7)	3.733457007993944
  (942, 6)	3.519107033635362
  (942, 5)	3.211760801934277
  (942, 4)	3.0115596179473685
  (942, 3)	3.2513896091083554
  (942, 2)	2.9385114349058212
  (942, 1)	3.0054336170990554
  (942, 0)	3.568074104837565
this is the 206 epoch
rmse loss on training set is 0.9009562545999242
rmse loss on test set is 0.9167664551869558
for this epoch using 81.53973007202148 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.368074196911069
  (0, 1680)	3.378912688818387
  (0, 1679)	3.368074196911069
  (0, 1678)	3.368074196911069
  (0, 1677)	3.368074196911069
  (0, 1676)	3.368074196911069
  (0, 1675)	3.368074196911069
  (0, 1674)	3.368074196911069
  (0, 1673)	3.368074196911069
  (0, 1672)	3.368074196911069
  (0, 1671)	3.314919507522405
  (0, 1670)	3.368074196911069
  (0, 1669)	3.368074196911069
  (0, 1668)	3.368074196911069
  (0, 1667)	3.368074196911069
  (0, 1666)	3.368074196911069
  (0, 1665)	3.368074196911069
  (0, 1664)	3.368074196911069
  (0, 1663)	3.417871728538007
  (0, 1662)	3.368074196911069
  (0, 1661)	3.368074196911069
  (0, 1660)	3.2015287933660432
  (0, 1659)	3.2320696928878667
  (0, 1658)	3.368074196911069
  (0, 1657)	3.368074196911069
  :	:
  (942, 24)	2.968225086845629
  (942, 23)	3.1798758546088544
  (942, 22)	3.7106050108569364
  (942, 21)	3.768012729599629
  (942, 20)	2.590221522010961
  (942, 19)	3.3075465585150616
  (942, 18)	3.2625201880047747
  (942, 17)	3.0874835798736275
  (942, 16)	2.776498724920213
  (942, 15)	3.0109057556981624
  (942, 14)	3.356715001416653
  (942, 13)	3.593983375746707
  (942, 12)	3.0974539201964078
  (942, 11)	3.9488244026145467
  (942, 10)	3.536270845014711
  (942, 9)	3.476543709905087
  (942, 8)	3.547600832448317
  (942, 7)	3.7336727335849127
  (942, 6)	3.5192524783368144
  (942, 5)	3.2126462713369714
  (942, 4)	3.0115828598146956
  (942, 3)	3.2515193267477045
  (942, 2)	2.9384982319207835
  (942, 1)	3.0054784576768028
  (942, 0)	3.568207466306044
this is the 207 epoch
rmse loss on training set is 0.900895799637742
rmse loss on test set is 0.9167358872947853
for this epoch using 82.84495425224304 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3680055911063773
  (0, 1680)	3.37890449392604
  (0, 1679)	3.3680055911063773
  (0, 1678)	3.3680055911063773
  (0, 1677)	3.3680055911063773
  (0, 1676)	3.3680055911063773
  (0, 1675)	3.3680055911063773
  (0, 1674)	3.3680055911063773
  (0, 1673)	3.3680055911063773
  (0, 1672)	3.3680055911063773
  (0, 1671)	3.3146152025946467
  (0, 1670)	3.3680055911063773
  (0, 1669)	3.3680055911063773
  (0, 1668)	3.3680055911063773
  (0, 1667)	3.3680055911063773
  (0, 1666)	3.3680055911063773
  (0, 1665)	3.3680055911063773
  (0, 1664)	3.3680055911063773
  (0, 1663)	3.4180117008154305
  (0, 1662)	3.3680055911063773
  (0, 1661)	3.3680055911063773
  (0, 1660)	3.200695220624406
  (0, 1659)	3.231391217114064
  (0, 1658)	3.3680055911063773
  (0, 1657)	3.3680055911063773
  :	:
  (942, 24)	2.9683454712305952
  (942, 23)	3.1799486397172454
  (942, 22)	3.7109021635354176
  (942, 21)	3.7681679848822265
  (942, 20)	2.5899555667443734
  (942, 19)	3.30805695547516
  (942, 18)	3.263242838419633
  (942, 17)	3.08789883648814
  (942, 16)	2.7763775576924523
  (942, 15)	3.011053927165491
  (942, 14)	3.3568489903538428
  (942, 13)	3.594383302374054
  (942, 12)	3.0976444061545187
  (942, 11)	3.9490090537535267
  (942, 10)	3.536409792172692
  (942, 9)	3.477173438773145
  (942, 8)	3.5477829843014734
  (942, 7)	3.7338870107487976
  (942, 6)	3.5193971454015975
  (942, 5)	3.2135302288147867
  (942, 4)	3.0116064921910097
  (942, 3)	3.2516483830847838
  (942, 2)	2.938485970012807
  (942, 1)	3.00552342301114
  (942, 0)	3.5683401551870104
this is the 208 epoch
rmse loss on training set is 0.9008358723504226
rmse loss on test set is 0.9167056768613309
for this epoch using 83.54598140716553 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.367937387337472
  (0, 1680)	3.3788967029316614
  (0, 1679)	3.367937387337472
  (0, 1678)	3.367937387337472
  (0, 1677)	3.367937387337472
  (0, 1676)	3.367937387337472
  (0, 1675)	3.367937387337472
  (0, 1674)	3.367937387337472
  (0, 1673)	3.367937387337472
  (0, 1672)	3.367937387337472
  (0, 1671)	3.3143113899931413
  (0, 1670)	3.367937387337472
  (0, 1669)	3.367937387337472
  (0, 1668)	3.367937387337472
  (0, 1667)	3.367937387337472
  (0, 1666)	3.367937387337472
  (0, 1665)	3.367937387337472
  (0, 1664)	3.367937387337472
  (0, 1663)	3.4181519152399256
  (0, 1662)	3.367937387337472
  (0, 1661)	3.367937387337472
  (0, 1660)	3.1998624563890594
  (0, 1659)	3.230713598141845
  (0, 1658)	3.367937387337472
  (0, 1657)	3.367937387337472
  :	:
  (942, 24)	2.9684652620808554
  (942, 23)	3.180021255309835
  (942, 22)	3.71119683800516
  (942, 21)	3.7683223710200773
  (942, 20)	2.589694265836686
  (942, 19)	3.30856361798318
  (942, 18)	3.2639620796408297
  (942, 17)	3.0883138672428254
  (942, 16)	2.7762589026406537
  (942, 15)	3.011202260267187
  (942, 14)	3.356982278611009
  (942, 13)	3.5947794090027405
  (942, 12)	3.0978338054230785
  (942, 11)	3.9491925721962984
  (942, 10)	3.5365479969088347
  (942, 9)	3.477797627920126
  (942, 8)	3.547963972277907
  (942, 7)	3.7340998535110748
  (942, 6)	3.5195410386798627
  (942, 5)	3.214412674746891
  (942, 4)	3.011630506819925
  (942, 3)	3.2517767811213845
  (942, 2)	2.9384746322883197
  (942, 1)	3.00556850561476
  (942, 0)	3.5684721746190857
this is the 209 epoch
rmse loss on training set is 0.900776466079453
rmse loss on test set is 0.9166758191132881
for this epoch using 81.76656174659729 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3678695834437704
  (0, 1680)	3.3788893136210247
  (0, 1679)	3.3678695834437704
  (0, 1678)	3.3678695834437704
  (0, 1677)	3.3678695834437704
  (0, 1676)	3.3678695834437704
  (0, 1675)	3.3678695834437704
  (0, 1674)	3.3678695834437704
  (0, 1673)	3.3678695834437704
  (0, 1672)	3.3678695834437704
  (0, 1671)	3.3140080673815744
  (0, 1670)	3.3678695834437704
  (0, 1669)	3.3678695834437704
  (0, 1668)	3.3678695834437704
  (0, 1667)	3.3678695834437704
  (0, 1666)	3.3678695834437704
  (0, 1665)	3.3678695834437704
  (0, 1664)	3.3678695834437704
  (0, 1663)	3.418292370432718
  (0, 1662)	3.3678695834437704
  (0, 1661)	3.3678695834437704
  (0, 1660)	3.1990304971822874
  (0, 1659)	3.2300368320251573
  (0, 1658)	3.3678695834437704
  (0, 1657)	3.3678695834437704
  :	:
  (942, 24)	2.968584460819244
  (942, 23)	3.180093699282183
  (942, 22)	3.7114890674161005
  (942, 21)	3.7684758937065865
  (942, 20)	2.5894375460935692
  (942, 19)	3.30906657611893
  (942, 18)	3.264677924173147
  (942, 17)	3.0887286701896057
  (942, 16)	2.7761427179007043
  (942, 15)	3.011350746837737
  (942, 14)	3.3571148703759564
  (942, 13)	3.5951717479953014
  (942, 12)	3.0980221215700046
  (942, 11)	3.9493749676937915
  (942, 10)	3.5366854636760086
  (942, 9)	3.4784163336552427
  (942, 8)	3.5481438077014977
  (942, 7)	3.7343112756978494
  (942, 6)	3.5196841620567625
  (942, 5)	3.2152936095413795
  (942, 4)	3.0116548955602283
  (942, 3)	3.2519045238876814
  (942, 2)	2.938464202111744
  (942, 1)	3.0056136982003894
  (942, 0)	3.5686035277655077
this is the 210 epoch
rmse loss on training set is 0.90071757427558
rmse loss on test set is 0.9166463093568611
for this epoch using 80.85077667236328 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3678021772740823
  (0, 1680)	3.3788823237893735
  (0, 1679)	3.3678021772740823
  (0, 1678)	3.3678021772740823
  (0, 1677)	3.3678021772740823
  (0, 1676)	3.3678021772740823
  (0, 1675)	3.3678021772740823
  (0, 1674)	3.3678021772740823
  (0, 1673)	3.3678021772740823
  (0, 1672)	3.3678021772740823
  (0, 1671)	3.3137052324338683
  (0, 1670)	3.3678021772740823
  (0, 1669)	3.3678021772740823
  (0, 1668)	3.3678021772740823
  (0, 1667)	3.3678021772740823
  (0, 1666)	3.3678021772740823
  (0, 1665)	3.3678021772740823
  (0, 1664)	3.3678021772740823
  (0, 1663)	3.4184330650162735
  (0, 1662)	3.3678021772740823
  (0, 1661)	3.3678021772740823
  (0, 1660)	3.1981993395473305
  (0, 1659)	3.22936091484513
  (0, 1658)	3.3678021772740823
  (0, 1657)	3.3678021772740823
  :	:
  (942, 24)	2.9687030689594422
  (942, 23)	3.1801659695959996
  (942, 22)	3.711778884274565
  (942, 21)	3.7686285586103483
  (942, 20)	2.589185335440456
  (942, 19)	3.3095658597313653
  (942, 18)	3.2653903845485335
  (942, 17)	3.089143243405303
  (942, 16)	2.776028962269886
  (942, 15)	3.0114993788343596
  (942, 14)	3.3572467697999833
  (942, 13)	3.5955603708265396
  (942, 12)	3.098209358295784
  (942, 11)	3.949556249875919
  (942, 10)	3.5368221969126474
  (942, 9)	3.4790296116769217
  (942, 8)	3.5483225017142463
  (942, 7)	3.734521290940363
  (942, 6)	3.519826519449622
  (942, 5)	3.216173033634766
  (942, 4)	3.011679650384756
  (942, 3)	3.2520316144401655
  (942, 2)	2.93845466310183
  (942, 1)	3.0056589936757767
  (942, 0)	3.5687342178121213
this is the 211 epoch
rmse loss on training set is 0.9006591904965506
rmse loss on test set is 0.9166171429761137
for this epoch using 79.72270727157593 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.367735166686424
  (0, 1680)	3.378875731241209
  (0, 1679)	3.367735166686424
  (0, 1678)	3.367735166686424
  (0, 1677)	3.367735166686424
  (0, 1676)	3.367735166686424
  (0, 1675)	3.367735166686424
  (0, 1674)	3.367735166686424
  (0, 1673)	3.367735166686424
  (0, 1672)	3.367735166686424
  (0, 1671)	3.313402882833988
  (0, 1670)	3.367735166686424
  (0, 1669)	3.367735166686424
  (0, 1668)	3.367735166686424
  (0, 1667)	3.367735166686424
  (0, 1666)	3.367735166686424
  (0, 1665)	3.367735166686424
  (0, 1664)	3.367735166686424
  (0, 1663)	3.4185739976141822
  (0, 1662)	3.367735166686424
  (0, 1661)	3.367735166686424
  (0, 1660)	3.197368980048114
  (0, 1659)	3.228685842709678
  (0, 1658)	3.367735166686424
  (0, 1657)	3.367735166686424
  :	:
  (942, 24)	2.968821088101149
  (942, 23)	3.180238064278052
  (942, 22)	3.7120663204591966
  (942, 21)	3.76878037137462
  (942, 20)	2.5889375629057017
  (942, 19)	3.3100614984397976
  (942, 18)	3.2660994733244135
  (942, 17)	3.0895575849913444
  (942, 16)	2.775917595196826
  (942, 15)	3.0116481483351905
  (942, 14)	3.357377980999155
  (942, 13)	3.5959453281005023
  (942, 12)	3.098395519427212
  (942, 11)	3.949736428254092
  (942, 10)	3.5369582010424048
  (942, 9)	3.4796375170795764
  (942, 8)	3.5485000652810887
  (942, 7)	3.7347299126793962
  (942, 6)	3.5199681148052995
  (942, 5)	3.217050947491516
  (942, 4)	3.011704763379353
  (942, 3)	3.25215805585972
  (942, 2)	2.938445999128138
  (942, 1)	3.005704385138876
  (942, 0)	3.5688642479655193
this is the 212 epoch
rmse loss on training set is 0.90060130840498
rmse loss on test set is 0.9165883154313667
for this epoch using 81.42326235771179 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3676685495477248
  (0, 1680)	3.378869533790057
  (0, 1679)	3.3676685495477248
  (0, 1678)	3.3676685495477248
  (0, 1677)	3.3676685495477248
  (0, 1676)	3.3676685495477248
  (0, 1675)	3.3676685495477248
  (0, 1674)	3.3676685495477248
  (0, 1673)	3.3676685495477248
  (0, 1672)	3.3676685495477248
  (0, 1671)	3.313101016275622
  (0, 1670)	3.3676685495477248
  (0, 1669)	3.3676685495477248
  (0, 1668)	3.3676685495477248
  (0, 1667)	3.3676685495477248
  (0, 1666)	3.3676685495477248
  (0, 1665)	3.3676685495477248
  (0, 1664)	3.3676685495477248
  (0, 1663)	3.4187151668510336
  (0, 1662)	3.3676685495477248
  (0, 1661)	3.3676685495477248
  (0, 1660)	3.1965394152688735
  (0, 1659)	3.228011611753029
  (0, 1658)	3.3676685495477248
  (0, 1657)	3.3676685495477248
  :	:
  (942, 24)	2.9689385199254197
  (942, 23)	3.180309981419007
  (942, 22)	3.7123514072363863
  (942, 21)	3.7689313376168436
  (942, 20)	2.5886941586039947
  (942, 19)	3.310553521635094
  (942, 18)	3.2668052030820305
  (942, 17)	3.0899716930733954
  (942, 16)	2.7758085767716816
  (942, 15)	3.011797047537506
  (942, 14)	3.3575085080555405
  (942, 13)	3.5963266695670453
  (942, 12)	3.0985806089112984
  (942, 11)	3.949915512223817
  (942, 10)	3.5370934804738625
  (942, 9)	3.4802401043602766
  (942, 8)	3.548676509194461
  (942, 7)	3.7349371541693706
  (942, 6)	3.520108952097467
  (942, 5)	3.217927351603556
  (942, 4)	3.0117302267418085
  (942, 3)	3.252283851249632
  (942, 2)	2.9384381943074804
  (942, 1)	3.005749865873118
  (942, 0)	3.5689936214511557
this is the 213 epoch
rmse loss on training set is 0.900543921766271
rmse loss on test set is 0.9165598222576601
for this epoch using 81.70464587211609 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.367602323733698
  (0, 1680)	3.3788637292582697
  (0, 1679)	3.367602323733698
  (0, 1678)	3.367602323733698
  (0, 1677)	3.367602323733698
  (0, 1676)	3.367602323733698
  (0, 1675)	3.367602323733698
  (0, 1674)	3.367602323733698
  (0, 1673)	3.367602323733698
  (0, 1672)	3.367602323733698
  (0, 1671)	3.3127996304620915
  (0, 1670)	3.367602323733698
  (0, 1669)	3.367602323733698
  (0, 1668)	3.367602323733698
  (0, 1667)	3.367602323733698
  (0, 1666)	3.367602323733698
  (0, 1665)	3.367602323733698
  (0, 1664)	3.367602323733698
  (0, 1663)	3.4188565713523404
  (0, 1662)	3.367602323733698
  (0, 1661)	3.367602323733698
  (0, 1660)	3.195710641813937
  (0, 1659)	3.227338218135306
  (0, 1658)	3.367602323733698
  (0, 1657)	3.367602323733698
  :	:
  (942, 24)	2.969055366190226
  (942, 23)	3.180381719172322
  (942, 22)	3.7126341752752965
  (942, 21)	3.7690814629281584
  (942, 20)	2.588455053719964
  (942, 19)	3.311041958480849
  (942, 18)	3.2675075864248075
  (942, 17)	3.0903855658010504
  (942, 16)	2.775701867716385
  (942, 15)	3.0119460687559445
  (942, 14)	3.357638355018346
  (942, 13)	3.5967044441381764
  (942, 12)	3.0987646308093213
  (942, 11)	3.9500935110670268
  (942, 10)	3.5372280396001874
  (942, 9)	3.480837427425398
  (942, 8)	3.5488518440788037
  (942, 7)	3.735143028482507
  (942, 6)	3.5202490353242575
  (942, 5)	3.2188022464898425
  (942, 4)	3.011756032780744
  (942, 3)	3.252409003733907
  (942, 2)	2.938431233000432
  (942, 1)	3.0057954293427684
  (942, 0)	3.5691223415116773
this is the 214 epoch
rmse loss on training set is 0.9004870244465035
rmse loss on test set is 0.9165316590632159
for this epoch using 80.47283244132996 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3675364871286413
  (0, 1680)	3.378858315476841
  (0, 1679)	3.3675364871286413
  (0, 1678)	3.3675364871286413
  (0, 1677)	3.3675364871286413
  (0, 1676)	3.3675364871286413
  (0, 1675)	3.3675364871286413
  (0, 1674)	3.3675364871286413
  (0, 1673)	3.3675364871286413
  (0, 1672)	3.3675364871286413
  (0, 1671)	3.3124987231060663
  (0, 1670)	3.3675364871286413
  (0, 1669)	3.3675364871286413
  (0, 1668)	3.3675364871286413
  (0, 1667)	3.3675364871286413
  (0, 1666)	3.3675364871286413
  (0, 1665)	3.3675364871286413
  (0, 1664)	3.3675364871286413
  (0, 1663)	3.418998209744408
  (0, 1662)	3.3675364871286413
  (0, 1661)	3.3675364871286413
  (0, 1660)	3.194882656307378
  (0, 1659)	3.226665658042144
  (0, 1658)	3.3675364871286413
  (0, 1657)	3.3675364871286413
  :	:
  (942, 24)	2.9691716287262064
  (942, 23)	3.1804532757531088
  (942, 22)	3.712914654662375
  (942, 21)	3.76923075287296
  (942, 20)	2.5882201804920877
  (942, 19)	3.3115268379146463
  (942, 18)	3.2682066359767714
  (942, 17)	3.0907992013475094
  (942, 16)	2.7755974293750745
  (942, 15)	3.0120952044208433
  (942, 14)	3.357767525904999
  (942, 13)	3.5970786999039555
  (942, 12)	3.0989475892912104
  (942, 11)	3.9502704339544157
  (942, 10)	3.5373618827987827
  (942, 9)	3.4814295395971566
  (942, 8)	3.5490260803947797
  (942, 7)	3.735347548512681
  (942, 6)	3.5203883685057717
  (942, 5)	3.2196756326958513
  (942, 4)	3.011782173914564
  (942, 3)	3.2525335164554185
  (942, 2)	2.9384250998079007
  (942, 1)	3.0058410691885067
  (942, 0)	3.5692504114051955
this is the 215 epoch
rmse loss on training set is 0.9004306104105133
rmse loss on test set is 0.9165038215279665
for this epoch using 80.0402307510376 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3674710376252746
  (0, 1680)	3.3788532902852615
  (0, 1679)	3.3674710376252746
  (0, 1678)	3.3674710376252746
  (0, 1677)	3.3674710376252746
  (0, 1676)	3.3674710376252746
  (0, 1675)	3.3674710376252746
  (0, 1674)	3.3674710376252746
  (0, 1673)	3.3674710376252746
  (0, 1672)	3.3674710376252746
  (0, 1671)	3.312198291929497
  (0, 1670)	3.3674710376252746
  (0, 1669)	3.3674710376252746
  (0, 1668)	3.3674710376252746
  (0, 1667)	3.3674710376252746
  (0, 1666)	3.3674710376252746
  (0, 1665)	3.3674710376252746
  (0, 1664)	3.3674710376252746
  (0, 1663)	3.419140080654359
  (0, 1662)	3.3674710376252746
  (0, 1661)	3.3674710376252746
  (0, 1660)	3.1940554553928124
  (0, 1659)	3.2259939276843013
  (0, 1658)	3.3674710376252746
  (0, 1657)	3.3674710376252746
  :	:
  (942, 24)	2.9692873094326164
  (942, 23)	3.1805246494370176
  (942, 22)	3.7131928749156327
  (942, 21)	3.7693792129884374
  (942, 20)	2.587989472196781
  (942, 19)	3.3120081886492287
  (942, 18)	3.268902364380955
  (942, 17)	3.0912125979092693
  (942, 16)	2.7754952237046164
  (942, 15)	3.012244447076486
  (942, 14)	3.357896024702158
  (942, 13)	3.5974494841481293
  (942, 12)	3.0991294886299596
  (942, 11)	3.9504462899476778
  (942, 10)	3.5374950144309976
  (942, 9)	3.482016493620079
  (942, 8)	3.5491992284435
  (942, 7)	3.7355507269792194
  (942, 6)	3.520526955681858
  (942, 5)	3.220547510793193
  (942, 4)	3.011808642670342
  (942, 3)	3.252657392574304
  (942, 2)	2.938419779567745
  (942, 1)	3.0058867792229567
  (942, 0)	3.569377834403715
this is the 216 epoch
rmse loss on training set is 0.9003746737197977
rmse loss on test set is 0.9164763054021053
for this epoch using 80.56030774116516 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.367405973124571
  (0, 1680)	3.3788486515313023
  (0, 1679)	3.367405973124571
  (0, 1678)	3.367405973124571
  (0, 1677)	3.367405973124571
  (0, 1676)	3.367405973124571
  (0, 1675)	3.367405973124571
  (0, 1674)	3.367405973124571
  (0, 1673)	3.367405973124571
  (0, 1672)	3.367405973124571
  (0, 1671)	3.3118983346633266
  (0, 1670)	3.367405973124571
  (0, 1669)	3.367405973124571
  (0, 1668)	3.367405973124571
  (0, 1667)	3.367405973124571
  (0, 1666)	3.367405973124571
  (0, 1665)	3.367405973124571
  (0, 1664)	3.367405973124571
  (0, 1663)	3.4192821827099267
  (0, 1662)	3.367405973124571
  (0, 1661)	3.367405973124571
  (0, 1660)	3.1932290357330912
  (0, 1659)	3.225323023297276
  (0, 1658)	3.367405973124571
  (0, 1657)	3.367405973124571
  :	:
  (942, 24)	2.9694024102734424
  (942, 23)	3.1805958385591655
  (942, 22)	3.713468864998299
  (942, 21)	3.769526848784223
  (942, 20)	2.587762863132773
  (942, 19)	3.312486039173763
  (942, 18)	3.269594784297929
  (942, 17)	3.091625753705807
  (942, 16)	2.775395213265331
  (942, 15)	3.0123937893795176
  (942, 14)	3.358023855366656
  (942, 13)	3.5978168433634052
  (942, 12)	3.099310333196387
  (942, 11)	3.95062108800166
  (942, 10)	3.5376274388418123
  (942, 9)	3.4825983416674426
  (942, 8)	3.549371298370431
  (942, 7)	3.735752576430569
  (942, 6)	3.5206648009098878
  (942, 5)	3.22141788137913
  (942, 4)	3.011835431682736
  (942, 3)	3.252780635266345
  (942, 2)	2.9384152573513904
  (942, 1)	3.005932553426488
  (942, 0)	3.5695046137915747
this is the 217 epoch
rmse loss on training set is 0.9003192085307751
rmse loss on test set is 0.9164491065046764
for this epoch using 82.89927959442139 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.36734129153567
  (0, 1680)	3.3788443970709743
  (0, 1679)	3.36734129153567
  (0, 1678)	3.36734129153567
  (0, 1677)	3.36734129153567
  (0, 1676)	3.36734129153567
  (0, 1675)	3.36734129153567
  (0, 1674)	3.36734129153567
  (0, 1673)	3.36734129153567
  (0, 1672)	3.36734129153567
  (0, 1671)	3.311598849047519
  (0, 1670)	3.36734129153567
  (0, 1669)	3.36734129153567
  (0, 1668)	3.36734129153567
  (0, 1667)	3.36734129153567
  (0, 1666)	3.36734129153567
  (0, 1665)	3.36734129153567
  (0, 1664)	3.36734129153567
  (0, 1663)	3.419424514539598
  (0, 1662)	3.36734129153567
  (0, 1661)	3.36734129153567
  (0, 1660)	3.1924033940101526
  (0, 1659)	3.2246529411410196
  (0, 1658)	3.36734129153567
  (0, 1657)	3.36734129153567
  :	:
  (942, 24)	2.9695169332736913
  (942, 23)	3.180666841513007
  (942, 22)	3.713742653332241
  (942, 21)	3.7696736657419447
  (942, 20)	2.5875402886056826
  (942, 19)	3.3129604177550838
  (942, 18)	3.2702839084042417
  (942, 17)	3.0920386669792927
  (942, 16)	2.7752973612117615
  (942, 15)	3.01254322409723
  (942, 14)	3.3581510218264112
  (942, 13)	3.5981808232664663
  (942, 12)	3.099490127453926
  (942, 11)	3.950794836966366
  (942, 10)	3.5377591603595056
  (942, 9)	3.483175135347555
  (942, 8)	3.5495423001693265
  (942, 7)	3.7359531092478364
  (942, 6)	3.520801908262667
  (942, 5)	3.2222867450761656
  (942, 4)	3.011862533692922
  (942, 3)	3.252903247721406
  (942, 2)	2.9384115184605704
  (942, 1)	3.005978385942981
  (942, 0)	3.5696307528640054
this is the 218 epoch
rmse loss on training set is 0.900264209092792
rmse loss on test set is 0.916422220722203
for this epoch using 81.89651608467102 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3672769907757254
  (0, 1680)	3.37884052476834
  (0, 1679)	3.3672769907757254
  (0, 1678)	3.3672769907757254
  (0, 1677)	3.3672769907757254
  (0, 1676)	3.3672769907757254
  (0, 1675)	3.3672769907757254
  (0, 1674)	3.3672769907757254
  (0, 1673)	3.3672769907757254
  (0, 1672)	3.3672769907757254
  (0, 1671)	3.311299832830767
  (0, 1670)	3.3672769907757254
  (0, 1669)	3.3672769907757254
  (0, 1668)	3.3672769907757254
  (0, 1667)	3.3672769907757254
  (0, 1666)	3.3672769907757254
  (0, 1665)	3.3672769907757254
  (0, 1664)	3.3672769907757254
  (0, 1663)	3.4195670747724174
  (0, 1662)	3.3672769907757254
  (0, 1661)	3.3672769907757254
  (0, 1660)	3.191578526924738
  (0, 1659)	3.2239836774995427
  (0, 1658)	3.3672769907757254
  (0, 1657)	3.3672769907757254
  :	:
  (942, 24)	2.9696308805158216
  (942, 23)	3.1807376567492214
  (942, 22)	3.7140142678109775
  (942, 21)	3.7698196693148724
  (942, 20)	2.587321684912825
  (942, 19)	3.3134313524388825
  (942, 18)	3.2709697493909893
  (942, 17)	3.0924513359942725
  (942, 16)	2.7752016312836436
  (942, 15)	3.012692744106033
  (942, 14)	3.358277527981241
  (942, 13)	3.5985414688125994
  (942, 12)	3.0996688759537445
  (942, 11)	3.950967545589014
  (942, 10)	3.5378901832953717
  (942, 9)	3.483746925710069
  (942, 8)	3.5497122436859003
  (942, 7)	3.7361523376482353
  (942, 6)	3.520938281826445
  (942, 5)	3.223154102531629
  (942, 4)	3.011889941547465
  (942, 3)	3.253025233141999
  (942, 2)	2.938408548423998
  (942, 1)	3.006024271075793
  (942, 0)	3.569756254925705
this is the 219 epoch
rmse loss on training set is 0.9002096697463297
rmse loss on test set is 0.916395644007335
for this epoch using 82.79835724830627 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.367213068769792
  (0, 1680)	3.3788370324954182
  (0, 1679)	3.367213068769792
  (0, 1678)	3.367213068769792
  (0, 1677)	3.367213068769792
  (0, 1676)	3.367213068769792
  (0, 1675)	3.367213068769792
  (0, 1674)	3.367213068769792
  (0, 1673)	3.367213068769792
  (0, 1672)	3.367213068769792
  (0, 1671)	3.311001283770511
  (0, 1670)	3.367213068769792
  (0, 1669)	3.367213068769792
  (0, 1668)	3.367213068769792
  (0, 1667)	3.367213068769792
  (0, 1666)	3.367213068769792
  (0, 1665)	3.367213068769792
  (0, 1664)	3.367213068769792
  (0, 1663)	3.4197098620380832
  (0, 1662)	3.367213068769792
  (0, 1661)	3.367213068769792
  (0, 1660)	3.1907544311962064
  (0, 1659)	3.223315228680667
  (0, 1658)	3.367213068769792
  (0, 1657)	3.367213068769792
  :	:
  (942, 24)	2.9697442541363634
  (942, 23)	3.1808082827746924
  (942, 22)	3.7142837358123066
  (942, 21)	3.7699648649275947
  (942, 20)	2.5871069893282552
  (942, 19)	3.3138988710510238
  (942, 18)	3.271652319962376
  (942, 17)	3.092863759037374
  (942, 16)	2.7751079877969675
  (942, 15)	3.0128423423898485
  (942, 14)	3.3584033777037
  (942, 13)	3.598898824210089
  (942, 12)	3.099846583329891
  (942, 11)	3.9511392225159145
  (942, 10)	3.53802051194338
  (942, 9)	3.484313763252132
  (942, 8)	3.549881138621469
  (942, 7)	3.736350273688366
  (942, 6)	3.5210739256989814
  (942, 5)	3.22401995441725
  (942, 4)	3.01191764819726
  (942, 3)	3.253146594741858
  (942, 2)	2.9384063329941874
  (942, 1)	3.0060702032838047
  (942, 0)	3.569881123289487
this is the 220 epoch
rmse loss on training set is 0.9001555849212652
rmse loss on test set is 0.916369372377542
for this epoch using 82.71212124824524 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3671495234507614
  (0, 1680)	3.37883391813208
  (0, 1679)	3.3671495234507614
  (0, 1678)	3.3671495234507614
  (0, 1677)	3.3671495234507614
  (0, 1676)	3.3671495234507614
  (0, 1675)	3.3671495234507614
  (0, 1674)	3.3671495234507614
  (0, 1673)	3.3671495234507614
  (0, 1672)	3.3671495234507614
  (0, 1671)	3.310703199632764
  (0, 1670)	3.3671495234507614
  (0, 1669)	3.3671495234507614
  (0, 1668)	3.3671495234507614
  (0, 1667)	3.3671495234507614
  (0, 1666)	3.3671495234507614
  (0, 1665)	3.3671495234507614
  (0, 1664)	3.3671495234507614
  (0, 1663)	3.419852874966894
  (0, 1662)	3.3671495234507614
  (0, 1661)	3.3671495234507614
  (0, 1660)	3.1899311035623374
  (0, 1659)	3.222647591015676
  (0, 1658)	3.3671495234507614
  (0, 1657)	3.3671495234507614
  :	:
  (942, 24)	2.969857056322682
  (942, 23)	3.1808787181513742
  (942, 22)	3.7145510842105707
  (942, 21)	3.7701092579756295
  (942, 20)	2.586896140088022
  (942, 19)	3.314363001198763
  (942, 18)	3.272331632834275
  (942, 17)	3.093275934417046
  (942, 16)	2.7750163956351765
  (942, 15)	3.0129920120385507
  (942, 14)	3.358528574839738
  (942, 13)	3.5992529329342884
  (942, 12)	3.1000232542946873
  (942, 11)	3.951309876294334
  (942, 10)	3.5381501505799613
  (942, 9)	3.4848756979245334
  (942, 8)	3.5500489945363713
  (942, 7)	3.7365469292674423
  (942, 6)	3.5212088439877216
  (942, 5)	3.2248843014287476
  (942, 4)	3.011945646696403
  (942, 3)	3.253267335744579
  (942, 2)	2.9384048581442648
  (942, 1)	3.0061161771774976
  (942, 0)	3.570005361275024
this is the 221 epoch
rmse loss on training set is 0.9001019491350761
rmse loss on test set is 0.9163434019138352
for this epoch using 82.91887784004211 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3670863527592347
  (0, 1680)	3.378831179565988
  (0, 1679)	3.3670863527592347
  (0, 1678)	3.3670863527592347
  (0, 1677)	3.3670863527592347
  (0, 1676)	3.3670863527592347
  (0, 1675)	3.3670863527592347
  (0, 1674)	3.3670863527592347
  (0, 1673)	3.3670863527592347
  (0, 1672)	3.3670863527592347
  (0, 1671)	3.3104055781920283
  (0, 1670)	3.3670863527592347
  (0, 1669)	3.3670863527592347
  (0, 1668)	3.3670863527592347
  (0, 1667)	3.3670863527592347
  (0, 1666)	3.3670863527592347
  (0, 1665)	3.3670863527592347
  (0, 1664)	3.3670863527592347
  (0, 1663)	3.4199961121897475
  (0, 1662)	3.3670863527592347
  (0, 1661)	3.3670863527592347
  (0, 1660)	3.1891085407791566
  (0, 1659)	3.2219807608590663
  (0, 1658)	3.3670863527592347
  (0, 1657)	3.3670863527592347
  :	:
  (942, 24)	2.9699692893098444
  (942, 23)	3.1809489614952544
  (942, 22)	3.714816339388621
  (942, 21)	3.770252853825174
  (942, 20)	2.5866890763756323
  (942, 19)	3.3148237702720333
  (942, 18)	3.2730077007329053
  (942, 17)	3.0936878604632514
  (942, 16)	2.77492682024049
  (942, 15)	3.013141746246467
  (942, 14)	3.358653123209487
  (942, 13)	3.5996038377414323
  (942, 12)	3.100198893634303
  (942, 11)	3.951479515374291
  (942, 10)	3.5382791034636467
  (942, 9)	3.4854327791377977
  (942, 8)	3.5502158208533734
  (942, 7)	3.7367423161304423
  (942, 6)	3.5213430408080275
  (942, 5)	3.2257471442854517
  (942, 4)	3.011973930201138
  (942, 3)	3.2533874593822856
  (942, 2)	2.9384041100647913
  (942, 1)	3.006162187515238
  (942, 0)	3.570128972207564
this is the 222 epoch
rmse loss on training set is 0.9000487569911806
rmse loss on test set is 0.9163177287595109
for this epoch using 82.32728552818298 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.36702355464345
  (0, 1680)	3.378828814692447
  (0, 1679)	3.36702355464345
  (0, 1678)	3.36702355464345
  (0, 1677)	3.36702355464345
  (0, 1676)	3.36702355464345
  (0, 1675)	3.36702355464345
  (0, 1674)	3.36702355464345
  (0, 1673)	3.36702355464345
  (0, 1672)	3.36702355464345
  (0, 1671)	3.3101084172312265
  (0, 1670)	3.36702355464345
  (0, 1669)	3.36702355464345
  (0, 1668)	3.36702355464345
  (0, 1667)	3.36702355464345
  (0, 1666)	3.36702355464345
  (0, 1665)	3.36702355464345
  (0, 1664)	3.36702355464345
  (0, 1663)	3.4201395723381114
  (0, 1662)	3.36702355464345
  (0, 1661)	3.36702355464345
  (0, 1660)	3.1882867396207275
  (0, 1659)	3.221314734588221
  (0, 1658)	3.36702355464345
  (0, 1657)	3.36702355464345
  :	:
  (942, 24)	2.970080955377695
  (942, 23)	3.181019011475294
  (942, 22)	3.7150795272494546
  (942, 21)	3.7703956578127644
  (942, 20)	2.586485738307767
  (942, 19)	3.315281205444665
  (942, 18)	3.273680536393424
  (942, 17)	3.0940995355271896
  (942, 16)	2.774839227605353
  (942, 15)	3.0132915383108765
  (942, 14)	3.3587770266078447
  (942, 13)	3.59995158068211
  (942, 12)	3.1003735062043787
  (942, 11)	3.951648148110282
  (942, 10)	3.538407374834835
  (942, 9)	3.4859850557681087
  (942, 8)	3.5503816268608817
  (942, 7)	3.7369364458710708
  (942, 6)	3.521476520281521
  (942, 5)	3.2266084837299105
  (942, 4)	3.01200249196872
  (942, 3)	3.2535069688944804
  (942, 2)	2.9384040751607206
  (942, 1)	3.0062082291995624
  (942, 0)	3.5702519594167876
this is the 223 epoch
rmse loss on training set is 0.8999960031772476
rmse loss on test set is 0.9162923491189361
for this epoch using 82.74858236312866 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3669611270592754
  (0, 1680)	3.3788268214144175
  (0, 1679)	3.3669611270592754
  (0, 1678)	3.3669611270592754
  (0, 1677)	3.3669611270592754
  (0, 1676)	3.3669611270592754
  (0, 1675)	3.3669611270592754
  (0, 1674)	3.3669611270592754
  (0, 1673)	3.3669611270592754
  (0, 1672)	3.3669611270592754
  (0, 1671)	3.309811714541617
  (0, 1670)	3.3669611270592754
  (0, 1669)	3.3669611270592754
  (0, 1668)	3.3669611270592754
  (0, 1667)	3.3669611270592754
  (0, 1666)	3.3669611270592754
  (0, 1665)	3.3669611270592754
  (0, 1664)	3.3669611270592754
  (0, 1663)	3.420283254044148
  (0, 1662)	3.3669611270592754
  (0, 1661)	3.3669611270592754
  (0, 1660)	3.1874656968790434
  (0, 1659)	3.220649508603233
  (0, 1658)	3.3669611270592754
  (0, 1657)	3.3669611270592754
  :	:
  (942, 24)	2.970192056847965
  (942, 23)	3.1810888668123924
  (942, 22)	3.7153406732274346
  (942, 21)	3.770537675245027
  (942, 20)	2.586286066920151
  (942, 19)	3.3157353336757276
  (942, 18)	3.2743501525586414
  (942, 17)	3.094510957981032
  (942, 16)	2.7747535842640203
  (942, 15)	3.013441381630547
  (942, 14)	3.3589002888050996
  (942, 13)	3.6002962031145267
  (942, 12)	3.1005470969259266
  (942, 11)	3.9518157827629077
  (942, 10)	3.538534968915497
  (942, 9)	3.4865325761632704
  (942, 8)	3.550546421716105
  (942, 7)	3.737129329934687
  (942, 6)	3.5216092865344666
  (942, 5)	3.227468320527488
  (942, 4)	3.0120313253563697
  (942, 3)	3.2536258675267344
  (942, 2)	2.9384047400482745
  (942, 1)	3.00625429727359
  (942, 0)	3.5703743262356817
this is the 224 epoch
rmse loss on training set is 0.8999436824636156
rmse loss on test set is 0.9162672592563623
for this epoch using 82.91099238395691 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.366899067970051
  (0, 1680)	3.378825197642426
  (0, 1679)	3.366899067970051
  (0, 1678)	3.366899067970051
  (0, 1677)	3.366899067970051
  (0, 1676)	3.366899067970051
  (0, 1675)	3.366899067970051
  (0, 1674)	3.366899067970051
  (0, 1673)	3.366899067970051
  (0, 1672)	3.366899067970051
  (0, 1671)	3.309515467922754
  (0, 1670)	3.366899067970051
  (0, 1669)	3.366899067970051
  (0, 1668)	3.366899067970051
  (0, 1667)	3.366899067970051
  (0, 1666)	3.366899067970051
  (0, 1665)	3.366899067970051
  (0, 1664)	3.366899067970051
  (0, 1663)	3.4204271559406143
  (0, 1662)	3.366899067970051
  (0, 1661)	3.366899067970051
  (0, 1660)	3.1866454093638126
  (0, 1659)	3.219985079326571
  (0, 1658)	3.366899067970051
  (0, 1657)	3.366899067970051
  :	:
  (942, 24)	2.970302596081618
  (942, 23)	3.1811585262783377
  (942, 22)	3.7155998022993413
  (942, 21)	3.770678911398417
  (942, 20)	2.5860900041537005
  (942, 19)	3.3161861817107448
  (942, 18)	3.2750165619777434
  (942, 17)	3.094922126217647
  (942, 16)	2.774669857284209
  (942, 15)	3.013591269704248
  (942, 14)	3.359022913547511
  (942, 13)	3.600637745717459
  (942, 12)	3.100719670781278
  (942, 11)	3.9519824275005826
  (942, 10)	3.5386618899089513
  (942, 9)	3.4870753881485865
  (942, 8)	3.5507102144480442
  (942, 7)	3.7373209796211855
  (942, 6)	3.5217413436962484
  (942, 5)	3.2283266554659957
  (942, 4)	3.012060423820155
  (942, 3)	3.2537441585296523
  (942, 2)	2.93840609155198
  (942, 1)	3.006300386917521
  (942, 0)	3.5704960759994244
this is the 225 epoch
rmse loss on training set is 0.8998917897016566
rmse loss on test set is 0.9162424554947499
for this epoch using 83.02113509178162 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3668373753466145
  (0, 1680)	3.3788239412944683
  (0, 1679)	3.3668373753466145
  (0, 1678)	3.3668373753466145
  (0, 1677)	3.3668373753466145
  (0, 1676)	3.3668373753466145
  (0, 1675)	3.3668373753466145
  (0, 1674)	3.3668373753466145
  (0, 1673)	3.3668373753466145
  (0, 1672)	3.3668373753466145
  (0, 1671)	3.309219675182406
  (0, 1670)	3.3668373753466145
  (0, 1669)	3.3668373753466145
  (0, 1668)	3.3668373753466145
  (0, 1667)	3.3668373753466145
  (0, 1666)	3.3668373753466145
  (0, 1665)	3.3668373753466145
  (0, 1664)	3.3668373753466145
  (0, 1663)	3.420571276660977
  (0, 1662)	3.3668373753466145
  (0, 1661)	3.3668373753466145
  (0, 1660)	3.1858258739023326
  (0, 1659)	3.2193214432029156
  (0, 1658)	3.3668373753466145
  (0, 1657)	3.3668373753466145
  :	:
  (942, 24)	2.9704125754762116
  (942, 23)	3.1812279886947947
  (942, 22)	3.715856938994994
  (942, 21)	3.7708193715189537
  (942, 20)	2.5858974928408025
  (942, 19)	3.3166337760830156
  (942, 18)	3.2756797774049713
  (942, 17)	3.0953330386503493
  (942, 16)	2.7745880142589625
  (942, 15)	3.013741196129405
  (942, 14)	3.3591449045578585
  (942, 13)	3.6009762485029517
  (942, 12)	3.100891232810249
  (942, 11)	3.952148090401013
  (942, 10)	3.5387881419995764
  (942, 9)	3.487613539032621
  (942, 8)	3.550873013960471
  (942, 7)	3.737511406087712
  (942, 6)	3.521872695897897
  (942, 5)	3.2291834893553317
  (942, 4)	3.0120897809138807
  (942, 3)	3.2538618451576857
  (942, 2)	2.938408116701628
  (942, 1)	3.006346493445238
  (942, 0)	3.5706172120444117
this is the 226 epoch
rmse loss on training set is 0.899840319822275
rmse loss on test set is 0.9162179342146325
for this epoch using 80.66085910797119 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3667760471672175
  (0, 1680)	3.3788230502960266
  (0, 1679)	3.3667760471672175
  (0, 1678)	3.3667760471672175
  (0, 1677)	3.3667760471672175
  (0, 1676)	3.3667760471672175
  (0, 1675)	3.3667760471672175
  (0, 1674)	3.3667760471672175
  (0, 1673)	3.3667760471672175
  (0, 1672)	3.3667760471672175
  (0, 1671)	3.3089243341365036
  (0, 1670)	3.3667760471672175
  (0, 1669)	3.3667760471672175
  (0, 1668)	3.3667760471672175
  (0, 1667)	3.3667760471672175
  (0, 1666)	3.3667760471672175
  (0, 1665)	3.3667760471672175
  (0, 1664)	3.3667760471672175
  (0, 1663)	3.4207156148394144
  (0, 1662)	3.3667760471672175
  (0, 1661)	3.3667760471672175
  (0, 1660)	3.185007087339376
  (0, 1659)	3.21865859669886
  (0, 1658)	3.3667760471672175
  (0, 1657)	3.3667760471672175
  :	:
  (942, 24)	2.970521997463466
  (942, 23)	3.1812972529322807
  (942, 22)	3.716112107407694
  (942, 21)	3.7709590608220496
  (942, 20)	2.58570847669187
  (942, 19)	3.3170781431148617
  (942, 18)	3.276339811598448
  (942, 17)	3.0957436937126177
  (942, 16)	2.7745080232985337
  (942, 15)	3.013891154600625
  (942, 14)	3.3592662655358856
  (942, 13)	3.6013117508287844
  (942, 12)	3.101061788106357
  (942, 11)	3.952312779452783
  (942, 10)	3.5389137293525823
  (942, 9)	3.4881470756129525
  (942, 8)	3.5510348290347364
  (942, 7)	3.7377006203513248
  (942, 6)	3.522003347270708
  (942, 5)	3.2300388230271255
  (942, 4)	3.012119390288072
  (942, 3)	3.253978930668166
  (942, 2)	2.9384108027293703
  (942, 1)	3.0063926123009406
  (942, 0)	3.5707377377071974
this is the 227 epoch
rmse loss on training set is 0.89978926783436
rmse loss on test set is 0.9161936918530207
for this epoch using 82.2422423362732 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3667150814174835
  (0, 1680)	3.3788225225799935
  (0, 1679)	3.3667150814174835
  (0, 1678)	3.3667150814174835
  (0, 1677)	3.3667150814174835
  (0, 1676)	3.3667150814174835
  (0, 1675)	3.3667150814174835
  (0, 1674)	3.3667150814174835
  (0, 1673)	3.3667150814174835
  (0, 1672)	3.3667150814174835
  (0, 1671)	3.3086294426091074
  (0, 1670)	3.3667150814174835
  (0, 1669)	3.3667150814174835
  (0, 1668)	3.3667150814174835
  (0, 1667)	3.3667150814174835
  (0, 1666)	3.3667150814174835
  (0, 1665)	3.3667150814174835
  (0, 1664)	3.3667150814174835
  (0, 1663)	3.4208601691108522
  (0, 1662)	3.3667150814174835
  (0, 1661)	3.3667150814174835
  (0, 1660)	3.184189046536989
  (0, 1659)	3.217996536302748
  (0, 1658)	3.3667150814174835
  (0, 1657)	3.3667150814174835
  :	:
  (942, 24)	2.9706308645068606
  (942, 23)	3.181366317909196
  (942, 22)	3.7163653312042566
  (942, 21)	3.7710979844922226
  (942, 20)	2.585522900282038
  (942, 19)	3.3175193089189707
  (942, 18)	3.276996677318911
  (942, 17)	3.0961540898578614
  (942, 16)	2.7744298530224527
  (942, 15)	3.014041138908374
  (942, 14)	3.3593870001588293
  (942, 13)	3.60164429141065
  (942, 12)	3.101231341813243
  (942, 11)	3.9524765025567508
  (942, 10)	3.5390386561137785
  (942, 9)	3.4886760441818097
  (942, 8)	3.5511956683324857
  (942, 7)	3.737888633291604
  (942, 6)	3.5221333019449292
  (942, 5)	3.230892657334344
  (942, 4)	3.012149245688824
  (942, 3)	3.2540954183202295
  (942, 2)	2.938414137066814
  (942, 1)	3.0064387390559295
  (942, 0)	3.5708576563236334
this is the 228 epoch
rmse loss on training set is 0.8997386288233422
rmse loss on test set is 0.9161697249023026
for this epoch using 83.55724024772644 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.366654476090398
  (0, 1680)	3.378822356086619
  (0, 1679)	3.366654476090398
  (0, 1678)	3.366654476090398
  (0, 1677)	3.366654476090398
  (0, 1676)	3.366654476090398
  (0, 1675)	3.366654476090398
  (0, 1674)	3.366654476090398
  (0, 1673)	3.366654476090398
  (0, 1672)	3.366654476090398
  (0, 1671)	3.30833499843237
  (0, 1670)	3.366654476090398
  (0, 1669)	3.366654476090398
  (0, 1668)	3.366654476090398
  (0, 1667)	3.366654476090398
  (0, 1666)	3.366654476090398
  (0, 1665)	3.366654476090398
  (0, 1664)	3.366654476090398
  (0, 1663)	3.4210049381110146
  (0, 1662)	3.366654476090398
  (0, 1661)	3.366654476090398
  (0, 1660)	3.1833717483744026
  (0, 1659)	3.21733525852441
  (0, 1658)	3.366654476090398
  (0, 1657)	3.366654476090398
  :	:
  (942, 24)	2.9707391790993785
  (942, 23)	3.1814351825908136
  (942, 22)	3.7166166336349185
  (942, 21)	3.771236147683017
  (942, 20)	2.585340709038086
  (942, 19)	3.317957299399615
  (942, 18)	3.277650387328574
  (942, 17)	3.0965642255591455
  (942, 16)	2.774353472551682
  (942, 15)	3.0141911429375887
  (942, 14)	3.359507112081817
  (942, 13)	3.6019739083340823
  (942, 12)	3.101399899121216
  (942, 11)	3.952639267527537
  (942, 10)	3.5391629264093245
  (942, 9)	3.489200490531719
  (942, 8)	3.5513555403983763
  (942, 7)	3.7380754556531715
  (942, 6)	3.5222625640484457
  (942, 5)	3.231744993150991
  (942, 4)	3.0121793409567608
  (942, 3)	3.2542113113739113
  (942, 2)	2.938418107342128
  (942, 1)	3.0064848694054165
  (942, 0)	3.5709769712279034
this is the 229 epoch
rmse loss on training set is 0.8996883979497121
rmse loss on test set is 0.9161460299091911
for this epoch using 80.2062737941742 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3665942291862763
  (0, 1680)	3.3788225487635395
  (0, 1679)	3.3665942291862763
  (0, 1678)	3.3665942291862763
  (0, 1677)	3.3665942291862763
  (0, 1676)	3.3665942291862763
  (0, 1675)	3.3665942291862763
  (0, 1674)	3.3665942291862763
  (0, 1673)	3.3665942291862763
  (0, 1672)	3.3665942291862763
  (0, 1671)	3.308040999446499
  (0, 1670)	3.3665942291862763
  (0, 1669)	3.3665942291862763
  (0, 1668)	3.3665942291862763
  (0, 1667)	3.3665942291862763
  (0, 1666)	3.3665942291862763
  (0, 1665)	3.3665942291862763
  (0, 1664)	3.3665942291862763
  (0, 1663)	3.4211499204764846
  (0, 1662)	3.3665942291862763
  (0, 1661)	3.3665942291862763
  (0, 1660)	3.182555189747933
  (0, 1659)	3.216674759895
  (0, 1658)	3.3665942291862763
  (0, 1657)	3.3665942291862763
  :	:
  (942, 24)	2.9708469437613587
  (942, 23)	3.1815038459882925
  (942, 22)	3.7168660375428266
  (942, 21)	3.7713735555167274
  (942, 20)	2.585161849225562
  (942, 19)	3.3183921402540166
  (942, 18)	3.278300954389944
  (942, 17)	3.0969740993089574
  (942, 16)	2.7742788515008843
  (942, 15)	3.0143411606663744
  (942, 14)	3.3596266049383097
  (942, 13)	3.6023006390662142
  (942, 12)	3.101567465263881
  (942, 11)	3.9528010820948825
  (942, 10)	3.539286544345582
  (942, 9)	3.489720459961037
  (942, 8)	3.5515144536625805
  (942, 7)	3.7382610980481332
  (942, 6)	3.5223911377056276
  (942, 5)	3.2325958313717056
  (942, 4)	3.012209670025934
  (942, 3)	3.2543266130892046
  (942, 2)	2.938422701377228
  (942, 1)	3.0065309991654283
  (942, 0)	3.5710956857517187
this is the 230 epoch
rmse loss on training set is 0.899638570447619
rmse loss on test set is 0.9161226034736911
for this epoch using 80.71673464775085 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.366534338712685
  (0, 1680)	3.3788230985657037
  (0, 1679)	3.366534338712685
  (0, 1678)	3.366534338712685
  (0, 1677)	3.366534338712685
  (0, 1676)	3.366534338712685
  (0, 1675)	3.366534338712685
  (0, 1674)	3.366534338712685
  (0, 1673)	3.366534338712685
  (0, 1672)	3.366534338712685
  (0, 1671)	3.3077474434997307
  (0, 1670)	3.366534338712685
  (0, 1669)	3.366534338712685
  (0, 1668)	3.366534338712685
  (0, 1667)	3.366534338712685
  (0, 1666)	3.366534338712685
  (0, 1665)	3.366534338712685
  (0, 1664)	3.366534338712685
  (0, 1663)	3.421295114844742
  (0, 1662)	3.366534338712685
  (0, 1661)	3.366534338712685
  (0, 1660)	3.181739367570807
  (0, 1659)	3.216015036966786
  (0, 1658)	3.366534338712685
  (0, 1657)	3.366534338712685
  :	:
  (942, 24)	2.9709541610384456
  (942, 23)	3.1815723071577495
  (942, 22)	3.717113565373386
  (942, 21)	3.7715102130843046
  (942, 20)	2.584986267936069
  (942, 19)	3.31882385697358
  (942, 18)	3.278948391264678
  (942, 17)	3.0973837096189683
  (942, 16)	2.7742059599708275
  (942, 15)	3.0144911861646957
  (942, 14)	3.3597454823404322
  (942, 13)	3.6026245204671854
  (942, 12)	3.1017340455148825
  (942, 11)	3.9529619539049983
  (942, 10)	3.539409514008816
  (942, 9)	3.490235997279407
  (942, 8)	3.5516724164433353
  (942, 7)	3.738445570958421
  (942, 6)	3.5225190270361133
  (942, 5)	3.233445172911507
  (942, 4)	3.0122402269227706
  (942, 3)	3.254441326725183
  (942, 2)	2.9384279071849706
  (942, 1)	3.0065771242697994
  (942, 0)	3.5712138032234546
this is the 231 epoch
rmse loss on training set is 0.8995891416235003
rmse loss on test set is 0.9160994422480866
for this epoch using 79.07870888710022 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3664748026845275
  (0, 1680)	3.3788240034553927
  (0, 1679)	3.3664748026845275
  (0, 1678)	3.3664748026845275
  (0, 1677)	3.3664748026845275
  (0, 1676)	3.3664748026845275
  (0, 1675)	3.3664748026845275
  (0, 1674)	3.3664748026845275
  (0, 1673)	3.3664748026845275
  (0, 1672)	3.3664748026845275
  (0, 1671)	3.307454328448321
  (0, 1670)	3.3664748026845275
  (0, 1669)	3.3664748026845275
  (0, 1668)	3.3664748026845275
  (0, 1667)	3.3664748026845275
  (0, 1666)	3.3664748026845275
  (0, 1665)	3.3664748026845275
  (0, 1664)	3.3664748026845275
  (0, 1663)	3.4214405198542446
  (0, 1662)	3.3664748026845275
  (0, 1661)	3.3664748026845275
  (0, 1660)	3.1809242787730954
  (0, 1659)	3.215356086312961
  (0, 1658)	3.3664748026845275
  (0, 1657)	3.3664748026845275
  :	:
  (942, 24)	2.9710608334995627
  (942, 23)	3.181640565199297
  (942, 22)	3.7173592391832653
  (942, 21)	3.771646125445183
  (942, 20)	2.584813913074768
  (942, 19)	3.319252474845256
  (942, 18)	3.2795927107124974
  (942, 17)	3.0977930550197836
  (942, 16)	2.7741347685408555
  (942, 15)	3.0146412135930487
  (942, 14)	3.3598637478793774
  (942, 13)	3.6029455888014374
  (942, 12)	3.1018996451848646
  (942, 11)	3.9531218905218384
  (942, 10)	3.539531839465055
  (942, 9)	3.490747146813216
  (942, 8)	3.5518294369492556
  (942, 7)	3.7386288847381706
  (942, 6)	3.5226462361537907
  (942, 5)	3.234293018705353
  (942, 4)	3.012271005765005
  (942, 3)	3.2545554555391436
  (942, 2)	2.938433712966428
  (942, 1)	3.006623240767253
  (942, 0)	3.5713313269674103
this is the 232 epoch
rmse loss on training set is 0.8995401068547262
rmse loss on test set is 0.9160765429359489
for this epoch using 80.24608540534973 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.366415619123935
  (0, 1680)	3.3788252614021568
  (0, 1679)	3.366415619123935
  (0, 1678)	3.366415619123935
  (0, 1677)	3.366415619123935
  (0, 1676)	3.366415619123935
  (0, 1675)	3.366415619123935
  (0, 1674)	3.366415619123935
  (0, 1673)	3.366415619123935
  (0, 1672)	3.366415619123935
  (0, 1671)	3.307161652156499
  (0, 1670)	3.366415619123935
  (0, 1669)	3.366415619123935
  (0, 1668)	3.366415619123935
  (0, 1667)	3.366415619123935
  (0, 1666)	3.366415619123935
  (0, 1665)	3.366415619123935
  (0, 1664)	3.366415619123935
  (0, 1663)	3.421586134144456
  (0, 1662)	3.366415619123935
  (0, 1661)	3.366415619123935
  (0, 1660)	3.1801099203015775
  (0, 1659)	3.2146979045274633
  (0, 1658)	3.366415619123935
  (0, 1657)	3.366415619123935
  :	:
  (942, 24)	2.9711669637351004
  (942, 23)	3.1817086192560846
  (942, 22)	3.7176030806492624
  (942, 21)	3.7717812976271854
  (942, 20)	2.5846447333480533
  (942, 19)	3.3196780189527657
  (942, 18)	3.2802339254900854
  (942, 17)	3.098202134060713
  (942, 16)	2.7740652482615142
  (942, 15)	3.0147912372012526
  (942, 14)	3.359981405125729
  (942, 13)	3.603263879748691
  (942, 12)	3.102064269618408
  (942, 11)	3.953280899428452
  (942, 10)	3.539653524759912
  (942, 9)	3.4912539524109225
  (942, 8)	3.5519855232817816
  (942, 7)	3.738811049615892
  (942, 6)	3.5227727691656825
  (942, 5)	3.235139369707923
  (942, 4)	3.0123020007605916
  (942, 3)	3.254669002785853
  (942, 2)	2.938440107108133
  (942, 1)	3.0066693448184796
  (942, 0)	3.571448260303039
this is the 233 epoch
rmse loss on training set is 0.8994914615882599
rmse loss on test set is 0.9160539022911747
for this epoch using 80.93827652931213 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.366356786060283
  (0, 1680)	3.378826870382845
  (0, 1679)	3.366356786060283
  (0, 1678)	3.366356786060283
  (0, 1677)	3.366356786060283
  (0, 1676)	3.366356786060283
  (0, 1675)	3.366356786060283
  (0, 1674)	3.366356786060283
  (0, 1673)	3.366356786060283
  (0, 1672)	3.366356786060283
  (0, 1671)	3.3068694124964924
  (0, 1670)	3.366356786060283
  (0, 1669)	3.366356786060283
  (0, 1668)	3.366356786060283
  (0, 1667)	3.366356786060283
  (0, 1666)	3.366356786060283
  (0, 1665)	3.366356786060283
  (0, 1664)	3.366356786060283
  (0, 1663)	3.4217319563559396
  (0, 1662)	3.366356786060283
  (0, 1661)	3.366356786060283
  (0, 1660)	3.179296289119653
  (0, 1659)	3.214040488224772
  (0, 1658)	3.366356786060283
  (0, 1657)	3.366356786060283
  :	:
  (942, 24)	2.971272554355055
  (942, 23)	3.1817764685134016
  (942, 22)	3.7178451110768282
  (942, 21)	3.7719157346263694
  (942, 20)	2.5844786782514206
  (942, 19)	3.320100514177977
  (942, 18)	3.280872048350058
  (942, 17)	3.0986109453095216
  (942, 16)	2.7739973706472503
  (942, 15)	3.0149412513271674
  (942, 14)	3.360098457629745
  (942, 13)	3.603579428414722
  (942, 12)	3.1022279241911406
  (942, 11)	3.9534389880281124
  (942, 10)	3.5397745739183577
  (942, 9)	3.4917564574483917
  (942, 8)	3.5521406834373432
  (942, 7)	3.7389920756967188
  (942, 6)	3.522898630171007
  (942, 5)	3.2359842268932235
  (942, 4)	3.012333206206665
  (942, 3)	3.2547819717167132
  (942, 2)	2.9384470781794074
  (942, 1)	3.0067154326933894
  (942, 0)	3.57156460654422
this is the 234 epoch
rmse loss on training set is 0.899443201339397
rmse loss on test set is 0.9160315171170431
for this epoch using 79.24576544761658 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3662983015302355
  (0, 1680)	3.3788288283816077
  (0, 1679)	3.3662983015302355
  (0, 1678)	3.3662983015302355
  (0, 1677)	3.3662983015302355
  (0, 1676)	3.3662983015302355
  (0, 1675)	3.3662983015302355
  (0, 1674)	3.3662983015302355
  (0, 1673)	3.3662983015302355
  (0, 1672)	3.3662983015302355
  (0, 1671)	3.3065776073484727
  (0, 1670)	3.3662983015302355
  (0, 1669)	3.3662983015302355
  (0, 1668)	3.3662983015302355
  (0, 1667)	3.3662983015302355
  (0, 1666)	3.3662983015302355
  (0, 1665)	3.3662983015302355
  (0, 1664)	3.3662983015302355
  (0, 1663)	3.421877985130422
  (0, 1662)	3.3662983015302355
  (0, 1661)	3.3662983015302355
  (0, 1660)	3.1784833822072316
  (0, 1659)	3.21338383403979
  (0, 1658)	3.3662983015302355
  (0, 1657)	3.3662983015302355
  :	:
  (942, 24)	2.9713776079873573
  (942, 23)	3.181844112197736
  (942, 22)	3.7180853514084116
  (942, 21)	3.7720494414069674
  (942, 20)	2.5843156980574826
  (942, 19)	3.320519985202158
  (942, 18)	3.28150709203987
  (942, 17)	3.09901948735223
  (942, 16)	2.7739311076692426
  (942, 15)	3.0150912503954737
  (942, 14)	3.360214908921664
  (942, 13)	3.6038922693420288
  (942, 12)	3.1023906143069935
  (942, 11)	3.953596163645591
  (942, 10)	3.5398949909445605
  (942, 9)	3.4922547048341133
  (942, 8)	3.552294925309574
  (942, 7)	3.7391719729644786
  (942, 6)	3.523023823260196
  (942, 5)	3.2368275912543
  (942, 4)	3.0123646164884983
  (942, 3)	3.254894365579086
  (942, 2)	2.938454614929718
  (942, 1)	3.0067615007683455
  (942, 0)	3.571680368998663
this is the 235 epoch
rmse loss on training set is 0.8993953216905004
rmse loss on test set is 0.9160093842652881
for this epoch using 79.69260740280151 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.36624016357767
  (0, 1680)	3.3788311333898573
  (0, 1679)	3.36624016357767
  (0, 1678)	3.36624016357767
  (0, 1677)	3.36624016357767
  (0, 1676)	3.36624016357767
  (0, 1675)	3.36624016357767
  (0, 1674)	3.36624016357767
  (0, 1673)	3.36624016357767
  (0, 1672)	3.36624016357767
  (0, 1671)	3.3062862346006083
  (0, 1670)	3.36624016357767
  (0, 1669)	3.36624016357767
  (0, 1668)	3.36624016357767
  (0, 1667)	3.36624016357767
  (0, 1666)	3.36624016357767
  (0, 1665)	3.36624016357767
  (0, 1664)	3.36624016357767
  (0, 1663)	3.422024219110825
  (0, 1662)	3.36624016357767
  (0, 1661)	3.36624016357767
  (0, 1660)	3.1776711965606648
  (0, 1659)	3.2127279386276517
  (0, 1658)	3.36624016357767
  (0, 1657)	3.36624016357767
  :	:
  (942, 24)	2.9714821272761887
  (942, 23)	3.1819115495759425
  (942, 22)	3.7183238222316075
  (942, 21)	3.7721824229012544
  (942, 20)	2.5841557438042373
  (942, 19)	3.320936456507299
  (942, 18)	3.282139069300845
  (942, 17)	3.0994277587928765
  (942, 16)	2.7738664317483264
  (942, 15)	3.0152412289164747
  (942, 14)	3.3603307625119876
  (942, 13)	3.604202436520065
  (942, 12)	3.1025523453955
  (942, 11)	3.953752433528314
  (942, 10)	3.540014779821782
  (942, 9)	3.4927487370143955
  (942, 8)	3.5524482566914535
  (942, 7)	3.7393507512838227
  (942, 6)	3.523148352514021
  (942, 5)	3.237669463802934
  (942, 4)	3.012396226078408
  (942, 3)	3.255006187615556
  (942, 2)	2.9384627062860385
  (942, 1)	3.006807545523536
  (942, 0)	3.571795550967178
this is the 236 epoch
rmse loss on training set is 0.8993478182897274
rmse loss on test set is 0.9159875006352025
for this epoch using 80.26980543136597 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3661823702537013
  (0, 1680)	3.3788337834062876
  (0, 1679)	3.3661823702537013
  (0, 1678)	3.3661823702537013
  (0, 1677)	3.3661823702537013
  (0, 1676)	3.3661823702537013
  (0, 1675)	3.3661823702537013
  (0, 1674)	3.3661823702537013
  (0, 1673)	3.3661823702537013
  (0, 1672)	3.3661823702537013
  (0, 1671)	3.3059952921489906
  (0, 1670)	3.3661823702537013
  (0, 1669)	3.3661823702537013
  (0, 1668)	3.3661823702537013
  (0, 1667)	3.3661823702537013
  (0, 1666)	3.3661823702537013
  (0, 1665)	3.3661823702537013
  (0, 1664)	3.3661823702537013
  (0, 1663)	3.4221706569414083
  (0, 1662)	3.3661823702537013
  (0, 1661)	3.3661823702537013
  (0, 1660)	3.1768597291926004
  (0, 1659)	3.2120727986635567
  (0, 1658)	3.3661823702537013
  (0, 1657)	3.3661823702537013
  :	:
  (942, 24)	2.971586114880464
  (942, 23)	3.1819787799542585
  (942, 22)	3.718560543787035
  (942, 21)	3.772314684009531
  (942, 20)	2.583998767283411
  (942, 19)	3.32134995237739
  (942, 18)	3.2827679928671967
  (942, 17)	3.099835758253276
  (942, 16)	2.773803315748013
  (942, 15)	3.0153911814848984
  (942, 14)	3.360446021891716
  (942, 13)	3.604509963395502
  (942, 12)	3.102713122909217
  (942, 11)	3.953907804847478
  (942, 10)	3.5401339445121587
  (942, 9)	3.493238595978519
  (942, 8)	3.5526006852773406
  (942, 7)	3.7395284204021935
  (942, 6)	3.523272222002743
  (942, 5)	3.2385098455693266
  (942, 4)	3.0124280295347696
  (942, 3)	3.2551174410632804
  (942, 2)	2.938471341350318
  (942, 1)	3.0068535635403353
  (942, 0)	3.5719101557430952
this is the 237 epoch
rmse loss on training set is 0.8993006868498571
rmse loss on test set is 0.915965863172756
for this epoch using 79.5112566947937 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3661249196166816
  (0, 1680)	3.3788367764368603
  (0, 1679)	3.3661249196166816
  (0, 1678)	3.3661249196166816
  (0, 1677)	3.3661249196166816
  (0, 1676)	3.3661249196166816
  (0, 1675)	3.3661249196166816
  (0, 1674)	3.3661249196166816
  (0, 1673)	3.3661249196166816
  (0, 1672)	3.3661249196166816
  (0, 1671)	3.305704777897667
  (0, 1670)	3.3661249196166816
  (0, 1669)	3.3661249196166816
  (0, 1668)	3.3661249196166816
  (0, 1667)	3.3661249196166816
  (0, 1666)	3.3661249196166816
  (0, 1665)	3.3661249196166816
  (0, 1664)	3.3661249196166816
  (0, 1663)	3.4223172972677234
  (0, 1662)	3.3661249196166816
  (0, 1661)	3.3661249196166816
  (0, 1660)	3.1760489771319342
  (0, 1659)	3.211418410842603
  (0, 1658)	3.3661249196166816
  (0, 1657)	3.3661249196166816
  :	:
  (942, 24)	2.9716895734722972
  (942, 23)	3.182045802677529
  (942, 22)	3.7187955359760316
  (942, 21)	3.7724462296000065
  (942, 20)	2.5838447210290614
  (942, 19)	3.3217604968997856
  (942, 18)	3.283393875464997
  (942, 17)	3.100243484372833
  (942, 16)	2.7737417329676353
  (942, 15)	3.015541102778731
  (942, 14)	3.360560690532566
  (942, 13)	3.6048148828821343
  (942, 12)	3.1028729523212117
  (942, 11)	3.9540622846991673
  (942, 10)	3.540252488956574
  (942, 9)	3.4937243232637583
  (942, 8)	3.5527522186649625
  (942, 7)	3.739704989951797
  (942, 6)	3.523395435785282
  (942, 5)	3.23934873760179
  (942, 4)	3.0124600215009347
  (942, 3)	3.2552281291533367
  (942, 2)	2.93848050939687
  (942, 1)	3.00689955149882
  (942, 0)	3.572024186611689
this is the 238 epoch
rmse loss on training set is 0.8992539231471003
rmse loss on test set is 0.9159444688697301
for this epoch using 84.16996240615845 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3660678097322534
  (0, 1680)	3.378840110494847
  (0, 1679)	3.3660678097322534
  (0, 1678)	3.3660678097322534
  (0, 1677)	3.3660678097322534
  (0, 1676)	3.3660678097322534
  (0, 1675)	3.3660678097322534
  (0, 1674)	3.3660678097322534
  (0, 1673)	3.3660678097322534
  (0, 1672)	3.3660678097322534
  (0, 1671)	3.3054146897586696
  (0, 1670)	3.3660678097322534
  (0, 1669)	3.3660678097322534
  (0, 1668)	3.3660678097322534
  (0, 1667)	3.3660678097322534
  (0, 1666)	3.3660678097322534
  (0, 1665)	3.3660678097322534
  (0, 1664)	3.3660678097322534
  (0, 1663)	3.422464138736852
  (0, 1662)	3.3660678097322534
  (0, 1661)	3.3660678097322534
  (0, 1660)	3.1752389374237353
  (0, 1659)	3.210764771879694
  (0, 1658)	3.3660678097322534
  (0, 1657)	3.3660678097322534
  :	:
  (942, 24)	2.971792505735598
  (942, 23)	3.1821126171282685
  (942, 22)	3.7190288183681695
  (942, 21)	3.7725770645088144
  (942, 20)	2.583693558306322
  (942, 19)	3.3221681139664447
  (942, 18)	3.2840167298113103
  (942, 17)	3.100650935808313
  (942, 16)	2.7736816571355782
  (942, 15)	3.0156909875580933
  (942, 14)	3.3606747718872336
  (942, 13)	3.6051172273706418
  (942, 12)	3.103031839122712
  (942, 11)	3.954215880105467
  (942, 10)	3.5403704170745405
  (942, 9)	3.494205959960445
  (942, 8)	3.552902864357382
  (942, 7)	3.739880469451529
  (942, 6)	3.523517997908488
  (942, 5)	3.240186140966485
  (942, 4)	3.0124921967042164
  (942, 3)	3.255338255110135
  (942, 2)	2.93849019986993
  (942, 1)	3.0069455061752564
  (942, 0)	3.5721376468496273
this is the 239 epoch
rmse loss on training set is 0.8992075230199336
rmse loss on test set is 0.9159233147628746
for this epoch using 84.2659363746643 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3660110386732462
  (0, 1680)	3.3788437836007983
  (0, 1679)	3.3660110386732462
  (0, 1678)	3.3660110386732462
  (0, 1677)	3.3660110386732462
  (0, 1676)	3.3660110386732462
  (0, 1675)	3.3660110386732462
  (0, 1674)	3.3660110386732462
  (0, 1673)	3.3660110386732462
  (0, 1672)	3.3660110386732462
  (0, 1671)	3.3051250256519666
  (0, 1670)	3.3660110386732462
  (0, 1669)	3.3660110386732462
  (0, 1668)	3.3660110386732462
  (0, 1667)	3.3660110386732462
  (0, 1666)	3.3660110386732462
  (0, 1665)	3.3660110386732462
  (0, 1664)	3.3660110386732462
  (0, 1663)	3.4226111799973142
  (0, 1662)	3.3660110386732462
  (0, 1661)	3.3660110386732462
  (0, 1660)	3.1744296071291185
  (0, 1659)	3.2101118785093306
  (0, 1658)	3.3660110386732462
  (0, 1657)	3.3660110386732462
  :	:
  (942, 24)	2.9718949143646918
  (942, 23)	3.182179222725878
  (942, 22)	3.71926041020853
  (942, 21)	3.772707193539904
  (942, 20)	2.5835452331002773
  (942, 19)	3.322572827275267
  (942, 18)	3.284636568613192
  (942, 17)	3.1010581112336384
  (942, 16)	2.7736230624025864
  (942, 15)	3.0158408306640423
  (942, 14)	3.360788269389547
  (942, 13)	3.605417028738161
  (942, 12)	3.1031897888207833
  (942, 11)	3.954368598015479
  (942, 10)	3.5404877327640762
  (942, 9)	3.494683546716913
  (942, 8)	3.5530526297647964
  (942, 7)	3.7400548683088455
  (942, 6)	3.523639912406378
  (942, 5)	3.241022056747102
  (942, 4)	3.012524549954872
  (942, 3)	3.255447822150814
  (942, 2)	2.9385004023811074
  (942, 1)	3.006991424439713
  (942, 0)	3.5722505397244313
this is the 240 epoch
rmse loss on training set is 0.8991614823680092
rmse loss on test set is 0.9159023979330796
for this epoch using 82.57673144340515 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3659546045198003
  (0, 1680)	3.3788477937825485
  (0, 1679)	3.3659546045198003
  (0, 1678)	3.3659546045198003
  (0, 1677)	3.3659546045198003
  (0, 1676)	3.3659546045198003
  (0, 1675)	3.3659546045198003
  (0, 1674)	3.3659546045198003
  (0, 1673)	3.3659546045198003
  (0, 1672)	3.3659546045198003
  (0, 1671)	3.3048357835054833
  (0, 1670)	3.3659546045198003
  (0, 1669)	3.3659546045198003
  (0, 1668)	3.3659546045198003
  (0, 1667)	3.3659546045198003
  (0, 1666)	3.3659546045198003
  (0, 1665)	3.3659546045198003
  (0, 1664)	3.3659546045198003
  (0, 1663)	3.422758419699255
  (0, 1662)	3.3659546045198003
  (0, 1661)	3.3659546045198003
  (0, 1660)	3.173620983325172
  (0, 1659)	3.209459727485497
  (0, 1658)	3.3659546045198003
  (0, 1657)	3.3659546045198003
  :	:
  (942, 24)	2.9719968020630385
  (942, 23)	3.1822456189257715
  (942, 22)	3.719490330424785
  (942, 21)	3.7728366214650855
  (942, 20)	2.5833997001050597
  (942, 19)	3.3229746603313863
  (942, 18)	3.2852534045668444
  (942, 17)	3.101465009339655
  (942, 16)	2.773565923335241
  (942, 15)	3.0159906270175467
  (942, 14)	3.360901186454674
  (942, 13)	3.605714318357657
  (942, 12)	3.1033468069361287
  (942, 11)	3.95452044530638
  (942, 10)	3.5406044399015606
  (942, 9)	3.4951571237443697
  (942, 8)	3.5532015222064444
  (942, 7)	3.740228195821577
  (942, 6)	3.5237611832994657
  (942, 5)	3.2418564860445964
  (942, 4)	3.0125570761450664
  (942, 3)	3.255556833484687
  (942, 2)	2.938511106707004
  (942, 1)	3.0070373032536972
  (942, 0)	3.572362868493982
this is the 241 epoch
rmse loss on training set is 0.8991157971509651
rmse loss on test set is 0.9158817155045887
for this epoch using 81.33782005310059 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3658985053592887
  (0, 1680)	3.3788521390752795
  (0, 1679)	3.3658985053592887
  (0, 1678)	3.3658985053592887
  (0, 1677)	3.3658985053592887
  (0, 1676)	3.3658985053592887
  (0, 1675)	3.3658985053592887
  (0, 1674)	3.3658985053592887
  (0, 1673)	3.3658985053592887
  (0, 1672)	3.3658985053592887
  (0, 1671)	3.3045469612551432
  (0, 1670)	3.3658985053592887
  (0, 1669)	3.3658985053592887
  (0, 1668)	3.3658985053592887
  (0, 1667)	3.3658985053592887
  (0, 1666)	3.3658985053592887
  (0, 1665)	3.3658985053592887
  (0, 1664)	3.3658985053592887
  (0, 1663)	3.4229058564944737
  (0, 1662)	3.3658985053592887
  (0, 1661)	3.3658985053592887
  (0, 1660)	3.1728130631049445
  (0, 1659)	3.208808315581522
  (0, 1658)	3.3658985053592887
  (0, 1657)	3.3658985053592887
  :	:
  (942, 24)	2.9720981715419885
  (942, 23)	3.1823118052185793
  (942, 22)	3.719718597634176
  (942, 21)	3.772965353023966
  (942, 20)	2.5832569147130813
  (942, 19)	3.323373636448485
  (942, 18)	3.285867250356694
  (942, 17)	3.101871628833974
  (942, 16)	2.7735102149094435
  (942, 15)	3.0161403716183184
  (942, 14)	3.361013526479322
  (942, 13)	3.6060091271070953
  (942, 12)	3.103502899000919
  (942, 11)	3.954671428784412
  (942, 10)	3.540720542341641
  (942, 9)	3.495626730821804
  (942, 8)	3.553349548912312
  (942, 7)	3.740400461179655
  (942, 6)	3.52388181459411
  (942, 5)	3.2426894299768754
  (942, 4)	3.0125897702478603
  (942, 3)	3.255665292312754
  (942, 2)	2.938522302786765
  (942, 1)	3.0070831396678934
  (942, 0)	3.5724746364060405
this is the 242 epoch
rmse loss on training set is 0.8990704633874367
rmse loss on test set is 0.9158612646441843
for this epoch using 82.86145782470703 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.365842739286396
  (0, 1680)	3.378856817521481
  (0, 1679)	3.365842739286396
  (0, 1678)	3.365842739286396
  (0, 1677)	3.365842739286396
  (0, 1676)	3.365842739286396
  (0, 1675)	3.365842739286396
  (0, 1674)	3.365842739286396
  (0, 1673)	3.365842739286396
  (0, 1672)	3.365842739286396
  (0, 1671)	3.3042585568448244
  (0, 1670)	3.365842739286396
  (0, 1669)	3.365842739286396
  (0, 1668)	3.365842739286396
  (0, 1667)	3.365842739286396
  (0, 1666)	3.365842739286396
  (0, 1665)	3.365842739286396
  (0, 1664)	3.365842739286396
  (0, 1663)	3.42305348903653
  (0, 1662)	3.365842739286396
  (0, 1661)	3.365842739286396
  (0, 1660)	3.172005843577263
  (0, 1659)	3.2081576395899476
  (0, 1658)	3.365842739286396
  (0, 1657)	3.365842739286396
  :	:
  (942, 24)	2.972199025519601
  (942, 23)	3.1823777811293366
  (942, 22)	3.7199452301501736
  (942, 21)	3.7730933929239816
  (942, 20)	2.583116833004422
  (942, 19)	3.323769778750085
  (942, 18)	3.286478118654566
  (942, 17)	3.10227796844072
  (942, 16)	2.773455912504071
  (942, 15)	3.016290059543751
  (942, 14)	3.3611252928418494
  (942, 13)	3.6063014853784554
  (942, 12)	3.1036580705567904
  (942, 11)	3.95482155518589
  (942, 10)	3.5408360439171456
  (942, 9)	3.4960924073007567
  (942, 8)	3.5534967170248737
  (942, 7)	3.740571673466932
  (942, 6)	3.5240018102819195
  (942, 5)	3.2435208896785843
  (942, 4)	3.012622627316231
  (942, 3)	3.255773201827144
  (942, 2)	2.938533980719688
  (942, 1)	3.0071289308198708
  (942, 0)	3.5725858466978013
this is the 243 epoch
rmse loss on training set is 0.8990254771539297
rmse loss on test set is 0.9158410425604361
for this epoch using 82.46265196800232 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3657873044030846
  (0, 1680)	3.3788618271709754
  (0, 1679)	3.3657873044030846
  (0, 1678)	3.3657873044030846
  (0, 1677)	3.3657873044030846
  (0, 1676)	3.3657873044030846
  (0, 1675)	3.3657873044030846
  (0, 1674)	3.3657873044030846
  (0, 1673)	3.3657873044030846
  (0, 1672)	3.3657873044030846
  (0, 1671)	3.303970568226422
  (0, 1670)	3.3657873044030846
  (0, 1669)	3.3657873044030846
  (0, 1668)	3.3657873044030846
  (0, 1667)	3.3657873044030846
  (0, 1666)	3.3657873044030846
  (0, 1665)	3.3657873044030846
  (0, 1664)	3.3657873044030846
  (0, 1663)	3.4232013159807746
  (0, 1662)	3.3657873044030846
  (0, 1661)	3.3657873044030846
  (0, 1660)	3.171199321866751
  (0, 1659)	3.2075076963223874
  (0, 1658)	3.3657873044030846
  (0, 1657)	3.3657873044030846
  :	:
  (942, 24)	2.9722993667195055
  (942, 23)	3.182443546216678
  (942, 22)	3.7201702459890975
  (942, 21)	3.7732207458403835
  (942, 20)	2.582979411736411
  (942, 19)	3.3241631101708315
  (942, 18)	3.2870860221187845
  (942, 17)	3.1026840269003713
  (942, 16)	2.7734029918946796
  (942, 15)	3.0164396859478697
  (942, 14)	3.3612364889024686
  (942, 13)	3.606591423086542
  (942, 12)	3.1038123271528666
  (942, 11)	3.954970831178123
  (942, 10)	3.5409509484389647
  (942, 9)	3.4965541921100587
  (942, 8)	3.5536430336007343
  (942, 7)	3.7407418416627976
  (942, 6)	3.5241211743391343
  (942, 5)	3.2443508663007696
  (942, 4)	3.012655642482033
  (942, 3)	3.2558805652106675
  (942, 2)	2.938546130762922
  (942, 1)	3.0071746739319676
  (942, 0)	3.5726965025955058
this is the 244 epoch
rmse loss on training set is 0.898980834583817
rmse loss on test set is 0.9158210465029383
for this epoch using 81.69260573387146 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3657321988186113
  (0, 1680)	3.3788671660809344
  (0, 1679)	3.3657321988186113
  (0, 1678)	3.3657321988186113
  (0, 1677)	3.3657321988186113
  (0, 1676)	3.3657321988186113
  (0, 1675)	3.3657321988186113
  (0, 1674)	3.3657321988186113
  (0, 1673)	3.3657321988186113
  (0, 1672)	3.3657321988186113
  (0, 1671)	3.303682993359808
  (0, 1670)	3.3657321988186113
  (0, 1669)	3.3657321988186113
  (0, 1668)	3.3657321988186113
  (0, 1667)	3.3657321988186113
  (0, 1666)	3.3657321988186113
  (0, 1665)	3.3657321988186113
  (0, 1664)	3.3657321988186113
  (0, 1663)	3.4233493359844918
  (0, 1662)	3.3657321988186113
  (0, 1661)	3.3657321988186113
  (0, 1660)	3.170393495113698
  (0, 1659)	3.206858482609419
  (0, 1658)	3.3657321988186113
  (0, 1657)	3.3657321988186113
  :	:
  (942, 24)	2.9723991978698465
  (942, 23)	3.1825091000720733
  (942, 22)	3.720393662876507
  (942, 21)	3.7733474164162413
  (942, 20)	2.5828446083332985
  (942, 19)	3.324553653457844
  (942, 18)	3.287690973393426
  (942, 17)	3.1030898029695404
  (942, 16)	2.7733514292473123
  (942, 15)	3.0165892460602954
  (942, 14)	3.3613471180033496
  (942, 13)	3.606878969677657
  (942, 12)	3.1039656743438577
  (942, 11)	3.9551192633603893
  (942, 10)	3.5410652596959973
  (942, 9)	3.497012123760525
  (942, 8)	3.553788505612277
  (942, 7)	3.740910974643842
  (942, 6)	3.524239910726085
  (942, 5)	3.245179361010653
  (942, 4)	3.0126888109550447
  (942, 3)	3.2559873856363772
  (942, 2)	2.938558743329106
  (942, 1)	3.0072203663091095
  (942, 0)	3.5728066073139444
this is the 245 epoch
rmse loss on training set is 0.8989365318663219
rmse loss on test set is 0.9158012737615674
for this epoch using 82.24626874923706 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.365677420649569
  (0, 1680)	3.3788728323159107
  (0, 1679)	3.365677420649569
  (0, 1678)	3.365677420649569
  (0, 1677)	3.365677420649569
  (0, 1676)	3.365677420649569
  (0, 1675)	3.365677420649569
  (0, 1674)	3.365677420649569
  (0, 1673)	3.365677420649569
  (0, 1672)	3.365677420649569
  (0, 1671)	3.303395830212878
  (0, 1670)	3.365677420649569
  (0, 1669)	3.365677420649569
  (0, 1668)	3.365677420649569
  (0, 1667)	3.365677420649569
  (0, 1666)	3.365677420649569
  (0, 1665)	3.365677420649569
  (0, 1664)	3.365677420649569
  (0, 1663)	3.4234975477069
  (0, 1662)	3.365677420649569
  (0, 1661)	3.365677420649569
  (0, 1660)	3.169588360474014
  (0, 1659)	3.2062099953004286
  (0, 1658)	3.365677420649569
  (0, 1657)	3.365677420649569
  :	:
  (942, 24)	2.972498521702249
  (942, 23)	3.1825744423190794
  (942, 22)	3.720615498253359
  (942, 21)	3.7734734092625284
  (942, 20)	2.5827123808761576
  (942, 19)	3.3249414311719465
  (942, 18)	3.288292985107437
  (942, 17)	3.103495295420799
  (942, 16)	2.773301201112425
  (942, 15)	3.016738735185161
  (942, 14)	3.3614571834687585
  (942, 13)	3.6071641541380663
  (942, 12)	3.104118117688255
  (942, 11)	3.9552668582648605
  (942, 10)	3.541178981455045
  (942, 9)	3.49746624034961
  (942, 8)	3.553933139949184
  (942, 7)	3.7410790811854997
  (942, 6)	3.5243580233867102
  (942, 5)	3.246006374991371
  (942, 4)	3.012722128021949
  (942, 3)	3.256093666267111
  (942, 2)	2.9385718089840975
  (942, 1)	3.0072660053367635
  (942, 0)	3.572916164056189
this is the 246 epoch
rmse loss on training set is 0.8988925652454959
rmse loss on test set is 0.9157817216657734
for this epoch using 84.379634141922 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3656229680198786
  (0, 1680)	3.378878823947849
  (0, 1679)	3.3656229680198786
  (0, 1678)	3.3656229680198786
  (0, 1677)	3.3656229680198786
  (0, 1676)	3.3656229680198786
  (0, 1675)	3.3656229680198786
  (0, 1674)	3.3656229680198786
  (0, 1673)	3.3656229680198786
  (0, 1672)	3.3656229680198786
  (0, 1671)	3.303109076761546
  (0, 1670)	3.3656229680198786
  (0, 1669)	3.3656229680198786
  (0, 1668)	3.3656229680198786
  (0, 1667)	3.3656229680198786
  (0, 1666)	3.3656229680198786
  (0, 1665)	3.3656229680198786
  (0, 1664)	3.3656229680198786
  (0, 1663)	3.4236459498093215
  (0, 1662)	3.3656229680198786
  (0, 1661)	3.3656229680198786
  (0, 1660)	3.1687839151191732
  (0, 1659)	3.2055622312635164
  (0, 1658)	3.3656229680198786
  (0, 1657)	3.3656229680198786
  :	:
  (942, 24)	2.972597340950839
  (942, 23)	3.1826395726125267
  (942, 22)	3.720835769282188
  (942, 21)	3.7735987289580666
  (942, 20)	2.582582688092882
  (942, 19)	3.325326465689032
  (942, 18)	3.288892069873906
  (942, 17)	3.1039005030424613
  (942, 16)	2.77325228441885
  (942, 15)	3.0168881487001644
  (942, 14)	3.3615666886051936
  (942, 13)	3.6074470050023284
  (942, 12)	3.1042696627465722
  (942, 11)	3.9554136223574505
  (942, 10)	3.5412921174607477
  (942, 9)	3.4979165795659566
  (942, 8)	3.554076943420024
  (942, 7)	3.7412461699635573
  (942, 6)	3.5244755162480375
  (942, 5)	3.2468319094416827
  (942, 4)	3.0127555890453754
  (942, 3)	3.256199410255073
  (942, 2)	2.9385853184447304
  (942, 1)	3.0073115884789186
  (942, 0)	3.573025176013117
this is the 247 epoch
rmse loss on training set is 0.8988489310192819
rmse loss on test set is 0.9157623875838636
for this epoch using 83.40262579917908 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.365568839060811
  (0, 1680)	3.37888513905606
  (0, 1679)	3.365568839060811
  (0, 1678)	3.365568839060811
  (0, 1677)	3.365568839060811
  (0, 1676)	3.365568839060811
  (0, 1675)	3.365568839060811
  (0, 1674)	3.365568839060811
  (0, 1673)	3.365568839060811
  (0, 1672)	3.365568839060811
  (0, 1671)	3.302822730989769
  (0, 1670)	3.365568839060811
  (0, 1669)	3.365568839060811
  (0, 1668)	3.365568839060811
  (0, 1667)	3.365568839060811
  (0, 1666)	3.365568839060811
  (0, 1665)	3.365568839060811
  (0, 1664)	3.365568839060811
  (0, 1663)	3.4237945409551545
  (0, 1662)	3.365568839060811
  (0, 1661)	3.365568839060811
  (0, 1660)	3.1679801562360947
  (0, 1659)	3.2049151873853705
  (0, 1658)	3.365568839060811
  (0, 1657)	3.365568839060811
  :	:
  (942, 24)	2.972695658351328
  (942, 23)	3.182704490637844
  (942, 22)	3.7210544928529097
  (942, 21)	3.773723380049682
  (942, 20)	2.5824554893483533
  (942, 19)	3.325708779201286
  (942, 18)	3.2894882402892796
  (942, 17)	3.104305424638437
  (942, 16)	2.773204656467916
  (942, 15)	3.0170374820555126
  (942, 14)	3.361675636701505
  (942, 13)	3.60772755036139
  (942, 12)	3.1044203150796696
  (942, 11)	3.955559562038769
  (942, 10)	3.5414046714355534
  (942, 9)	3.4983631786939924
  (942, 8)	3.5542199227536595
  (942, 7)	3.741412249555753
  (942, 6)	3.5245923932197325
  (942, 5)	3.247655965575753
  (942, 4)	3.012789189462943
  (942, 3)	3.2563046207414748
  (942, 2)	2.938599262576565
  (942, 1)	3.0073571132760897
  (942, 0)	3.5731336463631744
this is the 248 epoch
rmse loss on training set is 0.898805625538557
rmse loss on test set is 0.9157432689223087
for this epoch using 81.2855761051178 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3655150319110057
  (0, 1680)	3.378891775727305
  (0, 1679)	3.3655150319110057
  (0, 1678)	3.3655150319110057
  (0, 1677)	3.3655150319110057
  (0, 1676)	3.3655150319110057
  (0, 1675)	3.3655150319110057
  (0, 1674)	3.3655150319110057
  (0, 1673)	3.3655150319110057
  (0, 1672)	3.3655150319110057
  (0, 1671)	3.302536790889565
  (0, 1670)	3.3655150319110057
  (0, 1669)	3.3655150319110057
  (0, 1668)	3.3655150319110057
  (0, 1667)	3.3655150319110057
  (0, 1666)	3.3655150319110057
  (0, 1665)	3.3655150319110057
  (0, 1664)	3.3655150319110057
  (0, 1663)	3.4239433198100415
  (0, 1662)	3.3655150319110057
  (0, 1661)	3.3655150319110057
  (0, 1660)	3.167177081027139
  (0, 1659)	3.204268860571131
  (0, 1658)	3.3655150319110057
  (0, 1657)	3.3655150319110057
  :	:
  (942, 24)	2.972793476640123
  (942, 23)	3.1827691961102906
  (942, 22)	3.7212716855886434
  (942, 21)	3.77384736705213
  (942, 20)	2.5823307446347648
  (942, 19)	3.3260883937185297
  (942, 18)	3.2900815089326167
  (942, 17)	3.1047100590280086
  (942, 16)	2.773158294927591
  (942, 15)	3.0171867307729654
  (942, 14)	3.3617840310289355
  (942, 13)	3.608005817870663
  (942, 12)	3.104570080247161
  (942, 11)	3.9557046836449397
  (942, 10)	3.5415166470796184
  (942, 9)	3.4988060746183707
  (942, 8)	3.5543620846007546
  (942, 7)	3.741577328443264
  (942, 6)	3.52470865819367
  (942, 5)	3.2484785446228965
  (942, 4)	3.012822924786246
  (942, 3)	3.256409300856171
  (942, 2)	2.9386136323917325
  (942, 1)	3.007402577343406
  (942, 0)	3.573241578271968
this is the 249 epoch
rmse loss on training set is 0.8987626452061721
rmse loss on test set is 0.9157243631250774
for this epoch using 82.15715408325195 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.365461544716481
  (0, 1680)	3.3788987320557746
  (0, 1679)	3.365461544716481
  (0, 1678)	3.365461544716481
  (0, 1677)	3.365461544716481
  (0, 1676)	3.365461544716481
  (0, 1675)	3.365461544716481
  (0, 1674)	3.365461544716481
  (0, 1673)	3.365461544716481
  (0, 1672)	3.365461544716481
  (0, 1671)	3.302251254460991
  (0, 1670)	3.365461544716481
  (0, 1669)	3.365461544716481
  (0, 1668)	3.365461544716481
  (0, 1667)	3.365461544716481
  (0, 1666)	3.365461544716481
  (0, 1665)	3.365461544716481
  (0, 1664)	3.365461544716481
  (0, 1663)	3.4240922850419033
  (0, 1662)	3.365461544716481
  (0, 1661)	3.365461544716481
  (0, 1660)	3.166374686709979
  (0, 1659)	3.2036232477443045
  (0, 1658)	3.365461544716481
  (0, 1657)	3.365461544716481
  :	:
  (942, 24)	2.972890798553472
  (942, 23)	3.1828336887742714
  (942, 22)	3.7214873638513004
  (942, 21)	3.7739706944482916
  (942, 20)	2.582208414562071
  (942, 19)	3.3264653310694854
  (942, 18)	3.290671888364832
  (942, 17)	3.105114405045667
  (942, 16)	2.773113177826756
  (942, 15)	3.017335890444868
  (942, 14)	3.3618918748413114
  (942, 13)	3.60828183475776
  (942, 12)	3.1047189638058694
  (942, 11)	3.9558489934484284
  (942, 10)	3.541628048070789
  (942, 9)	3.499245303828418
  (942, 8)	3.5545034355351564
  (942, 7)	3.7417414150121346
  (942, 6)	3.5248243150435337
  (942, 5)	3.249299647827314
  (942, 4)	3.012856790599971
  (942, 3)	3.2565134537172473
  (942, 2)	2.938628419046722
  (942, 1)	3.0074479783687376
  (942, 0)	3.573348974892031
this is the 250 epoch
rmse loss on training set is 0.8987199864760805
rmse loss on test set is 0.9157056676729626
for this epoch using 83.38758707046509 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.365408375630647
  (0, 1680)	3.3789060061431226
  (0, 1679)	3.365408375630647
  (0, 1678)	3.365408375630647
  (0, 1677)	3.365408375630647
  (0, 1676)	3.365408375630647
  (0, 1675)	3.365408375630647
  (0, 1674)	3.365408375630647
  (0, 1673)	3.365408375630647
  (0, 1672)	3.365408375630647
  (0, 1671)	3.301966119712208
  (0, 1670)	3.365408375630647
  (0, 1669)	3.365408375630647
  (0, 1668)	3.365408375630647
  (0, 1667)	3.365408375630647
  (0, 1666)	3.365408375630647
  (0, 1665)	3.365408375630647
  (0, 1664)	3.365408375630647
  (0, 1663)	3.4242414353210293
  (0, 1662)	3.365408375630647
  (0, 1661)	3.365408375630647
  (0, 1660)	3.165572970517612
  (0, 1659)	3.202978345846641
  (0, 1658)	3.365408375630647
  (0, 1657)	3.365408375630647
  :	:
  (942, 24)	2.972987626826666
  (942, 23)	3.182897968402589
  (942, 22)	3.721701543747091
  (942, 21)	3.7740933666891254
  (942, 20)	2.582088460348595
  (942, 19)	3.3268396129030777
  (942, 18)	3.291259391128037
  (942, 17)	3.1055184615409517
  (942, 16)	2.773069283549547
  (942, 15)	3.017484956733176
  (942, 14)	3.36199917137509
  (942, 13)	3.6085556278302393
  (942, 12)	3.1048669713083394
  (942, 11)	3.955992497658922
  (942, 10)	3.541738878064571
  (942, 9)	3.4996809024225257
  (942, 8)	3.554643982055229
  (942, 7)	3.741904517554757
  (942, 6)	3.524939367624453
  (942, 5)	3.250119276447851
  (942, 4)	3.0128907825608855
  (942, 3)	3.2566170824307736
  (942, 2)	2.9386436138402865
  (942, 1)	3.007493314110839
  (942, 0)	3.5734558393624822
this is the 251 epoch
rmse loss on training set is 0.8986776458524138
rmse loss on test set is 0.9156871800829463
for this epoch using 83.02290511131287 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.365355522814362
  (0, 1680)	3.37891359609846
  (0, 1679)	3.365355522814362
  (0, 1678)	3.365355522814362
  (0, 1677)	3.365355522814362
  (0, 1676)	3.365355522814362
  (0, 1675)	3.365355522814362
  (0, 1674)	3.365355522814362
  (0, 1673)	3.365355522814362
  (0, 1672)	3.365355522814362
  (0, 1671)	3.301681384659477
  (0, 1670)	3.365355522814362
  (0, 1669)	3.365355522814362
  (0, 1668)	3.365355522814362
  (0, 1667)	3.365355522814362
  (0, 1666)	3.365355522814362
  (0, 1665)	3.365355522814362
  (0, 1664)	3.365355522814362
  (0, 1663)	3.424390769320131
  (0, 1662)	3.365355522814362
  (0, 1661)	3.365355522814362
  (0, 1660)	3.1647719296982335
  (0, 1659)	3.20233415183801
  (0, 1658)	3.365355522814362
  (0, 1657)	3.365355522814362
  :	:
  (942, 24)	2.9730839641932922
  (942, 23)	3.1829620347958167
  (942, 22)	3.7219142411317745
  (942, 21)	3.77421538819382
  (942, 20)	2.5819708438117543
  (942, 19)	3.327211260689689
  (942, 18)	3.291844029744789
  (942, 17)	3.1059222273782368
  (942, 16)	2.7730265908298057
  (942, 15)	3.0176339253685343
  (942, 14)	3.3621059238493993
  (942, 13)	3.6088272234830963
  (942, 12)	3.1050141083014116
  (942, 11)	3.956135202424109
  (942, 10)	3.541849140694064
  (942, 9)	3.500112906112497
  (942, 8)	3.5547837305852252
  (942, 7)	3.742066644271237
  (942, 6)	3.5250538197725962
  (942, 5)	3.25093743175781
  (942, 4)	3.012924896396944
  (942, 3)	3.2567201900904243
  (942, 2)	2.9386592082113245
  (942, 1)	3.007538582397616
  (942, 0)	3.573562174808797
this is the 252 epoch
rmse loss on training set is 0.8986356198886153
rmse loss on test set is 0.9156688979075378
for this epoch using 82.01211071014404 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.36530298443589
  (0, 1680)	3.3789215000384214
  (0, 1679)	3.36530298443589
  (0, 1678)	3.36530298443589
  (0, 1677)	3.36530298443589
  (0, 1676)	3.36530298443589
  (0, 1675)	3.36530298443589
  (0, 1674)	3.36530298443589
  (0, 1673)	3.36530298443589
  (0, 1672)	3.36530298443589
  (0, 1671)	3.301397047327165
  (0, 1670)	3.36530298443589
  (0, 1669)	3.36530298443589
  (0, 1668)	3.36530298443589
  (0, 1667)	3.36530298443589
  (0, 1666)	3.36530298443589
  (0, 1665)	3.36530298443589
  (0, 1664)	3.36530298443589
  (0, 1663)	3.4245402857144596
  (0, 1662)	3.36530298443589
  (0, 1661)	3.36530298443589
  (0, 1660)	3.163971561515178
  (0, 1659)	3.201690662696309
  (0, 1658)	3.36530298443589
  (0, 1657)	3.36530298443589
  :	:
  (942, 24)	2.9731798133844984
  (942, 23)	3.1830258877815503
  (942, 22)	3.7221254716159664
  (942, 21)	3.7743367633498175
  (942, 20)	2.5818555273589876
  (942, 19)	3.327580295722465
  (942, 18)	3.2924258167174685
  (942, 17)	3.106325701436569
  (942, 16)	2.7729850787455494
  (942, 15)	3.017782792149333
  (942, 14)	3.3622121354661934
  (942, 13)	3.6090966477061657
  (942, 12)	3.1051603803248877
  (942, 11)	3.956277113830487
  (942, 10)	3.5419588395699573
  (942, 9)	3.5005413502278153
  (942, 8)	3.554922687476531
  (942, 7)	3.7422278032708194
  (942, 6)	3.5251676753049237
  (942, 5)	3.25175411504463
  (942, 4)	3.012959127906312
  (942, 3)	3.2568227797772185
  (942, 2)	2.9386751937367857
  (942, 1)	3.007583781124312
  (942, 0)	3.5736679843425265
this is the 253 epoch
rmse loss on training set is 0.8985939051865812
rmse loss on test set is 0.9156508187341973
for this epoch using 83.01873254776001 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3652507586709506
  (0, 1680)	3.3789297160871152
  (0, 1679)	3.3652507586709506
  (0, 1678)	3.3652507586709506
  (0, 1677)	3.3652507586709506
  (0, 1676)	3.3652507586709506
  (0, 1675)	3.3652507586709506
  (0, 1674)	3.3652507586709506
  (0, 1673)	3.3652507586709506
  (0, 1672)	3.3652507586709506
  (0, 1671)	3.3011131057477456
  (0, 1670)	3.3652507586709506
  (0, 1669)	3.3652507586709506
  (0, 1668)	3.3652507586709506
  (0, 1667)	3.3652507586709506
  (0, 1666)	3.3652507586709506
  (0, 1665)	3.3652507586709506
  (0, 1664)	3.3652507586709506
  (0, 1663)	3.424689983181817
  (0, 1662)	3.3652507586709506
  (0, 1661)	3.3652507586709506
  (0, 1660)	3.1631718632469057
  (0, 1659)	3.2010478754173506
  (0, 1658)	3.3652507586709506
  (0, 1657)	3.3652507586709506
  :	:
  (942, 24)	2.973275177128293
  (942, 23)	3.183089527213822
  (942, 22)	3.7223352505701284
  (942, 21)	3.7744574965129933
  (942, 20)	2.5817424739787094
  (942, 19)	3.327946739118575
  (942, 18)	3.293004764527561
  (942, 17)	3.1067288826095276
  (942, 16)	2.772944726713627
  (942, 15)	3.017931552940813
  (942, 14)	3.3623178094102983
  (942, 13)	3.609363926091341
  (942, 12)	3.105305792910201
  (942, 11)	3.956418237904136
  (942, 10)	3.542067978280516
  (942, 9)	3.5009662697199126
  (942, 8)	3.5550608590089623
  (942, 7)	3.7423880025731395
  (942, 6)	3.525280938018787
  (942, 5)	3.252569327609734
  (942, 4)	3.012993472956499
  (942, 3)	3.256924854559218
  (942, 2)	2.938691562129667
  (942, 1)	3.0076289082518577
  (942, 0)	3.5737732710610746
this is the 254 epoch
rmse loss on training set is 0.8985524983958577
rmse loss on test set is 0.9156329401846942
for this epoch using 81.99323415756226 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.365198843702742
  (0, 1680)	3.3789382423762278
  (0, 1679)	3.365198843702742
  (0, 1678)	3.365198843702742
  (0, 1677)	3.365198843702742
  (0, 1676)	3.365198843702742
  (0, 1675)	3.365198843702742
  (0, 1674)	3.365198843702742
  (0, 1673)	3.365198843702742
  (0, 1672)	3.365198843702742
  (0, 1671)	3.3008295579618707
  (0, 1670)	3.365198843702742
  (0, 1669)	3.365198843702742
  (0, 1668)	3.365198843702742
  (0, 1667)	3.365198843702742
  (0, 1666)	3.365198843702742
  (0, 1665)	3.365198843702742
  (0, 1664)	3.365198843702742
  (0, 1663)	3.4248398604027126
  (0, 1662)	3.365198843702742
  (0, 1661)	3.365198843702742
  (0, 1660)	3.162372832186898
  (0, 1659)	3.200405787014754
  (0, 1658)	3.365198843702742
  (0, 1657)	3.365198843702742
  :	:
  (942, 24)	2.9733700581488844
  (942, 23)	3.1831529529723626
  (942, 22)	3.722543593129513
  (942, 21)	3.7745775920076268
  (942, 20)	2.581631647231516
  (942, 19)	3.3283106118205
  (942, 18)	3.293580885635052
  (942, 17)	3.107131769805016
  (942, 16)	2.772905514484345
  (942, 15)	3.0180802036741556
  (942, 14)	3.362422948849459
  (942, 13)	3.609629083839662
  (942, 12)	3.105450351579193
  (942, 11)	3.956558580611498
  (942, 10)	3.5421765603915474
  (942, 9)	3.5013876991663424
  (942, 8)	3.555198251391946
  (942, 7)	3.742547250109657
  (942, 6)	3.52539361169173
  (942, 5)	3.2533830707682783
  (942, 4)	3.013027927483391
  (942, 3)	3.257026417491284
  (942, 2)	2.938708305236925
  (942, 1)	3.007673961805207
  (942, 0)	3.5738780380474675
this is the 255 epoch
rmse loss on training set is 0.8985113962127395
rmse loss on test set is 0.9156152599145089
for this epoch using 80.94457244873047 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3651472377219376
  (0, 1680)	3.378947077044953
  (0, 1679)	3.3651472377219376
  (0, 1678)	3.3651472377219376
  (0, 1677)	3.3651472377219376
  (0, 1676)	3.3651472377219376
  (0, 1675)	3.3651472377219376
  (0, 1674)	3.3651472377219376
  (0, 1673)	3.3651472377219376
  (0, 1672)	3.3651472377219376
  (0, 1671)	3.3005464020183113
  (0, 1670)	3.3651472377219376
  (0, 1669)	3.3651472377219376
  (0, 1668)	3.3651472377219376
  (0, 1667)	3.3651472377219376
  (0, 1666)	3.3651472377219376
  (0, 1665)	3.3651472377219376
  (0, 1664)	3.3651472377219376
  (0, 1663)	3.4249899160603503
  (0, 1662)	3.3651472377219376
  (0, 1661)	3.3651472377219376
  (0, 1660)	3.1615744656435947
  (0, 1659)	3.1997643945198537
  (0, 1658)	3.3651472377219376
  (0, 1657)	3.3651472377219376
  :	:
  (942, 24)	2.973464459166087
  (942, 23)	3.183216164962042
  (942, 22)	3.7227505141990345
  (942, 21)	3.7746970541266074
  (942, 20)	2.5815230112414533
  (942, 19)	3.328671934597278
  (942, 18)	3.2941541924778046
  (942, 17)	3.1075343619451092
  (942, 16)	2.7728674221362515
  (942, 15)	3.018228740345586
  (942, 14)	3.3625275569344466
  (942, 13)	3.6098921457683173
  (942, 12)	3.1055940618429134
  (942, 11)	3.956698147860088
  (942, 10)	3.5422845894464032
  (942, 9)	3.5018056727749385
  (942, 8)	3.555334870765757
  (942, 7)	3.7427055537248473
  (942, 6)	3.5255057000811614
  (942, 5)	3.2541953458488986
  (942, 4)	3.0130624874903646
  (942, 3)	3.257127471614834
  (942, 2)	2.938725415037552
  (942, 1)	3.007718939871707
  (942, 0)	3.573982288370154
this is the 256 epoch
rmse loss on training set is 0.8984705953795606
rmse loss on test set is 0.9155977756122765
for this epoch using 80.36849784851074 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3650959389267148
  (0, 1680)	3.3789562182400705
  (0, 1679)	3.3650959389267148
  (0, 1678)	3.3650959389267148
  (0, 1677)	3.3650959389267148
  (0, 1676)	3.3650959389267148
  (0, 1675)	3.3650959389267148
  (0, 1674)	3.3650959389267148
  (0, 1673)	3.3650959389267148
  (0, 1672)	3.3650959389267148
  (0, 1671)	3.3002636359740216
  (0, 1670)	3.3650959389267148
  (0, 1669)	3.3650959389267148
  (0, 1668)	3.3650959389267148
  (0, 1667)	3.3650959389267148
  (0, 1666)	3.3650959389267148
  (0, 1665)	3.3650959389267148
  (0, 1664)	3.3650959389267148
  (0, 1663)	3.4251401488407645
  (0, 1662)	3.3650959389267148
  (0, 1661)	3.3650959389267148
  (0, 1660)	3.1607767609403536
  (0, 1659)	3.1991236949815653
  (0, 1658)	3.3650959389267148
  (0, 1657)	3.3650959389267148
  :	:
  (942, 24)	2.9735583828947028
  (942, 23)	3.183279163112163
  (942, 22)	3.7229560284578924
  (942, 21)	3.774815887131515
  (942, 20)	2.5814165306874197
  (942, 19)	3.329030728045817
  (942, 18)	3.294724697470896
  (942, 17)	3.107936657965908
  (942, 16)	2.772830430070993
  (942, 15)	3.0183771590155324
  (942, 14)	3.362631636799061
  (942, 13)	3.6101531363173636
  (942, 12)	3.105736929200444
  (942, 11)	3.956836945499325
  (942, 10)	3.5423920689659814
  (942, 9)	3.5022202243879357
  (942, 8)	3.5554707232026304
  (942, 7)	3.742862921177514
  (942, 6)	3.5256172069241316
  (942, 5)	3.25500615419354
  (942, 4)	3.0130971490474
  (942, 3)	3.257228019957542
  (942, 2)	2.9387428836405713
  (942, 1)	3.007763840599533
  (942, 0)	3.5740860250828015
this is the 257 epoch
rmse loss on training set is 0.8984300926838212
rmse loss on test set is 0.9155804849991914
for this epoch using 79.53282475471497 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3650449455227878
  (0, 1680)	3.3789656641159675
  (0, 1679)	3.3650449455227878
  (0, 1678)	3.3650449455227878
  (0, 1677)	3.3650449455227878
  (0, 1676)	3.3650449455227878
  (0, 1675)	3.3650449455227878
  (0, 1674)	3.3650449455227878
  (0, 1673)	3.3650449455227878
  (0, 1672)	3.3650449455227878
  (0, 1671)	3.299981257894152
  (0, 1670)	3.3650449455227878
  (0, 1669)	3.3650449455227878
  (0, 1668)	3.3650449455227878
  (0, 1667)	3.3650449455227878
  (0, 1666)	3.3650449455227878
  (0, 1665)	3.3650449455227878
  (0, 1664)	3.3650449455227878
  (0, 1663)	3.425290557432858
  (0, 1662)	3.3650449455227878
  (0, 1661)	3.3650449455227878
  (0, 1660)	3.1599797154154006
  (0, 1659)	3.198483685466336
  (0, 1658)	3.3650449455227878
  (0, 1657)	3.3650449455227878
  :	:
  (942, 24)	2.9736518320439647
  (942, 23)	3.1833419473759266
  (942, 22)	3.7231601503642247
  (942, 21)	3.774934095252713
  (942, 20)	2.581312170794734
  (942, 19)	3.3293870125920875
  (942, 18)	3.2952924130060772
  (942, 17)	3.1083386568173386
  (942, 16)	2.7727945190081797
  (942, 15)	3.0185254558077204
  (942, 14)	3.362735191560245
  (942, 13)	3.610412079556547
  (942, 12)	3.1058789591378737
  (942, 11)	3.9569749793211306
  (942, 10)	3.542499002448724
  (942, 9)	3.5026313874859945
  (942, 8)	3.555605814707929
  (942, 7)	3.7430193601419797
  (942, 6)	3.5257281359371233
  (942, 5)	3.255815497157195
  (942, 4)	3.013131908290158
  (942, 3)	3.2573280655332204
  (942, 2)	2.9387607032831005
  (942, 1)	3.0078086621961417
  (942, 0)	3.574189251224141
this is the 258 epoch
rmse loss on training set is 0.8983898849574927
rmse loss on test set is 0.9155633858284605
for this epoch using 80.3501992225647 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3649942557233854
  (0, 1680)	3.3789754128346057
  (0, 1679)	3.3649942557233854
  (0, 1678)	3.3649942557233854
  (0, 1677)	3.3649942557233854
  (0, 1676)	3.3649942557233854
  (0, 1675)	3.3649942557233854
  (0, 1674)	3.3649942557233854
  (0, 1673)	3.3649942557233854
  (0, 1672)	3.3649942557233854
  (0, 1671)	3.2996992658520514
  (0, 1670)	3.3649942557233854
  (0, 1669)	3.3649942557233854
  (0, 1668)	3.3649942557233854
  (0, 1667)	3.3649942557233854
  (0, 1666)	3.3649942557233854
  (0, 1665)	3.3649942557233854
  (0, 1664)	3.3649942557233854
  (0, 1663)	3.4254411405284944
  (0, 1662)	3.3649942557233854
  (0, 1661)	3.3649942557233854
  (0, 1660)	3.1591833264217546
  (0, 1659)	3.1978443630580093
  (0, 1658)	3.3649942557233854
  (0, 1657)	3.3649942557233854
  :	:
  (942, 24)	2.973744809317001
  (942, 23)	3.1834045177297434
  (942, 22)	3.7233628941595103
  (942, 21)	3.775051682689457
  (942, 20)	2.5812098973267905
  (942, 19)	3.3297408084924363
  (942, 18)	3.2958573514511498
  (942, 17)	3.10874035746303
  (942, 16)	2.772759669980427
  (942, 15)	3.0186736269083743
  (942, 14)	3.3628382243181094
  (942, 13)	3.610668999191751
  (942, 12)	3.1060201571271775
  (942, 11)	3.957112255060769
  (942, 10)	3.542605393370651
  (942, 9)	3.5030391951922373
  (942, 8)	3.555740151221222
  (942, 7)	3.7431748782093224
  (942, 6)	3.5258384908157976
  (942, 5)	3.2566233761077417
  (942, 4)	3.0131667614191397
  (942, 3)	3.2574276113415332
  (942, 2)	2.938778866328466
  (942, 1)	3.0078534029267674
  (942, 0)	3.574291969817734
this is the 259 epoch
rmse loss on training set is 0.898349969076182
rmse loss on test set is 0.9155464758847625
for this epoch using 79.98032116889954 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.364943867749287
  (0, 1680)	3.378985462565582
  (0, 1679)	3.364943867749287
  (0, 1678)	3.364943867749287
  (0, 1677)	3.364943867749287
  (0, 1676)	3.364943867749287
  (0, 1675)	3.364943867749287
  (0, 1674)	3.364943867749287
  (0, 1673)	3.364943867749287
  (0, 1672)	3.364943867749287
  (0, 1671)	3.2994176579292493
  (0, 1670)	3.364943867749287
  (0, 1669)	3.364943867749287
  (0, 1668)	3.364943867749287
  (0, 1667)	3.364943867749287
  (0, 1666)	3.364943867749287
  (0, 1665)	3.364943867749287
  (0, 1664)	3.364943867749287
  (0, 1663)	3.425591896822537
  (0, 1662)	3.364943867749287
  (0, 1661)	3.364943867749287
  (0, 1660)	3.1583875913271404
  (0, 1659)	3.19720572485771
  (0, 1658)	3.364943867749287
  (0, 1657)	3.364943867749287
  :	:
  (942, 24)	2.9738373174103288
  (942, 23)	3.183466874172724
  (942, 22)	3.7235642738729746
  (942, 21)	3.775168653610074
  (942, 20)	2.5811096765768755
  (942, 19)	3.3300921358348172
  (942, 18)	3.2964195251494304
  (942, 17)	3.109141758880152
  (942, 16)	2.7727258643283967
  (942, 15)	3.018821668565336
  (942, 14)	3.3629407381559897
  (942, 13)	3.6109239185714563
  (942, 12)	3.106160528625297
  (942, 11)	3.9572487783974695
  (942, 10)	3.5427112451853264
  (942, 9)	3.503443680276197
  (942, 8)	3.5558737386173713
  (942, 7)	3.7433294828886017
  (942, 6)	3.525948275234845
  (942, 5)	3.2574297924256683
  (942, 4)	3.013201704698772
  (942, 3)	3.2575266603678426
  (942, 2)	2.938797365264278
  (942, 1)	3.0078980611129675
  (942, 0)	3.5743941838719153
this is the 260 epoch
rmse loss on training set is 0.898310341958447
rmse loss on test set is 0.9155297529836828
for this epoch using 81.12527060508728 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3648937798288707
  (0, 1680)	3.3789958114861514
  (0, 1679)	3.3648937798288707
  (0, 1678)	3.3648937798288707
  (0, 1677)	3.3648937798288707
  (0, 1676)	3.3648937798288707
  (0, 1675)	3.3648937798288707
  (0, 1674)	3.3648937798288707
  (0, 1673)	3.3648937798288707
  (0, 1672)	3.3648937798288707
  (0, 1671)	3.2991364322155547
  (0, 1670)	3.3648937798288707
  (0, 1669)	3.3648937798288707
  (0, 1668)	3.3648937798288707
  (0, 1667)	3.3648937798288707
  (0, 1666)	3.3648937798288707
  (0, 1665)	3.3648937798288707
  (0, 1664)	3.3648937798288707
  (0, 1663)	3.4257428250129545
  (0, 1662)	3.3648937798288707
  (0, 1661)	3.3648937798288707
  (0, 1660)	3.157592507514011
  (0, 1659)	3.1965677679838116
  (0, 1658)	3.3648937798288707
  (0, 1657)	3.3648937798288707
  :	:
  (942, 24)	2.9739293590134
  (942, 23)	3.183529016726006
  (942, 22)	3.7237643033258156
  (942, 21)	3.7752850121520516
  (942, 20)	2.5810114753600724
  (942, 19)	3.3304410145400527
  (942, 18)	3.296978946419176
  (942, 17)	3.1095428600592387
  (942, 16)	2.7726930836959656
  (942, 15)	3.0189695770872778
  (942, 14)	3.363042736140496
  (942, 13)	3.6111768606930936
  (942, 12)	3.1063000790731325
  (942, 11)	3.957384554955111
  (942, 10)	3.54281656132393
  (942, 9)	3.503844875157758
  (942, 8)	3.556006582707581
  (942, 7)	3.743483181607926
  (942, 6)	3.5260574928477957
  (942, 5)	3.258234747503928
  (942, 4)	3.0132367344565685
  (942, 3)	3.257625215583015
  (942, 2)	2.938816192700607
  (942, 1)	3.0079426351312004
  (942, 0)	3.5744958963795654
this is the 261 epoch
rmse loss on training set is 0.8982710005650723
rmse loss on test set is 0.9155132149712248
for this epoch using 82.88088035583496 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.364843990198068
  (0, 1680)	3.3790064577811987
  (0, 1679)	3.364843990198068
  (0, 1678)	3.364843990198068
  (0, 1677)	3.364843990198068
  (0, 1676)	3.364843990198068
  (0, 1675)	3.364843990198068
  (0, 1674)	3.364843990198068
  (0, 1673)	3.364843990198068
  (0, 1672)	3.364843990198068
  (0, 1671)	3.298855586808978
  (0, 1670)	3.364843990198068
  (0, 1669)	3.364843990198068
  (0, 1668)	3.364843990198068
  (0, 1667)	3.364843990198068
  (0, 1666)	3.364843990198068
  (0, 1665)	3.364843990198068
  (0, 1664)	3.364843990198068
  (0, 1663)	3.4258939238008583
  (0, 1662)	3.364843990198068
  (0, 1661)	3.364843990198068
  (0, 1660)	3.156798072379387
  (0, 1659)	3.1959304895717855
  (0, 1658)	3.364843990198068
  (0, 1657)	3.364843990198068
  :	:
  (942, 24)	2.9740209368080968
  (942, 23)	3.1835909454322784
  (942, 22)	3.7239629961353535
  (942, 21)	3.7754007624221706
  (942, 20)	2.5809152610053077
  (942, 19)	3.330787464363059
  (942, 18)	3.2975356275530383
  (942, 17)	3.10994366000405
  (942, 16)	2.77266131002541
  (942, 15)	3.019117348842874
  (942, 14)	3.3631442213215563
  (942, 13)	3.611427848209153
  (942, 12)	3.106438813894646
  (942, 11)	3.9575195903029496
  (942, 10)	3.5429213451952473
  (942, 9)	3.504242811911024
  (942, 8)	3.5561386892403686
  (942, 7)	3.743635981715659
  (942, 6)	3.5261661472868515
  (942, 5)	3.259038242747698
  (942, 4)	3.0132718470822435
  (942, 3)	3.2577232799432494
  (942, 2)	2.938835341368142
  (942, 1)	3.007987123411421
  (942, 0)	3.5745971103180003
this is the 262 epoch
rmse loss on training set is 0.8982319418983176
rmse loss on test set is 0.9154968597232745
for this epoch using 81.05098009109497 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.36479449710041
  (0, 1680)	3.3790173996433186
  (0, 1679)	3.36479449710041
  (0, 1678)	3.36479449710041
  (0, 1677)	3.36479449710041
  (0, 1676)	3.36479449710041
  (0, 1675)	3.36479449710041
  (0, 1674)	3.36479449710041
  (0, 1673)	3.36479449710041
  (0, 1672)	3.36479449710041
  (0, 1671)	3.2985751198157924
  (0, 1670)	3.36479449710041
  (0, 1669)	3.36479449710041
  (0, 1668)	3.36479449710041
  (0, 1667)	3.36479449710041
  (0, 1666)	3.36479449710041
  (0, 1665)	3.36479449710041
  (0, 1664)	3.36479449710041
  (0, 1663)	3.4260451918905805
  (0, 1662)	3.36479449710041
  (0, 1661)	3.36479449710041
  (0, 1660)	3.1560042833348967
  (0, 1659)	3.19529388677411
  (0, 1658)	3.36479449710041
  (0, 1657)	3.36479449710041
  :	:
  (942, 24)	2.974112053468338
  (942, 23)	3.183652660355134
  (942, 22)	3.7241603657190763
  (942, 21)	3.775515908496651
  (942, 20)	2.5808210013475312
  (942, 19)	3.331131504894103
  (942, 18)	3.298089580817566
  (942, 17)	3.110344157731432
  (942, 16)	2.772630525552724
  (942, 15)	3.019264980259989
  (942, 14)	3.363245196732461
  (942, 13)	3.6116769034332967
  (942, 12)	3.1065767384959986
  (942, 11)	3.957653889956257
  (942, 10)	3.5430256001857137
  (942, 9)	3.5046375222681663
  (942, 8)	3.5562700639026494
  (942, 7)	3.74378789048153
  (942, 6)	3.5262742421627653
  (942, 5)	3.2598402795742065
  (942, 4)	3.0133070390269077
  (942, 3)	3.2578208563899413
  (942, 2)	2.938854804116375
  (942, 1)	3.008031524435724
  (942, 0)	3.574697828648859
this is the 263 epoch
rmse loss on training set is 0.8981931630012377
rmse loss on test set is 0.9154806851450947
for this epoch using 80.99257612228394 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3647452987870516
  (0, 1680)	3.3790286352727454
  (0, 1679)	3.3647452987870516
  (0, 1678)	3.3647452987870516
  (0, 1677)	3.3647452987870516
  (0, 1676)	3.3647452987870516
  (0, 1675)	3.3647452987870516
  (0, 1674)	3.3647452987870516
  (0, 1673)	3.3647452987870516
  (0, 1672)	3.3647452987870516
  (0, 1671)	3.2982950293505224
  (0, 1670)	3.3647452987870516
  (0, 1669)	3.3647452987870516
  (0, 1668)	3.3647452987870516
  (0, 1667)	3.3647452987870516
  (0, 1666)	3.3647452987870516
  (0, 1665)	3.3647452987870516
  (0, 1664)	3.3647452987870516
  (0, 1663)	3.426196627989729
  (0, 1662)	3.3647452987870516
  (0, 1661)	3.3647452987870516
  (0, 1660)	3.1552111378066354
  (0, 1659)	3.1946579567601945
  (0, 1658)	3.3647452987870516
  (0, 1657)	3.3647452987870516
  :	:
  (942, 24)	2.9742027116596685
  (942, 23)	3.1837141615785884
  (942, 22)	3.7243564252986032
  (942, 21)	3.775630454421307
  (942, 20)	2.5807286647199645
  (942, 19)	3.331473155560039
  (942, 18)	3.298640818452686
  (942, 17)	3.1107443522711438
  (942, 16)	2.772600712802978
  (942, 15)	3.0194124678249183
  (942, 14)	3.363345665389916
  (942, 13)	3.6119240483463098
  (942, 12)	3.1067138582647518
  (942, 11)	3.9577874593769646
  (942, 10)	3.543129329659462
  (942, 9)	3.505029037623177
  (942, 8)	3.5564007123206336
  (942, 7)	3.7439389150976994
  (942, 6)	3.5263817810646865
  (942, 5)	3.260640859412512
  (942, 4)	3.0133423068021856
  (942, 3)	3.2579179478494873
  (942, 2)	2.9388745739118134
  (942, 1)	3.0080758367370337
  (942, 0)	3.574798054317997
this is the 264 epoch
rmse loss on training set is 0.8981546609570249
rmse loss on test set is 0.9154646891708442
for this epoch using 83.25591897964478 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.364696393516758
  (0, 1680)	3.379040162877452
  (0, 1679)	3.364696393516758
  (0, 1678)	3.364696393516758
  (0, 1677)	3.364696393516758
  (0, 1676)	3.364696393516758
  (0, 1675)	3.364696393516758
  (0, 1674)	3.364696393516758
  (0, 1673)	3.364696393516758
  (0, 1672)	3.364696393516758
  (0, 1671)	3.2980153135359904
  (0, 1670)	3.364696393516758
  (0, 1669)	3.364696393516758
  (0, 1668)	3.364696393516758
  (0, 1667)	3.364696393516758
  (0, 1666)	3.364696393516758
  (0, 1665)	3.364696393516758
  (0, 1664)	3.364696393516758
  (0, 1663)	3.4263482308092676
  (0, 1662)	3.364696393516758
  (0, 1661)	3.364696393516758
  (0, 1660)	3.154418633235163
  (0, 1659)	3.194022696716287
  (0, 1658)	3.364696393516758
  (0, 1657)	3.364696393516758
  :	:
  (942, 24)	2.974292914038856
  (942, 23)	3.183775449206496
  (942, 22)	3.724551187903507
  (942, 21)	3.775744404211667
  (942, 20)	2.580638219946518
  (942, 19)	3.3318124356255248
  (942, 18)	3.2991893526711893
  (942, 17)	3.1111442426657403
  (942, 16)	2.7725718545857254
  (942, 15)	3.0195598080816013
  (942, 14)	3.36344563029405
  (942, 13)	3.612169304601881
  (942, 12)	3.106850178569021
  (942, 11)	3.9579203039743316
  (942, 10)	3.5432325369583424
  (942, 9)	3.5054173890357085
  (942, 8)	3.556530640060784
  (942, 7)	3.744089062679862
  (942, 6)	3.526488767560056
  (942, 5)	3.2614399837033163
  (942, 4)	3.0133776469793987
  (942, 3)	3.258014557233219
  (942, 2)	2.938894643836247
  (942, 1)	3.008120058897784
  (942, 0)	3.5748977902553665
this is the 265 epoch
rmse loss on training set is 0.898116432888295
rmse loss on test set is 0.9154488697630808
for this epoch using 78.77146816253662 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3646477795559466
  (0, 1680)	3.379051980673141
  (0, 1679)	3.3646477795559466
  (0, 1678)	3.3646477795559466
  (0, 1677)	3.3646477795559466
  (0, 1676)	3.3646477795559466
  (0, 1675)	3.3646477795559466
  (0, 1674)	3.3646477795559466
  (0, 1673)	3.3646477795559466
  (0, 1672)	3.3646477795559466
  (0, 1671)	3.297735970503285
  (0, 1670)	3.3646477795559466
  (0, 1669)	3.3646477795559466
  (0, 1668)	3.3646477795559466
  (0, 1667)	3.3646477795559466
  (0, 1666)	3.3646477795559466
  (0, 1665)	3.3646477795559466
  (0, 1664)	3.3646477795559466
  (0, 1663)	3.4264999990635534
  (0, 1662)	3.3646477795559466
  (0, 1661)	3.3646477795559466
  (0, 1660)	3.1536267670754303
  (0, 1659)	3.193388103845357
  (0, 1658)	3.3646477795559466
  (0, 1657)	3.3646477795559466
  :	:
  (942, 24)	2.974382663253533
  (942, 23)	3.1838365233620647
  (942, 22)	3.724744666375073
  (942, 21)	3.7758577618531457
  (942, 20)	2.5805496363343168
  (942, 19)	3.3321493641942537
  (942, 18)	3.2997351956582506
  (942, 17)	3.1115438279703924
  (942, 16)	2.7725439339905487
  (942, 15)	3.019706997630835
  (942, 14)	3.363545094428509
  (942, 13)	3.612412693532368
  (942, 12)	3.106985704756782
  (942, 11)	3.9580524291055585
  (942, 10)	3.5433352254019783
  (942, 9)	3.5058026072346595
  (942, 8)	3.5566598526307818
  (942, 7)	3.7442383402682693
  (942, 6)	3.5265952051945098
  (942, 5)	3.262237653898769
  (942, 4)	3.0134130561887567
  (942, 3)	3.2581106874372194
  (942, 2)	2.9389150070849874
  (942, 1)	3.008164189548686
  (942, 0)	3.5749970393749178
this is the 266 epoch
rmse loss on training set is 0.8980784759564793
rmse loss on test set is 0.915433224912295
for this epoch using 79.68570137023926 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3645994551786838
  (0, 1680)	3.3790640868832162
  (0, 1679)	3.3645994551786838
  (0, 1678)	3.3645994551786838
  (0, 1677)	3.3645994551786838
  (0, 1676)	3.3645994551786838
  (0, 1675)	3.3645994551786838
  (0, 1674)	3.3645994551786838
  (0, 1673)	3.3645994551786838
  (0, 1672)	3.3645994551786838
  (0, 1671)	3.2974569983917967
  (0, 1670)	3.3645994551786838
  (0, 1669)	3.3645994551786838
  (0, 1668)	3.3645994551786838
  (0, 1667)	3.3645994551786838
  (0, 1666)	3.3645994551786838
  (0, 1665)	3.3645994551786838
  (0, 1664)	3.3645994551786838
  (0, 1663)	3.426651931470442
  (0, 1662)	3.3645994551786838
  (0, 1661)	3.3645994551786838
  (0, 1660)	3.152835536796726
  (0, 1659)	3.1927541753670465
  (0, 1658)	3.3645994551786838
  (0, 1657)	3.3645994551786838
  :	:
  (942, 24)	2.974471961941871
  (942, 23)	3.183897384187288
  (942, 22)	3.7249368733700283
  (942, 21)	3.775970531301187
  (942, 20)	2.5804628836662884
  (942, 19)	3.3324839602101908
  (942, 18)	3.300278359570987
  (942, 17)	3.1119431072527948
  (942, 16)	2.7725169343825855
  (942, 15)	3.019854033129549
  (942, 14)	3.3636440607604383
  (942, 13)	3.6126542361544165
  (942, 12)	3.1071204421551384
  (942, 11)	3.9581838400764013
  (942, 10)	3.5434373982878014
  (942, 9)	3.506184722621963
  (942, 8)	3.5567883554803887
  (942, 7)	3.7443867548288043
  (942, 6)	3.526701097491758
  (942, 5)	3.263033871462297
  (942, 4)	3.013448531118505
  (942, 3)	3.258206341342234
  (942, 2)	2.938935656965192
  (942, 1)	3.0082082273674944
  (942, 0)	3.5750958045745524
this is the 267 epoch
rmse loss on training set is 0.8980407873611356
rmse loss on test set is 0.9154177526364375
for this epoch using 79.9183611869812 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3645514186666743
  (0, 1680)	3.37907647973885
  (0, 1679)	3.3645514186666743
  (0, 1678)	3.3645514186666743
  (0, 1677)	3.3645514186666743
  (0, 1676)	3.3645514186666743
  (0, 1675)	3.3645514186666743
  (0, 1674)	3.3645514186666743
  (0, 1673)	3.3645514186666743
  (0, 1672)	3.3645514186666743
  (0, 1671)	3.297178395349226
  (0, 1670)	3.3645514186666743
  (0, 1669)	3.3645514186666743
  (0, 1668)	3.3645514186666743
  (0, 1667)	3.3645514186666743
  (0, 1666)	3.3645514186666743
  (0, 1665)	3.3645514186666743
  (0, 1664)	3.3645514186666743
  (0, 1663)	3.4268040267512783
  (0, 1662)	3.3645514186666743
  (0, 1661)	3.3645514186666743
  (0, 1660)	3.1520449398825905
  (0, 1659)	3.1921209085175417
  (0, 1658)	3.3645514186666743
  (0, 1657)	3.3645514186666743
  :	:
  (942, 24)	2.974560812732226
  (942, 23)	3.1839580318424816
  (942, 22)	3.7251278213640258
  (942, 21)	3.7760827164814157
  (942, 20)	2.5803779321939233
  (942, 19)	3.3328162424587577
  (942, 18)	3.3008188565379677
  (942, 17)	3.1123420795929664
  (942, 16)	2.7724908393982135
  (942, 15)	3.0200009112900426
  (942, 14)	3.3637425322405505
  (942, 13)	3.6128939531744106
  (942, 12)	3.1072543960696457
  (942, 11)	3.9583145421418324
  (942, 10)	3.543539058891126
  (942, 9)	3.5065637652761157
  (942, 8)	3.556916154002338
  (942, 7)	3.744534313253961
  (942, 6)	3.5268064479535615
  (942, 5)	3.2638286378684063
  (942, 4)	3.013484068514155
  (942, 3)	3.2583015218135616
  (942, 2)	2.9389565868941365
  (942, 1)	3.0082521710777925
  (942, 0)	3.5751940887359903
this is the 268 epoch
rmse loss on training set is 0.8980033643393316
rmse loss on test set is 0.9154024509804854
for this epoch using 80.02995324134827 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3645036683093426
  (0, 1680)	3.3790891574789743
  (0, 1679)	3.3645036683093426
  (0, 1678)	3.3645036683093426
  (0, 1677)	3.3645036683093426
  (0, 1676)	3.3645036683093426
  (0, 1675)	3.3645036683093426
  (0, 1674)	3.3645036683093426
  (0, 1673)	3.3645036683093426
  (0, 1672)	3.3645036683093426
  (0, 1671)	3.296900159531589
  (0, 1670)	3.3645036683093426
  (0, 1669)	3.3645036683093426
  (0, 1668)	3.3645036683093426
  (0, 1667)	3.3645036683093426
  (0, 1666)	3.3645036683093426
  (0, 1665)	3.3645036683093426
  (0, 1664)	3.3645036683093426
  (0, 1663)	3.426956283631028
  (0, 1662)	3.3645036683093426
  (0, 1661)	3.3645036683093426
  (0, 1660)	3.1512549738308127
  (0, 1659)	3.1914883005494925
  (0, 1658)	3.3645036683093426
  (0, 1657)	3.3645036683093426
  :	:
  (942, 24)	2.9746492182428645
  (942, 23)	3.1840184665057767
  (942, 22)	3.7253175226552133
  (942, 21)	3.776194321289793
  (942, 20)	2.5802947526301296
  (942, 19)	3.3331462295680794
  (942, 18)	3.3013566986587657
  (942, 17)	3.112740744083159
  (942, 16)	2.7724656329407145
  (942, 15)	3.0201476288792493
  (942, 14)	3.363840511803183
  (942, 13)	3.613131864993919
  (942, 12)	3.1073875717836525
  (942, 11)	3.9584445405065796
  (942, 10)	3.5436402104651825
  (942, 9)	3.506939764955836
  (942, 8)	3.5570432535332257
  (942, 7)	3.7446810223638276
  (942, 6)	3.526911260059634
  (942, 5)	3.2646219546025024
  (942, 4)	3.013519665177667
  (942, 3)	3.25839623170096
  (942, 2)	2.9389777903975935
  (942, 1)	3.0082960194478385
  (942, 0)	3.575291894724765
this is the 269 epoch
rmse loss on training set is 0.8979662041650573
rmse loss on test set is 0.9153873180159624
for this epoch using 81.39240598678589 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.364456202403755
  (0, 1680)	3.379102118350284
  (0, 1679)	3.364456202403755
  (0, 1678)	3.364456202403755
  (0, 1677)	3.364456202403755
  (0, 1676)	3.364456202403755
  (0, 1675)	3.364456202403755
  (0, 1674)	3.364456202403755
  (0, 1673)	3.364456202403755
  (0, 1672)	3.364456202403755
  (0, 1671)	3.2966222891032073
  (0, 1670)	3.364456202403755
  (0, 1669)	3.364456202403755
  (0, 1668)	3.364456202403755
  (0, 1667)	3.364456202403755
  (0, 1666)	3.364456202403755
  (0, 1665)	3.364456202403755
  (0, 1664)	3.364456202403755
  (0, 1663)	3.4271087008382866
  (0, 1662)	3.364456202403755
  (0, 1661)	3.364456202403755
  (0, 1660)	3.1504656361533305
  (0, 1659)	3.1908563487319315
  (0, 1658)	3.364456202403755
  (0, 1657)	3.364456202403755
  :	:
  (942, 24)	2.9747371810816476
  (942, 23)	3.1840786883726215
  (942, 22)	3.725505989367622
  (942, 21)	3.776305349592811
  (942, 20)	2.580213316142148
  (942, 19)	3.3334739400101565
  (942, 18)	3.301891898003562
  (942, 17)	3.1131390998277038
  (942, 16)	2.7724412991760716
  (942, 15)	3.0202941827180365
  (942, 14)	3.363938002366251
  (942, 13)	3.61336799171495
  (942, 12)	3.107519974557721
  (942, 11)	3.958573840325803
  (942, 10)	3.5437408562412007
  (942, 9)	3.5073127511035627
  (942, 8)	3.557169659354287
  (942, 7)	3.744826888907133
  (942, 6)	3.52701553726757
  (942, 5)	3.2654138231606793
  (942, 4)	3.013555317966669
  (942, 3)	3.2584904738385543
  (942, 2)	2.9389992611081657
  (942, 1)	3.008339771289426
  (942, 0)	3.575389225390119
this is the 270 epoch
rmse loss on training set is 0.8979293041485749
rmse loss on test set is 0.9153723518405226
for this epoch using 103.80597805976868 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3644090192546834
  (0, 1680)	3.3791153606072584
  (0, 1679)	3.3644090192546834
  (0, 1678)	3.3644090192546834
  (0, 1677)	3.3644090192546834
  (0, 1676)	3.3644090192546834
  (0, 1675)	3.3644090192546834
  (0, 1674)	3.3644090192546834
  (0, 1673)	3.3644090192546834
  (0, 1672)	3.3644090192546834
  (0, 1671)	3.296344782236742
  (0, 1670)	3.3644090192546834
  (0, 1669)	3.3644090192546834
  (0, 1668)	3.3644090192546834
  (0, 1667)	3.3644090192546834
  (0, 1666)	3.3644090192546834
  (0, 1665)	3.3644090192546834
  (0, 1664)	3.3644090192546834
  (0, 1663)	3.4272612771053375
  (0, 1662)	3.3644090192546834
  (0, 1661)	3.3644090192546834
  (0, 1660)	3.1496769243761773
  (0, 1659)	3.1902250503501883
  (0, 1658)	3.3644090192546834
  (0, 1657)	3.3644090192546834
  :	:
  (942, 24)	2.9748247038457594
  (942, 23)	3.184138697655324
  (942, 22)	3.725693233454469
  (942, 21)	3.7764158052276113
  (942, 20)	2.5801335943446424
  (942, 19)	3.3337993921020974
  (942, 18)	3.302424466612684
  (942, 17)	3.1135371459428667
  (942, 16)	2.7724178225287948
  (942, 15)	3.02044056968047
  (942, 14)	3.3640350068313802
  (942, 13)	3.6136023531451857
  (942, 12)	3.107651609629049
  (942, 11)	3.958702446705576
  (942, 10)	3.5438409994284443
  (942, 9)	3.507682752848984
  (942, 8)	3.5572953766922937
  (942, 7)	3.7449719195621105
  (942, 6)	3.5271192830128357
  (942, 5)	3.2662042450496043
  (942, 4)	3.0135910237936585
  (942, 3)	3.258584251044749
  (942, 2)	2.9390209927637017
  (942, 1)	3.0083834254567523
  (942, 0)	3.575486083564971
this is the 271 epoch
rmse loss on training set is 0.897892661635856
rmse loss on test set is 0.9153575505775238
for this epoch using 88.16616678237915 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.364362117174611
  (0, 1680)	3.3791288825121675
  (0, 1679)	3.364362117174611
  (0, 1678)	3.364362117174611
  (0, 1677)	3.364362117174611
  (0, 1676)	3.364362117174611
  (0, 1675)	3.364362117174611
  (0, 1674)	3.364362117174611
  (0, 1673)	3.364362117174611
  (0, 1672)	3.364362117174611
  (0, 1671)	3.296067637113185
  (0, 1670)	3.364362117174611
  (0, 1669)	3.364362117174611
  (0, 1668)	3.364362117174611
  (0, 1667)	3.364362117174611
  (0, 1666)	3.364362117174611
  (0, 1665)	3.364362117174611
  (0, 1664)	3.364362117174611
  (0, 1663)	3.4274140111682407
  (0, 1662)	3.364362117174611
  (0, 1661)	3.364362117174611
  (0, 1660)	3.1488888360394545
  (0, 1659)	3.18959440270578
  (0, 1658)	3.364362117174611
  (0, 1657)	3.364362117174611
  :	:
  (942, 24)	2.9749117891214887
  (942, 23)	3.184198494582558
  (942, 22)	3.7258792667014755
  (942, 21)	3.7765256920022017
  (942, 20)	2.580055559292862
  (942, 19)	3.334122604007271
  (942, 18)	3.302954416496201
  (942, 17)	3.113934881556735
  (942, 16)	2.7723951876778252
  (942, 15)	3.0205867866931095
  (942, 14)	3.364131528083896
  (942, 13)	3.61383496880303
  (942, 12)	3.1077824822108875
  (942, 11)	3.958830364703574
  (942, 10)	3.5439406432143277
  (942, 9)	3.508049799012508
  (942, 8)	3.5574204107203076
  (942, 7)	3.745116120937513
  (942, 6)	3.5272225007087203
  (942, 5)	3.266993221786298
  (942, 4)	3.0136267796252465
  (942, 3)	3.2586775661221705
  (942, 2)	2.939042979205671
  (942, 1)	3.0084269808453583
  (942, 0)	3.575582472065865
this is the 272 epoch
rmse loss on training set is 0.8978562740079683
rmse loss on test set is 0.9153429123755991
for this epoch using 83.31279635429382 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.364315494483712
  (0, 1680)	3.3791426823351007
  (0, 1679)	3.364315494483712
  (0, 1678)	3.364315494483712
  (0, 1677)	3.364315494483712
  (0, 1676)	3.364315494483712
  (0, 1675)	3.364315494483712
  (0, 1674)	3.364315494483712
  (0, 1673)	3.364315494483712
  (0, 1672)	3.364315494483712
  (0, 1671)	3.2957908519218817
  (0, 1670)	3.364315494483712
  (0, 1669)	3.364315494483712
  (0, 1668)	3.364315494483712
  (0, 1667)	3.364315494483712
  (0, 1666)	3.364315494483712
  (0, 1665)	3.364315494483712
  (0, 1664)	3.364315494483712
  (0, 1663)	3.42756690176686
  (0, 1662)	3.364315494483712
  (0, 1661)	3.364315494483712
  (0, 1660)	3.148101368697252
  (0, 1659)	3.1889644031163495
  (0, 1658)	3.364315494483712
  (0, 1657)	3.364315494483712
  :	:
  (942, 24)	2.974998439483946
  (942, 23)	3.1842580793989494
  (942, 22)	3.726064100729975
  (942, 21)	3.7766350136955826
  (942, 20)	2.5799791834758996
  (942, 19)	3.334443593736536
  (942, 18)	3.3034817596335735
  (942, 17)	3.114332305809085
  (942, 16)	2.7723733795525027
  (942, 15)	3.0207328307343424
  (942, 14)	3.3642275689928396
  (942, 13)	3.6140658579226153
  (942, 12)	3.107912597492059
  (942, 11)	3.9589575993295587
  (942, 10)	3.5440397907644243
  (942, 9)	3.5084139181086607
  (942, 8)	3.557544766558474
  (942, 7)	3.7452594995735224
  (942, 6)	3.5273251937462953
  (942, 5)	3.26778075489797
  (942, 4)	3.0136625824814063
  (942, 3)	3.2587704218576095
  (942, 2)	2.939065214377628
  (942, 1)	3.0084704363910593
  (942, 0)	3.5756783936929435
this is the 273 epoch
rmse loss on training set is 0.8978201386805336
rmse loss on test set is 0.9153284354082378
for this epoch using 81.93254590034485 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3642691495099126
  (0, 1680)	3.379156758353941
  (0, 1679)	3.3642691495099126
  (0, 1678)	3.3642691495099126
  (0, 1677)	3.3642691495099126
  (0, 1676)	3.3642691495099126
  (0, 1675)	3.3642691495099126
  (0, 1674)	3.3642691495099126
  (0, 1673)	3.3642691495099126
  (0, 1672)	3.3642691495099126
  (0, 1671)	3.2955144248605133
  (0, 1670)	3.3642691495099126
  (0, 1669)	3.3642691495099126
  (0, 1668)	3.3642691495099126
  (0, 1667)	3.3642691495099126
  (0, 1666)	3.3642691495099126
  (0, 1665)	3.3642691495099126
  (0, 1664)	3.3642691495099126
  (0, 1663)	3.427719947644898
  (0, 1662)	3.3642691495099126
  (0, 1661)	3.3642691495099126
  (0, 1660)	3.147314519917571
  (0, 1659)	3.1883350489155577
  (0, 1658)	3.3642691495099126
  (0, 1657)	3.3642691495099126
  :	:
  (942, 24)	2.9750846574968577
  (942, 23)	3.184317452364582
  (942, 22)	3.726247747000039
  (942, 21)	3.776743774057923
  (942, 20)	2.57990443981005
  (942, 19)	3.334762379149419
  (942, 18)	3.3040065079731837
  (942, 17)	3.1147294178512235
  (942, 16)	2.7723523833285797
  (942, 15)	3.0208786988336738
  (942, 14)	3.364323132411042
  (942, 13)	3.6142950394587383
  (942, 12)	3.1080419606364593
  (942, 11)	3.959084155545954
  (942, 10)	3.5441384452225684
  (942, 9)	3.5087751383495274
  (942, 8)	3.557668449274804
  (942, 7)	3.7454020619426314
  (942, 6)	3.5274273654944226
  (942, 5)	3.2685668459218435
  (942, 4)	3.0136984294346623
  (942, 3)	3.2588628210219293
  (942, 2)	2.939087692323628
  (942, 1)	3.008513791068908
  (942, 0)	3.5757738512298904
this is the 274 epoch
rmse loss on training set is 0.8977842531031457
rmse loss on test set is 0.9153141178734067
for this epoch using 84.03724336624146 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3642230805888302
  (0, 1680)	3.379171108854411
  (0, 1679)	3.3642230805888302
  (0, 1678)	3.3642230805888302
  (0, 1677)	3.3642230805888302
  (0, 1676)	3.3642230805888302
  (0, 1675)	3.3642230805888302
  (0, 1674)	3.3642230805888302
  (0, 1673)	3.3642230805888302
  (0, 1672)	3.3642230805888302
  (0, 1671)	3.295238354135127
  (0, 1670)	3.3642230805888302
  (0, 1669)	3.3642230805888302
  (0, 1668)	3.3642230805888302
  (0, 1667)	3.3642230805888302
  (0, 1666)	3.3642230805888302
  (0, 1665)	3.3642230805888302
  (0, 1664)	3.3642230805888302
  (0, 1663)	3.4278731475499917
  (0, 1662)	3.3642230805888302
  (0, 1661)	3.3642230805888302
  (0, 1660)	3.146528287282326
  (0, 1659)	3.187706337453022
  (0, 1658)	3.3642230805888302
  (0, 1657)	3.3642230805888302
  :	:
  (942, 24)	2.9751704457123602
  (942, 23)	3.184376613754591
  (942, 22)	3.726430216813535
  (942, 21)	3.7768519768107867
  (942, 20)	2.5798313016323076
  (942, 19)	3.335078977955243
  (942, 18)	3.3045286734320496
  (942, 17)	3.115126216845893
  (942, 16)	2.7723321844243136
  (942, 15)	3.0210243880710568
  (942, 14)	3.364418221175146
  (942, 13)	3.6145225320916192
  (942, 12)	3.1081705767825887
  (942, 11)	3.9592100382684414
  (942, 10)	3.5442366097109725
  (942, 9)	3.509133487648037
  (942, 8)	3.5577914638859123
  (942, 7)	3.7455438144505595
  (942, 6)	3.5275290192997195
  (942, 5)	3.2693514964049992
  (942, 4)	3.013734317609401
  (942, 3)	3.2589547663700604
  (942, 2)	2.939110407186749
  (942, 1)	3.008557043892201
  (942, 0)	3.5758688474439473
this is the 275 epoch
rmse loss on training set is 0.8977486147588525
rmse loss on test set is 0.9152999579931168
for this epoch using 83.7510461807251 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.364177286063825
  (0, 1680)	3.3791857321300363
  (0, 1679)	3.364177286063825
  (0, 1678)	3.364177286063825
  (0, 1677)	3.364177286063825
  (0, 1676)	3.364177286063825
  (0, 1675)	3.364177286063825
  (0, 1674)	3.364177286063825
  (0, 1673)	3.364177286063825
  (0, 1672)	3.364177286063825
  (0, 1671)	3.294962637960114
  (0, 1670)	3.364177286063825
  (0, 1669)	3.364177286063825
  (0, 1668)	3.364177286063825
  (0, 1667)	3.364177286063825
  (0, 1666)	3.364177286063825
  (0, 1665)	3.364177286063825
  (0, 1664)	3.364177286063825
  (0, 1663)	3.4280265002337225
  (0, 1662)	3.364177286063825
  (0, 1661)	3.364177286063825
  (0, 1660)	3.1457426683872307
  (0, 1659)	3.1870782660942067
  (0, 1658)	3.364177286063825
  (0, 1657)	3.364177286063825
  :	:
  (942, 24)	2.9752558066707944
  (942, 23)	3.1844355638587243
  (942, 22)	3.726611521317014
  (942, 21)	3.7769596256472355
  (942, 20)	2.5797597426939096
  (942, 19)	3.335393407714382
  (942, 18)	3.305048267895388
  (942, 17)	3.1155227019671496
  (942, 16)	2.772312768496624
  (942, 15)	3.0211698955762296
  (942, 14)	3.364512838105615
  (942, 13)	3.6147483542316343
  (942, 12)	3.108298451043139
  (942, 11)	3.9593352523664516
  (942, 10)	3.5443342873302313
  (942, 9)	3.5094889936213565
  (942, 8)	3.557913815357778
  (942, 7)	3.7456847634371297
  (942, 6)	3.5276301584866228
  (942, 5)	3.270134707904226
  (942, 4)	3.0137702441811083
  (942, 3)	3.259046260640928
  (942, 2)	2.9391333532075254
  (942, 1)	3.008600193911476
  (942, 0)	3.5759633850858576
this is the 276 epoch
rmse loss on training set is 0.8977132211635778
rmse loss on test set is 0.9152859540130739
for this epoch using 83.12077641487122 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3641317642860065
  (0, 1680)	3.3792006264822056
  (0, 1679)	3.3641317642860065
  (0, 1678)	3.3641317642860065
  (0, 1677)	3.3641317642860065
  (0, 1676)	3.3641317642860065
  (0, 1675)	3.3641317642860065
  (0, 1674)	3.3641317642860065
  (0, 1673)	3.3641317642860065
  (0, 1672)	3.3641317642860065
  (0, 1671)	3.294687274558215
  (0, 1670)	3.3641317642860065
  (0, 1669)	3.3641317642860065
  (0, 1668)	3.3641317642860065
  (0, 1667)	3.3641317642860065
  (0, 1666)	3.3641317642860065
  (0, 1665)	3.3641317642860065
  (0, 1664)	3.3641317642860065
  (0, 1663)	3.428180004451685
  (0, 1662)	3.3641317642860065
  (0, 1661)	3.3641317642860065
  (0, 1660)	3.144957660841768
  (0, 1659)	3.186450832220335
  (0, 1658)	3.3641317642860065
  (0, 1657)	3.3641317642860065
  :	:
  (942, 24)	2.9753407429005176
  (942, 23)	3.1844943029809323
  (942, 22)	3.7267916715046923
  (942, 21)	3.7770667242320526
  (942, 20)	2.579689737154012
  (942, 19)	3.335705685839346
  (942, 18)	3.3055653032163015
  (942, 17)	3.1159188724001985
  (942, 16)	2.7722941214372763
  (942, 15)	3.0213152185280796
  (942, 14)	3.364606986006802
  (942, 13)	3.6149725240239463
  (942, 12)	3.108425588504549
  (942, 11)	3.9594598026637398
  (942, 10)	3.544431481159462
  (942, 9)	3.5098416835940887
  (942, 8)	3.5580355086064333
  (942, 7)	3.74582491517712
  (942, 6)	3.5277307863572864
  (942, 5)	3.2709164819858088
  (942, 4)	3.013806206375636
  (942, 3)	3.2591373065574185
  (942, 2)	2.9391565247225433
  (942, 1)	3.0086432402135874
  (942, 0)	3.576057466889887
this is the 277 epoch
rmse loss on training set is 0.8976780698656034
rmse loss on test set is 0.9152721042022667
for this epoch using 81.35315918922424 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3640865136142155
  (0, 1680)	3.3792157902201354
  (0, 1679)	3.3640865136142155
  (0, 1678)	3.3640865136142155
  (0, 1677)	3.3640865136142155
  (0, 1676)	3.3640865136142155
  (0, 1675)	3.3640865136142155
  (0, 1674)	3.3640865136142155
  (0, 1673)	3.3640865136142155
  (0, 1672)	3.3640865136142155
  (0, 1671)	3.294412262160545
  (0, 1670)	3.3640865136142155
  (0, 1669)	3.3640865136142155
  (0, 1668)	3.3640865136142155
  (0, 1667)	3.3640865136142155
  (0, 1666)	3.3640865136142155
  (0, 1665)	3.3640865136142155
  (0, 1664)	3.3640865136142155
  (0, 1663)	3.428333658963529
  (0, 1662)	3.3640865136142155
  (0, 1661)	3.3640865136142155
  (0, 1660)	3.144173262269122
  (0, 1659)	3.1858240332283505
  (0, 1658)	3.3640865136142155
  (0, 1657)	3.3640865136142155
  :	:
  (942, 24)	2.9754252569177573
  (942, 23)	3.1845528314389253
  (942, 22)	3.726970678221187
  (942, 21)	3.7771732762019012
  (942, 20)	2.579621259573448
  (942, 19)	3.3360158295960014
  (942, 18)	3.306079791215422
  (942, 17)	3.1163147273413223
  (942, 16)	2.7722762293691767
  (942, 15)	3.0214603541539615
  (942, 14)	3.3647006676669715
  (942, 13)	3.6151950593530544
  (942, 12)	3.108551994226667
  (942, 11)	3.9595836939388724
  (942, 10)	3.5445281942563707
  (942, 9)	3.510191584601568
  (942, 8)	3.5581565484986704
  (942, 7)	3.7459642758811182
  (942, 6)	3.527830906191711
  (942, 5)	3.2716968202254284
  (942, 4)	3.0138422014684756
  (942, 3)	3.259227906826373
  (942, 2)	2.9391799161629097
  (942, 1)	3.008686181920732
  (942, 0)	3.5761510955737656
this is the 278 epoch
rmse loss on training set is 0.897643158445075
rmse loss on test set is 0.9152584068526042
for this epoch using 83.56678199768066 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3640415324150283
  (0, 1680)	3.379231221660883
  (0, 1679)	3.3640415324150283
  (0, 1678)	3.3640415324150283
  (0, 1677)	3.3640415324150283
  (0, 1676)	3.3640415324150283
  (0, 1675)	3.3640415324150283
  (0, 1674)	3.3640415324150283
  (0, 1673)	3.3640415324150283
  (0, 1672)	3.3640415324150283
  (0, 1671)	3.2941375990065875
  (0, 1670)	3.3640415324150283
  (0, 1669)	3.3640415324150283
  (0, 1668)	3.3640415324150283
  (0, 1667)	3.3640415324150283
  (0, 1666)	3.3640415324150283
  (0, 1665)	3.3640415324150283
  (0, 1664)	3.3640415324150283
  (0, 1663)	3.428487462532998
  (0, 1662)	3.3640415324150283
  (0, 1661)	3.3640415324150283
  (0, 1660)	3.1433894703061394
  (0, 1659)	3.1851978665307534
  (0, 1658)	3.3640415324150283
  (0, 1657)	3.3640415324150283
  :	:
  (942, 24)	2.9755093512264135
  (942, 23)	3.1846111495638323
  (942, 22)	3.7271485521643384
  (942, 21)	3.7772792851655295
  (942, 20)	2.57955428490857
  (942, 19)	3.336323856104679
  (942, 18)	3.3065917436805914
  (942, 17)	3.1167102659977113
  (942, 16)	2.772259078642669
  (942, 15)	3.0216052997291025
  (942, 14)	3.3647938858583366
  (942, 13)	3.6154159778472024
  (942, 12)	3.1086776732423655
  (942, 11)	3.9597069309257775
  (942, 10)	3.544624429657344
  (942, 9)	3.51053872339304
  (942, 8)	3.5582769398527554
  (942, 7)	3.746102851696359
  (942, 6)	3.5279305212477143
  (942, 5)	3.2724757242079456
  (942, 4)	3.0138782267840654
  (942, 3)	3.259318064138528
  (942, 2)	2.939203522052856
  (942, 1)	3.0087290181895603
  (942, 0)	3.576244273838758
this is the 279 epoch
rmse loss on training set is 0.8976084845134643
rmse loss on test set is 0.9152448602785641
for this epoch using 81.27306795120239 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3639968190627862
  (0, 1680)	3.3792469191293657
  (0, 1679)	3.3639968190627862
  (0, 1678)	3.3639968190627862
  (0, 1677)	3.3639968190627862
  (0, 1676)	3.3639968190627862
  (0, 1675)	3.3639968190627862
  (0, 1674)	3.3639968190627862
  (0, 1673)	3.3639968190627862
  (0, 1672)	3.3639968190627862
  (0, 1671)	3.29386328334418
  (0, 1670)	3.3639968190627862
  (0, 1669)	3.3639968190627862
  (0, 1668)	3.3639968190627862
  (0, 1667)	3.3639968190627862
  (0, 1666)	3.3639968190627862
  (0, 1665)	3.3639968190627862
  (0, 1664)	3.3639968190627862
  (0, 1663)	3.4286414139280015
  (0, 1662)	3.3639968190627862
  (0, 1661)	3.3639968190627862
  (0, 1660)	3.1426062826032486
  (0, 1659)	3.1845723295556003
  (0, 1658)	3.3639968190627862
  (0, 1657)	3.3639968190627862
  :	:
  (942, 24)	2.9755930283179564
  (942, 23)	3.1846692576997415
  (942, 22)	3.7273253038878567
  (942, 21)	3.777384754703927
  (942, 20)	2.5794887885052264
  (942, 19)	3.3366297823413698
  (942, 18)	3.307101172366502
  (942, 17)	3.117105487587384
  (942, 16)	2.772242655831914
  (942, 15)	3.0217500525759293
  (942, 14)	3.364886643337078
  (942, 13)	3.615635296882797
  (942, 12)	3.108802630557195
  (942, 11)	3.9598295183142787
  (942, 10)	3.544720190377521
  (942, 9)	3.510883126434839
  (942, 8)	3.5583966874390645
  (942, 7)	3.746240648707522
  (942, 6)	3.5280296347609545
  (942, 5)	3.273253195527292
  (942, 4)	3.0139142796950398
  (942, 3)	3.2594077811685334
  (942, 2)	2.939227337008288
  (942, 1)	3.00877174821031
  (942, 0)	3.5763370043696106
this is the 280 epoch
rmse loss on training set is 0.8975740457130769
rmse loss on test set is 0.9152314628168035
for this epoch using 81.24719953536987 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3639523719395665
  (0, 1680)	3.3792628809583563
  (0, 1679)	3.3639523719395665
  (0, 1678)	3.3639523719395665
  (0, 1677)	3.3639523719395665
  (0, 1676)	3.3639523719395665
  (0, 1675)	3.3639523719395665
  (0, 1674)	3.3639523719395665
  (0, 1673)	3.3639523719395665
  (0, 1672)	3.3639523719395665
  (0, 1671)	3.2935893134295178
  (0, 1670)	3.3639523719395665
  (0, 1669)	3.3639523719395665
  (0, 1668)	3.3639523719395665
  (0, 1667)	3.3639523719395665
  (0, 1666)	3.3639523719395665
  (0, 1665)	3.3639523719395665
  (0, 1664)	3.3639523719395665
  (0, 1663)	3.428795511920591
  (0, 1662)	3.3639523719395665
  (0, 1661)	3.3639523719395665
  (0, 1660)	3.1418236968244084
  (0, 1659)	3.1839474197463473
  (0, 1658)	3.3639523719395665
  (0, 1657)	3.3639523719395665
  :	:
  (942, 24)	2.9756762906712426
  (942, 23)	3.184727156203369
  (942, 22)	3.7275009438039675
  (942, 21)	3.7774896883705265
  (942, 20)	2.579424746092785
  (942, 19)	3.3369336251388053
  (942, 18)	3.307608088994441
  (942, 17)	3.117500391339051
  (942, 16)	2.7722269477313537
  (942, 15)	3.0218946100634816
  (942, 14)	3.36497894284342
  (942, 13)	3.6158530335886625
  (942, 12)	3.1089268711490976
  (942, 11)	3.959951460750522
  (942, 10)	3.5448154794109215
  (942, 9)	3.511224819913528
  (942, 8)	3.5585157959807874
  (942, 7)	3.74637767293759
  (942, 6)	3.52812824994499
  (942, 5)	3.274029235786296
  (942, 4)	3.0139503576215905
  (942, 3)	3.259497060574913
  (942, 2)	2.9392513557354265
  (942, 1)	3.0088143712058875
  (942, 0)	3.5764292898345547
this is the 281 epoch
rmse loss on training set is 0.8975398397165932
rmse loss on test set is 0.915218212825832
for this epoch using 81.87026786804199 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.363908189435216
  (0, 1680)	3.3792791054884748
  (0, 1679)	3.363908189435216
  (0, 1678)	3.363908189435216
  (0, 1677)	3.363908189435216
  (0, 1676)	3.363908189435216
  (0, 1675)	3.363908189435216
  (0, 1674)	3.363908189435216
  (0, 1673)	3.363908189435216
  (0, 1672)	3.363908189435216
  (0, 1671)	3.2933156875271545
  (0, 1670)	3.363908189435216
  (0, 1669)	3.363908189435216
  (0, 1668)	3.363908189435216
  (0, 1667)	3.363908189435216
  (0, 1666)	3.363908189435216
  (0, 1665)	3.363908189435216
  (0, 1664)	3.363908189435216
  (0, 1663)	3.4289497552870865
  (0, 1662)	3.363908189435216
  (0, 1661)	3.363908189435216
  (0, 1660)	3.1410417106470687
  (0, 1659)	3.1833231345618236
  (0, 1658)	3.363908189435216
  (0, 1657)	3.363908189435216
  :	:
  (942, 24)	2.9757591407524315
  (942, 23)	3.1847848454436227
  (942, 22)	3.727675482186044
  (942, 21)	3.7775940896913602
  (942, 20)	2.5793621337782446
  (942, 19)	3.3372354011876655
  (942, 18)	3.308112505251935
  (942, 17)	3.1178949764920123
  (942, 16)	2.7722119413521686
  (942, 15)	3.0220389696067844
  (942, 14)	3.3650707871016143
  (942, 13)	3.616069204850249
  (942, 12)	3.1090503999680923
  (942, 11)	3.9600727628375636
  (942, 10)	3.5449102997305175
  (942, 9)	3.511563829738968
  (942, 8)	3.5586342701545433
  (942, 7)	3.7465139303485446
  (942, 6)	3.528226369991288
  (942, 5)	3.2748038465965283
  (942, 4)	3.0139864580307245
  (942, 3)	3.2595859050000624
  (942, 2)	2.9392755730293825
  (942, 1)	3.0088568864310656
  (942, 0)	3.576521132885396
this is the 282 epoch
rmse loss on training set is 0.8975058642265147
rmse loss on test set is 0.9152051086856429
for this epoch using 80.93593192100525 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3638642699473094
  (0, 1680)	3.379295591068205
  (0, 1679)	3.3638642699473094
  (0, 1678)	3.3638642699473094
  (0, 1677)	3.3638642699473094
  (0, 1676)	3.3638642699473094
  (0, 1675)	3.3638642699473094
  (0, 1674)	3.3638642699473094
  (0, 1673)	3.3638642699473094
  (0, 1672)	3.3638642699473094
  (0, 1671)	3.29304240391002
  (0, 1670)	3.3638642699473094
  (0, 1669)	3.3638642699473094
  (0, 1668)	3.3638642699473094
  (0, 1667)	3.3638642699473094
  (0, 1666)	3.3638642699473094
  (0, 1665)	3.3638642699473094
  (0, 1664)	3.3638642699473094
  (0, 1663)	3.4291041428080544
  (0, 1662)	3.3638642699473094
  (0, 1661)	3.3638642699473094
  (0, 1660)	3.1402603217620912
  (0, 1659)	3.182699471476129
  (0, 1658)	3.3638642699473094
  (0, 1657)	3.3638642699473094
  :	:
  (942, 24)	2.975841581014827
  (942, 23)	3.1848423258013185
  (942, 22)	3.7278489291710186
  (942, 21)	3.777697962165288
  (942, 20)	2.579300928040485
  (942, 19)	3.3375351270376434
  (942, 18)	3.3086144327924685
  (942, 17)	3.1182892422960022
  (942, 16)	2.772197623918842
  (942, 15)	3.022183128666252
  (942, 14)	3.36516217882002
  (942, 13)	3.6162838273137834
  (942, 12)	3.1091732219360217
  (942, 11)	3.9601934291358107
  (942, 10)	3.545004654288325
  (942, 9)	3.511900181547412
  (942, 8)	3.5587521145910244
  (942, 7)	3.7466494268422417
  (942, 6)	3.528323998069329
  (942, 5)	3.2755770295781526
  (942, 4)	3.0140225784356005
  (942, 3)	3.2596743170702585
  (942, 2)	2.9392999837728397
  (942, 1)	3.0088992931716354
  (942, 0)	3.576612536157421
this is the 283 epoch
rmse loss on training set is 0.8974721169747853
rmse loss on test set is 0.9151921487974083
for this epoch using 80.47545218467712 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.363820611881213
  (0, 1680)	3.379312336053914
  (0, 1679)	3.363820611881213
  (0, 1678)	3.363820611881213
  (0, 1677)	3.363820611881213
  (0, 1676)	3.363820611881213
  (0, 1675)	3.363820611881213
  (0, 1674)	3.363820611881213
  (0, 1673)	3.363820611881213
  (0, 1672)	3.363820611881213
  (0, 1671)	3.2927694608594065
  (0, 1670)	3.363820611881213
  (0, 1669)	3.363820611881213
  (0, 1668)	3.363820611881213
  (0, 1667)	3.363820611881213
  (0, 1666)	3.363820611881213
  (0, 1665)	3.363820611881213
  (0, 1664)	3.363820611881213
  (0, 1663)	3.4292586732683823
  (0, 1662)	3.363820611881213
  (0, 1661)	3.363820611881213
  (0, 1660)	3.1394795278737164
  (0, 1659)	3.1820764279785214
  (0, 1658)	3.363820611881213
  (0, 1657)	3.363820611881213
  :	:
  (942, 24)	2.975923613898817
  (942, 23)	3.184899597668739
  (942, 22)	3.728021294761908
  (942, 21)	3.7778013092641327
  (942, 20)	2.5792411057245546
  (942, 19)	3.337832819098607
  (942, 18)	3.3091138832352467
  (942, 17)	3.118683188011145
  (942, 16)	2.7721839828657546
  (942, 15)	3.022327084747095
  (942, 14)	3.365253120691138
  (942, 13)	3.616496917390276
  (942, 12)	3.1092953419462828
  (942, 11)	3.9603134641635216
  (942, 10)	3.545098546015525
  (942, 9)	3.512233900704515
  (942, 8)	3.5588693338756365
  (942, 7)	3.7467841682611507
  (942, 6)	3.528421137326626
  (942, 5)	3.2763487863598058
  (942, 4)	3.0140587163948855
  (942, 3)	3.2597622993956414
  (942, 2)	2.939324582934673
  (942, 1)	3.008941590743615
  (942, 0)	3.5767035022695066
this is the 284 epoch
rmse loss on training set is 0.8974385957222587
rmse loss on test set is 0.9151793315831045
for this epoch using 81.77084636688232 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3637772136500215
  (0, 1680)	3.3793293388098204
  (0, 1679)	3.3637772136500215
  (0, 1678)	3.3637772136500215
  (0, 1677)	3.3637772136500215
  (0, 1676)	3.3637772136500215
  (0, 1675)	3.3637772136500215
  (0, 1674)	3.3637772136500215
  (0, 1673)	3.3637772136500215
  (0, 1672)	3.3637772136500215
  (0, 1671)	3.292496856664945
  (0, 1670)	3.3637772136500215
  (0, 1669)	3.3637772136500215
  (0, 1668)	3.3637772136500215
  (0, 1667)	3.3637772136500215
  (0, 1666)	3.3637772136500215
  (0, 1665)	3.3637772136500215
  (0, 1664)	3.3637772136500215
  (0, 1663)	3.42941334545732
  (0, 1662)	3.3637772136500215
  (0, 1661)	3.3637772136500215
  (0, 1660)	3.138699326699462
  (0, 1659)	3.1814540015734134
  (0, 1658)	3.3637772136500215
  (0, 1657)	3.3637772136500215
  :	:
  (942, 24)	2.9760052418317255
  (942, 23)	3.1849566614493185
  (942, 22)	3.7281925888301983
  (942, 21)	3.7779041344329256
  (942, 20)	2.5791826440360706
  (942, 19)	3.3381284936417006
  (942, 18)	3.3096108681648357
  (942, 17)	3.1190768129077746
  (942, 16)	2.7721710058338296
  (942, 15)	3.0224708353987113
  (942, 14)	3.3653436153916267
  (942, 13)	3.616708491259496
  (942, 12)	3.1094167648636044
  (942, 11)	3.9604328723972637
  (942, 10)	3.5451919778225545
  (942, 9)	3.5125650123083276
  (942, 8)	3.5589859325490636
  (942, 7)	3.746918160389057
  (942, 6)	3.5285177908887584
  (942, 5)	3.277119118578404
  (942, 4)	3.01409486951203
  (942, 3)	3.2598498545702608
  (942, 2)	2.939349365568677
  (942, 1)	3.008983778492465
  (942, 0)	3.5767940338241098
this is the 285 epoch
rmse loss on training set is 0.8974052982582799
rmse loss on test set is 0.9151666554852137
for this epoch using 80.91983890533447 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3637340736745784
  (0, 1680)	3.379346597707972
  (0, 1679)	3.3637340736745784
  (0, 1678)	3.3637340736745784
  (0, 1677)	3.3637340736745784
  (0, 1676)	3.3637340736745784
  (0, 1675)	3.3637340736745784
  (0, 1674)	3.3637340736745784
  (0, 1673)	3.3637340736745784
  (0, 1672)	3.3637340736745784
  (0, 1671)	3.2922245896246154
  (0, 1670)	3.3637340736745784
  (0, 1669)	3.3637340736745784
  (0, 1668)	3.3637340736745784
  (0, 1667)	3.3637340736745784
  (0, 1666)	3.3637340736745784
  (0, 1665)	3.3637340736745784
  (0, 1664)	3.3637340736745784
  (0, 1663)	3.429568158168445
  (0, 1662)	3.3637340736745784
  (0, 1661)	3.3637340736745784
  (0, 1660)	3.137919715970112
  (0, 1659)	3.180832189780174
  (0, 1658)	3.3637340736745784
  (0, 1657)	3.3637340736745784
  :	:
  (942, 24)	2.976086467227777
  (942, 23)	3.185013517557311
  (942, 22)	3.7283628211182127
  (942, 21)	3.7780064410900334
  (942, 20)	2.579125520535681
  (942, 19)	3.3384221668004694
  (942, 18)	3.3101053991309692
  (942, 17)	3.1194701162663723
  (942, 16)	2.7721586806672494
  (942, 15)	3.022614378214154
  (942, 14)	3.3654336655823585
  (942, 13)	3.616918564873916
  (942, 12)	3.109537495523844
  (942, 11)	3.960551658272422
  (942, 10)	3.545284952599204
  (942, 9)	3.5128935411922853
  (942, 8)	3.5591019151079046
  (942, 7)	3.747051408951879
  (942, 6)	3.528613961859483
  (942, 5)	3.2778880278790496
  (942, 4)	3.014131035434657
  (942, 3)	3.2599369851720352
  (942, 2)	2.93937432681221
  (942, 1)	3.0090258557923173
  (942, 0)	3.5768841334072876
this is the 286 epoch
rmse loss on training set is 0.8973722224002179
rmse loss on test set is 0.9151541189663904
for this epoch using 80.61490035057068 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.363691190383484
  (0, 1680)	3.3793641111283295
  (0, 1679)	3.363691190383484
  (0, 1678)	3.363691190383484
  (0, 1677)	3.363691190383484
  (0, 1676)	3.363691190383484
  (0, 1675)	3.363691190383484
  (0, 1674)	3.363691190383484
  (0, 1673)	3.363691190383484
  (0, 1672)	3.363691190383484
  (0, 1671)	3.291952658044777
  (0, 1670)	3.363691190383484
  (0, 1669)	3.363691190383484
  (0, 1668)	3.363691190383484
  (0, 1667)	3.363691190383484
  (0, 1666)	3.363691190383484
  (0, 1665)	3.363691190383484
  (0, 1664)	3.363691190383484
  (0, 1663)	3.4297231101998222
  (0, 1662)	3.363691190383484
  (0, 1661)	3.363691190383484
  (0, 1660)	3.1371406934296453
  (0, 1659)	3.180210990133163
  (0, 1658)	3.363691190383484
  (0, 1657)	3.363691190383484
  :	:
  (942, 24)	2.9761672924879674
  (942, 23)	3.1850701664174097
  (942, 22)	3.728532001241342
  (942, 21)	3.778108232627407
  (942, 20)	2.57906971313365
  (942, 19)	3.3387138545719415
  (942, 18)	3.310597487648261
  (942, 17)	3.119863097377434
  (942, 16)	2.772146995410203
  (942, 15)	3.0227577108295005
  (942, 14)	3.365523273908461
  (942, 13)	3.6171271539624956
  (942, 12)	3.1096575387337553
  (942, 11)	3.9606698261836395
  (942, 10)	3.5453774732147276
  (942, 9)	3.5132195119280882
  (942, 8)	3.5592172860052336
  (942, 7)	3.7471839196183288
  (942, 6)	3.5287096533207936
  (942, 5)	3.2786555159148416
  (942, 4)	3.014167211853878
  (942, 3)	3.2600236937627978
  (942, 2)	2.9393994618849524
  (942, 1)	3.00906782204522
  (942, 0)	3.576973803588763
this is the 287 epoch
rmse loss on training set is 0.8973393659930393
rmse loss on test set is 0.9151417205091648
for this epoch using 82.08856081962585 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3636485622130947
  (0, 1680)	3.3793818774586777
  (0, 1679)	3.3636485622130947
  (0, 1678)	3.3636485622130947
  (0, 1677)	3.3636485622130947
  (0, 1676)	3.3636485622130947
  (0, 1675)	3.3636485622130947
  (0, 1674)	3.3636485622130947
  (0, 1673)	3.3636485622130947
  (0, 1672)	3.3636485622130947
  (0, 1671)	3.291681060240093
  (0, 1670)	3.3636485622130947
  (0, 1669)	3.3636485622130947
  (0, 1668)	3.3636485622130947
  (0, 1667)	3.3636485622130947
  (0, 1666)	3.3636485622130947
  (0, 1665)	3.3636485622130947
  (0, 1664)	3.3636485622130947
  (0, 1663)	3.42987820035392
  (0, 1662)	3.3636485622130947
  (0, 1661)	3.3636485622130947
  (0, 1660)	3.1363622568351417
  (0, 1659)	3.1795904001815796
  (0, 1658)	3.3636485622130947
  (0, 1657)	3.3636485622130947
  :	:
  (942, 24)	2.976247720000023
  (942, 23)	3.185126608464477
  (942, 22)	3.7287001386903755
  (942, 21)	3.7782095124107014
  (942, 20)	2.5790152000844917
  (942, 19)	3.3390035728177554
  (942, 18)	3.311087145195966
  (942, 17)	3.1202557555413586
  (942, 16)	2.772135938303679
  (942, 15)	3.022900830923358
  (942, 14)	3.365612442999331
  (942, 13)	3.617334274034432
  (942, 12)	3.1097768992708548
  (942, 11)	3.960787380485288
  (942, 10)	3.5454695425179477
  (942, 9)	3.513542948828635
  (942, 8)	3.5593320496511933
  (942, 7)	3.7473156980006865
  (942, 6)	3.528804868332974
  (942, 5)	3.279421584346796
  (942, 4)	3.014203396503688
  (942, 3)	3.260109982888328
  (942, 2)	2.9394247660876376
  (942, 1)	3.009109676680442
  (942, 0)	3.577063046921919
this is the 288 epoch
rmse loss on training set is 0.8973067269089134
rmse loss on test set is 0.9151294586156021
for this epoch using 81.09208416938782 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3636061876074947
  (0, 1680)	3.3793998950946875
  (0, 1679)	3.3636061876074947
  (0, 1678)	3.3636061876074947
  (0, 1677)	3.3636061876074947
  (0, 1676)	3.3636061876074947
  (0, 1675)	3.3636061876074947
  (0, 1674)	3.3636061876074947
  (0, 1673)	3.3636061876074947
  (0, 1672)	3.3636061876074947
  (0, 1671)	3.2914097945335934
  (0, 1670)	3.3636061876074947
  (0, 1669)	3.3636061876074947
  (0, 1668)	3.3636061876074947
  (0, 1667)	3.3636061876074947
  (0, 1666)	3.3636061876074947
  (0, 1665)	3.3636061876074947
  (0, 1664)	3.3636061876074947
  (0, 1663)	3.4300334274377224
  (0, 1662)	3.3636061876074947
  (0, 1661)	3.3636061876074947
  (0, 1660)	3.1355844039567984
  (0, 1659)	3.178970417489395
  (0, 1658)	3.3636061876074947
  (0, 1657)	3.3636061876074947
  :	:
  (942, 24)	2.9763277521383174
  (942, 23)	3.1851828441431542
  (942, 22)	3.728867242833635
  (942, 21)	3.7783102837795295
  (942, 20)	2.5789619599816693
  (942, 19)	3.3392913372652098
  (942, 18)	3.311574383217713
  (942, 17)	3.120648090068379
  (942, 16)	2.772125497782355
  (942, 15)	3.0230437362162315
  (942, 14)	3.365701175468721
  (942, 13)	3.6175399403828363
  (942, 12)	3.1098955818832357
  (942, 11)	3.960904325491904
  (942, 10)	3.545561163337353
  (942, 9)	3.513863875950872
  (942, 8)	3.5594462104135363
  (942, 7)	3.7474467496554644
  (942, 6)	3.5288996099346774
  (942, 5)	3.280186234843635
  (942, 4)	3.0142395871602963
  (942, 3)	3.26019585507835
  (942, 2)	2.939450234800776
  (942, 1)	3.0091514191537203
  (942, 0)	3.5771518659438932
this is the 289 epoch
rmse loss on training set is 0.8972743030467084
rmse loss on test set is 0.9151173318070305
for this epoch using 81.22631216049194 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.363564065018521
  (0, 1680)	3.379418162439856
  (0, 1679)	3.363564065018521
  (0, 1678)	3.363564065018521
  (0, 1677)	3.363564065018521
  (0, 1676)	3.363564065018521
  (0, 1675)	3.363564065018521
  (0, 1674)	3.363564065018521
  (0, 1673)	3.363564065018521
  (0, 1672)	3.363564065018521
  (0, 1671)	3.2911388592566033
  (0, 1670)	3.363564065018521
  (0, 1669)	3.363564065018521
  (0, 1668)	3.363564065018521
  (0, 1667)	3.363564065018521
  (0, 1666)	3.363564065018521
  (0, 1665)	3.363564065018521
  (0, 1664)	3.363564065018521
  (0, 1663)	3.430188790262691
  (0, 1662)	3.363564065018521
  (0, 1661)	3.363564065018521
  (0, 1660)	3.1348071325777815
  (0, 1659)	3.178351039635285
  (0, 1658)	3.363564065018521
  (0, 1657)	3.363564065018521
  :	:
  (942, 24)	2.9764073912638294
  (942, 23)	3.18523887390761
  (942, 22)	3.7290333229191623
  (942, 21)	3.778410550047617
  (942, 20)	2.57890997175245
  (942, 19)	3.3395771635084066
  (942, 18)	3.3120592131213056
  (942, 17)	3.1210401002784045
  (942, 16)	2.772115662471444
  (942, 15)	3.023186424470044
  (942, 14)	3.3657894739147505
  (942, 13)	3.617744168088404
  (942, 12)	3.110013591289401
  (942, 11)	3.9610206654786526
  (942, 10)	3.5456523384812537
  (942, 9)	3.514182317098629
  (942, 8)	3.5595597726182144
  (942, 7)	3.7475770800841346
  (942, 6)	3.5289938811430486
  (942, 5)	3.2809494690817282
  (942, 4)	3.0142757816415306
  (942, 3)	3.2602813128465473
  (942, 2)	2.9394758634834592
  (942, 1)	3.009193048946603
  (942, 0)	3.5772402631755393
this is the 290 epoch
rmse loss on training set is 0.8972420923316489
rmse loss on test set is 0.9151053386237221
for this epoch using 80.45937132835388 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.363522192905742
  (0, 1680)	3.3794366779055514
  (0, 1679)	3.363522192905742
  (0, 1678)	3.363522192905742
  (0, 1677)	3.363522192905742
  (0, 1676)	3.363522192905742
  (0, 1675)	3.363522192905742
  (0, 1674)	3.363522192905742
  (0, 1673)	3.363522192905742
  (0, 1672)	3.363522192905742
  (0, 1671)	3.2908682527488082
  (0, 1670)	3.363522192905742
  (0, 1669)	3.363522192905742
  (0, 1668)	3.363522192905742
  (0, 1667)	3.363522192905742
  (0, 1666)	3.363522192905742
  (0, 1665)	3.363522192905742
  (0, 1664)	3.363522192905742
  (0, 1663)	3.430344287644898
  (0, 1662)	3.363522192905742
  (0, 1661)	3.363522192905742
  (0, 1660)	3.1340304404942443
  (0, 1659)	3.1777322642125423
  (0, 1658)	3.363522192905742
  (0, 1657)	3.363522192905742
  :	:
  (942, 24)	2.97648663972408
  (942, 23)	3.185294698221197
  (942, 22)	3.7291983880767754
  (942, 21)	3.7785103145029986
  (942, 20)	2.5788592146527294
  (942, 19)	3.3398610670092683
  (942, 18)	3.3125416462785
  (942, 17)	3.1214317855009557
  (942, 16)	2.7721064211837283
  (942, 15)	3.023328893487554
  (942, 14)	3.3658773409199765
  (942, 13)	3.617946972022889
  (942, 12)	3.110130932178186
  (942, 11)	3.9611364046817474
  (942, 10)	3.5457430707378284
  (942, 9)	3.5144982958253905
  (942, 8)	3.5596727405498525
  (942, 7)	3.7477066947337865
  (942, 6)	3.5290876849537485
  (942, 5)	3.2817112887448987
  (942, 4)	3.014311977806194
  (942, 3)	3.2603663586906526
  (942, 2)	2.939501647672144
  (942, 1)	3.0092345655657664
  (942, 0)	3.5773282411215597
this is the 291 epoch
rmse loss on training set is 0.897210092714906
rmse loss on test set is 0.9150934776246256
for this epoch using 80.09177732467651 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3634805697364483
  (0, 1680)	3.379455439910985
  (0, 1679)	3.3634805697364483
  (0, 1678)	3.3634805697364483
  (0, 1677)	3.3634805697364483
  (0, 1676)	3.3634805697364483
  (0, 1675)	3.3634805697364483
  (0, 1674)	3.3634805697364483
  (0, 1673)	3.3634805697364483
  (0, 1672)	3.3634805697364483
  (0, 1671)	3.2905979733581936
  (0, 1670)	3.3634805697364483
  (0, 1669)	3.3634805697364483
  (0, 1668)	3.3634805697364483
  (0, 1667)	3.3634805697364483
  (0, 1666)	3.3634805697364483
  (0, 1665)	3.3634805697364483
  (0, 1664)	3.3634805697364483
  (0, 1663)	3.4304999184049376
  (0, 1662)	3.3634805697364483
  (0, 1661)	3.3634805697364483
  (0, 1660)	3.133254325515218
  (0, 1659)	3.1771140888290073
  (0, 1658)	3.3634805697364483
  (0, 1657)	3.3634805697364483
  :	:
  (942, 24)	2.9765654998531006
  (942, 23)	3.1853503175561504
  (942, 22)	3.729362447320144
  (942, 21)	3.7786095804081876
  (942, 20)	2.578809668262052
  (942, 19)	3.3401430630986426
  (942, 18)	3.313021694024763
  (942, 17)	3.1218231450750547
  (942, 16)	2.7720977629164723
  (942, 15)	3.0234711411118393
  (942, 14)	3.3659647790513985
  (942, 13)	3.618148366852608
  (942, 12)	3.1102476092085944
  (942, 11)	3.961251547298937
  (942, 10)	3.5458333628752663
  (942, 9)	3.514811835437109
  (942, 8)	3.5597851184523637
  (942, 7)	3.74783559899779
  (942, 6)	3.529181024341099
  (942, 5)	3.2824716955243294
  (942, 4)	3.0143481735534543
  (942, 3)	3.2604509950924236
  (942, 2)	2.9395275829794545
  (942, 1)	3.0092759685423314
  (942, 0)	3.5774158022705165
this is the 292 epoch
rmse loss on training set is 0.8971783021731502
rmse loss on test set is 0.9150817473870503
for this epoch using 81.0056962966919 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3634391939856685
  (0, 1680)	3.379474446883219
  (0, 1679)	3.3634391939856685
  (0, 1678)	3.3634391939856685
  (0, 1677)	3.3634391939856685
  (0, 1676)	3.3634391939856685
  (0, 1675)	3.3634391939856685
  (0, 1674)	3.3634391939856685
  (0, 1673)	3.3634391939856685
  (0, 1672)	3.3634391939856685
  (0, 1671)	3.290328019441045
  (0, 1670)	3.3634391939856685
  (0, 1669)	3.3634391939856685
  (0, 1668)	3.3634391939856685
  (0, 1667)	3.3634391939856685
  (0, 1666)	3.3634391939856685
  (0, 1665)	3.3634391939856685
  (0, 1664)	3.3634391939856685
  (0, 1663)	3.4306556813680493
  (0, 1662)	3.3634391939856685
  (0, 1661)	3.3634391939856685
  (0, 1660)	3.1324787854626113
  (0, 1659)	3.176496511106958
  (0, 1658)	3.3634391939856685
  (0, 1657)	3.3634391939856685
  :	:
  (942, 24)	2.976643973971371
  (942, 23)	3.185405732393304
  (942, 22)	3.729525509548813
  (942, 21)	3.7787083510004256
  (942, 20)	2.5787613124786053
  (942, 19)	3.3404231669773785
  (942, 18)	3.3134993676590616
  (942, 17)	3.122214178349118
  (942, 16)	2.7720896768485415
  (942, 15)	3.0236131652257674
  (942, 14)	3.3660517908605296
  (942, 13)	3.6183483670418677
  (942, 12)	3.1103636270097104
  (942, 11)	3.9613660974898313
  (942, 10)	3.5459232176418882
  (942, 9)	3.5151229589948985
  (942, 8)	3.559896910529402
  (942, 7)	3.7479637982165355
  (942, 6)	3.5292739022581214
  (942, 5)	3.2832306911184013
  (942, 4)	3.014384366822259
  (942, 3)	3.2605352245177004
  (942, 2)	2.9395536650929914
  (942, 1)	3.0093172574312614
  (942, 0)	3.577502949094852
this is the 293 epoch
rmse loss on training set is 0.8971467187082185
rmse loss on test set is 0.9150701465064035
for this epoch using 80.6643590927124 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.363398064136146
  (0, 1680)	3.3794936972571357
  (0, 1679)	3.363398064136146
  (0, 1678)	3.363398064136146
  (0, 1677)	3.363398064136146
  (0, 1676)	3.363398064136146
  (0, 1675)	3.363398064136146
  (0, 1674)	3.363398064136146
  (0, 1673)	3.363398064136146
  (0, 1672)	3.363398064136146
  (0, 1671)	3.2900583893619553
  (0, 1670)	3.363398064136146
  (0, 1669)	3.363398064136146
  (0, 1668)	3.363398064136146
  (0, 1667)	3.363398064136146
  (0, 1666)	3.363398064136146
  (0, 1665)	3.363398064136146
  (0, 1664)	3.363398064136146
  (0, 1663)	3.430811575364106
  (0, 1662)	3.363398064136146
  (0, 1661)	3.363398064136146
  (0, 1660)	3.1317038181710726
  (0, 1659)	3.1758795286830632
  (0, 1658)	3.363398064136146
  (0, 1657)	3.363398064136146
  :	:
  (942, 24)	2.976722064385819
  (942, 23)	3.185460943221813
  (942, 22)	3.7296875835501235
  (942, 21)	3.7788066294917932
  (942, 20)	2.5787141275143433
  (942, 19)	3.340701393717355
  (942, 18)	3.313974678443719
  (942, 17)	3.1226048846808503
  (942, 16)	2.772082152337439
  (942, 15)	3.023754963751461
  (942, 14)	3.3661383788834436
  (942, 13)	3.618546986856329
  (942, 12)	3.110478990180615
  (942, 11)	3.9614800593764667
  (942, 10)	3.546012637766254
  (942, 9)	3.5154316893177766
  (942, 8)	3.5600081209449
  (942, 7)	3.7480912976779694
  (942, 6)	3.529366321636675
  (942, 5)	3.2839882772326185
  (942, 4)	3.0144205555907284
  (942, 3)	3.260619049416435
  (942, 2)	2.939579889774204
  (942, 1)	3.0093584318107
  (942, 0)	3.5775896840510018
this is the 294 epoch
rmse loss on training set is 0.8971153403466874
rmse loss on test set is 0.9150586735959079
for this epoch using 80.31796717643738 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.363357178678312
  (0, 1680)	3.379513189475447
  (0, 1679)	3.363357178678312
  (0, 1678)	3.363357178678312
  (0, 1677)	3.363357178678312
  (0, 1676)	3.363357178678312
  (0, 1675)	3.363357178678312
  (0, 1674)	3.363357178678312
  (0, 1673)	3.363357178678312
  (0, 1672)	3.363357178678312
  (0, 1671)	3.2897890814937925
  (0, 1670)	3.363357178678312
  (0, 1669)	3.363357178678312
  (0, 1668)	3.363357178678312
  (0, 1667)	3.363357178678312
  (0, 1666)	3.363357178678312
  (0, 1665)	3.363357178678312
  (0, 1664)	3.363357178678312
  (0, 1663)	3.430967599227608
  (0, 1662)	3.363357178678312
  (0, 1661)	3.363357178678312
  (0, 1660)	3.130929421487983
  (0, 1659)	3.175263139208291
  (0, 1658)	3.363357178678312
  (0, 1657)	3.363357178678312
  :	:
  (942, 24)	2.9767997733897817
  (942, 23)	3.1855159505388486
  (942, 22)	3.7298486780011904
  (942, 21)	3.778904419069468
  (942, 20)	2.5786680938901805
  (942, 19)	3.340977758262558
  (942, 18)	3.3144476376041347
  (942, 17)	3.122995263437162
  (942, 16)	2.772075178916482
  (942, 15)	3.023896534649813
  (942, 14)	3.3662245456408186
  (942, 13)	3.6187442403662398
  (942, 12)	3.1105937032903004
  (942, 11)	3.9615934370436046
  (942, 10)	3.546101625957259
  (942, 9)	3.515738048985286
  (942, 8)	3.5601187538235806
  (942, 7)	3.748218102618339
  (942, 6)	3.5294582853875527
  (942, 5)	3.284744455579404
  (942, 4)	3.0144567378755553
  (942, 3)	3.260702472222782
  (942, 2)	2.9396062528572373
  (942, 1)	3.0093994912813837
  (942, 0)	3.5776760095794065
this is the 295 epoch
rmse loss on training set is 0.8970841651395248
rmse loss on test set is 0.9150473272863433
for this epoch using 80.83351230621338 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3633165361103328
  (0, 1680)	3.3795329219887087
  (0, 1679)	3.3633165361103328
  (0, 1678)	3.3633165361103328
  (0, 1677)	3.3633165361103328
  (0, 1676)	3.3633165361103328
  (0, 1675)	3.3633165361103328
  (0, 1674)	3.3633165361103328
  (0, 1673)	3.3633165361103328
  (0, 1672)	3.3633165361103328
  (0, 1671)	3.289520094217702
  (0, 1670)	3.3633165361103328
  (0, 1669)	3.3633165361103328
  (0, 1668)	3.3633165361103328
  (0, 1667)	3.3633165361103328
  (0, 1666)	3.3633165361103328
  (0, 1665)	3.3633165361103328
  (0, 1664)	3.3633165361103328
  (0, 1663)	3.431123751797787
  (0, 1662)	3.3633165361103328
  (0, 1661)	3.3633165361103328
  (0, 1660)	3.1301555932734026
  (0, 1659)	3.1746473403478244
  (0, 1658)	3.3633165361103328
  (0, 1657)	3.3633165361103328
  :	:
  (942, 24)	2.9768771032629555
  (942, 23)	3.1855707548493384
  (942, 22)	3.7300088014707242
  (942, 21)	3.7790017228958517
  (942, 20)	2.578623192431253
  (942, 19)	3.341252275430113
  (942, 18)	3.314918256328681
  (942, 17)	3.1233853139940764
  (942, 16)	2.772068746291969
  (942, 15)	3.0240378759199764
  (942, 14)	3.3663102936379845
  (942, 13)	3.6189401414497397
  (942, 12)	3.1107077708776303
  (942, 11)	3.9617062345391765
  (942, 10)	3.5461901849042947
  (942, 9)	3.5160420603402174
  (942, 8)	3.560228813251442
  (942, 7)	3.748344218222764
  (942, 6)	3.529549796400544
  (942, 5)	3.2854992278780584
  (942, 4)	3.0144929117314585
  (942, 3)	3.260785495355066
  (942, 2)	2.9396327502478004
  (942, 1)	3.0094404354660327
  (942, 0)	3.5777619281045725
this is the 296 epoch
rmse loss on training set is 0.8970531911616896
rmse loss on test set is 0.9150361062257534
for this epoch using 83.41441249847412 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.363276134938053
  (0, 1680)	3.3795528932552727
  (0, 1679)	3.363276134938053
  (0, 1678)	3.363276134938053
  (0, 1677)	3.363276134938053
  (0, 1676)	3.363276134938053
  (0, 1675)	3.363276134938053
  (0, 1674)	3.363276134938053
  (0, 1673)	3.363276134938053
  (0, 1672)	3.363276134938053
  (0, 1671)	3.2892514259231187
  (0, 1670)	3.363276134938053
  (0, 1669)	3.363276134938053
  (0, 1668)	3.363276134938053
  (0, 1667)	3.363276134938053
  (0, 1666)	3.363276134938053
  (0, 1665)	3.363276134938053
  (0, 1664)	3.363276134938053
  (0, 1663)	3.431280031918555
  (0, 1662)	3.363276134938053
  (0, 1661)	3.363276134938053
  (0, 1660)	3.1293823313999827
  (0, 1659)	3.174032129780986
  (0, 1658)	3.363276134938053
  (0, 1657)	3.363276134938053
  :	:
  (942, 24)	2.9769540562714463
  (942, 23)	3.1856253566656956
  (942, 22)	3.7301679624209205
  (942, 21)	3.7790985441088263
  (942, 20)	2.578579404262247
  (942, 19)	3.3415249599113297
  (942, 18)	3.3153865457684772
  (942, 17)	3.1237750357366183
  (942, 16)	2.7720628443404194
  (942, 15)	3.0241789855988337
  (942, 14)	3.366395625364959
  (942, 13)	3.619134703795957
  (942, 12)	3.110821197451254
  (942, 11)	3.961818455874737
  (942, 10)	3.5462783172773134
  (942, 9)	3.516343745491129
  (942, 8)	3.560338303276239
  (942, 7)	3.7484696496258914
  (942, 6)	3.5296408575445857
  (942, 5)	3.2862525958545707
  (942, 4)	3.0145290752505645
  (942, 3)	3.2608681212159043
  (942, 2)	2.9396593779220583
  (942, 1)	3.0094812640087802
  (942, 0)	3.5778474420351754
this is the 297 epoch
rmse loss on training set is 0.8970224165118192
rmse loss on test set is 0.9150250090792111
for this epoch using 82.19935703277588 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3632359736749824
  (0, 1680)	3.3795731017413084
  (0, 1679)	3.3632359736749824
  (0, 1678)	3.3632359736749824
  (0, 1677)	3.3632359736749824
  (0, 1676)	3.3632359736749824
  (0, 1675)	3.3632359736749824
  (0, 1674)	3.3632359736749824
  (0, 1673)	3.3632359736749824
  (0, 1672)	3.3632359736749824
  (0, 1671)	3.2889830750077054
  (0, 1670)	3.3632359736749824
  (0, 1669)	3.3632359736749824
  (0, 1668)	3.3632359736749824
  (0, 1667)	3.3632359736749824
  (0, 1666)	3.3632359736749824
  (0, 1665)	3.3632359736749824
  (0, 1664)	3.3632359736749824
  (0, 1663)	3.431436438438589
  (0, 1662)	3.3632359736749824
  (0, 1661)	3.3632359736749824
  (0, 1660)	3.12860963375292
  (0, 1659)	3.173417505201171
  (0, 1658)	3.3632359736749824
  (0, 1657)	3.3632359736749824
  :	:
  (942, 24)	2.9770306346676927
  (942, 23)	3.185679756507549
  (942, 22)	3.730326169209225
  (942, 21)	3.77919488582188
  (942, 20)	2.578536710802784
  (942, 19)	3.341795826272726
  (942, 18)	3.3158525170372113
  (942, 17)	3.124164428058702
  (942, 16)	2.772057463105827
  (942, 15)	3.0243198617605342
  (942, 14)	3.366480543296529
  (942, 13)	3.6193279409081796
  (942, 12)	3.1109339874895907
  (942, 11)	3.961930105025813
  (942, 10)	3.5463660257269765
  (942, 9)	3.516643126315027
  (942, 8)	3.5604472279079578
  (942, 7)	3.748594401912486
  (942, 6)	3.529731471667835
  (942, 5)	3.28700456124153
  (942, 4)	3.014565226561866
  (942, 3)	3.2609503521922063
  (942, 2)	2.9396861319255394
  (942, 1)	3.009521976574601
  (942, 0)	3.5779325537640685
this is the 298 epoch
rmse loss on training set is 0.8969918393117953
rmse loss on test set is 0.915014034528548
for this epoch using 83.64734053611755 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.363196050842327
  (0, 1680)	3.379593545920789
  (0, 1679)	3.363196050842327
  (0, 1678)	3.363196050842327
  (0, 1677)	3.363196050842327
  (0, 1676)	3.363196050842327
  (0, 1675)	3.363196050842327
  (0, 1674)	3.363196050842327
  (0, 1673)	3.363196050842327
  (0, 1672)	3.363196050842327
  (0, 1671)	3.28871503987736
  (0, 1670)	3.363196050842327
  (0, 1669)	3.363196050842327
  (0, 1668)	3.363196050842327
  (0, 1667)	3.363196050842327
  (0, 1666)	3.363196050842327
  (0, 1665)	3.363196050842327
  (0, 1664)	3.363196050842327
  (0, 1663)	3.431592970211293
  (0, 1662)	3.363196050842327
  (0, 1661)	3.363196050842327
  (0, 1660)	3.127837498229911
  (0, 1659)	3.1728034643157588
  (0, 1658)	3.363196050842327
  (0, 1657)	3.363196050842327
  :	:
  (942, 24)	2.9771068406905017
  (942, 23)	3.185733954901515
  (942, 22)	3.730483430090102
  (942, 21)	3.7792907511243516
  (942, 20)	2.57849509376292
  (942, 19)	3.3420648889570796
  (942, 18)	3.316316181211036
  (942, 17)	3.124553490363098
  (942, 16)	2.7720525927969804
  (942, 15)	3.0244605025160136
  (942, 14)	3.3665650498922557
  (942, 13)	3.619519866106867
  (942, 12)	3.1110461454407994
  (942, 11)	3.9620411859323093
  (942, 10)	3.5464533128847835
  (942, 9)	3.516940224459835
  (942, 8)	3.5605555911192948
  (942, 7)	3.748718480118061
  (942, 6)	3.529821641597786
  (942, 5)	3.2877551257780118
  (942, 4)	3.014601363830671
  (942, 3)	3.2610321906552615
  (942, 2)	2.9397130083720797
  (942, 1)	3.0095625728487434
  (942, 0)	3.5780172656683775
this is the 299 epoch
rmse loss on training set is 0.8969614577064793
rmse loss on test set is 0.9150031812721124
for this epoch using 84.30546808242798 seconds
P updating finished 12.5%!
P updating finished 25.0%!
P updating finished 37.5%!
P updating finished 50.0%!
Q updating finished 12.5%!
Q updating finished 25.0%!
Q updating finished 37.5%!
Q updating finished 50.0%!
  (0, 1681)	3.3631563649689715
  (0, 1680)	3.379614224275457
  (0, 1679)	3.3631563649689715
  (0, 1678)	3.3631563649689715
  (0, 1677)	3.3631563649689715
  (0, 1676)	3.3631563649689715
  (0, 1675)	3.3631563649689715
  (0, 1674)	3.3631563649689715
  (0, 1673)	3.3631563649689715
  (0, 1672)	3.3631563649689715
  (0, 1671)	3.288447318946241
  (0, 1670)	3.3631563649689715
  (0, 1669)	3.3631563649689715
  (0, 1668)	3.3631563649689715
  (0, 1667)	3.3631563649689715
  (0, 1666)	3.3631563649689715
  (0, 1665)	3.3631563649689715
  (0, 1664)	3.3631563649689715
  (0, 1663)	3.4317496260948706
  (0, 1662)	3.3631563649689715
  (0, 1661)	3.3631563649689715
  (0, 1660)	3.1270659227410635
  (0, 1659)	3.172190004846025
  (0, 1658)	3.3631563649689715
  (0, 1657)	3.3631563649689715
  :	:
  (942, 24)	2.9771826765650298
  (942, 23)	3.1857879523809074
  (942, 22)	3.7306397532167703
  (942, 21)	3.7793861430815534
  (942, 20)	2.5784545351386883
  (942, 19)	3.342332162284412
  (942, 18)	3.316777549328325
  (942, 17)	3.1249422220612795
  (942, 16)	2.7720482237848088
  (942, 15)	3.024600906012487
  (942, 14)	3.366649147596588
  (942, 13)	3.6197104925326458
  (942, 12)	3.1111576757227435
  (942, 11)	3.962151702498938
  (942, 10)	3.5465401813631554
  (942, 9)	3.517235061347002
  (942, 8)	3.5606633968461026
  (942, 7)	3.748841889229436
  (942, 6)	3.529911370141405
  (942, 5)	3.2885042912094358
  (942, 4)	3.0146374852580258
  (942, 3)	3.261113638960778
  (942, 2)	2.9397400034427332
  (942, 1)	3.0096030525362143
  (942, 0)	3.5781015801095655
this is the 300 epoch
rmse loss on training set is 0.8969312698633113
rmse loss on test set is 0.9149924480245036
for this epoch using 82.68667197227478 seconds
